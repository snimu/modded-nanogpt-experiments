# Results: Multiple latents added

## 8000-add-skip-multiple-2-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [11, 10]
step:125/5550 val_loss:4.260118 train_time:28552ms step_avg:228.42ms x-lambda: 1.0494449138641357 lambdas: [0.06435445696115494, 0.07647373527288437] skip-layers: [11, 10]
step:250/5550 val_loss:3.852296 train_time:58375ms step_avg:233.50ms x-lambda: 0.9841328859329224 lambdas: [0.037230174988508224, 0.0578872412443161] skip-layers: [11, 10]
step:375/5550 val_loss:3.677218 train_time:88677ms step_avg:236.47ms x-lambda: 0.9680787920951843 lambdas: [0.011940455064177513, 0.0015431006904691458] skip-layers: [11, 10]
step:500/5550 val_loss:3.559587 train_time:118289ms step_avg:236.58ms x-lambda: 0.9522125720977783 lambdas: [-0.00907343253493309, -0.05514099448919296] skip-layers: [11, 10]
step:625/5550 val_loss:3.482390 train_time:148111ms step_avg:236.98ms x-lambda: 0.9379776120185852 lambdas: [-0.020941659808158875, -0.09955878555774689] skip-layers: [11, 10]
step:750/5550 val_loss:3.429797 train_time:181373ms step_avg:241.83ms x-lambda: 0.9210300445556641 lambdas: [-0.030674481764435768, -0.1374158263206482] skip-layers: [11, 10]
step:875/5550 val_loss:3.382771 train_time:211554ms step_avg:241.78ms x-lambda: 0.904874324798584 lambdas: [-0.03556593507528305, -0.16690786182880402] skip-layers: [11, 10]
step:1000/5550 val_loss:3.347808 train_time:243082ms step_avg:243.08ms x-lambda: 0.8894418478012085 lambdas: [-0.03786215931177139, -0.1902882307767868] skip-layers: [11, 10]
step:1125/5550 val_loss:3.319516 train_time:273571ms step_avg:243.17ms x-lambda: 0.8722665309906006 lambdas: [-0.03999707102775574, -0.21265634894371033] skip-layers: [11, 10]
step:1250/5550 val_loss:3.292939 train_time:304237ms step_avg:243.39ms x-lambda: 0.860691249370575 lambdas: [-0.037929557263851166, -0.22530406713485718] skip-layers: [11, 10]
step:1375/5550 val_loss:3.270904 train_time:336142ms step_avg:244.47ms x-lambda: 0.8418571352958679 lambdas: [-0.03722791373729706, -0.23903211951255798] skip-layers: [11, 10]
step:1500/5550 val_loss:3.253137 train_time:368089ms step_avg:245.39ms x-lambda: 0.826492965221405 lambdas: [-0.03687911853194237, -0.251534104347229] skip-layers: [11, 10]
step:1625/5550 val_loss:3.238040 train_time:400178ms step_avg:246.26ms x-lambda: 0.8099939227104187 lambdas: [-0.03271370753645897, -0.2602120041847229] skip-layers: [11, 10]
step:1750/5550 val_loss:3.220700 train_time:431024ms step_avg:246.30ms x-lambda: 0.7980974912643433 lambdas: [-0.028769273310899734, -0.2639766335487366] skip-layers: [11, 10]
step:1875/5550 val_loss:3.202976 train_time:461951ms step_avg:246.37ms x-lambda: 0.7875993251800537 lambdas: [-0.02516946569085121, -0.2699486017227173] skip-layers: [11, 10]
step:2000/5550 val_loss:3.187079 train_time:493075ms step_avg:246.54ms x-lambda: 0.7730662226676941 lambdas: [-0.022099100053310394, -0.2745365500450134] skip-layers: [11, 10]
step:2125/5550 val_loss:3.172670 train_time:525424ms step_avg:247.26ms x-lambda: 0.7644621729850769 lambdas: [-0.0197710283100605, -0.2786172926425934] skip-layers: [11, 10]
step:2250/5550 val_loss:3.157483 train_time:556614ms step_avg:247.38ms x-lambda: 0.7571346163749695 lambdas: [-0.01657584309577942, -0.2814725637435913] skip-layers: [11, 10]
step:2375/5550 val_loss:3.146708 train_time:591092ms step_avg:248.88ms x-lambda: 0.7501256465911865 lambdas: [-0.012249812483787537, -0.2818249464035034] skip-layers: [11, 10]
step:2500/5550 val_loss:3.135623 train_time:622285ms step_avg:248.91ms x-lambda: 0.7417415380477905 lambdas: [-0.00967254489660263, -0.2834200859069824] skip-layers: [11, 10]
step:2625/5550 val_loss:3.123552 train_time:653415ms step_avg:248.92ms x-lambda: 0.7357239127159119 lambdas: [-0.007536574732512236, -0.28496861457824707] skip-layers: [11, 10]
step:2750/5550 val_loss:3.112425 train_time:687714ms step_avg:250.08ms x-lambda: 0.7302332520484924 lambdas: [-0.005033496767282486, -0.28640103340148926] skip-layers: [11, 10]
step:2875/5550 val_loss:3.103103 train_time:718876ms step_avg:250.04ms x-lambda: 0.7264649868011475 lambdas: [-0.0017005116678774357, -0.28644949197769165] skip-layers: [11, 10]
step:3000/5550 val_loss:3.091649 train_time:752321ms step_avg:250.77ms x-lambda: 0.7225647568702698 lambdas: [-7.252139039337635e-05, -0.2881435751914978] skip-layers: [11, 10]
step:3125/5550 val_loss:3.080803 train_time:785703ms step_avg:251.42ms x-lambda: 0.7195106744766235 lambdas: [0.0008494702633470297, -0.28874698281288147] skip-layers: [11, 10]
step:3250/5550 val_loss:3.069235 train_time:816842ms step_avg:251.34ms x-lambda: 0.719166100025177 lambdas: [0.003341814037412405, -0.28895482420921326] skip-layers: [11, 10]
step:3375/5550 val_loss:3.061130 train_time:847986ms step_avg:251.26ms x-lambda: 0.7170857787132263 lambdas: [0.005489509552717209, -0.29133671522140503] skip-layers: [11, 10]
step:3500/5550 val_loss:3.051857 train_time:879173ms step_avg:251.19ms x-lambda: 0.7158034443855286 lambdas: [0.0062484173104166985, -0.290528267621994] skip-layers: [11, 10]
step:3625/5550 val_loss:3.042915 train_time:911483ms step_avg:251.44ms x-lambda: 0.7157261967658997 lambdas: [0.008076002821326256, -0.2905011475086212] skip-layers: [11, 10]
step:3750/5550 val_loss:3.033459 train_time:942649ms step_avg:251.37ms x-lambda: 0.717269241809845 lambdas: [0.00900631956756115, -0.28964632749557495] skip-layers: [11, 10]
step:3875/5550 val_loss:3.024678 train_time:976003ms step_avg:251.87ms x-lambda: 0.7210036516189575 lambdas: [0.01102032046765089, -0.29245609045028687] skip-layers: [11, 10]
step:4000/5550 val_loss:3.015457 train_time:1007225ms step_avg:251.81ms x-lambda: 0.7213815450668335 lambdas: [0.011979123577475548, -0.2914511263370514] skip-layers: [11, 10]
step:4125/5550 val_loss:3.006187 train_time:1038451ms step_avg:251.75ms x-lambda: 0.7247418761253357 lambdas: [0.013729836791753769, -0.29269325733184814] skip-layers: [11, 10]
step:4250/5550 val_loss:2.998001 train_time:1069910ms step_avg:251.74ms x-lambda: 0.7279546856880188 lambdas: [0.013745937496423721, -0.2929306924343109] skip-layers: [11, 10]
step:4375/5550 val_loss:2.988824 train_time:1101441ms step_avg:251.76ms x-lambda: 0.7302743792533875 lambdas: [0.013986730016767979, -0.29450827836990356] skip-layers: [11, 10]
step:4500/5550 val_loss:2.980301 train_time:1134166ms step_avg:252.04ms x-lambda: 0.7348468899726868 lambdas: [0.015047854743897915, -0.29518023133277893] skip-layers: [11, 10]
step:4625/5550 val_loss:2.971037 train_time:1165876ms step_avg:252.08ms x-lambda: 0.7420129776000977 lambdas: [0.01542761828750372, -0.2954801321029663] skip-layers: [11, 10]
step:4750/5550 val_loss:2.961789 train_time:1197737ms step_avg:252.16ms x-lambda: 0.7464194297790527 lambdas: [0.016415413469076157, -0.29638808965682983] skip-layers: [11, 10]
step:4875/5550 val_loss:2.953018 train_time:1229742ms step_avg:252.25ms x-lambda: 0.7514529228210449 lambdas: [0.017339283600449562, -0.29814621806144714] skip-layers: [11, 10]
step:5000/5550 val_loss:2.944859 train_time:1262851ms step_avg:252.57ms x-lambda: 0.7578006982803345 lambdas: [0.018056420609354973, -0.2987178862094879] skip-layers: [11, 10]
step:5125/5550 val_loss:2.937287 train_time:1295059ms step_avg:252.69ms x-lambda: 0.7633615136146545 lambdas: [0.018424462527036667, -0.30087271332740784] skip-layers: [11, 10]
step:5250/5550 val_loss:2.930190 train_time:1328556ms step_avg:253.06ms x-lambda: 0.7687625885009766 lambdas: [0.018855487927794456, -0.30079385638237] skip-layers: [11, 10]
step:5375/5550 val_loss:2.923626 train_time:1363295ms step_avg:253.64ms x-lambda: 0.7748658657073975 lambdas: [0.019191799685359, -0.3021552264690399] skip-layers: [11, 10]
step:5500/5550 val_loss:2.918827 train_time:1396018ms step_avg:253.82ms x-lambda: 0.7789164781570435 lambdas: [0.019819999113678932, -0.30264267325401306] skip-layers: [11, 10]
step:5550/5550 val_loss:2.917641 train_time:1410298ms step_avg:254.11ms x-lambda: 0.7796132564544678 lambdas: [0.019991762936115265, -0.3033408522605896] skip-layers: [11, 10]

## 8000-add-skip-multiple-2-method-btw-1

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [11, 10]
step:125/5550 val_loss:4.260901 train_time:28533ms step_avg:228.27ms x-lambda: 1.0574805736541748 lambdas: [0.06668134778738022, 0.07399550825357437] skip-layers: [11, 10]
step:250/5550 val_loss:3.853384 train_time:57242ms step_avg:228.97ms x-lambda: 1.0064411163330078 lambdas: [0.03633961081504822, 0.043152593076229095] skip-layers: [11, 10]
step:375/5550 val_loss:3.676846 train_time:86442ms step_avg:230.51ms x-lambda: 0.9903998374938965 lambdas: [0.011585856787860394, -0.01808764412999153] skip-layers: [11, 10]
step:500/5550 val_loss:3.562594 train_time:116006ms step_avg:232.01ms x-lambda: 0.9751916527748108 lambdas: [-0.0074414415284991264, -0.07766488194465637] skip-layers: [11, 10]
step:625/5550 val_loss:3.483558 train_time:145789ms step_avg:233.26ms x-lambda: 0.9619582295417786 lambdas: [-0.019057374447584152, -0.1272224485874176] skip-layers: [11, 10]
step:750/5550 val_loss:3.430508 train_time:175898ms step_avg:234.53ms x-lambda: 0.9488825798034668 lambdas: [-0.023885447531938553, -0.16744525730609894] skip-layers: [11, 10]
step:875/5550 val_loss:3.385681 train_time:206135ms step_avg:235.58ms x-lambda: 0.9316364526748657 lambdas: [-0.02754884772002697, -0.20087465643882751] skip-layers: [11, 10]
step:1000/5550 val_loss:3.350697 train_time:236599ms step_avg:236.60ms x-lambda: 0.9159334897994995 lambdas: [-0.031389664858579636, -0.22984814643859863] skip-layers: [11, 10]
step:1125/5550 val_loss:3.319973 train_time:267757ms step_avg:238.01ms x-lambda: 0.8992794156074524 lambdas: [-0.03136175125837326, -0.25231409072875977] skip-layers: [11, 10]
step:1250/5550 val_loss:3.295528 train_time:299161ms step_avg:239.33ms x-lambda: 0.8865606784820557 lambdas: [-0.027571002021431923, -0.266535222530365] skip-layers: [11, 10]
step:1375/5550 val_loss:3.273605 train_time:329911ms step_avg:239.94ms x-lambda: 0.868080198764801 lambdas: [-0.02535093203186989, -0.2809578478336334] skip-layers: [11, 10]
step:1500/5550 val_loss:3.253445 train_time:360665ms step_avg:240.44ms x-lambda: 0.8547984957695007 lambdas: [-0.020976554602384567, -0.29155248403549194] skip-layers: [11, 10]
step:1625/5550 val_loss:3.238336 train_time:392615ms step_avg:241.61ms x-lambda: 0.8362042903900146 lambdas: [-0.01718778721988201, -0.3015180230140686] skip-layers: [11, 10]
step:1750/5550 val_loss:3.222440 train_time:424547ms step_avg:242.60ms x-lambda: 0.8204765319824219 lambdas: [-0.014206230640411377, -0.30884578824043274] skip-layers: [11, 10]
step:1875/5550 val_loss:3.203633 train_time:455481ms step_avg:242.92ms x-lambda: 0.8068656325340271 lambdas: [-0.009291933849453926, -0.31364312767982483] skip-layers: [11, 10]
step:2000/5550 val_loss:3.187464 train_time:487652ms step_avg:243.83ms x-lambda: 0.7935529351234436 lambdas: [-0.0048820627853274345, -0.31596627831459045] skip-layers: [11, 10]
step:2125/5550 val_loss:3.173324 train_time:518784ms step_avg:244.13ms x-lambda: 0.7838772535324097 lambdas: [-0.0019660654943436384, -0.32124054431915283] skip-layers: [11, 10]
step:2250/5550 val_loss:3.159331 train_time:551044ms step_avg:244.91ms x-lambda: 0.7758169174194336 lambdas: [0.0027375693898648024, -0.321201354265213] skip-layers: [11, 10]
step:2375/5550 val_loss:3.147183 train_time:582222ms step_avg:245.15ms x-lambda: 0.7662393450737 lambdas: [0.005200206767767668, -0.3229479491710663] skip-layers: [11, 10]
step:2500/5550 val_loss:3.136450 train_time:614462ms step_avg:245.78ms x-lambda: 0.758723795413971 lambdas: [0.008917825296521187, -0.3237142860889435] skip-layers: [11, 10]
step:2625/5550 val_loss:3.124733 train_time:648819ms step_avg:247.17ms x-lambda: 0.7524063587188721 lambdas: [0.011395959183573723, -0.3244720995426178] skip-layers: [11, 10]
step:2750/5550 val_loss:3.113028 train_time:679955ms step_avg:247.26ms x-lambda: 0.745544970035553 lambdas: [0.012304818257689476, -0.3246852159500122] skip-layers: [11, 10]
step:2875/5550 val_loss:3.103998 train_time:713078ms step_avg:248.03ms x-lambda: 0.7417479157447815 lambdas: [0.015794947743415833, -0.32525527477264404] skip-layers: [11, 10]
step:3000/5550 val_loss:3.092236 train_time:745399ms step_avg:248.47ms x-lambda: 0.7380446791648865 lambdas: [0.018463177606463432, -0.3251001834869385] skip-layers: [11, 10]
step:3125/5550 val_loss:3.081511 train_time:777657ms step_avg:248.85ms x-lambda: 0.7337607741355896 lambdas: [0.018944161012768745, -0.326505184173584] skip-layers: [11, 10]
step:3250/5550 val_loss:3.070253 train_time:809826ms step_avg:249.18ms x-lambda: 0.733624279499054 lambdas: [0.02222406305372715, -0.3261064887046814] skip-layers: [11, 10]
step:3375/5550 val_loss:3.061992 train_time:841933ms step_avg:249.46ms x-lambda: 0.7304957509040833 lambdas: [0.022945741191506386, -0.32746589183807373] skip-layers: [11, 10]
step:3500/5550 val_loss:3.052600 train_time:873121ms step_avg:249.46ms x-lambda: 0.7289108037948608 lambdas: [0.024449961259961128, -0.3248463571071625] skip-layers: [11, 10]
step:3625/5550 val_loss:3.044408 train_time:908404ms step_avg:250.59ms x-lambda: 0.7286638617515564 lambdas: [0.027106156572699547, -0.32489874958992004] skip-layers: [11, 10]
step:3750/5550 val_loss:3.034481 train_time:940695ms step_avg:250.85ms x-lambda: 0.7290119528770447 lambdas: [0.028510883450508118, -0.3233857750892639] skip-layers: [11, 10]
step:3875/5550 val_loss:3.025978 train_time:971942ms step_avg:250.82ms x-lambda: 0.7355549931526184 lambdas: [0.030125580728054047, -0.3271944224834442] skip-layers: [11, 10]
step:4000/5550 val_loss:3.016117 train_time:1006217ms step_avg:251.55ms x-lambda: 0.7351629137992859 lambdas: [0.03141627088189125, -0.325266569852829] skip-layers: [11, 10]
step:4125/5550 val_loss:3.006439 train_time:1037486ms step_avg:251.51ms x-lambda: 0.7379802465438843 lambdas: [0.03208867460489273, -0.3258052170276642] skip-layers: [11, 10]
step:4250/5550 val_loss:2.998228 train_time:1070039ms step_avg:251.77ms x-lambda: 0.7406708598136902 lambdas: [0.0329551063477993, -0.32728272676467896] skip-layers: [11, 10]
step:4375/5550 val_loss:2.989170 train_time:1102579ms step_avg:252.02ms x-lambda: 0.7418773174285889 lambdas: [0.03348788619041443, -0.327522337436676] skip-layers: [11, 10]
step:4500/5550 val_loss:2.980971 train_time:1134127ms step_avg:252.03ms x-lambda: 0.747016966342926 lambdas: [0.03432104364037514, -0.32743018865585327] skip-layers: [11, 10]
step:4625/5550 val_loss:2.971476 train_time:1166906ms step_avg:252.30ms x-lambda: 0.7531640529632568 lambdas: [0.03467859700322151, -0.32936355471611023] skip-layers: [11, 10]
step:4750/5550 val_loss:2.962186 train_time:1199741ms step_avg:252.58ms x-lambda: 0.757854163646698 lambdas: [0.03586225211620331, -0.33031418919563293] skip-layers: [11, 10]
step:4875/5550 val_loss:2.953396 train_time:1232805ms step_avg:252.88ms x-lambda: 0.7627427577972412 lambdas: [0.037510037422180176, -0.33185964822769165] skip-layers: [11, 10]
step:5000/5550 val_loss:2.945096 train_time:1264864ms step_avg:252.97ms x-lambda: 0.7693153619766235 lambdas: [0.038287125527858734, -0.3334605395793915] skip-layers: [11, 10]
step:5125/5550 val_loss:2.937568 train_time:1298220ms step_avg:253.31ms x-lambda: 0.7747709155082703 lambdas: [0.03901800885796547, -0.3349185883998871] skip-layers: [11, 10]
step:5250/5550 val_loss:2.930445 train_time:1330574ms step_avg:253.44ms x-lambda: 0.7800903916358948 lambdas: [0.039249129593372345, -0.3351052701473236] skip-layers: [11, 10]
step:5375/5550 val_loss:2.923943 train_time:1364171ms step_avg:253.80ms x-lambda: 0.7864841222763062 lambdas: [0.03996630758047104, -0.33666306734085083] skip-layers: [11, 10]
step:5500/5550 val_loss:2.919153 train_time:1397968ms step_avg:254.18ms x-lambda: 0.7902753353118896 lambdas: [0.0402495414018631, -0.33697643876075745] skip-layers: [11, 10]
step:5550/5550 val_loss:2.917946 train_time:1411169ms step_avg:254.26ms x-lambda: 0.7911221385002136 lambdas: [0.04036382958292961, -0.33735254406929016] skip-layers: [11, 10]

## 8000-add-skip-multiple-2-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [14, 13]
step:125/5550 val_loss:4.260280 train_time:28531ms step_avg:228.25ms x-lambda: 1.064366102218628 lambdas: [0.057757411152124405, 0.06480863690376282] skip-layers: [14, 13]
step:250/5550 val_loss:3.853284 train_time:57283ms step_avg:229.13ms x-lambda: 0.9986088871955872 lambdas: [0.01446889340877533, 0.03701376914978027] skip-layers: [14, 13]
step:375/5550 val_loss:3.677904 train_time:86462ms step_avg:230.57ms x-lambda: 0.9550095796585083 lambdas: [-0.0059531801380217075, 0.0156747717410326] skip-layers: [14, 13]
step:500/5550 val_loss:3.562188 train_time:117090ms step_avg:234.18ms x-lambda: 0.9315032362937927 lambdas: [-0.023837527260184288, -0.008061228320002556] skip-layers: [14, 13]
step:625/5550 val_loss:3.483756 train_time:147909ms step_avg:236.65ms x-lambda: 0.90778648853302 lambdas: [-0.04175791144371033, -0.03336654603481293] skip-layers: [14, 13]
step:750/5550 val_loss:3.429993 train_time:177995ms step_avg:237.33ms x-lambda: 0.8956899642944336 lambdas: [-0.05168610066175461, -0.053253330290317535] skip-layers: [14, 13]
step:875/5550 val_loss:3.384447 train_time:209414ms step_avg:239.33ms x-lambda: 0.8792915940284729 lambdas: [-0.05870913341641426, -0.07120776176452637] skip-layers: [14, 13]
step:1000/5550 val_loss:3.348421 train_time:240857ms step_avg:240.86ms x-lambda: 0.8659036159515381 lambdas: [-0.06529621034860611, -0.09013484418392181] skip-layers: [14, 13]
step:1125/5550 val_loss:3.319889 train_time:272492ms step_avg:242.22ms x-lambda: 0.8562027812004089 lambdas: [-0.06873922795057297, -0.10490383952856064] skip-layers: [14, 13]
step:1250/5550 val_loss:3.294917 train_time:304116ms step_avg:243.29ms x-lambda: 0.8466006517410278 lambdas: [-0.07198569178581238, -0.1200709342956543] skip-layers: [14, 13]
step:1375/5550 val_loss:3.275172 train_time:336035ms step_avg:244.39ms x-lambda: 0.8375115394592285 lambdas: [-0.07429042458534241, -0.13439543545246124] skip-layers: [14, 13]
step:1500/5550 val_loss:3.256184 train_time:366829ms step_avg:244.55ms x-lambda: 0.8325230479240417 lambdas: [-0.07199255377054214, -0.14401192963123322] skip-layers: [14, 13]
step:1625/5550 val_loss:3.240898 train_time:397716ms step_avg:244.75ms x-lambda: 0.8236042857170105 lambdas: [-0.07235449552536011, -0.15613391995429993] skip-layers: [14, 13]
step:1750/5550 val_loss:3.224366 train_time:428584ms step_avg:244.91ms x-lambda: 0.8146304488182068 lambdas: [-0.07418496161699295, -0.16885541379451752] skip-layers: [14, 13]
step:1875/5550 val_loss:3.206145 train_time:460656ms step_avg:245.68ms x-lambda: 0.8134023547172546 lambdas: [-0.07116653025150299, -0.17604997754096985] skip-layers: [14, 13]
step:2000/5550 val_loss:3.190193 train_time:491827ms step_avg:245.91ms x-lambda: 0.8088297247886658 lambdas: [-0.07149123400449753, -0.1873389184474945] skip-layers: [14, 13]
step:2125/5550 val_loss:3.175781 train_time:523000ms step_avg:246.12ms x-lambda: 0.806866466999054 lambdas: [-0.07008667290210724, -0.1965264528989792] skip-layers: [14, 13]
step:2250/5550 val_loss:3.161342 train_time:555306ms step_avg:246.80ms x-lambda: 0.8067318797111511 lambdas: [-0.06913518160581589, -0.20656590163707733] skip-layers: [14, 13]
step:2375/5550 val_loss:3.149740 train_time:591977ms step_avg:249.25ms x-lambda: 0.8074769377708435 lambdas: [-0.06680286675691605, -0.21573209762573242] skip-layers: [14, 13]
step:2500/5550 val_loss:3.137908 train_time:626313ms step_avg:250.53ms x-lambda: 0.809230625629425 lambdas: [-0.06526470929384232, -0.22320981323719025] skip-layers: [14, 13]
step:2625/5550 val_loss:3.127109 train_time:658469ms step_avg:250.85ms x-lambda: 0.8106725215911865 lambdas: [-0.0632878765463829, -0.23183123767375946] skip-layers: [14, 13]
step:2750/5550 val_loss:3.115447 train_time:691720ms step_avg:251.53ms x-lambda: 0.812151312828064 lambdas: [-0.06262142211198807, -0.24130256474018097] skip-layers: [14, 13]
step:2875/5550 val_loss:3.105675 train_time:724998ms step_avg:252.17ms x-lambda: 0.8144330382347107 lambdas: [-0.06085054576396942, -0.24870818853378296] skip-layers: [14, 13]
step:3000/5550 val_loss:3.094880 train_time:757207ms step_avg:252.40ms x-lambda: 0.8185297250747681 lambdas: [-0.05839484557509422, -0.25608816742897034] skip-layers: [14, 13]
step:3125/5550 val_loss:3.083783 train_time:788395ms step_avg:252.29ms x-lambda: 0.8207640051841736 lambdas: [-0.05807929113507271, -0.2637718617916107] skip-layers: [14, 13]
step:3250/5550 val_loss:3.072480 train_time:820697ms step_avg:252.52ms x-lambda: 0.826232373714447 lambdas: [-0.05519057810306549, -0.2708306312561035] skip-layers: [14, 13]
step:3375/5550 val_loss:3.063691 train_time:851785ms step_avg:252.38ms x-lambda: 0.8292471170425415 lambdas: [-0.05432865768671036, -0.2777560353279114] skip-layers: [14, 13]
step:3500/5550 val_loss:3.055121 train_time:884041ms step_avg:252.58ms x-lambda: 0.8323469758033752 lambdas: [-0.05224220082163811, -0.2846779525279999] skip-layers: [14, 13]
step:3625/5550 val_loss:3.046435 train_time:916327ms step_avg:252.78ms x-lambda: 0.8381826281547546 lambdas: [-0.04978001490235329, -0.2905491292476654] skip-layers: [14, 13]
step:3750/5550 val_loss:3.036337 train_time:947483ms step_avg:252.66ms x-lambda: 0.8424800038337708 lambdas: [-0.04781150445342064, -0.29644256830215454] skip-layers: [14, 13]
step:3875/5550 val_loss:3.028005 train_time:979841ms step_avg:252.86ms x-lambda: 0.8506889939308167 lambdas: [-0.04416031017899513, -0.30134209990501404] skip-layers: [14, 13]
step:4000/5550 val_loss:3.018487 train_time:1012049ms step_avg:253.01ms x-lambda: 0.8564274907112122 lambdas: [-0.043531373143196106, -0.3076418340206146] skip-layers: [14, 13]
step:4125/5550 val_loss:3.009227 train_time:1046551ms step_avg:253.71ms x-lambda: 0.8637865781784058 lambdas: [-0.04157496616244316, -0.31359800696372986] skip-layers: [14, 13]
step:4250/5550 val_loss:3.001017 train_time:1078012ms step_avg:253.65ms x-lambda: 0.8680006265640259 lambdas: [-0.04055385664105415, -0.3186052739620209] skip-layers: [14, 13]
step:4375/5550 val_loss:2.991637 train_time:1110533ms step_avg:253.84ms x-lambda: 0.8741406798362732 lambdas: [-0.039867743849754333, -0.3233039975166321] skip-layers: [14, 13]
step:4500/5550 val_loss:2.983426 train_time:1146380ms step_avg:254.75ms x-lambda: 0.8809259533882141 lambdas: [-0.037923119962215424, -0.3278160095214844] skip-layers: [14, 13]
step:4625/5550 val_loss:2.974274 train_time:1182456ms step_avg:255.67ms x-lambda: 0.8876212239265442 lambdas: [-0.035326674580574036, -0.3313677906990051] skip-layers: [14, 13]
step:4750/5550 val_loss:2.964815 train_time:1214282ms step_avg:255.64ms x-lambda: 0.8948732018470764 lambdas: [-0.03416607528924942, -0.33425241708755493] skip-layers: [14, 13]
step:4875/5550 val_loss:2.955830 train_time:1247376ms step_avg:255.87ms x-lambda: 0.9012800455093384 lambdas: [-0.03295081853866577, -0.3376224637031555] skip-layers: [14, 13]
step:5000/5550 val_loss:2.947818 train_time:1279429ms step_avg:255.89ms x-lambda: 0.9092828631401062 lambdas: [-0.031223686411976814, -0.34114745259284973] skip-layers: [14, 13]
step:5125/5550 val_loss:2.940137 train_time:1311637ms step_avg:255.93ms x-lambda: 0.9160402417182922 lambdas: [-0.02997155487537384, -0.343195378780365] skip-layers: [14, 13]
step:5250/5550 val_loss:2.932924 train_time:1346243ms step_avg:256.43ms x-lambda: 0.921593189239502 lambdas: [-0.02962120994925499, -0.34623879194259644] skip-layers: [14, 13]
step:5375/5550 val_loss:2.926523 train_time:1382027ms step_avg:257.12ms x-lambda: 0.9278513789176941 lambdas: [-0.02858327329158783, -0.34785932302474976] skip-layers: [14, 13]
step:5500/5550 val_loss:2.921696 train_time:1414797ms step_avg:257.24ms x-lambda: 0.9315034747123718 lambdas: [-0.027399256825447083, -0.34822186827659607] skip-layers: [14, 13]
step:5550/5550 val_loss:2.920460 train_time:1427992ms step_avg:257.30ms x-lambda: 0.9322582483291626 lambdas: [-0.02742256410419941, -0.34874317049980164] skip-layers: [14, 13]

## 8000-add-skip-multiple-2-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [0, 1]
step:125/5550 val_loss:4.255004 train_time:28570ms step_avg:228.56ms x-lambda: 1.1016608476638794 lambdas: [0.09298108518123627, 0.03681633993983269] skip-layers: [0, 1]
step:250/5550 val_loss:3.843181 train_time:58330ms step_avg:233.32ms x-lambda: 1.0507768392562866 lambdas: [0.05347559601068497, -0.0449603796005249] skip-layers: [0, 1]
step:375/5550 val_loss:3.674299 train_time:87524ms step_avg:233.40ms x-lambda: 0.998785674571991 lambdas: [0.04132753238081932, -0.0715327039361] skip-layers: [0, 1]
step:500/5550 val_loss:3.557582 train_time:117115ms step_avg:234.23ms x-lambda: 0.9424699544906616 lambdas: [0.033160507678985596, -0.0860212966799736] skip-layers: [0, 1]
step:625/5550 val_loss:3.479420 train_time:146901ms step_avg:235.04ms x-lambda: 0.8915643095970154 lambdas: [0.03260278329253197, -0.08991020917892456] skip-layers: [0, 1]
step:750/5550 val_loss:3.429198 train_time:176983ms step_avg:235.98ms x-lambda: 0.8493243455886841 lambdas: [0.030066976323723793, -0.09413255006074905] skip-layers: [0, 1]
step:875/5550 val_loss:3.382458 train_time:207186ms step_avg:236.78ms x-lambda: 0.8101376891136169 lambdas: [0.029011493548750877, -0.09248650819063187] skip-layers: [0, 1]
step:1000/5550 val_loss:3.347166 train_time:237646ms step_avg:237.65ms x-lambda: 0.7771593928337097 lambdas: [0.02929743379354477, -0.08945368975400925] skip-layers: [0, 1]
step:1125/5550 val_loss:3.319221 train_time:268152ms step_avg:238.36ms x-lambda: 0.7479606866836548 lambdas: [0.026851844042539597, -0.08764934539794922] skip-layers: [0, 1]
step:1250/5550 val_loss:3.294492 train_time:300966ms step_avg:240.77ms x-lambda: 0.7252474427223206 lambdas: [0.028547927737236023, -0.08285249769687653] skip-layers: [0, 1]
step:1375/5550 val_loss:3.273416 train_time:331806ms step_avg:241.31ms x-lambda: 0.6995199918746948 lambdas: [0.02428208664059639, -0.081593357026577] skip-layers: [0, 1]
step:1500/5550 val_loss:3.255881 train_time:362632ms step_avg:241.75ms x-lambda: 0.6822142004966736 lambdas: [0.0250509325414896, -0.07721123844385147] skip-layers: [0, 1]
step:1625/5550 val_loss:3.237963 train_time:393548ms step_avg:242.18ms x-lambda: 0.6610972881317139 lambdas: [0.023734958842396736, -0.07505122572183609] skip-layers: [0, 1]
step:1750/5550 val_loss:3.223220 train_time:426653ms step_avg:243.80ms x-lambda: 0.6458138823509216 lambdas: [0.024372754618525505, -0.07029645889997482] skip-layers: [0, 1]
step:1875/5550 val_loss:3.203943 train_time:457626ms step_avg:244.07ms x-lambda: 0.6341240406036377 lambdas: [0.02275894023478031, -0.06844556331634521] skip-layers: [0, 1]
step:2000/5550 val_loss:3.189396 train_time:488835ms step_avg:244.42ms x-lambda: 0.6226385235786438 lambdas: [0.02320783957839012, -0.06514455378055573] skip-layers: [0, 1]
step:2125/5550 val_loss:3.174632 train_time:522079ms step_avg:245.68ms x-lambda: 0.6143935322761536 lambdas: [0.022321784868836403, -0.06337826699018478] skip-layers: [0, 1]
step:2250/5550 val_loss:3.160724 train_time:556512ms step_avg:247.34ms x-lambda: 0.6073980927467346 lambdas: [0.02163529396057129, -0.06113569810986519] skip-layers: [0, 1]
step:2375/5550 val_loss:3.149476 train_time:591784ms step_avg:249.17ms x-lambda: 0.6000683903694153 lambdas: [0.02174951508641243, -0.060060299932956696] skip-layers: [0, 1]
step:2500/5550 val_loss:3.137633 train_time:622949ms step_avg:249.18ms x-lambda: 0.5973846912384033 lambdas: [0.021526651456952095, -0.05745372548699379] skip-layers: [0, 1]
step:2625/5550 val_loss:3.125587 train_time:656328ms step_avg:250.03ms x-lambda: 0.5926951169967651 lambdas: [0.019451677799224854, -0.0581161305308342] skip-layers: [0, 1]
step:2750/5550 val_loss:3.115042 train_time:688467ms step_avg:250.35ms x-lambda: 0.5906435251235962 lambdas: [0.01929854229092598, -0.056102849543094635] skip-layers: [0, 1]
step:2875/5550 val_loss:3.105255 train_time:719669ms step_avg:250.32ms x-lambda: 0.5881187915802002 lambdas: [0.01997499354183674, -0.05371873453259468] skip-layers: [0, 1]
step:3000/5550 val_loss:3.094403 train_time:755121ms step_avg:251.71ms x-lambda: 0.5868383049964905 lambdas: [0.018398454412817955, -0.053060512989759445] skip-layers: [0, 1]
step:3125/5550 val_loss:3.083029 train_time:787403ms step_avg:251.97ms x-lambda: 0.58609938621521 lambdas: [0.019775966182351112, -0.05249805375933647] skip-layers: [0, 1]
step:3250/5550 val_loss:3.072273 train_time:820732ms step_avg:252.53ms x-lambda: 0.5882421731948853 lambdas: [0.01930359937250614, -0.051976483315229416] skip-layers: [0, 1]
step:3375/5550 val_loss:3.063335 train_time:851887ms step_avg:252.41ms x-lambda: 0.5885835289955139 lambdas: [0.018518483266234398, -0.051518891006708145] skip-layers: [0, 1]
step:3500/5550 val_loss:3.054448 train_time:883109ms step_avg:252.32ms x-lambda: 0.5900207757949829 lambdas: [0.018004870042204857, -0.05172266811132431] skip-layers: [0, 1]
step:3625/5550 val_loss:3.045863 train_time:914309ms step_avg:252.22ms x-lambda: 0.594231903553009 lambdas: [0.017166826874017715, -0.050741761922836304] skip-layers: [0, 1]
step:3750/5550 val_loss:3.036172 train_time:946544ms step_avg:252.41ms x-lambda: 0.595531165599823 lambdas: [0.01897778920829296, -0.04888799786567688] skip-layers: [0, 1]
step:3875/5550 val_loss:3.027527 train_time:977802ms step_avg:252.34ms x-lambda: 0.6030335426330566 lambdas: [0.018527735024690628, -0.04800289124250412] skip-layers: [0, 1]
step:4000/5550 val_loss:3.018047 train_time:1011230ms step_avg:252.81ms x-lambda: 0.6048490405082703 lambdas: [0.017687510699033737, -0.04792371392250061] skip-layers: [0, 1]
step:4125/5550 val_loss:3.008865 train_time:1043474ms step_avg:252.96ms x-lambda: 0.6109626293182373 lambdas: [0.019019734114408493, -0.04729890823364258] skip-layers: [0, 1]
step:4250/5550 val_loss:3.000579 train_time:1074945ms step_avg:252.93ms x-lambda: 0.6141009330749512 lambdas: [0.017895223572850227, -0.04677757993340492] skip-layers: [0, 1]
step:4375/5550 val_loss:2.991262 train_time:1110663ms step_avg:253.87ms x-lambda: 0.6185916066169739 lambdas: [0.018010679632425308, -0.04763871803879738] skip-layers: [0, 1]
step:4500/5550 val_loss:2.982696 train_time:1142220ms step_avg:253.83ms x-lambda: 0.624687910079956 lambdas: [0.018118593841791153, -0.04654676094651222] skip-layers: [0, 1]
step:4625/5550 val_loss:2.973326 train_time:1173925ms step_avg:253.82ms x-lambda: 0.6348931789398193 lambdas: [0.016234304755926132, -0.04691702127456665] skip-layers: [0, 1]
step:4750/5550 val_loss:2.964102 train_time:1205774ms step_avg:253.85ms x-lambda: 0.640739917755127 lambdas: [0.01824270188808441, -0.04556220769882202] skip-layers: [0, 1]
step:4875/5550 val_loss:2.955076 train_time:1237770ms step_avg:253.90ms x-lambda: 0.6473108530044556 lambdas: [0.01770072989165783, -0.04621736705303192] skip-layers: [0, 1]
step:5000/5550 val_loss:2.947106 train_time:1269815ms step_avg:253.96ms x-lambda: 0.6561946272850037 lambdas: [0.01750355213880539, -0.04600933566689491] skip-layers: [0, 1]
step:5125/5550 val_loss:2.939454 train_time:1303205ms step_avg:254.28ms x-lambda: 0.6630135178565979 lambdas: [0.016645174473524094, -0.04500916600227356] skip-layers: [0, 1]
step:5250/5550 val_loss:2.932181 train_time:1335636ms step_avg:254.41ms x-lambda: 0.6716610193252563 lambdas: [0.01651698537170887, -0.044995833188295364] skip-layers: [0, 1]
step:5375/5550 val_loss:2.925706 train_time:1372518ms step_avg:255.35ms x-lambda: 0.6803640127182007 lambdas: [0.017723942175507545, -0.045587632805109024] skip-layers: [0, 1]
step:5500/5550 val_loss:2.920925 train_time:1407475ms step_avg:255.90ms x-lambda: 0.6870072484016418 lambdas: [0.016926441341638565, -0.045070815831422806] skip-layers: [0, 1]
step:5550/5550 val_loss:2.919730 train_time:1421824ms step_avg:256.18ms x-lambda: 0.6881504058837891 lambdas: [0.016929995268583298, -0.04462744668126106] skip-layers: [0, 1]

## 8000-add-skip-multiple-2-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [10, 1]
step:125/5550 val_loss:4.255990 train_time:28595ms step_avg:228.76ms x-lambda: 1.1198556423187256 lambdas: [0.04655391350388527, 0.007445622701197863] skip-layers: [10, 1]
step:250/5550 val_loss:3.852877 train_time:57368ms step_avg:229.47ms x-lambda: 1.0553269386291504 lambdas: [-0.021328050643205643, -0.017985135316848755] skip-layers: [10, 1]
step:375/5550 val_loss:3.677291 train_time:86609ms step_avg:230.96ms x-lambda: 0.9737616777420044 lambdas: [-0.025246206670999527, -0.015829242765903473] skip-layers: [10, 1]
step:500/5550 val_loss:3.562736 train_time:116267ms step_avg:232.53ms x-lambda: 0.9088780879974365 lambdas: [-0.02560555376112461, -0.01761879213154316] skip-layers: [10, 1]
step:625/5550 val_loss:3.483697 train_time:146158ms step_avg:233.85ms x-lambda: 0.8568658232688904 lambdas: [-0.022924358025193214, -0.013900436460971832] skip-layers: [10, 1]
step:750/5550 val_loss:3.431328 train_time:176255ms step_avg:235.01ms x-lambda: 0.8134022951126099 lambdas: [-0.023391801863908768, -0.015951115638017654] skip-layers: [10, 1]
step:875/5550 val_loss:3.384733 train_time:206486ms step_avg:235.98ms x-lambda: 0.7750836610794067 lambdas: [-0.02158610336482525, -0.014834537170827389] skip-layers: [10, 1]
step:1000/5550 val_loss:3.350805 train_time:238172ms step_avg:238.17ms x-lambda: 0.7389868497848511 lambdas: [-0.02251424454152584, -0.015596145763993263] skip-layers: [10, 1]
step:1125/5550 val_loss:3.320482 train_time:269789ms step_avg:239.81ms x-lambda: 0.7108231782913208 lambdas: [-0.018856357783079147, -0.013790920376777649] skip-layers: [10, 1]
step:1250/5550 val_loss:3.296337 train_time:301499ms step_avg:241.20ms x-lambda: 0.6887335777282715 lambdas: [-0.01866791397333145, -0.01339706126600504] skip-layers: [10, 1]
step:1375/5550 val_loss:3.275297 train_time:334462ms step_avg:243.24ms x-lambda: 0.6648662686347961 lambdas: [-0.017203468829393387, -0.012080611661076546] skip-layers: [10, 1]
step:1500/5550 val_loss:3.254962 train_time:365329ms step_avg:243.55ms x-lambda: 0.6475274562835693 lambdas: [-0.01818898878991604, -0.013099497184157372] skip-layers: [10, 1]
step:1625/5550 val_loss:3.239879 train_time:396255ms step_avg:243.85ms x-lambda: 0.6322579383850098 lambdas: [-0.015516056679189205, -0.01069082785397768] skip-layers: [10, 1]
step:1750/5550 val_loss:3.223609 train_time:428216ms step_avg:244.69ms x-lambda: 0.6137701869010925 lambdas: [-0.014933326281607151, -0.010093748569488525] skip-layers: [10, 1]
step:1875/5550 val_loss:3.206310 train_time:460201ms step_avg:245.44ms x-lambda: 0.6020640730857849 lambdas: [-0.014283680357038975, -0.01059283409267664] skip-layers: [10, 1]
step:2000/5550 val_loss:3.191019 train_time:492445ms step_avg:246.22ms x-lambda: 0.5924275517463684 lambdas: [-0.011856567114591599, -0.009638464078307152] skip-layers: [10, 1]
step:2125/5550 val_loss:3.175752 train_time:525692ms step_avg:247.38ms x-lambda: 0.586895763874054 lambdas: [-0.012403711676597595, -0.008608974516391754] skip-layers: [10, 1]
step:2250/5550 val_loss:3.162178 train_time:556876ms step_avg:247.50ms x-lambda: 0.5792202949523926 lambdas: [-0.011433546431362629, -0.009183593094348907] skip-layers: [10, 1]
step:2375/5550 val_loss:3.151364 train_time:588103ms step_avg:247.62ms x-lambda: 0.5733506083488464 lambdas: [-0.011883514001965523, -0.008792639710009098] skip-layers: [10, 1]
step:2500/5550 val_loss:3.139077 train_time:623574ms step_avg:249.43ms x-lambda: 0.5701061487197876 lambdas: [-0.00965317152440548, -0.007355131208896637] skip-layers: [10, 1]
step:2625/5550 val_loss:3.127608 train_time:656992ms step_avg:250.28ms x-lambda: 0.5659604668617249 lambdas: [-0.01201329380273819, -0.009088854305446148] skip-layers: [10, 1]
step:2750/5550 val_loss:3.115904 train_time:688116ms step_avg:250.22ms x-lambda: 0.564324140548706 lambdas: [-0.01132242288440466, -0.008120594546198845] skip-layers: [10, 1]
step:2875/5550 val_loss:3.106276 train_time:719288ms step_avg:250.19ms x-lambda: 0.5634312033653259 lambdas: [-0.011150655336678028, -0.00681083370000124] skip-layers: [10, 1]
step:3000/5550 val_loss:3.095371 train_time:750489ms step_avg:250.16ms x-lambda: 0.5614372491836548 lambdas: [-0.009874558076262474, -0.008939502760767937] skip-layers: [10, 1]
step:3125/5550 val_loss:3.085376 train_time:782707ms step_avg:250.47ms x-lambda: 0.5607061386108398 lambdas: [-0.010358846746385098, -0.008058941923081875] skip-layers: [10, 1]
step:3250/5550 val_loss:3.073242 train_time:814973ms step_avg:250.76ms x-lambda: 0.5628712177276611 lambdas: [-0.008352350443601608, -0.00676905270665884] skip-layers: [10, 1]
step:3375/5550 val_loss:3.064237 train_time:847129ms step_avg:251.00ms x-lambda: 0.5640112161636353 lambdas: [-0.008817637339234352, -0.006874992977827787] skip-layers: [10, 1]
step:3500/5550 val_loss:3.055724 train_time:878365ms step_avg:250.96ms x-lambda: 0.5638636946678162 lambdas: [-0.009260345250368118, -0.007705934811383486] skip-layers: [10, 1]
step:3625/5550 val_loss:3.046824 train_time:910707ms step_avg:251.23ms x-lambda: 0.5669675469398499 lambdas: [-0.007717570755630732, -0.006469142157584429] skip-layers: [10, 1]
step:3750/5550 val_loss:3.037447 train_time:943013ms step_avg:251.47ms x-lambda: 0.5682920813560486 lambdas: [-0.008589197881519794, -0.006108857225626707] skip-layers: [10, 1]
step:3875/5550 val_loss:3.028622 train_time:974304ms step_avg:251.43ms x-lambda: 0.5749770998954773 lambdas: [-0.007923993282020092, -0.006327612791210413] skip-layers: [10, 1]
step:4000/5550 val_loss:3.019091 train_time:1005555ms step_avg:251.39ms x-lambda: 0.5776076316833496 lambdas: [-0.007016753312200308, -0.005707398056983948] skip-layers: [10, 1]
step:4125/5550 val_loss:3.009697 train_time:1041084ms step_avg:252.38ms x-lambda: 0.5827036499977112 lambdas: [-0.007446112111210823, -0.004916543141007423] skip-layers: [10, 1]
step:4250/5550 val_loss:3.001485 train_time:1079881ms step_avg:254.09ms x-lambda: 0.5858929753303528 lambdas: [-0.007846486754715443, -0.0051696342416107655] skip-layers: [10, 1]
step:4375/5550 val_loss:2.992156 train_time:1112446ms step_avg:254.27ms x-lambda: 0.5891894102096558 lambdas: [-0.0077233570627868176, -0.006829211488366127] skip-layers: [10, 1]
step:4500/5550 val_loss:2.983882 train_time:1147392ms step_avg:254.98ms x-lambda: 0.596791684627533 lambdas: [-0.007401666603982449, -0.005693061742931604] skip-layers: [10, 1]
step:4625/5550 val_loss:2.974472 train_time:1180146ms step_avg:255.17ms x-lambda: 0.6033484935760498 lambdas: [-0.007137589622288942, -0.005641300231218338] skip-layers: [10, 1]
step:4750/5550 val_loss:2.965147 train_time:1211987ms step_avg:255.16ms x-lambda: 0.6101590991020203 lambdas: [-0.007443211507052183, -0.005485669244080782] skip-layers: [10, 1]
step:4875/5550 val_loss:2.956321 train_time:1243962ms step_avg:255.17ms x-lambda: 0.6168756484985352 lambdas: [-0.00753131415694952, -0.004916550125926733] skip-layers: [10, 1]
step:5000/5550 val_loss:2.948262 train_time:1278182ms step_avg:255.64ms x-lambda: 0.6236948370933533 lambdas: [-0.006387685425579548, -0.006141084246337414] skip-layers: [10, 1]
step:5125/5550 val_loss:2.940773 train_time:1310394ms step_avg:255.69ms x-lambda: 0.6321291327476501 lambdas: [-0.006152668967843056, -0.005300461780279875] skip-layers: [10, 1]
step:5250/5550 val_loss:2.933423 train_time:1342828ms step_avg:255.78ms x-lambda: 0.6393657922744751 lambdas: [-0.007077396847307682, -0.004855428822338581] skip-layers: [10, 1]
step:5375/5550 val_loss:2.926919 train_time:1379560ms step_avg:256.66ms x-lambda: 0.6484992504119873 lambdas: [-0.006787391379475594, -0.005649981088936329] skip-layers: [10, 1]
step:5500/5550 val_loss:2.922115 train_time:1412344ms step_avg:256.79ms x-lambda: 0.6531569361686707 lambdas: [-0.006826285272836685, -0.005330119747668505] skip-layers: [10, 1]
step:5550/5550 val_loss:2.920901 train_time:1425544ms step_avg:256.85ms x-lambda: 0.654700756072998 lambdas: [-0.006860857829451561, -0.005299043375998735] skip-layers: [10, 1]

## 8000-add-skip-multiple-2-method-random-1

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:0.61ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [8, 9]
step:125/5550 val_loss:4.257397 train_time:28549ms step_avg:228.39ms x-lambda: 1.117966890335083 lambdas: [0.051564984023571014, 0.011184468865394592] skip-layers: [8, 9]
step:250/5550 val_loss:3.858760 train_time:57243ms step_avg:228.97ms x-lambda: 1.0806549787521362 lambdas: [-0.014559327624738216, -0.011924549005925655] skip-layers: [8, 9]
step:375/5550 val_loss:3.683836 train_time:86368ms step_avg:230.31ms x-lambda: 1.0100411176681519 lambdas: [-0.023442775011062622, -0.016196606680750847] skip-layers: [8, 9]
step:500/5550 val_loss:3.565917 train_time:117042ms step_avg:234.08ms x-lambda: 0.9428117871284485 lambdas: [-0.02536594308912754, -0.018740428611636162] skip-layers: [8, 9]
step:625/5550 val_loss:3.487209 train_time:146807ms step_avg:234.89ms x-lambda: 0.8899114727973938 lambdas: [-0.02333325520157814, -0.01774606853723526] skip-layers: [8, 9]
step:750/5550 val_loss:3.435595 train_time:176882ms step_avg:235.84ms x-lambda: 0.8459276556968689 lambdas: [-0.02407863177359104, -0.018377719447016716] skip-layers: [8, 9]
step:875/5550 val_loss:3.388180 train_time:207053ms step_avg:236.63ms x-lambda: 0.8066847920417786 lambdas: [-0.020745202898979187, -0.01621539518237114] skip-layers: [8, 9]
step:1000/5550 val_loss:3.352556 train_time:237512ms step_avg:237.51ms x-lambda: 0.7698466777801514 lambdas: [-0.020216912031173706, -0.015984833240509033] skip-layers: [8, 9]
step:1125/5550 val_loss:3.324114 train_time:267987ms step_avg:238.21ms x-lambda: 0.7403929829597473 lambdas: [-0.01883518695831299, -0.014607067219913006] skip-layers: [8, 9]
step:1250/5550 val_loss:3.298180 train_time:298642ms step_avg:238.91ms x-lambda: 0.7162218689918518 lambdas: [-0.017179114744067192, -0.011986587196588516] skip-layers: [8, 9]
step:1375/5550 val_loss:3.276538 train_time:330487ms step_avg:240.35ms x-lambda: 0.692997395992279 lambdas: [-0.01844213157892227, -0.01357900071889162] skip-layers: [8, 9]
step:1500/5550 val_loss:3.257908 train_time:362267ms step_avg:241.51ms x-lambda: 0.6730103492736816 lambdas: [-0.01717008277773857, -0.014256271533668041] skip-layers: [8, 9]
step:1625/5550 val_loss:3.243342 train_time:393106ms step_avg:241.91ms x-lambda: 0.6566045880317688 lambdas: [-0.013776367530226707, -0.011225470341742039] skip-layers: [8, 9]
step:1750/5550 val_loss:3.225835 train_time:423974ms step_avg:242.27ms x-lambda: 0.6378552913665771 lambdas: [-0.014810236170887947, -0.010823546908795834] skip-layers: [8, 9]
step:1875/5550 val_loss:3.207577 train_time:454870ms step_avg:242.60ms x-lambda: 0.62722247838974 lambdas: [-0.01491636410355568, -0.011096730828285217] skip-layers: [8, 9]
step:2000/5550 val_loss:3.192235 train_time:487041ms step_avg:243.52ms x-lambda: 0.6154342293739319 lambdas: [-0.01375049352645874, -0.011169200763106346] skip-layers: [8, 9]
step:2125/5550 val_loss:3.177515 train_time:519387ms step_avg:244.42ms x-lambda: 0.6089540719985962 lambdas: [-0.01266567874699831, -0.009485390968620777] skip-layers: [8, 9]
step:2250/5550 val_loss:3.163658 train_time:554671ms step_avg:246.52ms x-lambda: 0.6034303903579712 lambdas: [-0.011459160596132278, -0.008504881523549557] skip-layers: [8, 9]
step:2375/5550 val_loss:3.152332 train_time:585828ms step_avg:246.66ms x-lambda: 0.5969723463058472 lambdas: [-0.012213461101055145, -0.008906777948141098] skip-layers: [8, 9]
step:2500/5550 val_loss:3.140367 train_time:616988ms step_avg:246.80ms x-lambda: 0.5915678143501282 lambdas: [-0.01144068967550993, -0.00774140702560544] skip-layers: [8, 9]
step:2625/5550 val_loss:3.128645 train_time:649184ms step_avg:247.31ms x-lambda: 0.5883122086524963 lambdas: [-0.012530982494354248, -0.009581286460161209] skip-layers: [8, 9]
step:2750/5550 val_loss:3.117405 train_time:680297ms step_avg:247.38ms x-lambda: 0.5838395953178406 lambdas: [-0.012052292935550213, -0.008457680232822895] skip-layers: [8, 9]
step:2875/5550 val_loss:3.107763 train_time:711426ms step_avg:247.45ms x-lambda: 0.5850623846054077 lambdas: [-0.011213227175176144, -0.007953237742185593] skip-layers: [8, 9]
step:3000/5550 val_loss:3.097205 train_time:742631ms step_avg:247.54ms x-lambda: 0.5837492942810059 lambdas: [-0.011680776253342628, -0.008767015300691128] skip-layers: [8, 9]
step:3125/5550 val_loss:3.086536 train_time:774819ms step_avg:247.94ms x-lambda: 0.5830995440483093 lambdas: [-0.010488908737897873, -0.0074956961907446384] skip-layers: [8, 9]
step:3250/5550 val_loss:3.075312 train_time:805967ms step_avg:247.99ms x-lambda: 0.5844576358795166 lambdas: [-0.00973935890942812, -0.007346148602664471] skip-layers: [8, 9]
step:3375/5550 val_loss:3.066724 train_time:837108ms step_avg:248.03ms x-lambda: 0.5847874283790588 lambdas: [-0.011113947257399559, -0.007487835828214884] skip-layers: [8, 9]
step:3500/5550 val_loss:3.056989 train_time:873398ms step_avg:249.54ms x-lambda: 0.5872266888618469 lambdas: [-0.010392879135906696, -0.006879150401800871] skip-layers: [8, 9]
step:3625/5550 val_loss:3.048111 train_time:905721ms step_avg:249.85ms x-lambda: 0.5901256203651428 lambdas: [-0.010519658215343952, -0.00686132675036788] skip-layers: [8, 9]
step:3750/5550 val_loss:3.039122 train_time:938003ms step_avg:250.13ms x-lambda: 0.5897581577301025 lambdas: [-0.009743794798851013, -0.006268268916755915] skip-layers: [8, 9]
step:3875/5550 val_loss:3.029887 train_time:971404ms step_avg:250.68ms x-lambda: 0.5987979173660278 lambdas: [-0.010133420117199421, -0.006124134641140699] skip-layers: [8, 9]
step:4000/5550 val_loss:3.020565 train_time:1003644ms step_avg:250.91ms x-lambda: 0.6016576886177063 lambdas: [-0.009645786136388779, -0.006527080200612545] skip-layers: [8, 9]
step:4125/5550 val_loss:3.011258 train_time:1034892ms step_avg:250.88ms x-lambda: 0.6070111989974976 lambdas: [-0.008828622289001942, -0.00693672988563776] skip-layers: [8, 9]
step:4250/5550 val_loss:3.003202 train_time:1066321ms step_avg:250.90ms x-lambda: 0.6113064289093018 lambdas: [-0.009857315570116043, -0.0068063922226428986] skip-layers: [8, 9]
step:4375/5550 val_loss:2.993758 train_time:1097805ms step_avg:250.93ms x-lambda: 0.6141029596328735 lambdas: [-0.01069166325032711, -0.0066285450011491776] skip-layers: [8, 9]
step:4500/5550 val_loss:2.985298 train_time:1129331ms step_avg:250.96ms x-lambda: 0.6199358105659485 lambdas: [-0.008489885367453098, -0.00719424057751894] skip-layers: [8, 9]
step:4625/5550 val_loss:2.976195 train_time:1163356ms step_avg:251.54ms x-lambda: 0.6302366852760315 lambdas: [-0.01101306825876236, -0.0068515995517373085] skip-layers: [8, 9]
step:4750/5550 val_loss:2.966769 train_time:1195184ms step_avg:251.62ms x-lambda: 0.6352810859680176 lambdas: [-0.008301680907607079, -0.006618819665163755] skip-layers: [8, 9]
step:4875/5550 val_loss:2.957740 train_time:1228169ms step_avg:251.93ms x-lambda: 0.641823410987854 lambdas: [-0.008513050153851509, -0.005723207723349333] skip-layers: [8, 9]
step:5000/5550 val_loss:2.949708 train_time:1262450ms step_avg:252.49ms x-lambda: 0.6506547927856445 lambdas: [-0.008516306057572365, -0.005910593084990978] skip-layers: [8, 9]
step:5125/5550 val_loss:2.942001 train_time:1294638ms step_avg:252.61ms x-lambda: 0.6584683060646057 lambdas: [-0.009085231460630894, -0.006136882118880749] skip-layers: [8, 9]
step:5250/5550 val_loss:2.934732 train_time:1328058ms step_avg:252.96ms x-lambda: 0.6660038232803345 lambdas: [-0.008779251947999, -0.00635784026235342] skip-layers: [8, 9]
step:5375/5550 val_loss:2.928265 train_time:1362615ms step_avg:253.51ms x-lambda: 0.6758407354354858 lambdas: [-0.009141025133430958, -0.006158967036753893] skip-layers: [8, 9]
step:5500/5550 val_loss:2.923501 train_time:1395352ms step_avg:253.70ms x-lambda: 0.6811103820800781 lambdas: [-0.008399023674428463, -0.006118588615208864] skip-layers: [8, 9]
step:5550/5550 val_loss:2.922289 train_time:1408533ms step_avg:253.79ms x-lambda: 0.6827089786529541 lambdas: [-0.008677071891725063, -0.00604415824636817] skip-layers: [8, 9]

## 8000-add-skip-multiple-2-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [1, 2]
step:125/5550 val_loss:4.260612 train_time:29669ms step_avg:237.35ms x-lambda: 1.1211915016174316 lambdas: [0.05863358825445175, 0.0231002364307642] skip-layers: [1, 2]
step:250/5550 val_loss:3.850017 train_time:59410ms step_avg:237.64ms x-lambda: 1.07895827293396 lambdas: [0.006505413446575403, -0.07385292649269104] skip-layers: [1, 2]
step:375/5550 val_loss:3.677182 train_time:88608ms step_avg:236.29ms x-lambda: 1.0273785591125488 lambdas: [-0.004273341968655586, -0.11625075340270996] skip-layers: [1, 2]
step:500/5550 val_loss:3.559137 train_time:118238ms step_avg:236.48ms x-lambda: 0.9712557792663574 lambdas: [-0.0076308040879666805, -0.14254383742809296] skip-layers: [1, 2]
step:625/5550 val_loss:3.479642 train_time:148096ms step_avg:236.95ms x-lambda: 0.9206607937812805 lambdas: [-0.004098204895853996, -0.1561603546142578] skip-layers: [1, 2]
step:750/5550 val_loss:3.428686 train_time:178205ms step_avg:237.61ms x-lambda: 0.8760627508163452 lambdas: [-0.001893376698717475, -0.16460344195365906] skip-layers: [1, 2]
step:875/5550 val_loss:3.384106 train_time:208414ms step_avg:238.19ms x-lambda: 0.8364055752754211 lambdas: [0.003076059278100729, -0.16440539062023163] skip-layers: [1, 2]
step:1000/5550 val_loss:3.348408 train_time:238873ms step_avg:238.87ms x-lambda: 0.7990299463272095 lambdas: [0.005215500947088003, -0.16377313435077667] skip-layers: [1, 2]
step:1125/5550 val_loss:3.317796 train_time:270540ms step_avg:240.48ms x-lambda: 0.7685781121253967 lambdas: [0.007632076740264893, -0.15950645506381989] skip-layers: [1, 2]
step:1250/5550 val_loss:3.292158 train_time:301213ms step_avg:240.97ms x-lambda: 0.7406120896339417 lambdas: [0.008496700786054134, -0.1566224843263626] skip-layers: [1, 2]
step:1375/5550 val_loss:3.272012 train_time:333064ms step_avg:242.23ms x-lambda: 0.7148016095161438 lambdas: [0.009087180718779564, -0.15164491534233093] skip-layers: [1, 2]
step:1500/5550 val_loss:3.252890 train_time:364929ms step_avg:243.29ms x-lambda: 0.695378839969635 lambdas: [0.011091233231127262, -0.14514467120170593] skip-layers: [1, 2]
step:1625/5550 val_loss:3.237734 train_time:397056ms step_avg:244.34ms x-lambda: 0.6743354797363281 lambdas: [0.011511432006955147, -0.13971173763275146] skip-layers: [1, 2]
step:1750/5550 val_loss:3.221475 train_time:429068ms step_avg:245.18ms x-lambda: 0.6542114615440369 lambdas: [0.011298133991658688, -0.1351080983877182] skip-layers: [1, 2]
step:1875/5550 val_loss:3.202425 train_time:459989ms step_avg:245.33ms x-lambda: 0.6415488719940186 lambdas: [0.01021425612270832, -0.13138540089130402] skip-layers: [1, 2]
step:2000/5550 val_loss:3.187620 train_time:491155ms step_avg:245.58ms x-lambda: 0.627933144569397 lambdas: [0.012049451470375061, -0.1255258172750473] skip-layers: [1, 2]
step:2125/5550 val_loss:3.172679 train_time:523368ms step_avg:246.29ms x-lambda: 0.6206826567649841 lambdas: [0.012161982245743275, -0.1220124140381813] skip-layers: [1, 2]
step:2250/5550 val_loss:3.158624 train_time:556646ms step_avg:247.40ms x-lambda: 0.6114456057548523 lambdas: [0.01200459711253643, -0.117802195250988] skip-layers: [1, 2]
step:2375/5550 val_loss:3.147614 train_time:589002ms step_avg:248.00ms x-lambda: 0.6054351329803467 lambdas: [0.011236943304538727, -0.11517006903886795] skip-layers: [1, 2]
step:2500/5550 val_loss:3.135654 train_time:620210ms step_avg:248.08ms x-lambda: 0.600616991519928 lambdas: [0.013070429675281048, -0.11043546348810196] skip-layers: [1, 2]
step:2625/5550 val_loss:3.123578 train_time:651352ms step_avg:248.13ms x-lambda: 0.5945058465003967 lambdas: [0.010360515676438808, -0.1098998486995697] skip-layers: [1, 2]
step:2750/5550 val_loss:3.112902 train_time:683579ms step_avg:248.57ms x-lambda: 0.5932701826095581 lambdas: [0.011853882111608982, -0.10569402575492859] skip-layers: [1, 2]
step:2875/5550 val_loss:3.103771 train_time:714722ms step_avg:248.60ms x-lambda: 0.592045783996582 lambdas: [0.012495456263422966, -0.1014222800731659] skip-layers: [1, 2]
step:3000/5550 val_loss:3.092142 train_time:748025ms step_avg:249.34ms x-lambda: 0.5896982550621033 lambdas: [0.010151711292564869, -0.10064589232206345] skip-layers: [1, 2]
step:3125/5550 val_loss:3.081846 train_time:779235ms step_avg:249.36ms x-lambda: 0.587489902973175 lambdas: [0.010940088890492916, -0.10161557048559189] skip-layers: [1, 2]
step:3250/5550 val_loss:3.069941 train_time:810393ms step_avg:249.35ms x-lambda: 0.5891602039337158 lambdas: [0.01267988234758377, -0.09797462821006775] skip-layers: [1, 2]
step:3375/5550 val_loss:3.061251 train_time:841547ms step_avg:249.35ms x-lambda: 0.5907455086708069 lambdas: [0.01089912187308073, -0.09696350991725922] skip-layers: [1, 2]
step:3500/5550 val_loss:3.052486 train_time:873921ms step_avg:249.69ms x-lambda: 0.5894826650619507 lambdas: [0.010663771070539951, -0.09567181766033173] skip-layers: [1, 2]
step:3625/5550 val_loss:3.044139 train_time:905125ms step_avg:249.69ms x-lambda: 0.5940417051315308 lambdas: [0.010529066435992718, -0.09426414221525192] skip-layers: [1, 2]
step:3750/5550 val_loss:3.034079 train_time:936298ms step_avg:249.68ms x-lambda: 0.5952340960502625 lambdas: [0.012148866429924965, -0.0914735272526741] skip-layers: [1, 2]
step:3875/5550 val_loss:3.025394 train_time:972851ms step_avg:251.06ms x-lambda: 0.6012076735496521 lambdas: [0.010728446766734123, -0.0914212092757225] skip-layers: [1, 2]
step:4000/5550 val_loss:3.015807 train_time:1004018ms step_avg:251.00ms x-lambda: 0.6045243740081787 lambdas: [0.010805869475007057, -0.08988562226295471] skip-layers: [1, 2]
step:4125/5550 val_loss:3.006888 train_time:1035233ms step_avg:250.97ms x-lambda: 0.609803318977356 lambdas: [0.011265715584158897, -0.09028586745262146] skip-layers: [1, 2]
step:4250/5550 val_loss:2.998576 train_time:1067888ms step_avg:251.27ms x-lambda: 0.6128250360488892 lambdas: [0.010418185032904148, -0.08926433324813843] skip-layers: [1, 2]
step:4375/5550 val_loss:2.989265 train_time:1104845ms step_avg:252.54ms x-lambda: 0.6151880025863647 lambdas: [0.009625263512134552, -0.08768941462039948] skip-layers: [1, 2]
step:4500/5550 val_loss:2.981233 train_time:1137440ms step_avg:252.76ms x-lambda: 0.6222938299179077 lambdas: [0.010181738995015621, -0.08668575435876846] skip-layers: [1, 2]
step:4625/5550 val_loss:2.971767 train_time:1169090ms step_avg:252.78ms x-lambda: 0.6304633617401123 lambdas: [0.009748900309205055, -0.08636154979467392] skip-layers: [1, 2]
step:4750/5550 val_loss:2.962572 train_time:1200892ms step_avg:252.82ms x-lambda: 0.6371793746948242 lambdas: [0.010508210398256779, -0.08691795915365219] skip-layers: [1, 2]
step:4875/5550 val_loss:2.953652 train_time:1232839ms step_avg:252.89ms x-lambda: 0.642814576625824 lambdas: [0.0099929915741086, -0.08634985983371735] skip-layers: [1, 2]
step:5000/5550 val_loss:2.945561 train_time:1268254ms step_avg:253.65ms x-lambda: 0.6506894826889038 lambdas: [0.010335938073694706, -0.08563148230314255] skip-layers: [1, 2]
step:5125/5550 val_loss:2.937800 train_time:1300458ms step_avg:253.75ms x-lambda: 0.6581144332885742 lambdas: [0.009786183945834637, -0.08473655581474304] skip-layers: [1, 2]
step:5250/5550 val_loss:2.930613 train_time:1335049ms step_avg:254.30ms x-lambda: 0.6643733382225037 lambdas: [0.009374773129820824, -0.08458305895328522] skip-layers: [1, 2]
step:5375/5550 val_loss:2.924151 train_time:1369722ms step_avg:254.83ms x-lambda: 0.6736637949943542 lambdas: [0.009688368067145348, -0.08411169052124023] skip-layers: [1, 2]
step:5500/5550 val_loss:2.919403 train_time:1404744ms step_avg:255.41ms x-lambda: 0.6781696081161499 lambdas: [0.00966324470937252, -0.08432283252477646] skip-layers: [1, 2]
step:5550/5550 val_loss:2.918208 train_time:1417954ms step_avg:255.49ms x-lambda: 0.679875373840332 lambdas: [0.009696964174509048, -0.08423059433698654] skip-layers: [1, 2]

## 8000-add-skip-multiple-3-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.10ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [11, 10, 8]
step:125/5550 val_loss:4.271165 train_time:29738ms step_avg:237.91ms x-lambda: 1.0451020002365112 lambdas: [0.05469987541437149, 0.0618092343211174, 0.049006931483745575] skip-layers: [11, 10, 8]
step:250/5550 val_loss:3.858192 train_time:58521ms step_avg:234.08ms x-lambda: 0.996446967124939 lambdas: [0.03750980645418167, 0.046026408672332764, -0.011518174782395363] skip-layers: [11, 10, 8]
step:375/5550 val_loss:3.678921 train_time:88502ms step_avg:236.01ms x-lambda: 0.9832924604415894 lambdas: [0.02154548652470112, -0.004406235180795193, -0.046628545969724655] skip-layers: [11, 10, 8]
step:500/5550 val_loss:3.562320 train_time:118114ms step_avg:236.23ms x-lambda: 0.9632687568664551 lambdas: [0.003452801378443837, -0.05969619005918503, -0.06019384413957596] skip-layers: [11, 10, 8]
step:625/5550 val_loss:3.483944 train_time:149039ms step_avg:238.46ms x-lambda: 0.9478176236152649 lambdas: [-0.008190648630261421, -0.10661587119102478, -0.058053478598594666] skip-layers: [11, 10, 8]
step:750/5550 val_loss:3.430632 train_time:179152ms step_avg:238.87ms x-lambda: 0.9299180507659912 lambdas: [-0.02032078243792057, -0.15039129555225372, -0.054048653692007065] skip-layers: [11, 10, 8]
step:875/5550 val_loss:3.385013 train_time:209378ms step_avg:239.29ms x-lambda: 0.9167428016662598 lambdas: [-0.025174135342240334, -0.18387629091739655, -0.044797055423259735] skip-layers: [11, 10, 8]
step:1000/5550 val_loss:3.348687 train_time:241861ms step_avg:241.86ms x-lambda: 0.9021693468093872 lambdas: [-0.028787462040781975, -0.211873397231102, -0.03768601268529892] skip-layers: [11, 10, 8]
step:1125/5550 val_loss:3.319681 train_time:272396ms step_avg:242.13ms x-lambda: 0.8846174478530884 lambdas: [-0.03277112916111946, -0.2383742332458496, -0.0354611761868] skip-layers: [11, 10, 8]
step:1250/5550 val_loss:3.294958 train_time:305164ms step_avg:244.13ms x-lambda: 0.8737729787826538 lambdas: [-0.031058819964528084, -0.2552848160266876, -0.02783551625907421] skip-layers: [11, 10, 8]
step:1375/5550 val_loss:3.272354 train_time:336035ms step_avg:244.39ms x-lambda: 0.856689453125 lambdas: [-0.031428415328264236, -0.2722799479961395, -0.024711446836590767] skip-layers: [11, 10, 8]
step:1500/5550 val_loss:3.252763 train_time:367761ms step_avg:245.17ms x-lambda: 0.8443902134895325 lambdas: [-0.02804068848490715, -0.2844245135784149, -0.02211388573050499] skip-layers: [11, 10, 8]
step:1625/5550 val_loss:3.237024 train_time:398698ms step_avg:245.35ms x-lambda: 0.8299432396888733 lambdas: [-0.02491041272878647, -0.2960762083530426, -0.01691083237528801] skip-layers: [11, 10, 8]
step:1750/5550 val_loss:3.221364 train_time:430797ms step_avg:246.17ms x-lambda: 0.8137130737304688 lambdas: [-0.02342485636472702, -0.30541670322418213, -0.016533298417925835] skip-layers: [11, 10, 8]
step:1875/5550 val_loss:3.203259 train_time:464993ms step_avg:248.00ms x-lambda: 0.8040931224822998 lambdas: [-0.017583072185516357, -0.30977487564086914, -0.013404441997408867] skip-layers: [11, 10, 8]
step:2000/5550 val_loss:3.187394 train_time:498408ms step_avg:249.20ms x-lambda: 0.7897270321846008 lambdas: [-0.01418287679553032, -0.3159220516681671, -0.01223104540258646] skip-layers: [11, 10, 8]
step:2125/5550 val_loss:3.173413 train_time:529625ms step_avg:249.24ms x-lambda: 0.7799172401428223 lambdas: [-0.011354383081197739, -0.32117605209350586, -0.012051146477460861] skip-layers: [11, 10, 8]
step:2250/5550 val_loss:3.159070 train_time:560844ms step_avg:249.26ms x-lambda: 0.7718494534492493 lambdas: [-0.007366310339421034, -0.3244338631629944, -0.010531595908105373] skip-layers: [11, 10, 8]
step:2375/5550 val_loss:3.147089 train_time:593122ms step_avg:249.74ms x-lambda: 0.7639039158821106 lambdas: [-0.0033481826540082693, -0.3268890082836151, -0.008999884128570557] skip-layers: [11, 10, 8]
step:2500/5550 val_loss:3.136298 train_time:626473ms step_avg:250.59ms x-lambda: 0.7575745582580566 lambdas: [0.0007583298720419407, -0.32747480273246765, -0.008535703644156456] skip-layers: [11, 10, 8]
step:2625/5550 val_loss:3.123674 train_time:658761ms step_avg:250.96ms x-lambda: 0.7507921457290649 lambdas: [0.003598942421376705, -0.3308477997779846, -0.00851942878216505] skip-layers: [11, 10, 8]
step:2750/5550 val_loss:3.114019 train_time:691788ms step_avg:251.56ms x-lambda: 0.7437977194786072 lambdas: [0.0052165258675813675, -0.33353081345558167, -0.00771418958902359] skip-layers: [11, 10, 8]
step:2875/5550 val_loss:3.103997 train_time:722930ms step_avg:251.45ms x-lambda: 0.7412635684013367 lambdas: [0.010042226873338223, -0.3331741690635681, -0.00743861636146903] skip-layers: [11, 10, 8]
step:3000/5550 val_loss:3.092984 train_time:757382ms step_avg:252.46ms x-lambda: 0.7384766340255737 lambdas: [0.013674210757017136, -0.33290228247642517, -0.006997372023761272] skip-layers: [11, 10, 8]
step:3125/5550 val_loss:3.081674 train_time:788602ms step_avg:252.35ms x-lambda: 0.7345973253250122 lambdas: [0.014672099612653255, -0.3359377980232239, -0.0066857002675533295] skip-layers: [11, 10, 8]
step:3250/5550 val_loss:3.069678 train_time:819767ms step_avg:252.24ms x-lambda: 0.73344886302948 lambdas: [0.01714889332652092, -0.3367275297641754, -0.006683303974568844] skip-layers: [11, 10, 8]
step:3375/5550 val_loss:3.061566 train_time:850955ms step_avg:252.13ms x-lambda: 0.7321234345436096 lambdas: [0.018724994733929634, -0.33844664692878723, -0.006199861876666546] skip-layers: [11, 10, 8]
step:3500/5550 val_loss:3.052878 train_time:885409ms step_avg:252.97ms x-lambda: 0.7293409705162048 lambdas: [0.020440537482500076, -0.3376946747303009, -0.0059355478733778] skip-layers: [11, 10, 8]
step:3625/5550 val_loss:3.043484 train_time:916593ms step_avg:252.85ms x-lambda: 0.7313195466995239 lambdas: [0.025178173556923866, -0.3382357954978943, -0.005305677652359009] skip-layers: [11, 10, 8]
step:3750/5550 val_loss:3.034424 train_time:947753ms step_avg:252.73ms x-lambda: 0.7296048998832703 lambdas: [0.025390123948454857, -0.3393571972846985, -0.005214034114032984] skip-layers: [11, 10, 8]
step:3875/5550 val_loss:3.025366 train_time:980072ms step_avg:252.92ms x-lambda: 0.7334780693054199 lambdas: [0.028617609292268753, -0.3395991027355194, -0.005662010982632637] skip-layers: [11, 10, 8]
step:4000/5550 val_loss:3.016271 train_time:1012419ms step_avg:253.10ms x-lambda: 0.7339763045310974 lambdas: [0.030271757394075394, -0.3414934575557709, -0.005908792372792959] skip-layers: [11, 10, 8]
step:4125/5550 val_loss:3.006727 train_time:1044794ms step_avg:253.28ms x-lambda: 0.7384654879570007 lambdas: [0.031680669635534286, -0.3415100574493408, -0.004654823802411556] skip-layers: [11, 10, 8]
step:4250/5550 val_loss:2.998824 train_time:1076228ms step_avg:253.23ms x-lambda: 0.7399025559425354 lambdas: [0.03325797617435455, -0.3434522747993469, -0.006173689849674702] skip-layers: [11, 10, 8]
step:4375/5550 val_loss:2.989058 train_time:1108848ms step_avg:253.45ms x-lambda: 0.7429533004760742 lambdas: [0.034510571509599686, -0.3447571396827698, -0.0056455060839653015] skip-layers: [11, 10, 8]
step:4500/5550 val_loss:2.981020 train_time:1140417ms step_avg:253.43ms x-lambda: 0.7471726536750793 lambdas: [0.035473525524139404, -0.34562671184539795, -0.006407622247934341] skip-layers: [11, 10, 8]
step:4625/5550 val_loss:2.971882 train_time:1172114ms step_avg:253.43ms x-lambda: 0.7525571584701538 lambdas: [0.036689866334199905, -0.3463093638420105, -0.006869092117995024] skip-layers: [11, 10, 8]
step:4750/5550 val_loss:2.962324 train_time:1205185ms step_avg:253.72ms x-lambda: 0.7574707865715027 lambdas: [0.038155097514390945, -0.3475137948989868, -0.006512099876999855] skip-layers: [11, 10, 8]
step:4875/5550 val_loss:2.953480 train_time:1239297ms step_avg:254.21ms x-lambda: 0.7621797323226929 lambdas: [0.03933703526854515, -0.3496633768081665, -0.005859394557774067] skip-layers: [11, 10, 8]
step:5000/5550 val_loss:2.945396 train_time:1271377ms step_avg:254.28ms x-lambda: 0.7683535814285278 lambdas: [0.0405062697827816, -0.3509817123413086, -0.00751621974632144] skip-layers: [11, 10, 8]
step:5125/5550 val_loss:2.937745 train_time:1306942ms step_avg:255.01ms x-lambda: 0.7733632326126099 lambdas: [0.04168908670544624, -0.3526088297367096, -0.006764731369912624] skip-layers: [11, 10, 8]
step:5250/5550 val_loss:2.930599 train_time:1340560ms step_avg:255.34ms x-lambda: 0.7774222493171692 lambdas: [0.04193546250462532, -0.35349035263061523, -0.006710823159664869] skip-layers: [11, 10, 8]
step:5375/5550 val_loss:2.924103 train_time:1374217ms step_avg:255.67ms x-lambda: 0.7833094596862793 lambdas: [0.04262397438287735, -0.3545296788215637, -0.007580919191241264] skip-layers: [11, 10, 8]
step:5500/5550 val_loss:2.919306 train_time:1407046ms step_avg:255.83ms x-lambda: 0.7873693108558655 lambdas: [0.043178316205739975, -0.3545331656932831, -0.007491551339626312] skip-layers: [11, 10, 8]
step:5550/5550 val_loss:2.918104 train_time:1420275ms step_avg:255.91ms x-lambda: 0.7880128026008606 lambdas: [0.043147020041942596, -0.3550761342048645, -0.0077491565607488155] skip-layers: [11, 10, 8]

## 8000-add-skip-multiple-3-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [14, 13, 12]
step:125/5550 val_loss:4.260652 train_time:28823ms step_avg:230.58ms x-lambda: 1.0507932901382446 lambdas: [0.04480874165892601, 0.04984993115067482, 0.0527668334543705] skip-layers: [14, 13, 12]
step:250/5550 val_loss:3.854989 train_time:58773ms step_avg:235.09ms x-lambda: 1.001105546951294 lambdas: [0.008677925914525986, 0.022005503997206688, 0.024598155170679092] skip-layers: [14, 13, 12]
step:375/5550 val_loss:3.678688 train_time:88185ms step_avg:235.16ms x-lambda: 0.9726953506469727 lambdas: [-0.00513565493747592, 0.0050689163617789745, -0.001658828929066658] skip-layers: [14, 13, 12]
step:500/5550 val_loss:3.561437 train_time:118723ms step_avg:237.45ms x-lambda: 0.9530139565467834 lambdas: [-0.021469559520483017, -0.015598366968333721, -0.03255882486701012] skip-layers: [14, 13, 12]
step:625/5550 val_loss:3.482908 train_time:148714ms step_avg:237.94ms x-lambda: 0.9426864981651306 lambdas: [-0.031831588596105576, -0.03100566752254963, -0.05776730924844742] skip-layers: [14, 13, 12]
step:750/5550 val_loss:3.431978 train_time:178984ms step_avg:238.65ms x-lambda: 0.9342324137687683 lambdas: [-0.041140127927064896, -0.046260081231594086, -0.0819554403424263] skip-layers: [14, 13, 12]
step:875/5550 val_loss:3.385350 train_time:210226ms step_avg:240.26ms x-lambda: 0.926428496837616 lambdas: [-0.047438181936740875, -0.06063675880432129, -0.10472047328948975] skip-layers: [14, 13, 12]
step:1000/5550 val_loss:3.350661 train_time:240865ms step_avg:240.86ms x-lambda: 0.9210488200187683 lambdas: [-0.04953053593635559, -0.07076685130596161, -0.12216634303331375] skip-layers: [14, 13, 12]
step:1125/5550 val_loss:3.321528 train_time:271548ms step_avg:241.38ms x-lambda: 0.9180676937103271 lambdas: [-0.05310611426830292, -0.08273981511592865, -0.13928528130054474] skip-layers: [14, 13, 12]
step:1250/5550 val_loss:3.296837 train_time:302332ms step_avg:241.87ms x-lambda: 0.9178616404533386 lambdas: [-0.05356009677052498, -0.09229815006256104, -0.1526651382446289] skip-layers: [14, 13, 12]
step:1375/5550 val_loss:3.275228 train_time:333306ms step_avg:242.40ms x-lambda: 0.9148725271224976 lambdas: [-0.05640528351068497, -0.10431350767612457, -0.16751736402511597] skip-layers: [14, 13, 12]
step:1500/5550 val_loss:3.254278 train_time:365273ms step_avg:243.52ms x-lambda: 0.9158275723457336 lambdas: [-0.05579180642962456, -0.11460408568382263, -0.17920328676700592] skip-layers: [14, 13, 12]
step:1625/5550 val_loss:3.238809 train_time:397473ms step_avg:244.60ms x-lambda: 0.9163815975189209 lambdas: [-0.055746063590049744, -0.1248404011130333, -0.18967820703983307] skip-layers: [14, 13, 12]
step:1750/5550 val_loss:3.223333 train_time:428484ms step_avg:244.85ms x-lambda: 0.9167212247848511 lambdas: [-0.0569031648337841, -0.13556671142578125, -0.20024718344211578] skip-layers: [14, 13, 12]
step:1875/5550 val_loss:3.206064 train_time:459576ms step_avg:245.11ms x-lambda: 0.9206163883209229 lambdas: [-0.05625505372881889, -0.1443711519241333, -0.20771144330501556] skip-layers: [14, 13, 12]
step:2000/5550 val_loss:3.190133 train_time:490852ms step_avg:245.43ms x-lambda: 0.9206079840660095 lambdas: [-0.05792625620961189, -0.15553559362888336, -0.21654708683490753] skip-layers: [14, 13, 12]
step:2125/5550 val_loss:3.175530 train_time:522160ms step_avg:245.72ms x-lambda: 0.9255202412605286 lambdas: [-0.056881122291088104, -0.16526788473129272, -0.22344079613685608] skip-layers: [14, 13, 12]
step:2250/5550 val_loss:3.161172 train_time:553451ms step_avg:245.98ms x-lambda: 0.9318128824234009 lambdas: [-0.05587035045027733, -0.1735994964838028, -0.22848841547966003] skip-layers: [14, 13, 12]
step:2375/5550 val_loss:3.149861 train_time:584759ms step_avg:246.21ms x-lambda: 0.9343903660774231 lambdas: [-0.057056378573179245, -0.18311281502246857, -0.23400817811489105] skip-layers: [14, 13, 12]
step:2500/5550 val_loss:3.137821 train_time:617074ms step_avg:246.83ms x-lambda: 0.9392883777618408 lambdas: [-0.05472680926322937, -0.18989646434783936, -0.23742569983005524] skip-layers: [14, 13, 12]
step:2625/5550 val_loss:3.126381 train_time:649416ms step_avg:247.40ms x-lambda: 0.942344069480896 lambdas: [-0.05465833097696304, -0.19876141846179962, -0.24152693152427673] skip-layers: [14, 13, 12]
step:2750/5550 val_loss:3.114953 train_time:681788ms step_avg:247.92ms x-lambda: 0.9466971158981323 lambdas: [-0.05353119969367981, -0.20659996569156647, -0.2448517382144928] skip-layers: [14, 13, 12]
step:2875/5550 val_loss:3.105659 train_time:713064ms step_avg:248.02ms x-lambda: 0.9515978097915649 lambdas: [-0.052726782858371735, -0.21325361728668213, -0.2465892881155014] skip-layers: [14, 13, 12]
step:3000/5550 val_loss:3.094271 train_time:745548ms step_avg:248.52ms x-lambda: 0.9556899666786194 lambdas: [-0.05154343694448471, -0.22050979733467102, -0.24904851615428925] skip-layers: [14, 13, 12]
step:3125/5550 val_loss:3.083359 train_time:778729ms step_avg:249.19ms x-lambda: 0.9600005149841309 lambdas: [-0.05140683054924011, -0.22624285519123077, -0.2504698932170868] skip-layers: [14, 13, 12]
step:3250/5550 val_loss:3.072554 train_time:811036ms step_avg:249.55ms x-lambda: 0.9652891755104065 lambdas: [-0.04987800493836403, -0.23199120163917542, -0.2522943913936615] skip-layers: [14, 13, 12]
step:3375/5550 val_loss:3.063304 train_time:842282ms step_avg:249.57ms x-lambda: 0.9712293148040771 lambdas: [-0.04842079430818558, -0.2386627346277237, -0.2545758783817291] skip-layers: [14, 13, 12]
step:3500/5550 val_loss:3.054529 train_time:874771ms step_avg:249.93ms x-lambda: 0.9753686785697937 lambdas: [-0.04835880920290947, -0.24492381513118744, -0.25624555349349976] skip-layers: [14, 13, 12]
step:3625/5550 val_loss:3.045774 train_time:906073ms step_avg:249.95ms x-lambda: 0.9814480543136597 lambdas: [-0.04584367200732231, -0.24914231896400452, -0.2569274604320526] skip-layers: [14, 13, 12]
step:3750/5550 val_loss:3.036288 train_time:939609ms step_avg:250.56ms x-lambda: 0.9862624406814575 lambdas: [-0.04515744000673294, -0.2542659342288971, -0.25747883319854736] skip-layers: [14, 13, 12]
step:3875/5550 val_loss:3.027560 train_time:970975ms step_avg:250.57ms x-lambda: 0.9935178756713867 lambdas: [-0.042816709727048874, -0.2595798969268799, -0.2587589919567108] skip-layers: [14, 13, 12]
step:4000/5550 val_loss:3.017956 train_time:1002335ms step_avg:250.58ms x-lambda: 0.9997097849845886 lambdas: [-0.0417802631855011, -0.263988733291626, -0.2600307762622833] skip-layers: [14, 13, 12]
step:4125/5550 val_loss:3.009170 train_time:1035751ms step_avg:251.09ms x-lambda: 1.0061390399932861 lambdas: [-0.040274728089571, -0.26924213767051697, -0.26029151678085327] skip-layers: [14, 13, 12]
step:4250/5550 val_loss:3.000399 train_time:1067358ms step_avg:251.14ms x-lambda: 1.0114296674728394 lambdas: [-0.03932049497961998, -0.27355262637138367, -0.26263466477394104] skip-layers: [14, 13, 12]
step:4375/5550 val_loss:2.991199 train_time:1098987ms step_avg:251.20ms x-lambda: 1.0160139799118042 lambdas: [-0.039138492196798325, -0.2790985703468323, -0.2642768919467926] skip-layers: [14, 13, 12]
step:4500/5550 val_loss:2.982964 train_time:1130645ms step_avg:251.25ms x-lambda: 1.022911548614502 lambdas: [-0.03629625588655472, -0.28228873014450073, -0.26520174741744995] skip-layers: [14, 13, 12]
step:4625/5550 val_loss:2.973695 train_time:1162444ms step_avg:251.34ms x-lambda: 1.029956340789795 lambdas: [-0.03390420973300934, -0.2848961651325226, -0.2662760615348816] skip-layers: [14, 13, 12]
step:4750/5550 val_loss:2.964394 train_time:1197238ms step_avg:252.05ms x-lambda: 1.0365543365478516 lambdas: [-0.03257456794381142, -0.28788167238235474, -0.2667384147644043] skip-layers: [14, 13, 12]
step:4875/5550 val_loss:2.955408 train_time:1230392ms step_avg:252.39ms x-lambda: 1.0416557788848877 lambdas: [-0.031984925270080566, -0.29150858521461487, -0.2677420675754547] skip-layers: [14, 13, 12]
step:5000/5550 val_loss:2.947292 train_time:1263666ms step_avg:252.73ms x-lambda: 1.0481607913970947 lambdas: [-0.03059229999780655, -0.2939720153808594, -0.2687559127807617] skip-layers: [14, 13, 12]
step:5125/5550 val_loss:2.939631 train_time:1297080ms step_avg:253.09ms x-lambda: 1.0535725355148315 lambdas: [-0.029155677184462547, -0.29585930705070496, -0.2700605094432831] skip-layers: [14, 13, 12]
step:5250/5550 val_loss:2.932342 train_time:1330803ms step_avg:253.49ms x-lambda: 1.0580238103866577 lambdas: [-0.028427666053175926, -0.2975793182849884, -0.2704400420188904] skip-layers: [14, 13, 12]
step:5375/5550 val_loss:2.925927 train_time:1364481ms step_avg:253.86ms x-lambda: 1.0628509521484375 lambdas: [-0.027155626565217972, -0.2991350293159485, -0.27181142568588257] skip-layers: [14, 13, 12]
step:5500/5550 val_loss:2.921058 train_time:1399234ms step_avg:254.41ms x-lambda: 1.066249132156372 lambdas: [-0.026363825425505638, -0.2999471127986908, -0.2719677686691284] skip-layers: [14, 13, 12]
step:5550/5550 val_loss:2.919857 train_time:1412466ms step_avg:254.50ms x-lambda: 1.0667906999588013 lambdas: [-0.026320919394493103, -0.30042341351509094, -0.2723868191242218] skip-layers: [14, 13, 12]

## 8000-add-skip-multiple-3-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [0, 1, 2]
step:125/5550 val_loss:4.268699 train_time:29943ms step_avg:239.54ms x-lambda: 1.1064560413360596 lambdas: [0.10412200540304184, 0.023072395473718643, 0.005163755267858505] skip-layers: [0, 1, 2]
step:250/5550 val_loss:3.850702 train_time:58916ms step_avg:235.66ms x-lambda: 1.0761715173721313 lambdas: [0.07925740629434586, -0.04448780417442322, -0.08066702634096146] skip-layers: [0, 1, 2]
step:375/5550 val_loss:3.677320 train_time:88344ms step_avg:235.58ms x-lambda: 1.0237908363342285 lambdas: [0.06434556841850281, -0.06177380308508873, -0.11352210491895676] skip-layers: [0, 1, 2]
step:500/5550 val_loss:3.558494 train_time:118137ms step_avg:236.27ms x-lambda: 0.9683924913406372 lambdas: [0.05499932914972305, -0.06740401685237885, -0.13390982151031494] skip-layers: [0, 1, 2]
step:625/5550 val_loss:3.481472 train_time:148148ms step_avg:237.04ms x-lambda: 0.9179671406745911 lambdas: [0.05210905522108078, -0.06460033357143402, -0.1433052122592926] skip-layers: [0, 1, 2]
step:750/5550 val_loss:3.430520 train_time:178428ms step_avg:237.90ms x-lambda: 0.8742250204086304 lambdas: [0.047430217266082764, -0.061566658318042755, -0.14999952912330627] skip-layers: [0, 1, 2]
step:875/5550 val_loss:3.383912 train_time:210998ms step_avg:241.14ms x-lambda: 0.8348439931869507 lambdas: [0.045154497027397156, -0.05407057702541351, -0.1495259553194046] skip-layers: [0, 1, 2]
step:1000/5550 val_loss:3.348799 train_time:241642ms step_avg:241.64ms x-lambda: 0.7990400791168213 lambdas: [0.04115217179059982, -0.049252718687057495, -0.14823028445243835] skip-layers: [0, 1, 2]
step:1125/5550 val_loss:3.320368 train_time:272332ms step_avg:242.07ms x-lambda: 0.7676337957382202 lambdas: [0.036734867841005325, -0.04540758952498436, -0.14655208587646484] skip-layers: [0, 1, 2]
step:1250/5550 val_loss:3.293674 train_time:304201ms step_avg:243.36ms x-lambda: 0.7450128197669983 lambdas: [0.037260305136442184, -0.03916241228580475, -0.1397969126701355] skip-layers: [0, 1, 2]
step:1375/5550 val_loss:3.272516 train_time:335168ms step_avg:243.76ms x-lambda: 0.7193191051483154 lambdas: [0.03373619541525841, -0.035603124648332596, -0.1350909024477005] skip-layers: [0, 1, 2]
step:1500/5550 val_loss:3.253676 train_time:366114ms step_avg:244.08ms x-lambda: 0.7005296945571899 lambdas: [0.033267825841903687, -0.031429875642061234, -0.1290796399116516] skip-layers: [0, 1, 2]
step:1625/5550 val_loss:3.238250 train_time:397156ms step_avg:244.40ms x-lambda: 0.6778078675270081 lambdas: [0.029117846861481667, -0.031189268454909325, -0.12709148228168488] skip-layers: [0, 1, 2]
step:1750/5550 val_loss:3.222889 train_time:429238ms step_avg:245.28ms x-lambda: 0.6597299575805664 lambdas: [0.029318952932953835, -0.026671960949897766, -0.12106326222419739] skip-layers: [0, 1, 2]
step:1875/5550 val_loss:3.205486 train_time:460318ms step_avg:245.50ms x-lambda: 0.6494386196136475 lambdas: [0.02964797243475914, -0.024363819509744644, -0.11502553522586823] skip-layers: [0, 1, 2]
step:2000/5550 val_loss:3.189738 train_time:491591ms step_avg:245.80ms x-lambda: 0.6351905465126038 lambdas: [0.028169043362140656, -0.02325659990310669, -0.11177472770214081] skip-layers: [0, 1, 2]
step:2125/5550 val_loss:3.175195 train_time:522938ms step_avg:246.09ms x-lambda: 0.6260861158370972 lambdas: [0.026644064113497734, -0.021240318194031715, -0.1080615222454071] skip-layers: [0, 1, 2]
step:2250/5550 val_loss:3.160688 train_time:555345ms step_avg:246.82ms x-lambda: 0.6177524924278259 lambdas: [0.02537481114268303, -0.021708354353904724, -0.10583595931529999] skip-layers: [0, 1, 2]
step:2375/5550 val_loss:3.148941 train_time:587740ms step_avg:247.47ms x-lambda: 0.6101877093315125 lambdas: [0.02510160394012928, -0.01915472000837326, -0.1018059179186821] skip-layers: [0, 1, 2]
step:2500/5550 val_loss:3.137293 train_time:620130ms step_avg:248.05ms x-lambda: 0.6051031947135925 lambdas: [0.025700954720377922, -0.018221748992800713, -0.09924193471670151] skip-layers: [0, 1, 2]
step:2625/5550 val_loss:3.126325 train_time:652493ms step_avg:248.57ms x-lambda: 0.601115882396698 lambdas: [0.023591114208102226, -0.018266769126057625, -0.09680101275444031] skip-layers: [0, 1, 2]
step:2750/5550 val_loss:3.114883 train_time:683741ms step_avg:248.63ms x-lambda: 0.597861647605896 lambdas: [0.022872526198625565, -0.01743725873529911, -0.09530433267354965] skip-layers: [0, 1, 2]
step:2875/5550 val_loss:3.104896 train_time:717236ms step_avg:249.47ms x-lambda: 0.5959752202033997 lambdas: [0.0233123991638422, -0.01582302711904049, -0.09242868423461914] skip-layers: [0, 1, 2]
step:3000/5550 val_loss:3.094509 train_time:751669ms step_avg:250.56ms x-lambda: 0.5938875079154968 lambdas: [0.021791189908981323, -0.015683334320783615, -0.0894421637058258] skip-layers: [0, 1, 2]
step:3125/5550 val_loss:3.084198 train_time:786108ms step_avg:251.55ms x-lambda: 0.5919455885887146 lambdas: [0.02184673584997654, -0.015417419373989105, -0.09023816138505936] skip-layers: [0, 1, 2]
step:3250/5550 val_loss:3.073020 train_time:819602ms step_avg:252.19ms x-lambda: 0.5935471057891846 lambdas: [0.02223600074648857, -0.014566440135240555, -0.08788697421550751] skip-layers: [0, 1, 2]
step:3375/5550 val_loss:3.063935 train_time:850864ms step_avg:252.11ms x-lambda: 0.5934121012687683 lambdas: [0.02077423967421055, -0.01450437307357788, -0.08660831302404404] skip-layers: [0, 1, 2]
step:3500/5550 val_loss:3.055053 train_time:882226ms step_avg:252.06ms x-lambda: 0.5935429334640503 lambdas: [0.02022368647158146, -0.014487228356301785, -0.08556866645812988] skip-layers: [0, 1, 2]
step:3625/5550 val_loss:3.046599 train_time:913565ms step_avg:252.02ms x-lambda: 0.5983969569206238 lambdas: [0.020879177376627922, -0.012673448771238327, -0.08384809643030167] skip-layers: [0, 1, 2]
step:3750/5550 val_loss:3.037062 train_time:944895ms step_avg:251.97ms x-lambda: 0.5978170037269592 lambdas: [0.021625535562634468, -0.014341435395181179, -0.08274287730455399] skip-layers: [0, 1, 2]
step:3875/5550 val_loss:3.027774 train_time:978369ms step_avg:252.48ms x-lambda: 0.6036780476570129 lambdas: [0.02096138708293438, -0.013210763223469257, -0.08213582634925842] skip-layers: [0, 1, 2]
step:4000/5550 val_loss:3.018405 train_time:1009728ms step_avg:252.43ms x-lambda: 0.6084628701210022 lambdas: [0.020514052361249924, -0.013082853518426418, -0.07967407256364822] skip-layers: [0, 1, 2]
step:4125/5550 val_loss:3.009242 train_time:1043177ms step_avg:252.89ms x-lambda: 0.6122738122940063 lambdas: [0.020840974524617195, -0.012539342045783997, -0.08048007637262344] skip-layers: [0, 1, 2]
step:4250/5550 val_loss:3.001318 train_time:1074753ms step_avg:252.88ms x-lambda: 0.6160668730735779 lambdas: [0.020124215632677078, -0.01253742165863514, -0.07870590686798096] skip-layers: [0, 1, 2]
step:4375/5550 val_loss:2.991587 train_time:1106383ms step_avg:252.89ms x-lambda: 0.619382381439209 lambdas: [0.019173137843608856, -0.012561487033963203, -0.07929389178752899] skip-layers: [0, 1, 2]
step:4500/5550 val_loss:2.983665 train_time:1138047ms step_avg:252.90ms x-lambda: 0.6261618137359619 lambdas: [0.01994648016989231, -0.011884759180247784, -0.07831618189811707] skip-layers: [0, 1, 2]
step:4625/5550 val_loss:2.974651 train_time:1169834ms step_avg:252.94ms x-lambda: 0.6341893076896667 lambdas: [0.018456019461154938, -0.01256419438868761, -0.0776715874671936] skip-layers: [0, 1, 2]
step:4750/5550 val_loss:2.965093 train_time:1202793ms step_avg:253.22ms x-lambda: 0.639872133731842 lambdas: [0.01998547650873661, -0.01129086036235094, -0.077619269490242] skip-layers: [0, 1, 2]
step:4875/5550 val_loss:2.956166 train_time:1234884ms step_avg:253.31ms x-lambda: 0.6474642753601074 lambdas: [0.0192251093685627, -0.010631663724780083, -0.07723153382539749] skip-layers: [0, 1, 2]
step:5000/5550 val_loss:2.948038 train_time:1268069ms step_avg:253.61ms x-lambda: 0.6540293097496033 lambdas: [0.018667886033654213, -0.011513348668813705, -0.0766986757516861] skip-layers: [0, 1, 2]
step:5125/5550 val_loss:2.940520 train_time:1302673ms step_avg:254.18ms x-lambda: 0.6613844037055969 lambdas: [0.019495192915201187, -0.010481960140168667, -0.07571657747030258] skip-layers: [0, 1, 2]
step:5250/5550 val_loss:2.933326 train_time:1338380ms step_avg:254.93ms x-lambda: 0.6685647368431091 lambdas: [0.018267780542373657, -0.01016273908317089, -0.07666154205799103] skip-layers: [0, 1, 2]
step:5375/5550 val_loss:2.926851 train_time:1371028ms step_avg:255.08ms x-lambda: 0.6766547560691833 lambdas: [0.019378507509827614, -0.010969352908432484, -0.07590664178133011] skip-layers: [0, 1, 2]
step:5500/5550 val_loss:2.922029 train_time:1404669ms step_avg:255.39ms x-lambda: 0.6822488903999329 lambdas: [0.018792275339365005, -0.010848280042409897, -0.07549355924129486] skip-layers: [0, 1, 2]
step:5550/5550 val_loss:2.920861 train_time:1417912ms step_avg:255.48ms x-lambda: 0.6840242147445679 lambdas: [0.01872703991830349, -0.010932277888059616, -0.07580306380987167] skip-layers: [0, 1, 2]

## 8000-add-skip-multiple-3-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.32ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [3, 10, 13]
step:125/5550 val_loss:4.267186 train_time:28606ms step_avg:228.85ms x-lambda: 1.1284747123718262 lambdas: [0.019299877807497978, 0.030067723244428635, 0.014951836317777634] skip-layers: [3, 10, 13]
step:250/5550 val_loss:3.852465 train_time:57346ms step_avg:229.39ms x-lambda: 1.1167097091674805 lambdas: [-0.022020360454916954, -0.022635875269770622, -0.012305193580687046] skip-layers: [3, 10, 13]
step:375/5550 val_loss:3.677476 train_time:86581ms step_avg:230.88ms x-lambda: 1.0520195960998535 lambdas: [-0.02846548706293106, -0.02992885187268257, -0.01893201470375061] skip-layers: [3, 10, 13]
step:500/5550 val_loss:3.559562 train_time:116196ms step_avg:232.39ms x-lambda: 0.9914032816886902 lambdas: [-0.027296191081404686, -0.02978169545531273, -0.017685549333691597] skip-layers: [3, 10, 13]
step:625/5550 val_loss:3.481310 train_time:146034ms step_avg:233.65ms x-lambda: 0.9300756454467773 lambdas: [-0.028346220031380653, -0.029715586453676224, -0.019688233733177185] skip-layers: [3, 10, 13]
step:750/5550 val_loss:3.428607 train_time:176163ms step_avg:234.88ms x-lambda: 0.885727047920227 lambdas: [-0.025525318458676338, -0.02624012902379036, -0.01705513522028923] skip-layers: [3, 10, 13]
step:875/5550 val_loss:3.383345 train_time:206373ms step_avg:235.85ms x-lambda: 0.8386269211769104 lambdas: [-0.02175077609717846, -0.02375194802880287, -0.016132161021232605] skip-layers: [3, 10, 13]
step:1000/5550 val_loss:3.348299 train_time:237785ms step_avg:237.79ms x-lambda: 0.7992262840270996 lambdas: [-0.021679528057575226, -0.02274153381586075, -0.015614522621035576] skip-layers: [3, 10, 13]
step:1125/5550 val_loss:3.320244 train_time:268285ms step_avg:238.48ms x-lambda: 0.7652378678321838 lambdas: [-0.022425085306167603, -0.02407398819923401, -0.016415197402238846] skip-layers: [3, 10, 13]
step:1250/5550 val_loss:3.294704 train_time:301168ms step_avg:240.93ms x-lambda: 0.7398870587348938 lambdas: [-0.01884736865758896, -0.019733978435397148, -0.013638456352055073] skip-layers: [3, 10, 13]
step:1375/5550 val_loss:3.274443 train_time:333124ms step_avg:242.27ms x-lambda: 0.713808000087738 lambdas: [-0.01875007152557373, -0.019063957035541534, -0.013224199414253235] skip-layers: [3, 10, 13]
step:1500/5550 val_loss:3.258820 train_time:364012ms step_avg:242.67ms x-lambda: 0.6932961940765381 lambdas: [-0.018304971978068352, -0.018369430676102638, -0.013760600239038467] skip-layers: [3, 10, 13]
step:1625/5550 val_loss:3.239953 train_time:395985ms step_avg:243.68ms x-lambda: 0.6753974556922913 lambdas: [-0.015511573292315006, -0.016045842319726944, -0.01137228962033987] skip-layers: [3, 10, 13]
step:1750/5550 val_loss:3.224442 train_time:426945ms step_avg:243.97ms x-lambda: 0.6546304821968079 lambdas: [-0.014240942895412445, -0.01579705812036991, -0.010083548724651337] skip-layers: [3, 10, 13]
step:1875/5550 val_loss:3.206370 train_time:459059ms step_avg:244.83ms x-lambda: 0.6420980095863342 lambdas: [-0.014107750728726387, -0.015411294996738434, -0.011714943684637547] skip-layers: [3, 10, 13]
step:2000/5550 val_loss:3.189598 train_time:492289ms step_avg:246.14ms x-lambda: 0.628791868686676 lambdas: [-0.013862074352800846, -0.013743633404374123, -0.010419118218123913] skip-layers: [3, 10, 13]
step:2125/5550 val_loss:3.175206 train_time:524648ms step_avg:246.89ms x-lambda: 0.6213684678077698 lambdas: [-0.01256604678928852, -0.012978345155715942, -0.010426148772239685] skip-layers: [3, 10, 13]
step:2250/5550 val_loss:3.161689 train_time:558056ms step_avg:248.02ms x-lambda: 0.6138473153114319 lambdas: [-0.012259960174560547, -0.012956958264112473, -0.010415008291602135] skip-layers: [3, 10, 13]
step:2375/5550 val_loss:3.150254 train_time:589310ms step_avg:248.13ms x-lambda: 0.6058916449546814 lambdas: [-0.012724680826067924, -0.012975333258509636, -0.0091606630012393] skip-layers: [3, 10, 13]
step:2500/5550 val_loss:3.138563 train_time:622410ms step_avg:248.96ms x-lambda: 0.6010472774505615 lambdas: [-0.011363319121301174, -0.01127071026712656, -0.007923005148768425] skip-layers: [3, 10, 13]
step:2625/5550 val_loss:3.126338 train_time:653571ms step_avg:248.98ms x-lambda: 0.5971155166625977 lambdas: [-0.010897637344896793, -0.012443876825273037, -0.009081370197236538] skip-layers: [3, 10, 13]
step:2750/5550 val_loss:3.115474 train_time:684777ms step_avg:249.01ms x-lambda: 0.5936664938926697 lambdas: [-0.010927800089120865, -0.011476912535727024, -0.008621934801340103] skip-layers: [3, 10, 13]
step:2875/5550 val_loss:3.106085 train_time:718158ms step_avg:249.79ms x-lambda: 0.5931040644645691 lambdas: [-0.010981491766870022, -0.010222123935818672, -0.008569849655032158] skip-layers: [3, 10, 13]
step:3000/5550 val_loss:3.095333 train_time:751509ms step_avg:250.50ms x-lambda: 0.5928906798362732 lambdas: [-0.01033480279147625, -0.010513560846447945, -0.008442902006208897] skip-layers: [3, 10, 13]
step:3125/5550 val_loss:3.085462 train_time:784892ms step_avg:251.17ms x-lambda: 0.5901521444320679 lambdas: [-0.011418748646974564, -0.011892426759004593, -0.007164475508034229] skip-layers: [3, 10, 13]
step:3250/5550 val_loss:3.072685 train_time:816100ms step_avg:251.11ms x-lambda: 0.5920755863189697 lambdas: [-0.009178460575640202, -0.00969398207962513, -0.006488824728876352] skip-layers: [3, 10, 13]
step:3375/5550 val_loss:3.064533 train_time:847292ms step_avg:251.05ms x-lambda: 0.5925390124320984 lambdas: [-0.009509793482720852, -0.01048748753964901, -0.0069758594036102295] skip-layers: [3, 10, 13]
step:3500/5550 val_loss:3.055603 train_time:878548ms step_avg:251.01ms x-lambda: 0.5915383696556091 lambdas: [-0.010629077441990376, -0.010966680012643337, -0.007819372229278088] skip-layers: [3, 10, 13]
step:3625/5550 val_loss:3.047040 train_time:909762ms step_avg:250.97ms x-lambda: 0.5949691534042358 lambdas: [-0.01018130499869585, -0.009051068685948849, -0.007974900305271149] skip-layers: [3, 10, 13]
step:3750/5550 val_loss:3.037344 train_time:940953ms step_avg:250.92ms x-lambda: 0.59699946641922 lambdas: [-0.008561457507312298, -0.009271567687392235, -0.006413835566490889] skip-layers: [3, 10, 13]
step:3875/5550 val_loss:3.028523 train_time:972247ms step_avg:250.90ms x-lambda: 0.6027039289474487 lambdas: [-0.009199708700180054, -0.008870319463312626, -0.006809133104979992] skip-layers: [3, 10, 13]
step:4000/5550 val_loss:3.018894 train_time:1003513ms step_avg:250.88ms x-lambda: 0.607697606086731 lambdas: [-0.00788508728146553, -0.007369327358901501, -0.006160768214613199] skip-layers: [3, 10, 13]
step:4125/5550 val_loss:3.009651 train_time:1034830ms step_avg:250.87ms x-lambda: 0.612725019454956 lambdas: [-0.00744426716119051, -0.008881916292011738, -0.006353437900543213] skip-layers: [3, 10, 13]
step:4250/5550 val_loss:3.001423 train_time:1067520ms step_avg:251.18ms x-lambda: 0.6160513758659363 lambdas: [-0.008834343403577805, -0.007453119847923517, -0.006482252851128578] skip-layers: [3, 10, 13]
step:4375/5550 val_loss:2.992047 train_time:1099084ms step_avg:251.22ms x-lambda: 0.6198275089263916 lambdas: [-0.010246790945529938, -0.007950692437589169, -0.006480975076556206] skip-layers: [3, 10, 13]
step:4500/5550 val_loss:2.983716 train_time:1131716ms step_avg:251.49ms x-lambda: 0.6259564757347107 lambdas: [-0.008664562366902828, -0.008760702796280384, -0.006274454295635223] skip-layers: [3, 10, 13]
step:4625/5550 val_loss:2.974273 train_time:1163434ms step_avg:251.55ms x-lambda: 0.6339909434318542 lambdas: [-0.0077034602873027325, -0.007951568812131882, -0.006296955980360508] skip-layers: [3, 10, 13]
step:4750/5550 val_loss:2.965264 train_time:1195264ms step_avg:251.63ms x-lambda: 0.6415165662765503 lambdas: [-0.007157346233725548, -0.006908903829753399, -0.005945929326117039] skip-layers: [3, 10, 13]
step:4875/5550 val_loss:2.956345 train_time:1227304ms step_avg:251.75ms x-lambda: 0.648353099822998 lambdas: [-0.008084830828011036, -0.007676429580897093, -0.006486239843070507] skip-layers: [3, 10, 13]
step:5000/5550 val_loss:2.948108 train_time:1259406ms step_avg:251.88ms x-lambda: 0.6556594967842102 lambdas: [-0.007736428175121546, -0.008353806100785732, -0.005426426883786917] skip-layers: [3, 10, 13]
step:5125/5550 val_loss:2.940546 train_time:1293711ms step_avg:252.43ms x-lambda: 0.6642200946807861 lambdas: [-0.00798895861953497, -0.007986575365066528, -0.005000729579478502] skip-layers: [3, 10, 13]
step:5250/5550 val_loss:2.933280 train_time:1327243ms step_avg:252.81ms x-lambda: 0.6704416871070862 lambdas: [-0.008388529531657696, -0.007559577934443951, -0.005609879735857248] skip-layers: [3, 10, 13]
step:5375/5550 val_loss:2.926775 train_time:1359810ms step_avg:252.99ms x-lambda: 0.6799247860908508 lambdas: [-0.0073363445699214935, -0.007259097415953875, -0.005591010209172964] skip-layers: [3, 10, 13]
step:5500/5550 val_loss:2.921981 train_time:1395981ms step_avg:253.81ms x-lambda: 0.6854314804077148 lambdas: [-0.00743310060352087, -0.007177166640758514, -0.00569757167249918] skip-layers: [3, 10, 13]
step:5550/5550 val_loss:2.920777 train_time:1409197ms step_avg:253.91ms x-lambda: 0.6869142055511475 lambdas: [-0.007664380595088005, -0.007413012441247702, -0.005427300464361906] skip-layers: [3, 10, 13]

## 8000-add-skip-multiple-3-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [1, 2, 7]
step:125/5550 val_loss:4.272185 train_time:28599ms step_avg:228.79ms x-lambda: 1.0835206508636475 lambdas: [0.0514630563557148, 0.011201445944607258, 0.08416114002466202] skip-layers: [1, 2, 7]
step:250/5550 val_loss:3.850803 train_time:58456ms step_avg:233.82ms x-lambda: 1.055290937423706 lambdas: [-0.004224090371280909, -0.08578815311193466, 0.0680740475654602] skip-layers: [1, 2, 7]
step:375/5550 val_loss:3.676290 train_time:87620ms step_avg:233.65ms x-lambda: 1.013196587562561 lambdas: [-0.014268665574491024, -0.12453577667474747, 0.041152093559503555] skip-layers: [1, 2, 7]
step:500/5550 val_loss:3.559390 train_time:120153ms step_avg:240.31ms x-lambda: 0.9648464918136597 lambdas: [-0.016634704545140266, -0.14855141937732697, 0.02055063471198082] skip-layers: [1, 2, 7]
step:625/5550 val_loss:3.481150 train_time:150030ms step_avg:240.05ms x-lambda: 0.9191187620162964 lambdas: [-0.010636950843036175, -0.15905091166496277, 0.01143704354763031] skip-layers: [1, 2, 7]
step:750/5550 val_loss:3.428440 train_time:180893ms step_avg:241.19ms x-lambda: 0.8789994120597839 lambdas: [-0.007135198451578617, -0.16491062939167023, 0.003677129512652755] skip-layers: [1, 2, 7]
step:875/5550 val_loss:3.382682 train_time:213131ms step_avg:243.58ms x-lambda: 0.8385433554649353 lambdas: [-0.0022569047287106514, -0.16515490412712097, 0.000370799214579165] skip-layers: [1, 2, 7]
step:1000/5550 val_loss:3.348623 train_time:243628ms step_avg:243.63ms x-lambda: 0.8046159744262695 lambdas: [0.0005673440173268318, -0.16375915706157684, -0.005372696556150913] skip-layers: [1, 2, 7]
step:1125/5550 val_loss:3.319263 train_time:274152ms step_avg:243.69ms x-lambda: 0.7719421982765198 lambdas: [0.001490019029006362, -0.16067005693912506, -0.009298611432313919] skip-layers: [1, 2, 7]
step:1250/5550 val_loss:3.294445 train_time:305850ms step_avg:244.68ms x-lambda: 0.7487726807594299 lambdas: [0.0052553885616362095, -0.15371733903884888, -0.007473111152648926] skip-layers: [1, 2, 7]
step:1375/5550 val_loss:3.271988 train_time:336726ms step_avg:244.89ms x-lambda: 0.7233746647834778 lambdas: [0.005842880345880985, -0.14907948672771454, -0.01019604317843914] skip-layers: [1, 2, 7]
step:1500/5550 val_loss:3.252628 train_time:368615ms step_avg:245.74ms x-lambda: 0.704917848110199 lambdas: [0.00713897030800581, -0.14254233241081238, -0.009992558509111404] skip-layers: [1, 2, 7]
step:1625/5550 val_loss:3.236788 train_time:400564ms step_avg:246.50ms x-lambda: 0.6813904643058777 lambdas: [0.006875438150018454, -0.1383143961429596, -0.01197783276438713] skip-layers: [1, 2, 7]
step:1750/5550 val_loss:3.221444 train_time:431460ms step_avg:246.55ms x-lambda: 0.6641936898231506 lambdas: [0.008651290088891983, -0.13007114827632904, -0.0114115746691823] skip-layers: [1, 2, 7]
step:1875/5550 val_loss:3.202739 train_time:462419ms step_avg:246.62ms x-lambda: 0.6509442329406738 lambdas: [0.006925270892679691, -0.1267615407705307, -0.013703739270567894] skip-layers: [1, 2, 7]
step:2000/5550 val_loss:3.188154 train_time:494642ms step_avg:247.32ms x-lambda: 0.6381998658180237 lambdas: [0.008507976308465004, -0.12080363929271698, -0.013389522209763527] skip-layers: [1, 2, 7]
step:2125/5550 val_loss:3.173811 train_time:527009ms step_avg:248.00ms x-lambda: 0.6271530985832214 lambdas: [0.007929475978016853, -0.11778830736875534, -0.01473456434905529] skip-layers: [1, 2, 7]
step:2250/5550 val_loss:3.159624 train_time:558190ms step_avg:248.08ms x-lambda: 0.619636595249176 lambdas: [0.007684390991926193, -0.1135028824210167, -0.015318457037210464] skip-layers: [1, 2, 7]
step:2375/5550 val_loss:3.147911 train_time:591561ms step_avg:249.08ms x-lambda: 0.6124275326728821 lambdas: [0.007307657040655613, -0.11022722721099854, -0.015228178352117538] skip-layers: [1, 2, 7]
step:2500/5550 val_loss:3.136921 train_time:622731ms step_avg:249.09ms x-lambda: 0.6072481870651245 lambdas: [0.008678021840751171, -0.1051032766699791, -0.015613393858075142] skip-layers: [1, 2, 7]
step:2625/5550 val_loss:3.124841 train_time:653898ms step_avg:249.10ms x-lambda: 0.6027408242225647 lambdas: [0.00852961465716362, -0.10369381308555603, -0.01575634442269802] skip-layers: [1, 2, 7]
step:2750/5550 val_loss:3.113960 train_time:685033ms step_avg:249.10ms x-lambda: 0.5996596217155457 lambdas: [0.007978636771440506, -0.1010364294052124, -0.015929101034998894] skip-layers: [1, 2, 7]
step:2875/5550 val_loss:3.104159 train_time:716210ms step_avg:249.12ms x-lambda: 0.5955531597137451 lambdas: [0.008397689089179039, -0.09842231124639511, -0.016239317134022713] skip-layers: [1, 2, 7]
step:3000/5550 val_loss:3.093904 train_time:748474ms step_avg:249.49ms x-lambda: 0.596030592918396 lambdas: [0.009355447255074978, -0.09438682347536087, -0.016921143978834152] skip-layers: [1, 2, 7]
step:3125/5550 val_loss:3.082651 train_time:780819ms step_avg:249.86ms x-lambda: 0.5937356948852539 lambdas: [0.008384044282138348, -0.09446191787719727, -0.0169951394200325] skip-layers: [1, 2, 7]
step:3250/5550 val_loss:3.071312 train_time:814177ms step_avg:250.52ms x-lambda: 0.5954186320304871 lambdas: [0.009126432240009308, -0.09168937802314758, -0.015360433608293533] skip-layers: [1, 2, 7]
step:3375/5550 val_loss:3.062791 train_time:845320ms step_avg:250.47ms x-lambda: 0.5944546461105347 lambdas: [0.007612330839037895, -0.09151821583509445, -0.01676361821591854] skip-layers: [1, 2, 7]
step:3500/5550 val_loss:3.053842 train_time:876542ms step_avg:250.44ms x-lambda: 0.5940226316452026 lambdas: [0.007205807603895664, -0.08961986750364304, -0.01754746399819851] skip-layers: [1, 2, 7]
step:3625/5550 val_loss:3.044717 train_time:908835ms step_avg:250.71ms x-lambda: 0.598142147064209 lambdas: [0.008686480112373829, -0.08792871981859207, -0.018121639266610146] skip-layers: [1, 2, 7]
step:3750/5550 val_loss:3.035423 train_time:943434ms step_avg:251.58ms x-lambda: 0.5982605218887329 lambdas: [0.009318666532635689, -0.08679124712944031, -0.01688573509454727] skip-layers: [1, 2, 7]
step:3875/5550 val_loss:3.026352 train_time:975857ms step_avg:251.83ms x-lambda: 0.6044014096260071 lambdas: [0.009002928622066975, -0.08524390310049057, -0.01895054057240486] skip-layers: [1, 2, 7]
step:4000/5550 val_loss:3.016930 train_time:1009256ms step_avg:252.31ms x-lambda: 0.6070564985275269 lambdas: [0.008038638159632683, -0.08435343950986862, -0.01808456890285015] skip-layers: [1, 2, 7]
step:4125/5550 val_loss:3.007957 train_time:1041633ms step_avg:252.52ms x-lambda: 0.6134867072105408 lambdas: [0.007890624925494194, -0.08399833738803864, -0.017771903425455093] skip-layers: [1, 2, 7]
step:4250/5550 val_loss:2.999419 train_time:1073147ms step_avg:252.51ms x-lambda: 0.6164885759353638 lambdas: [0.007872004993259907, -0.082943856716156, -0.018602309748530388] skip-layers: [1, 2, 7]
step:4375/5550 val_loss:2.990587 train_time:1109115ms step_avg:253.51ms x-lambda: 0.6195852160453796 lambdas: [0.007983412593603134, -0.0828651711344719, -0.019032660871744156] skip-layers: [1, 2, 7]
step:4500/5550 val_loss:2.982253 train_time:1140716ms step_avg:253.49ms x-lambda: 0.62493896484375 lambdas: [0.00861316453665495, -0.08125260472297668, -0.01845921389758587] skip-layers: [1, 2, 7]
step:4625/5550 val_loss:2.972865 train_time:1172371ms step_avg:253.49ms x-lambda: 0.6342259645462036 lambdas: [0.008423554711043835, -0.08023250848054886, -0.019472092390060425] skip-layers: [1, 2, 7]
step:4750/5550 val_loss:2.963565 train_time:1206466ms step_avg:253.99ms x-lambda: 0.6403363347053528 lambdas: [0.008059456013143063, -0.08041532337665558, -0.018183834850788116] skip-layers: [1, 2, 7]
step:4875/5550 val_loss:2.954726 train_time:1238470ms step_avg:254.05ms x-lambda: 0.6468042135238647 lambdas: [0.008113082498311996, -0.07936335355043411, -0.020678861066699028] skip-layers: [1, 2, 7]
step:5000/5550 val_loss:2.946665 train_time:1270554ms step_avg:254.11ms x-lambda: 0.652980625629425 lambdas: [0.008274132385849953, -0.07909086346626282, -0.020642200484871864] skip-layers: [1, 2, 7]
step:5125/5550 val_loss:2.938929 train_time:1303839ms step_avg:254.41ms x-lambda: 0.6619722843170166 lambdas: [0.007974057458341122, -0.07735058665275574, -0.01985565759241581] skip-layers: [1, 2, 7]
step:5250/5550 val_loss:2.931791 train_time:1336295ms step_avg:254.53ms x-lambda: 0.6683117747306824 lambdas: [0.007302765268832445, -0.07769689708948135, -0.020763874053955078] skip-layers: [1, 2, 7]
step:5375/5550 val_loss:2.925322 train_time:1372075ms step_avg:255.27ms x-lambda: 0.6767796874046326 lambdas: [0.007668815087527037, -0.07762905955314636, -0.02060440555214882] skip-layers: [1, 2, 7]
step:5500/5550 val_loss:2.920475 train_time:1405958ms step_avg:255.63ms x-lambda: 0.6819291114807129 lambdas: [0.007484620437026024, -0.07762281596660614, -0.0205039381980896] skip-layers: [1, 2, 7]
step:5550/5550 val_loss:2.919298 train_time:1420327ms step_avg:255.91ms x-lambda: 0.6831473112106323 lambdas: [0.0077132112346589565, -0.07760194689035416, -0.020768750458955765] skip-layers: [1, 2, 7]

## 8000-add-skip-multiple-4-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4]
step:125/5550 val_loss:4.253181 train_time:28649ms step_avg:229.19ms x-lambda: 1.028296709060669 lambdas: [0.03853879123926163, 0.047515224665403366, 0.03464799001812935, 0.08132896572351456] skip-layers: [11, 10, 8, 4]
step:250/5550 val_loss:3.850143 train_time:57508ms step_avg:230.03ms x-lambda: 0.9863881468772888 lambdas: [0.011925121769309044, 0.020925050601363182, -0.005267263390123844, 0.08845440298318863] skip-layers: [11, 10, 8, 4]
step:375/5550 val_loss:3.679093 train_time:86757ms step_avg:231.35ms x-lambda: 0.9891849160194397 lambdas: [-0.007479934487491846, -0.0277415718883276, -0.02684902958571911, 0.056335434317588806] skip-layers: [11, 10, 8, 4]
step:500/5550 val_loss:3.562669 train_time:116498ms step_avg:233.00ms x-lambda: 0.9782859086990356 lambdas: [-0.02622523158788681, -0.07413431257009506, -0.03413977846503258, 0.0318230576813221] skip-layers: [11, 10, 8, 4]
step:625/5550 val_loss:3.483146 train_time:146463ms step_avg:234.34ms x-lambda: 0.9679756760597229 lambdas: [-0.03884351626038551, -0.11279439181089401, -0.029573410749435425, 0.019284164533019066] skip-layers: [11, 10, 8, 4]
step:750/5550 val_loss:3.429493 train_time:176706ms step_avg:235.61ms x-lambda: 0.9580584168434143 lambdas: [-0.05034475401043892, -0.1452489048242569, -0.02511291392147541, 0.01085206214338541] skip-layers: [11, 10, 8, 4]
step:875/5550 val_loss:3.384728 train_time:207024ms step_avg:236.60ms x-lambda: 0.9397879838943481 lambdas: [-0.06150885671377182, -0.17326626181602478, -0.01934584230184555, 0.004312209784984589] skip-layers: [11, 10, 8, 4]
step:1000/5550 val_loss:3.349533 train_time:237606ms step_avg:237.61ms x-lambda: 0.9262447953224182 lambdas: [-0.06645113974809647, -0.1920686960220337, -0.013674331828951836, 0.004367112182080746] skip-layers: [11, 10, 8, 4]
step:1125/5550 val_loss:3.318109 train_time:268192ms step_avg:238.39ms x-lambda: 0.9110462665557861 lambdas: [-0.07415442913770676, -0.2099488526582718, -0.00966726802289486, -0.000598011480178684] skip-layers: [11, 10, 8, 4]
step:1250/5550 val_loss:3.293850 train_time:300095ms step_avg:240.08ms x-lambda: 0.8977408409118652 lambdas: [-0.07780654728412628, -0.22028331458568573, -0.005331095308065414, 0.0006915570702403784] skip-layers: [11, 10, 8, 4]
step:1375/5550 val_loss:3.271996 train_time:332122ms step_avg:241.54ms x-lambda: 0.8797719478607178 lambdas: [-0.08301014453172684, -0.2305338829755783, -0.004690078087151051, -0.00263269548304379] skip-layers: [11, 10, 8, 4]
step:1500/5550 val_loss:3.252919 train_time:363035ms step_avg:242.02ms x-lambda: 0.8668206930160522 lambdas: [-0.08710739761590958, -0.2381313592195511, -0.0033143889158964157, -0.00496993213891983] skip-layers: [11, 10, 8, 4]
step:1625/5550 val_loss:3.236759 train_time:394039ms step_avg:242.49ms x-lambda: 0.8520835638046265 lambdas: [-0.0886477679014206, -0.2412545382976532, -0.00019157017231918871, -0.002922599669545889] skip-layers: [11, 10, 8, 4]
step:1750/5550 val_loss:3.220460 train_time:427066ms step_avg:244.04ms x-lambda: 0.8381295204162598 lambdas: [-0.09212245047092438, -0.2451385110616684, 0.0006864077877253294, -0.0060063013806939125] skip-layers: [11, 10, 8, 4]
step:1875/5550 val_loss:3.202939 train_time:458140ms step_avg:244.34ms x-lambda: 0.8259211778640747 lambdas: [-0.09399745613336563, -0.246064692735672, 0.0022457565646618605, -0.006676072254776955] skip-layers: [11, 10, 8, 4]
step:2000/5550 val_loss:3.187746 train_time:489410ms step_avg:244.70ms x-lambda: 0.8152629733085632 lambdas: [-0.09446519613265991, -0.24546760320663452, 0.004861438646912575, -0.005075653083622456] skip-layers: [11, 10, 8, 4]
step:2125/5550 val_loss:3.172286 train_time:521792ms step_avg:245.55ms x-lambda: 0.8076366186141968 lambdas: [-0.09577394276857376, -0.2462494969367981, 0.0029310877434909344, -0.005174699705094099] skip-layers: [11, 10, 8, 4]
step:2250/5550 val_loss:3.158892 train_time:557415ms step_avg:247.74ms x-lambda: 0.8014088869094849 lambdas: [-0.09733042120933533, -0.24595949053764343, 0.0028989771381020546, -0.006559181492775679] skip-layers: [11, 10, 8, 4]
step:2375/5550 val_loss:3.147761 train_time:594087ms step_avg:250.14ms x-lambda: 0.7908099889755249 lambdas: [-0.09827204048633575, -0.24348677694797516, 0.003532948438078165, -0.006842041853815317] skip-layers: [11, 10, 8, 4]
step:2500/5550 val_loss:3.135829 train_time:625383ms step_avg:250.15ms x-lambda: 0.786112368106842 lambdas: [-0.09780840575695038, -0.24221815168857574, 0.005080899223685265, -0.00546011608093977] skip-layers: [11, 10, 8, 4]
step:2625/5550 val_loss:3.124204 train_time:656591ms step_avg:250.13ms x-lambda: 0.7795149683952332 lambdas: [-0.0979146659374237, -0.24170586466789246, 0.005827418062835932, -0.0073532299138605595] skip-layers: [11, 10, 8, 4]
step:2750/5550 val_loss:3.112606 train_time:688911ms step_avg:250.51ms x-lambda: 0.7750285863876343 lambdas: [-0.09948523342609406, -0.23947978019714355, 0.00504359882324934, -0.007210303097963333] skip-layers: [11, 10, 8, 4]
step:2875/5550 val_loss:3.103705 train_time:720156ms step_avg:250.49ms x-lambda: 0.7703827619552612 lambdas: [-0.09863503277301788, -0.2383616864681244, 0.004477315116673708, -0.006879006512463093] skip-layers: [11, 10, 8, 4]
step:3000/5550 val_loss:3.092597 train_time:751452ms step_avg:250.48ms x-lambda: 0.7698014974594116 lambdas: [-0.0981307327747345, -0.23744551837444305, 0.005327207036316395, -0.0068404534831643105] skip-layers: [11, 10, 8, 4]
step:3125/5550 val_loss:3.081916 train_time:782742ms step_avg:250.48ms x-lambda: 0.7655152678489685 lambdas: [-0.10038620233535767, -0.23827239871025085, 0.0044376845471560955, -0.007910938002169132] skip-layers: [11, 10, 8, 4]
step:3250/5550 val_loss:3.069975 train_time:813991ms step_avg:250.46ms x-lambda: 0.7663502097129822 lambdas: [-0.09799148887395859, -0.23522593080997467, 0.005154276732355356, -0.00784264039248228] skip-layers: [11, 10, 8, 4]
step:3375/5550 val_loss:3.061306 train_time:846268ms step_avg:250.75ms x-lambda: 0.7639603018760681 lambdas: [-0.09831515699625015, -0.23603922128677368, 0.004979274235665798, -0.008516260422766209] skip-layers: [11, 10, 8, 4]
step:3500/5550 val_loss:3.052193 train_time:877578ms step_avg:250.74ms x-lambda: 0.7623688578605652 lambdas: [-0.09952843189239502, -0.23331031203269958, 0.005159167107194662, -0.0082295723259449] skip-layers: [11, 10, 8, 4]
step:3625/5550 val_loss:3.043738 train_time:911058ms step_avg:251.33ms x-lambda: 0.7641695737838745 lambdas: [-0.09815807640552521, -0.2308434247970581, 0.004727147985249758, -0.008925529196858406] skip-layers: [11, 10, 8, 4]
step:3750/5550 val_loss:3.034187 train_time:943435ms step_avg:251.58ms x-lambda: 0.7632062435150146 lambdas: [-0.09910432994365692, -0.23094671964645386, 0.0058496142737567425, -0.007735523860901594] skip-layers: [11, 10, 8, 4]
step:3875/5550 val_loss:3.025117 train_time:974806ms step_avg:251.56ms x-lambda: 0.7683290243148804 lambdas: [-0.09792224317789078, -0.2308994084596634, 0.00497023668140173, -0.008169109001755714] skip-layers: [11, 10, 8, 4]
step:4000/5550 val_loss:3.015825 train_time:1007169ms step_avg:251.79ms x-lambda: 0.7695551514625549 lambdas: [-0.09733042865991592, -0.22981341183185577, 0.005224922671914101, -0.0081865219399333] skip-layers: [11, 10, 8, 4]
step:4125/5550 val_loss:3.006523 train_time:1038582ms step_avg:251.78ms x-lambda: 0.7719829082489014 lambdas: [-0.09737064689397812, -0.22964324057102203, 0.005556107498705387, -0.007503338158130646] skip-layers: [11, 10, 8, 4]
step:4250/5550 val_loss:2.998628 train_time:1070186ms step_avg:251.81ms x-lambda: 0.776818037033081 lambdas: [-0.09708429872989655, -0.2301972508430481, 0.00462551973760128, -0.00839327648282051] skip-layers: [11, 10, 8, 4]
step:4375/5550 val_loss:2.989306 train_time:1101824ms step_avg:251.85ms x-lambda: 0.7788499593734741 lambdas: [-0.09807374328374863, -0.23127765953540802, 0.004062446299940348, -0.009081658907234669] skip-layers: [11, 10, 8, 4]
step:4500/5550 val_loss:2.981011 train_time:1137770ms step_avg:252.84ms x-lambda: 0.7828851938247681 lambdas: [-0.09767557680606842, -0.2310103327035904, 0.004020277876406908, -0.008164732716977596] skip-layers: [11, 10, 8, 4]
step:4625/5550 val_loss:2.971615 train_time:1170706ms step_avg:253.13ms x-lambda: 0.7893067002296448 lambdas: [-0.09726613014936447, -0.22937728464603424, 0.003390587167814374, -0.010373865254223347] skip-layers: [11, 10, 8, 4]
step:4750/5550 val_loss:2.962410 train_time:1204784ms step_avg:253.64ms x-lambda: 0.7948523163795471 lambdas: [-0.09706892818212509, -0.23049142956733704, 0.003979790490120649, -0.0073641398921608925] skip-layers: [11, 10, 8, 4]
step:4875/5550 val_loss:2.953499 train_time:1237978ms step_avg:253.94ms x-lambda: 0.8003972172737122 lambdas: [-0.09660061448812485, -0.2311054915189743, 0.003508335677906871, -0.00816014688462019] skip-layers: [11, 10, 8, 4]
step:5000/5550 val_loss:2.945419 train_time:1272005ms step_avg:254.40ms x-lambda: 0.8070151209831238 lambdas: [-0.09670823067426682, -0.23155218362808228, 0.0031217460054904222, -0.008631096221506596] skip-layers: [11, 10, 8, 4]
step:5125/5550 val_loss:2.937772 train_time:1304328ms step_avg:254.50ms x-lambda: 0.813026487827301 lambdas: [-0.09632337093353271, -0.23261189460754395, 0.0030776248313486576, -0.008898616768419743] skip-layers: [11, 10, 8, 4]
step:5250/5550 val_loss:2.930582 train_time:1340148ms step_avg:255.27ms x-lambda: 0.8174304962158203 lambdas: [-0.09691820293664932, -0.2319263517856598, 0.002381579950451851, -0.008577484637498856] skip-layers: [11, 10, 8, 4]
step:5375/5550 val_loss:2.924090 train_time:1372788ms step_avg:255.40ms x-lambda: 0.823767364025116 lambdas: [-0.09658925235271454, -0.23389026522636414, 0.001999658765271306, -0.008694726973772049] skip-layers: [11, 10, 8, 4]
step:5500/5550 val_loss:2.919321 train_time:1405651ms step_avg:255.57ms x-lambda: 0.8279781937599182 lambdas: [-0.0959368497133255, -0.23358574509620667, 0.0022034328430891037, -0.009205462411046028] skip-layers: [11, 10, 8, 4]
step:5550/5550 val_loss:2.918114 train_time:1418892ms step_avg:255.66ms x-lambda: 0.8287822008132935 lambdas: [-0.09589733928442001, -0.2340214103460312, 0.0017598075792193413, -0.008761690929532051] skip-layers: [11, 10, 8, 4]

## 8000-add-skip-multiple-4-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.12ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11]
step:125/5550 val_loss:4.263803 train_time:28628ms step_avg:229.03ms x-lambda: 1.0413451194763184 lambdas: [0.035125669091939926, 0.0406842976808548, 0.04422539845108986, 0.04725686460733414] skip-layers: [14, 13, 12, 11]
step:250/5550 val_loss:3.853429 train_time:57424ms step_avg:229.70ms x-lambda: 0.9937204122543335 lambdas: [0.011860484257340431, 0.026355380192399025, 0.02714851312339306, 0.025949131697416306] skip-layers: [14, 13, 12, 11]
step:375/5550 val_loss:3.676628 train_time:86714ms step_avg:231.24ms x-lambda: 0.9774311780929565 lambdas: [0.001953961793333292, 0.011352467350661755, -0.0004600540269166231, -0.0165438000112772] skip-layers: [14, 13, 12, 11]
step:500/5550 val_loss:3.561399 train_time:116439ms step_avg:232.88ms x-lambda: 0.9750711917877197 lambdas: [-0.0036343149840831757, 0.0018472245428711176, -0.022128188982605934, -0.05377430468797684] skip-layers: [14, 13, 12, 11]
step:625/5550 val_loss:3.481845 train_time:146358ms step_avg:234.17ms x-lambda: 0.9668205380439758 lambdas: [-0.01194967795163393, -0.00864425953477621, -0.04354231804609299, -0.09037616103887558] skip-layers: [14, 13, 12, 11]
step:750/5550 val_loss:3.430506 train_time:176571ms step_avg:235.43ms x-lambda: 0.966060221195221 lambdas: [-0.013943069614470005, -0.0128750866279006, -0.05770344287157059, -0.11890935152769089] skip-layers: [14, 13, 12, 11]
step:875/5550 val_loss:3.383381 train_time:206848ms step_avg:236.40ms x-lambda: 0.9637912511825562 lambdas: [-0.015024429187178612, -0.016496997326612473, -0.07070965319871902, -0.1448708474636078] skip-layers: [14, 13, 12, 11]
step:1000/5550 val_loss:3.348026 train_time:237409ms step_avg:237.41ms x-lambda: 0.9573988318443298 lambdas: [-0.018015656620264053, -0.02132725715637207, -0.08395839482545853, -0.1700560599565506] skip-layers: [14, 13, 12, 11]
step:1125/5550 val_loss:3.319688 train_time:269047ms step_avg:239.15ms x-lambda: 0.9534882307052612 lambdas: [-0.01964610442519188, -0.024017317220568657, -0.09370826184749603, -0.18998275697231293] skip-layers: [14, 13, 12, 11]
step:1250/5550 val_loss:3.293712 train_time:300845ms step_avg:240.68ms x-lambda: 0.9517830610275269 lambdas: [-0.01773441769182682, -0.02377663366496563, -0.09944821149110794, -0.20420904457569122] skip-layers: [14, 13, 12, 11]
step:1375/5550 val_loss:3.273399 train_time:331700ms step_avg:241.24ms x-lambda: 0.9448832869529724 lambdas: [-0.019706901162862778, -0.0273832269012928, -0.10838072001934052, -0.22004079818725586] skip-layers: [14, 13, 12, 11]
step:1500/5550 val_loss:3.255509 train_time:363650ms step_avg:242.43ms x-lambda: 0.941584050655365 lambdas: [-0.019982483237981796, -0.029682453721761703, -0.11554205417633057, -0.23302845656871796] skip-layers: [14, 13, 12, 11]
step:1625/5550 val_loss:3.236706 train_time:394616ms step_avg:242.84ms x-lambda: 0.9377609491348267 lambdas: [-0.018382718786597252, -0.029401760548353195, -0.1189582422375679, -0.24058353900909424] skip-layers: [14, 13, 12, 11]
step:1750/5550 val_loss:3.221802 train_time:425566ms step_avg:243.18ms x-lambda: 0.9331509470939636 lambdas: [-0.018727239221334457, -0.031067125499248505, -0.1237345039844513, -0.24930475652217865] skip-layers: [14, 13, 12, 11]
step:1875/5550 val_loss:3.204410 train_time:456553ms step_avg:243.49ms x-lambda: 0.9289979934692383 lambdas: [-0.018086867406964302, -0.03218517079949379, -0.12816068530082703, -0.2559139132499695] skip-layers: [14, 13, 12, 11]
step:2000/5550 val_loss:3.187888 train_time:488975ms step_avg:244.49ms x-lambda: 0.9255903959274292 lambdas: [-0.01898624375462532, -0.034640468657016754, -0.13182155787944794, -0.2619606852531433] skip-layers: [14, 13, 12, 11]
step:2125/5550 val_loss:3.173573 train_time:521424ms step_avg:245.38ms x-lambda: 0.9236798286437988 lambdas: [-0.018566474318504333, -0.0355939157307148, -0.13506478071212769, -0.2661862373352051] skip-layers: [14, 13, 12, 11]
step:2250/5550 val_loss:3.159102 train_time:552679ms step_avg:245.64ms x-lambda: 0.9221048355102539 lambdas: [-0.01810857281088829, -0.03689420223236084, -0.13784044981002808, -0.2687607705593109] skip-layers: [14, 13, 12, 11]
step:2375/5550 val_loss:3.147382 train_time:583957ms step_avg:245.88ms x-lambda: 0.9194204807281494 lambdas: [-0.01773792877793312, -0.038366932421922684, -0.1392805129289627, -0.2709499001502991] skip-layers: [14, 13, 12, 11]
step:2500/5550 val_loss:3.135865 train_time:615180ms step_avg:246.07ms x-lambda: 0.9180801510810852 lambdas: [-0.017301445826888084, -0.03957459703087807, -0.1417180746793747, -0.27257582545280457] skip-layers: [14, 13, 12, 11]
step:2625/5550 val_loss:3.124631 train_time:648572ms step_avg:247.07ms x-lambda: 0.9176527857780457 lambdas: [-0.016041861847043037, -0.039926137775182724, -0.14343012869358063, -0.2735161781311035] skip-layers: [14, 13, 12, 11]
step:2750/5550 val_loss:3.113799 train_time:679808ms step_avg:247.20ms x-lambda: 0.9154682755470276 lambdas: [-0.015793485566973686, -0.041460294276475906, -0.1464228332042694, -0.2763291001319885] skip-layers: [14, 13, 12, 11]
step:2875/5550 val_loss:3.104169 train_time:711040ms step_avg:247.32ms x-lambda: 0.9150018095970154 lambdas: [-0.015564155764877796, -0.041912276297807693, -0.14678867161273956, -0.27580389380455017] skip-layers: [14, 13, 12, 11]
step:3000/5550 val_loss:3.092978 train_time:742272ms step_avg:247.42ms x-lambda: 0.9137290716171265 lambdas: [-0.014353104867041111, -0.04352732375264168, -0.14858748018741608, -0.27666351199150085] skip-layers: [14, 13, 12, 11]
step:3125/5550 val_loss:3.081918 train_time:773515ms step_avg:247.52ms x-lambda: 0.9134346842765808 lambdas: [-0.014795704744756222, -0.045380812138319016, -0.15072032809257507, -0.27818572521209717] skip-layers: [14, 13, 12, 11]
step:3250/5550 val_loss:3.070231 train_time:806879ms step_avg:248.27ms x-lambda: 0.914677619934082 lambdas: [-0.013600527308881283, -0.04513297230005264, -0.1506471335887909, -0.27797096967697144] skip-layers: [14, 13, 12, 11]
step:3375/5550 val_loss:3.061786 train_time:840338ms step_avg:248.99ms x-lambda: 0.9155720472335815 lambdas: [-0.013127235695719719, -0.04677891731262207, -0.15255065262317657, -0.27883756160736084] skip-layers: [14, 13, 12, 11]
step:3500/5550 val_loss:3.052846 train_time:872747ms step_avg:249.36ms x-lambda: 0.9163213968276978 lambdas: [-0.012284308671951294, -0.04809197783470154, -0.15436458587646484, -0.2805418372154236] skip-layers: [14, 13, 12, 11]
step:3625/5550 val_loss:3.044086 train_time:904020ms step_avg:249.38ms x-lambda: 0.9189660549163818 lambdas: [-0.010583254508674145, -0.048050496727228165, -0.15519391000270844, -0.2798757255077362] skip-layers: [14, 13, 12, 11]
step:3750/5550 val_loss:3.034837 train_time:935259ms step_avg:249.40ms x-lambda: 0.9197335839271545 lambdas: [-0.009617299772799015, -0.047981712967157364, -0.15552973747253418, -0.2802342176437378] skip-layers: [14, 13, 12, 11]
step:3875/5550 val_loss:3.025939 train_time:967751ms step_avg:249.74ms x-lambda: 0.9231515526771545 lambdas: [-0.0074247270822525024, -0.04797694832086563, -0.15613168478012085, -0.28024494647979736] skip-layers: [14, 13, 12, 11]
step:4000/5550 val_loss:3.016170 train_time:1000180ms step_avg:250.05ms x-lambda: 0.9260435700416565 lambdas: [-0.007325665559619665, -0.0496971532702446, -0.15781043469905853, -0.28086400032043457] skip-layers: [14, 13, 12, 11]
step:4125/5550 val_loss:3.007068 train_time:1032615ms step_avg:250.33ms x-lambda: 0.9294301867485046 lambdas: [-0.0055125500075519085, -0.04994741827249527, -0.15805914998054504, -0.2814391851425171] skip-layers: [14, 13, 12, 11]
step:4250/5550 val_loss:2.998574 train_time:1066197ms step_avg:250.87ms x-lambda: 0.9330771565437317 lambdas: [-0.0036225789226591587, -0.05023133009672165, -0.15969237685203552, -0.28374677896499634] skip-layers: [14, 13, 12, 11]
step:4375/5550 val_loss:2.989576 train_time:1099944ms step_avg:251.42ms x-lambda: 0.9360432624816895 lambdas: [-0.0035762495826929808, -0.05170932412147522, -0.16093841195106506, -0.2842619717121124] skip-layers: [14, 13, 12, 11]
step:4500/5550 val_loss:2.981573 train_time:1131559ms step_avg:251.46ms x-lambda: 0.9404779076576233 lambdas: [-0.0018195963930338621, -0.052234649658203125, -0.16246937215328217, -0.285089910030365] skip-layers: [14, 13, 12, 11]
step:4625/5550 val_loss:2.971755 train_time:1163332ms step_avg:251.53ms x-lambda: 0.9456034302711487 lambdas: [-0.00018905299657490104, -0.052319757640361786, -0.16220848262310028, -0.28398096561431885] skip-layers: [14, 13, 12, 11]
step:4750/5550 val_loss:2.962763 train_time:1195273ms step_avg:251.64ms x-lambda: 0.9509781002998352 lambdas: [0.0011433459585532546, -0.05269572511315346, -0.16317082941532135, -0.284537136554718] skip-layers: [14, 13, 12, 11]
step:4875/5550 val_loss:2.953913 train_time:1228444ms step_avg:251.99ms x-lambda: 0.9553008079528809 lambdas: [0.002734867623075843, -0.05324292182922363, -0.16376900672912598, -0.2861745357513428] skip-layers: [14, 13, 12, 11]
step:5000/5550 val_loss:2.945724 train_time:1261727ms step_avg:252.35ms x-lambda: 0.9610192179679871 lambdas: [0.0035130989272147417, -0.053020939230918884, -0.164556622505188, -0.2866854667663574] skip-layers: [14, 13, 12, 11]
step:5125/5550 val_loss:2.938011 train_time:1294000ms step_avg:252.49ms x-lambda: 0.9651554226875305 lambdas: [0.004485889803618193, -0.053504038602113724, -0.16521809995174408, -0.28770712018013] skip-layers: [14, 13, 12, 11]
step:5250/5550 val_loss:2.930913 train_time:1327544ms step_avg:252.87ms x-lambda: 0.9696485996246338 lambdas: [0.0051412093453109264, -0.05373163893818855, -0.16587592661380768, -0.2875615060329437] skip-layers: [14, 13, 12, 11]
step:5375/5550 val_loss:2.924440 train_time:1361297ms step_avg:253.26ms x-lambda: 0.9740946888923645 lambdas: [0.006338987033814192, -0.05381500720977783, -0.16666212677955627, -0.28821903467178345] skip-layers: [14, 13, 12, 11]
step:5500/5550 val_loss:2.919585 train_time:1395284ms step_avg:253.69ms x-lambda: 0.9770370721817017 lambdas: [0.0072533125057816505, -0.05365542322397232, -0.16693250834941864, -0.2885391116142273] skip-layers: [14, 13, 12, 11]
step:5550/5550 val_loss:2.918405 train_time:1408517ms step_avg:253.79ms x-lambda: 0.9775353670120239 lambdas: [0.007310487795621157, -0.053806014358997345, -0.16709744930267334, -0.28884243965148926] skip-layers: [14, 13, 12, 11]

## 8000-add-skip-multiple-4-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3]
step:125/5550 val_loss:4.268120 train_time:28635ms step_avg:229.08ms x-lambda: 1.1084953546524048 lambdas: [0.0958959236741066, 0.014968270435929298, 0.003728719661012292, 0.003303682431578636] skip-layers: [0, 1, 2, 3]
step:250/5550 val_loss:3.847856 train_time:58642ms step_avg:234.57ms x-lambda: 1.1016042232513428 lambdas: [0.0798792839050293, -0.04140033200383186, -0.06150153651833534, -0.07507205754518509] skip-layers: [0, 1, 2, 3]
step:375/5550 val_loss:3.673652 train_time:87900ms step_avg:234.40ms x-lambda: 1.0632578134536743 lambdas: [0.06569474190473557, -0.0527663417160511, -0.07873266935348511, -0.1088673323392868] skip-layers: [0, 1, 2, 3]
step:500/5550 val_loss:3.556560 train_time:117569ms step_avg:235.14ms x-lambda: 1.0113351345062256 lambdas: [0.05475064739584923, -0.055650494992733, -0.08956920355558395, -0.12782339751720428] skip-layers: [0, 1, 2, 3]
step:625/5550 val_loss:3.478379 train_time:147462ms step_avg:235.94ms x-lambda: 0.9615374803543091 lambdas: [0.05104627087712288, -0.04999628663063049, -0.09189172834157944, -0.12872406840324402] skip-layers: [0, 1, 2, 3]
step:750/5550 val_loss:3.427139 train_time:177609ms step_avg:236.81ms x-lambda: 0.9139321446418762 lambdas: [0.04381340742111206, -0.04814264923334122, -0.09671877324581146, -0.12819555401802063] skip-layers: [0, 1, 2, 3]
step:875/5550 val_loss:3.378213 train_time:207874ms step_avg:237.57ms x-lambda: 0.8698462843894958 lambdas: [0.04125060886144638, -0.041003379970788956, -0.09435738623142242, -0.11939732730388641] skip-layers: [0, 1, 2, 3]
step:1000/5550 val_loss:3.346592 train_time:239587ms step_avg:239.59ms x-lambda: 0.8286334276199341 lambdas: [0.03648926317691803, -0.03755500167608261, -0.09363771229982376, -0.11241143196821213] skip-layers: [0, 1, 2, 3]
step:1125/5550 val_loss:3.315557 train_time:272230ms step_avg:241.98ms x-lambda: 0.7932304739952087 lambdas: [0.0344482883810997, -0.0324782133102417, -0.09183541685342789, -0.1043156087398529] skip-layers: [0, 1, 2, 3]
step:1250/5550 val_loss:3.292992 train_time:302958ms step_avg:242.37ms x-lambda: 0.7656360268592834 lambdas: [0.034088291227817535, -0.028861993923783302, -0.08815880119800568, -0.09691047668457031] skip-layers: [0, 1, 2, 3]
step:1375/5550 val_loss:3.271291 train_time:333843ms step_avg:242.80ms x-lambda: 0.7326552867889404 lambdas: [0.028631556779146194, -0.028160234913229942, -0.08681274950504303, -0.09287494421005249] skip-layers: [0, 1, 2, 3]
step:1500/5550 val_loss:3.253970 train_time:365754ms step_avg:243.84ms x-lambda: 0.7117443680763245 lambdas: [0.0269304271787405, -0.02662496827542782, -0.08466266095638275, -0.08733102679252625] skip-layers: [0, 1, 2, 3]
step:1625/5550 val_loss:3.237025 train_time:396752ms step_avg:244.15ms x-lambda: 0.6899246573448181 lambdas: [0.027746187523007393, -0.021791566163301468, -0.07937049120664597, -0.08105800300836563] skip-layers: [0, 1, 2, 3]
step:1750/5550 val_loss:3.221067 train_time:427726ms step_avg:244.41ms x-lambda: 0.6700146794319153 lambdas: [0.02640758454799652, -0.019825054332613945, -0.07591361552476883, -0.07546942681074142] skip-layers: [0, 1, 2, 3]
step:1875/5550 val_loss:3.201821 train_time:459894ms step_avg:245.28ms x-lambda: 0.6544256806373596 lambdas: [0.024504179134964943, -0.019151506945490837, -0.07338361442089081, -0.0722661167383194] skip-layers: [0, 1, 2, 3]
step:2000/5550 val_loss:3.187563 train_time:491107ms step_avg:245.55ms x-lambda: 0.6400766372680664 lambdas: [0.023808985948562622, -0.017541706562042236, -0.0710398480296135, -0.06872492283582687] skip-layers: [0, 1, 2, 3]
step:2125/5550 val_loss:3.172232 train_time:524498ms step_avg:246.82ms x-lambda: 0.6301204562187195 lambdas: [0.02338700369000435, -0.016622958704829216, -0.06956558674573898, -0.0670844316482544] skip-layers: [0, 1, 2, 3]
step:2250/5550 val_loss:3.158030 train_time:556947ms step_avg:247.53ms x-lambda: 0.6214160323143005 lambdas: [0.023046689108014107, -0.015398849733173847, -0.06552539020776749, -0.06302323192358017] skip-layers: [0, 1, 2, 3]
step:2375/5550 val_loss:3.147118 train_time:588259ms step_avg:247.69ms x-lambda: 0.6122077703475952 lambdas: [0.020861448720097542, -0.015496578998863697, -0.06512320786714554, -0.06167776510119438] skip-layers: [0, 1, 2, 3]
step:2500/5550 val_loss:3.135271 train_time:621587ms step_avg:248.63ms x-lambda: 0.6074655652046204 lambdas: [0.021929757669568062, -0.013032041490077972, -0.062431689351797104, -0.05866724252700806] skip-layers: [0, 1, 2, 3]
step:2625/5550 val_loss:3.123259 train_time:652794ms step_avg:248.68ms x-lambda: 0.6031491756439209 lambdas: [0.020475704222917557, -0.013883359730243683, -0.06200818717479706, -0.057499051094055176] skip-layers: [0, 1, 2, 3]
step:2750/5550 val_loss:3.112705 train_time:683946ms step_avg:248.71ms x-lambda: 0.5994594693183899 lambdas: [0.019954916089773178, -0.013590192422270775, -0.060031142085790634, -0.05601157620549202] skip-layers: [0, 1, 2, 3]
step:2875/5550 val_loss:3.103080 train_time:716367ms step_avg:249.17ms x-lambda: 0.5959159731864929 lambdas: [0.020352445542812347, -0.012062760069966316, -0.0582960769534111, -0.05306911841034889] skip-layers: [0, 1, 2, 3]
step:3000/5550 val_loss:3.092278 train_time:747685ms step_avg:249.23ms x-lambda: 0.59422367811203 lambdas: [0.018645398318767548, -0.012782539241015911, -0.05690532177686691, -0.05200602486729622] skip-layers: [0, 1, 2, 3]
step:3125/5550 val_loss:3.081370 train_time:782268ms step_avg:250.33ms x-lambda: 0.5920597910881042 lambdas: [0.018936768174171448, -0.01313159242272377, -0.05721081793308258, -0.0522032305598259] skip-layers: [0, 1, 2, 3]
step:3250/5550 val_loss:3.070107 train_time:813550ms step_avg:250.32ms x-lambda: 0.5935714840888977 lambdas: [0.01924448274075985, -0.011058155447244644, -0.05493125692009926, -0.0495721735060215] skip-layers: [0, 1, 2, 3]
step:3375/5550 val_loss:3.061660 train_time:844786ms step_avg:250.31ms x-lambda: 0.5937683582305908 lambdas: [0.017753705382347107, -0.011903766542673111, -0.05470071732997894, -0.05015498772263527] skip-layers: [0, 1, 2, 3]
step:3500/5550 val_loss:3.052488 train_time:876077ms step_avg:250.31ms x-lambda: 0.5934227108955383 lambdas: [0.017914902418851852, -0.012006942182779312, -0.05401775613427162, -0.04783624783158302] skip-layers: [0, 1, 2, 3]
step:3625/5550 val_loss:3.043987 train_time:907347ms step_avg:250.30ms x-lambda: 0.5972778797149658 lambdas: [0.01718880608677864, -0.01075869332998991, -0.05333328619599342, -0.047551628202199936] skip-layers: [0, 1, 2, 3]
step:3750/5550 val_loss:3.033999 train_time:939729ms step_avg:250.59ms x-lambda: 0.5965689420700073 lambdas: [0.017730403691530228, -0.009950594045221806, -0.051508355885744095, -0.04559161886572838] skip-layers: [0, 1, 2, 3]
step:3875/5550 val_loss:3.025539 train_time:974394ms step_avg:251.46ms x-lambda: 0.6037991046905518 lambdas: [0.01739523373544216, -0.010161256417632103, -0.05033538490533829, -0.04588455334305763] skip-layers: [0, 1, 2, 3]
step:4000/5550 val_loss:3.016221 train_time:1005691ms step_avg:251.42ms x-lambda: 0.605462372303009 lambdas: [0.01771453395485878, -0.010491053573787212, -0.05092751607298851, -0.04520437866449356] skip-layers: [0, 1, 2, 3]
step:4125/5550 val_loss:3.006884 train_time:1037070ms step_avg:251.41ms x-lambda: 0.6111856698989868 lambdas: [0.018267454579472542, -0.010527309030294418, -0.051031213253736496, -0.045590683817863464] skip-layers: [0, 1, 2, 3]
step:4250/5550 val_loss:2.998608 train_time:1068661ms step_avg:251.45ms x-lambda: 0.6150883436203003 lambdas: [0.017227141186594963, -0.00970106478780508, -0.048746414482593536, -0.04407539591193199] skip-layers: [0, 1, 2, 3]
step:4375/5550 val_loss:2.989455 train_time:1101462ms step_avg:251.76ms x-lambda: 0.6184192895889282 lambdas: [0.017922358587384224, -0.010143902152776718, -0.04967388138175011, -0.04379401355981827] skip-layers: [0, 1, 2, 3]
step:4500/5550 val_loss:2.981335 train_time:1135325ms step_avg:252.29ms x-lambda: 0.6242997646331787 lambdas: [0.01723274402320385, -0.00964831467717886, -0.0492241196334362, -0.04250174015760422] skip-layers: [0, 1, 2, 3]
step:4625/5550 val_loss:2.972050 train_time:1170296ms step_avg:253.04ms x-lambda: 0.6314198970794678 lambdas: [0.015757976099848747, -0.009342332370579243, -0.04770936444401741, -0.04357195273041725] skip-layers: [0, 1, 2, 3]
step:4750/5550 val_loss:2.962763 train_time:1202212ms step_avg:253.10ms x-lambda: 0.6383771300315857 lambdas: [0.0170629620552063, -0.007960936054587364, -0.04796813428401947, -0.04190585017204285] skip-layers: [0, 1, 2, 3]
step:4875/5550 val_loss:2.953824 train_time:1234218ms step_avg:253.17ms x-lambda: 0.644209086894989 lambdas: [0.01672143116593361, -0.008056733757257462, -0.04714639484882355, -0.042157284915447235] skip-layers: [0, 1, 2, 3]
step:5000/5550 val_loss:2.945754 train_time:1267406ms step_avg:253.48ms x-lambda: 0.6519907712936401 lambdas: [0.016228830441832542, -0.008951948955655098, -0.047868214547634125, -0.04221140965819359] skip-layers: [0, 1, 2, 3]
step:5125/5550 val_loss:2.938099 train_time:1299694ms step_avg:253.60ms x-lambda: 0.660229504108429 lambdas: [0.01689022220671177, -0.008054031990468502, -0.04719359427690506, -0.04093974083662033] skip-layers: [0, 1, 2, 3]
step:5250/5550 val_loss:2.931026 train_time:1333260ms step_avg:253.95ms x-lambda: 0.6668869853019714 lambdas: [0.01621248759329319, -0.008276385255157948, -0.047254521399736404, -0.04137658700346947] skip-layers: [0, 1, 2, 3]
step:5375/5550 val_loss:2.924539 train_time:1365850ms step_avg:254.11ms x-lambda: 0.6743927001953125 lambdas: [0.017155639827251434, -0.008913467638194561, -0.04709852114319801, -0.04130043089389801] skip-layers: [0, 1, 2, 3]
step:5500/5550 val_loss:2.919673 train_time:1398673ms step_avg:254.30ms x-lambda: 0.680705726146698 lambdas: [0.01670757308602333, -0.008940319530665874, -0.047018151730298996, -0.04087242856621742] skip-layers: [0, 1, 2, 3]
step:5550/5550 val_loss:2.918516 train_time:1411922ms step_avg:254.40ms x-lambda: 0.6818865537643433 lambdas: [0.016545074060559273, -0.008759411983191967, -0.04698120430111885, -0.041054617613554] skip-layers: [0, 1, 2, 3]

## 8000-add-skip-multiple-4-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [3, 5, 6, 11]
step:125/5550 val_loss:4.259625 train_time:28927ms step_avg:231.42ms x-lambda: 1.0882768630981445 lambdas: [0.0024556685239076614, 0.008192239329218864, 0.025233177468180656, 0.06931179761886597] skip-layers: [3, 5, 6, 11]
step:250/5550 val_loss:3.854371 train_time:57967ms step_avg:231.87ms x-lambda: 1.0561505556106567 lambdas: [-0.011224573478102684, -0.009080905467271805, -0.013869939371943474, 0.0088186739012599] skip-layers: [3, 5, 6, 11]
step:375/5550 val_loss:3.680265 train_time:87433ms step_avg:233.15ms x-lambda: 0.99802565574646 lambdas: [-0.008747505955398083, -0.010850892402231693, -0.015542438253760338, -0.01878371089696884] skip-layers: [3, 5, 6, 11]
step:500/5550 val_loss:3.563729 train_time:117319ms step_avg:234.64ms x-lambda: 0.9375501871109009 lambdas: [-0.010598570108413696, -0.014271490275859833, -0.0180185716599226, -0.026417944580316544] skip-layers: [3, 5, 6, 11]
step:625/5550 val_loss:3.486396 train_time:147387ms step_avg:235.82ms x-lambda: 0.8878584504127502 lambdas: [-0.00855786819010973, -0.01106999721378088, -0.01631774567067623, -0.025507796555757523] skip-layers: [3, 5, 6, 11]
step:750/5550 val_loss:3.431621 train_time:177753ms step_avg:237.00ms x-lambda: 0.8461715579032898 lambdas: [-0.009205786511301994, -0.012256484478712082, -0.015627624467015266, -0.025489643216133118] skip-layers: [3, 5, 6, 11]
step:875/5550 val_loss:3.386072 train_time:208229ms step_avg:237.98ms x-lambda: 0.8069354295730591 lambdas: [-0.008084219880402088, -0.011759192682802677, -0.013802220113575459, -0.023359743878245354] skip-layers: [3, 5, 6, 11]
step:1000/5550 val_loss:3.352139 train_time:238915ms step_avg:238.92ms x-lambda: 0.7729333639144897 lambdas: [-0.009899374097585678, -0.012545481324195862, -0.01569516584277153, -0.022826673462986946] skip-layers: [3, 5, 6, 11]
step:1125/5550 val_loss:3.321753 train_time:269661ms step_avg:239.70ms x-lambda: 0.7447378635406494 lambdas: [-0.009756281971931458, -0.011888455599546432, -0.014555027708411217, -0.021231602877378464] skip-layers: [3, 5, 6, 11]
step:1250/5550 val_loss:3.297454 train_time:301266ms step_avg:241.01ms x-lambda: 0.7227818369865417 lambdas: [-0.007246605586260557, -0.008732398971915245, -0.011529898270964622, -0.017770331352949142] skip-layers: [3, 5, 6, 11]
step:1375/5550 val_loss:3.274349 train_time:333080ms step_avg:242.24ms x-lambda: 0.6985822319984436 lambdas: [-0.008166631683707237, -0.009943836368620396, -0.012005612254142761, -0.017179938033223152] skip-layers: [3, 5, 6, 11]
step:1500/5550 val_loss:3.255481 train_time:364125ms step_avg:242.75ms x-lambda: 0.6808270215988159 lambdas: [-0.006811321713030338, -0.009399555623531342, -0.011049645952880383, -0.015258497558534145] skip-layers: [3, 5, 6, 11]
step:1625/5550 val_loss:3.240881 train_time:396389ms step_avg:243.93ms x-lambda: 0.6612384915351868 lambdas: [-0.00698742875829339, -0.009592162445187569, -0.010759002529084682, -0.016617290675640106] skip-layers: [3, 5, 6, 11]
step:1750/5550 val_loss:3.223922 train_time:428590ms step_avg:244.91ms x-lambda: 0.6448677182197571 lambdas: [-0.0068630618043243885, -0.009061915799975395, -0.009790413081645966, -0.014796077273786068] skip-layers: [3, 5, 6, 11]
step:1875/5550 val_loss:3.206188 train_time:460758ms step_avg:245.74ms x-lambda: 0.635761022567749 lambdas: [-0.006765998899936676, -0.007128954865038395, -0.00778790470212698, -0.013139058835804462] skip-layers: [3, 5, 6, 11]
step:2000/5550 val_loss:3.191467 train_time:492079ms step_avg:246.04ms x-lambda: 0.6218641996383667 lambdas: [-0.008019674569368362, -0.010994261130690575, -0.010981819592416286, -0.014755398035049438] skip-layers: [3, 5, 6, 11]
step:2125/5550 val_loss:3.175738 train_time:523426ms step_avg:246.32ms x-lambda: 0.6155751347541809 lambdas: [-0.006819076370447874, -0.008770192041993141, -0.009904328733682632, -0.013970337808132172] skip-layers: [3, 5, 6, 11]
step:2250/5550 val_loss:3.161850 train_time:557734ms step_avg:247.88ms x-lambda: 0.6088102459907532 lambdas: [-0.006655407603830099, -0.00824735313653946, -0.009088277816772461, -0.013429036363959312] skip-layers: [3, 5, 6, 11]
step:2375/5550 val_loss:3.149905 train_time:591336ms step_avg:248.98ms x-lambda: 0.603335440158844 lambdas: [-0.006286649964749813, -0.007321685552597046, -0.008794174529612064, -0.0119149349629879] skip-layers: [3, 5, 6, 11]
step:2500/5550 val_loss:3.139328 train_time:625943ms step_avg:250.38ms x-lambda: 0.5979097485542297 lambdas: [-0.005387180019170046, -0.0068252356722950935, -0.007218752522021532, -0.011895593255758286] skip-layers: [3, 5, 6, 11]
step:2625/5550 val_loss:3.127081 train_time:657268ms step_avg:250.39ms x-lambda: 0.5948776006698608 lambdas: [-0.006959254387766123, -0.008573039434850216, -0.009378273971378803, -0.012251386418938637] skip-layers: [3, 5, 6, 11]
step:2750/5550 val_loss:3.116237 train_time:688623ms step_avg:250.41ms x-lambda: 0.5926141738891602 lambdas: [-0.005153078585863113, -0.007069170009344816, -0.007984193041920662, -0.011714591644704342] skip-layers: [3, 5, 6, 11]
step:2875/5550 val_loss:3.106215 train_time:720005ms step_avg:250.44ms x-lambda: 0.5912557244300842 lambdas: [-0.005736681167036295, -0.006842272821813822, -0.007393457926809788, -0.010994493961334229] skip-layers: [3, 5, 6, 11]
step:3000/5550 val_loss:3.095356 train_time:754697ms step_avg:251.57ms x-lambda: 0.5906875133514404 lambdas: [-0.005206333007663488, -0.005792325362563133, -0.007596250157803297, -0.011310282163321972] skip-layers: [3, 5, 6, 11]
step:3125/5550 val_loss:3.084675 train_time:786103ms step_avg:251.55ms x-lambda: 0.5883667469024658 lambdas: [-0.00476135965436697, -0.007145094685256481, -0.008094131015241146, -0.010933893732726574] skip-layers: [3, 5, 6, 11]
step:3250/5550 val_loss:3.073217 train_time:822971ms step_avg:253.22ms x-lambda: 0.592255711555481 lambdas: [-0.004323398228734732, -0.006688818335533142, -0.006952921859920025, -0.009792556054890156] skip-layers: [3, 5, 6, 11]
step:3375/5550 val_loss:3.065147 train_time:855394ms step_avg:253.45ms x-lambda: 0.5914050936698914 lambdas: [-0.004903994966298342, -0.007320736069232225, -0.007328685838729143, -0.009932274930179119] skip-layers: [3, 5, 6, 11]
step:3500/5550 val_loss:3.055842 train_time:887658ms step_avg:253.62ms x-lambda: 0.5925696492195129 lambdas: [-0.006118197925388813, -0.006771284155547619, -0.007390022277832031, -0.01035474892705679] skip-layers: [3, 5, 6, 11]
step:3625/5550 val_loss:3.046685 train_time:921156ms step_avg:254.11ms x-lambda: 0.5968548059463501 lambdas: [-0.004830691963434219, -0.005827176850289106, -0.006478569004684687, -0.009103692136704922] skip-layers: [3, 5, 6, 11]
step:3750/5550 val_loss:3.037172 train_time:952530ms step_avg:254.01ms x-lambda: 0.596219003200531 lambdas: [-0.004186362028121948, -0.006010926328599453, -0.006626887712627649, -0.009215114638209343] skip-layers: [3, 5, 6, 11]
step:3875/5550 val_loss:3.027933 train_time:985157ms step_avg:254.23ms x-lambda: 0.6037755608558655 lambdas: [-0.004236496053636074, -0.006118117831647396, -0.006891705095767975, -0.009653463959693909] skip-layers: [3, 5, 6, 11]
step:4000/5550 val_loss:3.018501 train_time:1017582ms step_avg:254.40ms x-lambda: 0.6080885529518127 lambdas: [-0.004018755163997412, -0.0050987787544727325, -0.005319186020642519, -0.00828279834240675] skip-layers: [3, 5, 6, 11]
step:4125/5550 val_loss:3.009754 train_time:1050164ms step_avg:254.59ms x-lambda: 0.6137257218360901 lambdas: [-0.0040474021807312965, -0.005430832039564848, -0.005591056775301695, -0.007959538139402866] skip-layers: [3, 5, 6, 11]
step:4250/5550 val_loss:3.001090 train_time:1081801ms step_avg:254.54ms x-lambda: 0.6185572743415833 lambdas: [-0.0046747056767344475, -0.005148863419890404, -0.006219214294105768, -0.008990351110696793] skip-layers: [3, 5, 6, 11]
step:4375/5550 val_loss:2.991922 train_time:1113503ms step_avg:254.52ms x-lambda: 0.621112585067749 lambdas: [-0.005648478865623474, -0.006125331856310368, -0.0072772991843521595, -0.009153475053608418] skip-layers: [3, 5, 6, 11]
step:4500/5550 val_loss:2.984012 train_time:1146327ms step_avg:254.74ms x-lambda: 0.6272560358047485 lambdas: [-0.003638287540525198, -0.006749470718204975, -0.006510596256703138, -0.009112553671002388] skip-layers: [3, 5, 6, 11]
step:4625/5550 val_loss:2.974297 train_time:1181692ms step_avg:255.50ms x-lambda: 0.6362882256507874 lambdas: [-0.004302620887756348, -0.005441281478852034, -0.006394015625119209, -0.008507070131599903] skip-layers: [3, 5, 6, 11]
step:4750/5550 val_loss:2.965080 train_time:1214784ms step_avg:255.74ms x-lambda: 0.6433023810386658 lambdas: [-0.004005608148872852, -0.005068913102149963, -0.005111861974000931, -0.0089342650026083] skip-layers: [3, 5, 6, 11]
step:4875/5550 val_loss:2.956116 train_time:1246974ms step_avg:255.79ms x-lambda: 0.6496587991714478 lambdas: [-0.004048679489642382, -0.005453132092952728, -0.006028274539858103, -0.008432013913989067] skip-layers: [3, 5, 6, 11]
step:5000/5550 val_loss:2.947813 train_time:1280278ms step_avg:256.06ms x-lambda: 0.6586260199546814 lambdas: [-0.004400379024446011, -0.005774662829935551, -0.005140988156199455, -0.008818927221000195] skip-layers: [3, 5, 6, 11]
step:5125/5550 val_loss:2.940235 train_time:1312628ms step_avg:256.12ms x-lambda: 0.666801929473877 lambdas: [-0.004457623697817326, -0.004986715968698263, -0.0059606279246509075, -0.008143861778080463] skip-layers: [3, 5, 6, 11]
step:5250/5550 val_loss:2.933086 train_time:1346244ms step_avg:256.43ms x-lambda: 0.6727862358093262 lambdas: [-0.00424590427428484, -0.005428980104625225, -0.00644349493086338, -0.0074677844531834126] skip-layers: [3, 5, 6, 11]
step:5375/5550 val_loss:2.926733 train_time:1379979ms step_avg:256.74ms x-lambda: 0.6818122267723083 lambdas: [-0.0041850898414850235, -0.004702853038907051, -0.005619548726826906, -0.008431000635027885] skip-layers: [3, 5, 6, 11]
step:5500/5550 val_loss:2.921939 train_time:1412905ms step_avg:256.89ms x-lambda: 0.688137412071228 lambdas: [-0.004318923689424992, -0.005500448867678642, -0.006039439234882593, -0.008154389448463917] skip-layers: [3, 5, 6, 11]
step:5550/5550 val_loss:2.920759 train_time:1426146ms step_avg:256.96ms x-lambda: 0.6889890432357788 lambdas: [-0.004293006379157305, -0.005617890041321516, -0.0062638698145747185, -0.008065427653491497] skip-layers: [3, 5, 6, 11]

## 8000-add-skip-multiple-4-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14]
step:125/5550 val_loss:4.268082 train_time:28643ms step_avg:229.14ms x-lambda: 1.0584660768508911 lambdas: [0.03310512378811836, 0.008362345397472382, 0.06199543550610542, 0.0511980801820755] skip-layers: [1, 2, 7, 14]
step:250/5550 val_loss:3.854198 train_time:57427ms step_avg:229.71ms x-lambda: 1.0204405784606934 lambdas: [-0.01670580357313156, -0.06251995265483856, 0.056187137961387634, 0.030307579785585403] skip-layers: [1, 2, 7, 14]
step:375/5550 val_loss:3.678445 train_time:86619ms step_avg:230.98ms x-lambda: 0.9849180579185486 lambdas: [-0.02889513224363327, -0.09669562429189682, 0.032477688044309616, 0.01247705053538084] skip-layers: [1, 2, 7, 14]
step:500/5550 val_loss:3.563190 train_time:116270ms step_avg:232.54ms x-lambda: 0.9546724557876587 lambdas: [-0.03166523575782776, -0.11873625218868256, 0.01466770563274622, -0.008406700566411018] skip-layers: [1, 2, 7, 14]
step:625/5550 val_loss:3.482645 train_time:146147ms step_avg:233.84ms x-lambda: 0.9280619621276855 lambdas: [-0.027427151799201965, -0.13014580309391022, 0.0058783600106835365, -0.02723989076912403] skip-layers: [1, 2, 7, 14]
step:750/5550 val_loss:3.432330 train_time:176304ms step_avg:235.07ms x-lambda: 0.9038954377174377 lambdas: [-0.02528052218258381, -0.1390930414199829, -0.0015586446970701218, -0.044782642275094986] skip-layers: [1, 2, 7, 14]
step:875/5550 val_loss:3.385022 train_time:206596ms step_avg:236.11ms x-lambda: 0.8788577914237976 lambdas: [-0.020387077704072, -0.1413893848657608, -0.005249476991593838, -0.06136289983987808] skip-layers: [1, 2, 7, 14]
step:1000/5550 val_loss:3.349957 train_time:238284ms step_avg:238.28ms x-lambda: 0.8589152693748474 lambdas: [-0.01435144990682602, -0.13835376501083374, -0.006515195593237877, -0.0733550488948822] skip-layers: [1, 2, 7, 14]
step:1125/5550 val_loss:3.319967 train_time:268900ms step_avg:239.02ms x-lambda: 0.8384868502616882 lambdas: [-0.013224251568317413, -0.13706566393375397, -0.010176141746342182, -0.08710198849439621] skip-layers: [1, 2, 7, 14]
step:1250/5550 val_loss:3.295357 train_time:300825ms step_avg:240.66ms x-lambda: 0.8252725601196289 lambdas: [-0.009024152532219887, -0.13194729387760162, -0.010041230358183384, -0.09612242877483368] skip-layers: [1, 2, 7, 14]
step:1375/5550 val_loss:3.274131 train_time:331691ms step_avg:241.23ms x-lambda: 0.8067691326141357 lambdas: [-0.008715955540537834, -0.12935347855091095, -0.014398230239748955, -0.10674997419118881] skip-layers: [1, 2, 7, 14]
step:1500/5550 val_loss:3.254319 train_time:362533ms step_avg:241.69ms x-lambda: 0.7958005666732788 lambdas: [-0.005210853181779385, -0.12339984625577927, -0.01384607795625925, -0.11262352764606476] skip-layers: [1, 2, 7, 14]
step:1625/5550 val_loss:3.239376 train_time:394621ms step_avg:242.84ms x-lambda: 0.7794979214668274 lambdas: [-0.005312541499733925, -0.12076670676469803, -0.014518051408231258, -0.12112219631671906] skip-layers: [1, 2, 7, 14]
step:1750/5550 val_loss:3.223155 train_time:425596ms step_avg:243.20ms x-lambda: 0.7680928111076355 lambdas: [-0.0024114518892019987, -0.11338704079389572, -0.013623341917991638, -0.12654627859592438] skip-layers: [1, 2, 7, 14]
step:1875/5550 val_loss:3.205174 train_time:457751ms step_avg:244.13ms x-lambda: 0.7615606784820557 lambdas: [-0.0017933649942278862, -0.10911218822002411, -0.013695615343749523, -0.13055309653282166] skip-layers: [1, 2, 7, 14]
step:2000/5550 val_loss:3.188650 train_time:490194ms step_avg:245.10ms x-lambda: 0.7494889497756958 lambdas: [-0.002384953200817108, -0.10648620873689651, -0.015678631141781807, -0.13740693032741547] skip-layers: [1, 2, 7, 14]
step:2125/5550 val_loss:3.174362 train_time:522596ms step_avg:245.93ms x-lambda: 0.7442516088485718 lambdas: [-0.0017256017308682203, -0.10347329080104828, -0.015801485627889633, -0.14015385508537292] skip-layers: [1, 2, 7, 14]
step:2250/5550 val_loss:3.160067 train_time:557106ms step_avg:247.60ms x-lambda: 0.740388810634613 lambdas: [-0.001474401680752635, -0.10005796700716019, -0.016561435535550117, -0.14447849988937378] skip-layers: [1, 2, 7, 14]
step:2375/5550 val_loss:3.148040 train_time:589553ms step_avg:248.23ms x-lambda: 0.7351070046424866 lambdas: [-0.0002617100835777819, -0.0971054956316948, -0.016939816996455193, -0.14697392284870148] skip-layers: [1, 2, 7, 14]
step:2500/5550 val_loss:3.136673 train_time:621931ms step_avg:248.77ms x-lambda: 0.7333997488021851 lambdas: [-6.225908873602748e-05, -0.09365846961736679, -0.017315225675702095, -0.14912493526935577] skip-layers: [1, 2, 7, 14]
step:2625/5550 val_loss:3.125156 train_time:653164ms step_avg:248.82ms x-lambda: 0.7300125360488892 lambdas: [0.0005270621040835977, -0.09190592914819717, -0.017051421105861664, -0.15137402713298798] skip-layers: [1, 2, 7, 14]
step:2750/5550 val_loss:3.114031 train_time:684406ms step_avg:248.87ms x-lambda: 0.7288746237754822 lambdas: [0.0007048011175356805, -0.0901128426194191, -0.016992514953017235, -0.1541796624660492] skip-layers: [1, 2, 7, 14]
step:2875/5550 val_loss:3.104190 train_time:717819ms step_avg:249.68ms x-lambda: 0.7291343212127686 lambdas: [0.0005652479594573379, -0.08565861731767654, -0.018053535372018814, -0.15610149502754211] skip-layers: [1, 2, 7, 14]
step:3000/5550 val_loss:3.093164 train_time:750217ms step_avg:250.07ms x-lambda: 0.7285937070846558 lambdas: [0.00023081491235643625, -0.08634842187166214, -0.018492305651307106, -0.15832433104515076] skip-layers: [1, 2, 7, 14]
step:3125/5550 val_loss:3.082752 train_time:781473ms step_avg:250.07ms x-lambda: 0.7281774878501892 lambdas: [0.0006866400362923741, -0.08437883853912354, -0.019528113305568695, -0.16234245896339417] skip-layers: [1, 2, 7, 14]
step:3250/5550 val_loss:3.071389 train_time:812708ms step_avg:250.06ms x-lambda: 0.7309076189994812 lambdas: [0.0013336425181478262, -0.08198805153369904, -0.01857227459549904, -0.16266101598739624] skip-layers: [1, 2, 7, 14]
step:3375/5550 val_loss:3.063298 train_time:846058ms step_avg:250.68ms x-lambda: 0.7322050929069519 lambdas: [0.00032050604932010174, -0.08271973580121994, -0.019520441070199013, -0.1668936014175415] skip-layers: [1, 2, 7, 14]
step:3500/5550 val_loss:3.054389 train_time:877361ms step_avg:250.67ms x-lambda: 0.734308660030365 lambdas: [-2.325093373656273e-05, -0.0812678262591362, -0.019876038655638695, -0.169056236743927] skip-layers: [1, 2, 7, 14]
step:3625/5550 val_loss:3.045259 train_time:908633ms step_avg:250.66ms x-lambda: 0.7392320036888123 lambdas: [0.0008815524051897228, -0.07917062193155289, -0.0199396051466465, -0.16930003464221954] skip-layers: [1, 2, 7, 14]
step:3750/5550 val_loss:3.035358 train_time:940901ms step_avg:250.91ms x-lambda: 0.7421119809150696 lambdas: [0.0013201299589127302, -0.0773572027683258, -0.01911761611700058, -0.17278645932674408] skip-layers: [1, 2, 7, 14]
step:3875/5550 val_loss:3.026567 train_time:972210ms step_avg:250.89ms x-lambda: 0.7489216923713684 lambdas: [0.0010624545393511653, -0.07668730616569519, -0.02049192786216736, -0.1748104840517044] skip-layers: [1, 2, 7, 14]
step:4000/5550 val_loss:3.017170 train_time:1003525ms step_avg:250.88ms x-lambda: 0.7552423477172852 lambdas: [0.0013885193038731813, -0.07552158087491989, -0.020069491118192673, -0.17777135968208313] skip-layers: [1, 2, 7, 14]
step:4125/5550 val_loss:3.008195 train_time:1034868ms step_avg:250.88ms x-lambda: 0.7611814141273499 lambdas: [0.0016604221891611814, -0.07547448575496674, -0.02032609097659588, -0.18066522479057312] skip-layers: [1, 2, 7, 14]
step:4250/5550 val_loss:2.999575 train_time:1066445ms step_avg:250.93ms x-lambda: 0.7683151364326477 lambdas: [0.0019035600125789642, -0.0740218460559845, -0.020772390067577362, -0.18259263038635254] skip-layers: [1, 2, 7, 14]
step:4375/5550 val_loss:2.990376 train_time:1098029ms step_avg:250.98ms x-lambda: 0.7726355791091919 lambdas: [0.0006780013209208846, -0.07444340735673904, -0.02085920237004757, -0.18680904805660248] skip-layers: [1, 2, 7, 14]
step:4500/5550 val_loss:2.982345 train_time:1131981ms step_avg:251.55ms x-lambda: 0.7804512977600098 lambdas: [0.0015099769225344062, -0.07279989868402481, -0.021772507578134537, -0.18882673978805542] skip-layers: [1, 2, 7, 14]
step:4625/5550 val_loss:2.973006 train_time:1165905ms step_avg:252.09ms x-lambda: 0.7903685569763184 lambdas: [0.000847492425236851, -0.07308317720890045, -0.02343258447945118, -0.19006161391735077] skip-layers: [1, 2, 7, 14]
step:4750/5550 val_loss:2.963511 train_time:1197877ms step_avg:252.18ms x-lambda: 0.7965825796127319 lambdas: [0.0019224408315494657, -0.07234702259302139, -0.020921118557453156, -0.19216397404670715] skip-layers: [1, 2, 7, 14]
step:4875/5550 val_loss:2.954779 train_time:1231009ms step_avg:252.51ms x-lambda: 0.803902804851532 lambdas: [0.0014974011573940516, -0.0724436491727829, -0.021882612258195877, -0.19481001794338226] skip-layers: [1, 2, 7, 14]
step:5000/5550 val_loss:2.946423 train_time:1265325ms step_avg:253.06ms x-lambda: 0.8130961060523987 lambdas: [0.0019264204893261194, -0.07138203084468842, -0.0221745353192091, -0.19754986464977264] skip-layers: [1, 2, 7, 14]
step:5125/5550 val_loss:2.938834 train_time:1298827ms step_avg:253.43ms x-lambda: 0.8208680748939514 lambdas: [0.0022117258049547672, -0.0704779103398323, -0.022022012621164322, -0.1984422206878662] skip-layers: [1, 2, 7, 14]
step:5250/5550 val_loss:2.931577 train_time:1331336ms step_avg:253.59ms x-lambda: 0.8280312418937683 lambdas: [0.0017980090342462063, -0.06920665502548218, -0.02264297567307949, -0.20008787512779236] skip-layers: [1, 2, 7, 14]
step:5375/5550 val_loss:2.925110 train_time:1363944ms step_avg:253.76ms x-lambda: 0.8359595537185669 lambdas: [0.001178403734229505, -0.06949848681688309, -0.02313232608139515, -0.20078164339065552] skip-layers: [1, 2, 7, 14]
step:5500/5550 val_loss:2.920264 train_time:1396808ms step_avg:253.97ms x-lambda: 0.8412323594093323 lambdas: [0.0013795646373182535, -0.0696856826543808, -0.02274530939757824, -0.2010376900434494] skip-layers: [1, 2, 7, 14]
step:5550/5550 val_loss:2.919125 train_time:1410052ms step_avg:254.06ms x-lambda: 0.8420391082763672 lambdas: [0.001353160128928721, -0.06982698291540146, -0.022944828495383263, -0.201232448220253] skip-layers: [1, 2, 7, 14]

## 8000-add-skip-multiple-5-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.32ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9]
step:125/5550 val_loss:4.262244 train_time:28701ms step_avg:229.61ms x-lambda: 1.0295835733413696 lambdas: [0.03586205840110779, 0.04287983477115631, 0.03067583590745926, 0.07163266092538834, 0.03108026459813118] skip-layers: [11, 10, 8, 4, 9]
step:250/5550 val_loss:3.858093 train_time:57571ms step_avg:230.28ms x-lambda: 1.017382025718689 lambdas: [0.01693108305335045, 0.02567400597035885, 0.0008232876425608993, 0.0800708681344986, -0.017799613997340202] skip-layers: [11, 10, 8, 4, 9]
step:375/5550 val_loss:3.675654 train_time:86859ms step_avg:231.62ms x-lambda: 1.027439832687378 lambdas: [0.00035171268973499537, -0.01516981516033411, -0.009136931970715523, 0.04121746867895126, -0.06693542003631592] skip-layers: [11, 10, 8, 4, 9]
step:500/5550 val_loss:3.562229 train_time:117605ms step_avg:235.21ms x-lambda: 1.0226880311965942 lambdas: [-0.014893871732056141, -0.052721861749887466, -0.008142128586769104, 0.008035850711166859, -0.0998738557100296] skip-layers: [11, 10, 8, 4, 9]
step:625/5550 val_loss:3.481192 train_time:147518ms step_avg:236.03ms x-lambda: 1.0157318115234375 lambdas: [-0.026136821135878563, -0.0817183330655098, 0.001588788814842701, -0.012552792206406593, -0.11808957904577255] skip-layers: [11, 10, 8, 4, 9]
step:750/5550 val_loss:3.428587 train_time:178877ms step_avg:238.50ms x-lambda: 1.0021555423736572 lambdas: [-0.03848207741975784, -0.10819465667009354, 0.004594533238559961, -0.027291296049952507, -0.12959440052509308] skip-layers: [11, 10, 8, 4, 9]
step:875/5550 val_loss:3.382618 train_time:210273ms step_avg:240.31ms x-lambda: 0.9871076345443726 lambdas: [-0.04675346612930298, -0.12689916789531708, 0.01142595149576664, -0.03238142281770706, -0.1306941658258438] skip-layers: [11, 10, 8, 4, 9]
step:1000/5550 val_loss:3.347365 train_time:240854ms step_avg:240.85ms x-lambda: 0.967798113822937 lambdas: [-0.057943955063819885, -0.1446555256843567, 0.01318043377250433, -0.03506343811750412, -0.12773942947387695] skip-layers: [11, 10, 8, 4, 9]
step:1125/5550 val_loss:3.318305 train_time:271493ms step_avg:241.33ms x-lambda: 0.9504174590110779 lambdas: [-0.0654957965016365, -0.16104841232299805, 0.015500812791287899, -0.03562447056174278, -0.12328526377677917] skip-layers: [11, 10, 8, 4, 9]
step:1250/5550 val_loss:3.294055 train_time:302300ms step_avg:241.84ms x-lambda: 0.9342988729476929 lambdas: [-0.07144879549741745, -0.17191915214061737, 0.01796942576766014, -0.03388101980090141, -0.11436046659946442] skip-layers: [11, 10, 8, 4, 9]
step:1375/5550 val_loss:3.271829 train_time:334427ms step_avg:243.22ms x-lambda: 0.9142832159996033 lambdas: [-0.0784829780459404, -0.18336668610572815, 0.01569138467311859, -0.03299650177359581, -0.10835323482751846] skip-layers: [11, 10, 8, 4, 9]
step:1500/5550 val_loss:3.251124 train_time:365421ms step_avg:243.61ms x-lambda: 0.8980357646942139 lambdas: [-0.08417973667383194, -0.1919311285018921, 0.016809780150651932, -0.030900945886969566, -0.10061729699373245] skip-layers: [11, 10, 8, 4, 9]
step:1625/5550 val_loss:3.236740 train_time:396409ms step_avg:243.94ms x-lambda: 0.8817946314811707 lambdas: [-0.08659906685352325, -0.19859282672405243, 0.018728280439972878, -0.02737213857471943, -0.09273034334182739] skip-layers: [11, 10, 8, 4, 9]
step:1750/5550 val_loss:3.219996 train_time:427409ms step_avg:244.23ms x-lambda: 0.8638834357261658 lambdas: [-0.09018568694591522, -0.20520609617233276, 0.017651481553912163, -0.027720872312784195, -0.08653145283460617] skip-layers: [11, 10, 8, 4, 9]
step:1875/5550 val_loss:3.202667 train_time:459627ms step_avg:245.13ms x-lambda: 0.8490186929702759 lambdas: [-0.09259012341499329, -0.2110370397567749, 0.01661129854619503, -0.0266867708414793, -0.08227889239788055] skip-layers: [11, 10, 8, 4, 9]
step:2000/5550 val_loss:3.187290 train_time:490917ms step_avg:245.46ms x-lambda: 0.8365883231163025 lambdas: [-0.09359315782785416, -0.2129342257976532, 0.01750064641237259, -0.023907411843538284, -0.0750957652926445] skip-layers: [11, 10, 8, 4, 9]
step:2125/5550 val_loss:3.171875 train_time:522230ms step_avg:245.76ms x-lambda: 0.8259105086326599 lambdas: [-0.09482713788747787, -0.21663038432598114, 0.01654212921857834, -0.02345173805952072, -0.07206295430660248] skip-layers: [11, 10, 8, 4, 9]
step:2250/5550 val_loss:3.158163 train_time:554656ms step_avg:246.51ms x-lambda: 0.816328763961792 lambdas: [-0.09463144838809967, -0.21782800555229187, 0.015753895044326782, -0.023010486736893654, -0.06865426152944565] skip-layers: [11, 10, 8, 4, 9]
step:2375/5550 val_loss:3.146656 train_time:587029ms step_avg:247.17ms x-lambda: 0.8064632415771484 lambdas: [-0.09584712982177734, -0.21943585574626923, 0.014946780167520046, -0.023109130561351776, -0.064914271235466] skip-layers: [11, 10, 8, 4, 9]
step:2500/5550 val_loss:3.134973 train_time:619414ms step_avg:247.77ms x-lambda: 0.7987090945243835 lambdas: [-0.09495346993207932, -0.21919451653957367, 0.014947771094739437, -0.021621286869049072, -0.062477268278598785] skip-layers: [11, 10, 8, 4, 9]
step:2625/5550 val_loss:3.123710 train_time:652810ms step_avg:248.69ms x-lambda: 0.7908835411071777 lambdas: [-0.0950900986790657, -0.22077110409736633, 0.014983086846768856, -0.022044522687792778, -0.059475336223840714] skip-layers: [11, 10, 8, 4, 9]
step:2750/5550 val_loss:3.112588 train_time:684104ms step_avg:248.76ms x-lambda: 0.7866097092628479 lambdas: [-0.09358061105012894, -0.21934252977371216, 0.015674488618969917, -0.019151980057358742, -0.05534978583455086] skip-layers: [11, 10, 8, 4, 9]
step:2875/5550 val_loss:3.102950 train_time:716423ms step_avg:249.19ms x-lambda: 0.7814438939094543 lambdas: [-0.09220000356435776, -0.21979308128356934, 0.015219894237816334, -0.017796263098716736, -0.053916189819574356] skip-layers: [11, 10, 8, 4, 9]
step:3000/5550 val_loss:3.091998 train_time:749855ms step_avg:249.95ms x-lambda: 0.7763278484344482 lambdas: [-0.0928349643945694, -0.21968583762645721, 0.014262164011597633, -0.019714947789907455, -0.05250374600291252] skip-layers: [11, 10, 8, 4, 9]
step:3125/5550 val_loss:3.080812 train_time:782306ms step_avg:250.34ms x-lambda: 0.7737353444099426 lambdas: [-0.09322106838226318, -0.22031952440738678, 0.013476391322910786, -0.018565461039543152, -0.05186435952782631] skip-layers: [11, 10, 8, 4, 9]
step:3250/5550 val_loss:3.069113 train_time:815741ms step_avg:251.00ms x-lambda: 0.7720016241073608 lambdas: [-0.09139793366193771, -0.21879000961780548, 0.013902531005442142, -0.018516559153795242, -0.05030377209186554] skip-layers: [11, 10, 8, 4, 9]
step:3375/5550 val_loss:3.061440 train_time:847027ms step_avg:250.97ms x-lambda: 0.7707503437995911 lambdas: [-0.09119594842195511, -0.21993017196655273, 0.01236665528267622, -0.01905267871916294, -0.04929577559232712] skip-layers: [11, 10, 8, 4, 9]
step:3500/5550 val_loss:3.052042 train_time:880398ms step_avg:251.54ms x-lambda: 0.7681490182876587 lambdas: [-0.09258635342121124, -0.2185567170381546, 0.013544077053666115, -0.019228937104344368, -0.04799232259392738] skip-layers: [11, 10, 8, 4, 9]
step:3625/5550 val_loss:3.042769 train_time:911730ms step_avg:251.51ms x-lambda: 0.7676158547401428 lambdas: [-0.09145250916481018, -0.21750515699386597, 0.013057887554168701, -0.018612567335367203, -0.04633843153715134] skip-layers: [11, 10, 8, 4, 9]
step:3750/5550 val_loss:3.033571 train_time:943024ms step_avg:251.47ms x-lambda: 0.7684771418571472 lambdas: [-0.0910499319434166, -0.21757371723651886, 0.013686315156519413, -0.018656564876437187, -0.04463792219758034] skip-layers: [11, 10, 8, 4, 9]
step:3875/5550 val_loss:3.024648 train_time:974403ms step_avg:251.46ms x-lambda: 0.7715029716491699 lambdas: [-0.09010303020477295, -0.21932247281074524, 0.01242585014551878, -0.01767406053841114, -0.04392118379473686] skip-layers: [11, 10, 8, 4, 9]
step:4000/5550 val_loss:3.015140 train_time:1009069ms step_avg:252.27ms x-lambda: 0.7734888792037964 lambdas: [-0.0893855094909668, -0.21862894296646118, 0.013139749877154827, -0.01766388677060604, -0.04451696574687958] skip-layers: [11, 10, 8, 4, 9]
step:4125/5550 val_loss:3.005743 train_time:1041583ms step_avg:252.51ms x-lambda: 0.77479487657547 lambdas: [-0.08963426202535629, -0.21859660744667053, 0.012515037320554256, -0.017369680106639862, -0.04216081649065018] skip-layers: [11, 10, 8, 4, 9]
step:4250/5550 val_loss:2.997760 train_time:1073225ms step_avg:252.52ms x-lambda: 0.7773392796516418 lambdas: [-0.08809321373701096, -0.21843396127223969, 0.012207573279738426, -0.0171988345682621, -0.042545534670352936] skip-layers: [11, 10, 8, 4, 9]
step:4375/5550 val_loss:2.988493 train_time:1107086ms step_avg:253.05ms x-lambda: 0.7791227698326111 lambdas: [-0.08989576250314713, -0.2199392020702362, 0.011629772372543812, -0.017191903665661812, -0.043371327221393585] skip-layers: [11, 10, 8, 4, 9]
step:4500/5550 val_loss:2.980341 train_time:1138756ms step_avg:253.06ms x-lambda: 0.7845807671546936 lambdas: [-0.08951732516288757, -0.21888256072998047, 0.011253785341978073, -0.01757144369184971, -0.04213975742459297] skip-layers: [11, 10, 8, 4, 9]
step:4625/5550 val_loss:2.970983 train_time:1170553ms step_avg:253.09ms x-lambda: 0.7899633646011353 lambdas: [-0.08962121605873108, -0.21958959102630615, 0.010959410108625889, -0.01914176717400551, -0.040526267141103745] skip-layers: [11, 10, 8, 4, 9]
step:4750/5550 val_loss:2.961814 train_time:1202488ms step_avg:253.16ms x-lambda: 0.7941770553588867 lambdas: [-0.08839516341686249, -0.21956199407577515, 0.012300335802137852, -0.016714878380298615, -0.041107676923274994] skip-layers: [11, 10, 8, 4, 9]
step:4875/5550 val_loss:2.952728 train_time:1235585ms step_avg:253.45ms x-lambda: 0.7990366220474243 lambdas: [-0.08786098659038544, -0.2207917422056198, 0.010999496094882488, -0.01659330353140831, -0.041259896010160446] skip-layers: [11, 10, 8, 4, 9]
step:5000/5550 val_loss:2.944696 train_time:1267804ms step_avg:253.56ms x-lambda: 0.8051172494888306 lambdas: [-0.08809593319892883, -0.22225110232830048, 0.010513361543416977, -0.01698828861117363, -0.041563063859939575] skip-layers: [11, 10, 8, 4, 9]
step:5125/5550 val_loss:2.937110 train_time:1300157ms step_avg:253.69ms x-lambda: 0.8107547163963318 lambdas: [-0.08765316754579544, -0.22277860343456268, 0.010905012488365173, -0.01710999570786953, -0.04118506610393524] skip-layers: [11, 10, 8, 4, 9]
step:5250/5550 val_loss:2.929931 train_time:1332701ms step_avg:253.85ms x-lambda: 0.8143563270568848 lambdas: [-0.08778322488069534, -0.22240455448627472, 0.009528744965791702, -0.016686752438545227, -0.040350332856178284] skip-layers: [11, 10, 8, 4, 9]
step:5375/5550 val_loss:2.923515 train_time:1365346ms step_avg:254.02ms x-lambda: 0.8200239539146423 lambdas: [-0.08756736665964127, -0.22344611585140228, 0.009551186114549637, -0.01655414141714573, -0.04114064201712608] skip-layers: [11, 10, 8, 4, 9]
step:5500/5550 val_loss:2.918711 train_time:1399315ms step_avg:254.42ms x-lambda: 0.8230002522468567 lambdas: [-0.08706342428922653, -0.22417287528514862, 0.009530719369649887, -0.01654822751879692, -0.040646959096193314] skip-layers: [11, 10, 8, 4, 9]
step:5550/5550 val_loss:2.917571 train_time:1412560ms step_avg:254.52ms x-lambda: 0.8236949443817139 lambdas: [-0.08721575140953064, -0.2243674099445343, 0.009520018473267555, -0.01671561412513256, -0.04097339138388634] skip-layers: [11, 10, 8, 4, 9]

## 8000-add-skip-multiple-5-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.16ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10]
step:125/5550 val_loss:4.267007 train_time:29809ms step_avg:238.47ms x-lambda: 1.0351482629776 lambdas: [0.02967890165746212, 0.034989289939403534, 0.03840268403291702, 0.04159391671419144, 0.05153714492917061] skip-layers: [14, 13, 12, 11, 10]
step:250/5550 val_loss:3.848898 train_time:58684ms step_avg:234.74ms x-lambda: 0.9885787963867188 lambdas: [0.0005830114241689444, 0.01749326102435589, 0.01835276372730732, 0.01860039494931698, 0.028399284929037094] skip-layers: [14, 13, 12, 11, 10]
step:375/5550 val_loss:3.676056 train_time:87966ms step_avg:234.58ms x-lambda: 0.9760763645172119 lambdas: [-0.0031976117752492428, 0.014779826626181602, 0.006200697273015976, -0.0021410230547189713, -0.029512561857700348] skip-layers: [14, 13, 12, 11, 10]
step:500/5550 val_loss:3.559346 train_time:117640ms step_avg:235.28ms x-lambda: 0.9722095727920532 lambdas: [-0.0084915766492486, 0.011339799501001835, -0.005619571544229984, -0.019118521362543106, -0.08771297335624695] skip-layers: [14, 13, 12, 11, 10]
step:625/5550 val_loss:3.482396 train_time:147540ms step_avg:236.06ms x-lambda: 0.9685003161430359 lambdas: [-0.010694880969822407, 0.01104297861456871, -0.012532554566860199, -0.02767772786319256, -0.1345689743757248] skip-layers: [14, 13, 12, 11, 10]
step:750/5550 val_loss:3.425673 train_time:178678ms step_avg:238.24ms x-lambda: 0.9630604386329651 lambdas: [-0.014058766886591911, 0.009550338611006737, -0.019718414172530174, -0.03364806994795799, -0.17278778553009033] skip-layers: [14, 13, 12, 11, 10]
step:875/5550 val_loss:3.383120 train_time:209031ms step_avg:238.89ms x-lambda: 0.9542880654335022 lambdas: [-0.017356570810079575, 0.008241408504545689, -0.025416480377316475, -0.03487401828169823, -0.20110726356506348] skip-layers: [14, 13, 12, 11, 10]
step:1000/5550 val_loss:3.349547 train_time:239623ms step_avg:239.62ms x-lambda: 0.9457637071609497 lambdas: [-0.022794492542743683, 0.0027523282915353775, -0.035363905131816864, -0.03862600401043892, -0.22786112129688263] skip-layers: [14, 13, 12, 11, 10]
step:1125/5550 val_loss:3.318200 train_time:270253ms step_avg:240.23ms x-lambda: 0.9370566606521606 lambdas: [-0.027389558032155037, -0.0006027306662872434, -0.04145725443959236, -0.03582796826958656, -0.24398201704025269] skip-layers: [14, 13, 12, 11, 10]
step:1250/5550 val_loss:3.291925 train_time:301026ms step_avg:240.82ms x-lambda: 0.9312837719917297 lambdas: [-0.029566466808319092, -0.0032520226668566465, -0.04607084020972252, -0.03184722736477852, -0.2552606165409088] skip-layers: [14, 13, 12, 11, 10]
step:1375/5550 val_loss:3.270998 train_time:331962ms step_avg:241.43ms x-lambda: 0.9225671887397766 lambdas: [-0.03364358842372894, -0.007298297714442015, -0.051365215331315994, -0.0273713618516922, -0.2643693685531616] skip-layers: [14, 13, 12, 11, 10]
step:1500/5550 val_loss:3.252994 train_time:362933ms step_avg:241.96ms x-lambda: 0.9184806942939758 lambdas: [-0.03473366051912308, -0.010441434569656849, -0.056339237838983536, -0.021325981244444847, -0.27068427205085754] skip-layers: [14, 13, 12, 11, 10]
step:1625/5550 val_loss:3.237583 train_time:393944ms step_avg:242.43ms x-lambda: 0.9091324210166931 lambdas: [-0.0392410084605217, -0.015363316982984543, -0.06221054494380951, -0.0161795224994421, -0.2768513858318329] skip-layers: [14, 13, 12, 11, 10]
step:1750/5550 val_loss:3.220275 train_time:426098ms step_avg:243.48ms x-lambda: 0.9022064805030823 lambdas: [-0.04338409751653671, -0.02064504101872444, -0.06828609853982925, -0.011615036986768246, -0.28023871779441833] skip-layers: [14, 13, 12, 11, 10]
step:1875/5550 val_loss:3.201339 train_time:457226ms step_avg:243.85ms x-lambda: 0.8954126834869385 lambdas: [-0.04674660414457321, -0.025338228791952133, -0.07371407002210617, -0.00695571256801486, -0.28313374519348145] skip-layers: [14, 13, 12, 11, 10]
step:2000/5550 val_loss:3.186818 train_time:493671ms step_avg:246.84ms x-lambda: 0.8912054896354675 lambdas: [-0.048971351236104965, -0.029684389010071754, -0.07797800004482269, -0.0019135491456836462, -0.2832329571247101] skip-layers: [14, 13, 12, 11, 10]
step:2125/5550 val_loss:3.171921 train_time:524980ms step_avg:247.05ms x-lambda: 0.8875744938850403 lambdas: [-0.05082244053483009, -0.03372674435377121, -0.08257092535495758, 0.0017148955957964063, -0.28597337007522583] skip-layers: [14, 13, 12, 11, 10]
step:2250/5550 val_loss:3.157114 train_time:558411ms step_avg:248.18ms x-lambda: 0.8851658701896667 lambdas: [-0.052322547882795334, -0.03718035668134689, -0.08590919524431229, 0.006497865077108145, -0.284990131855011] skip-layers: [14, 13, 12, 11, 10]
step:2375/5550 val_loss:3.146449 train_time:589746ms step_avg:248.31ms x-lambda: 0.8817335963249207 lambdas: [-0.05448554456233978, -0.04178125783801079, -0.09032783657312393, 0.009506570175290108, -0.284551203250885] skip-layers: [14, 13, 12, 11, 10]
step:2500/5550 val_loss:3.134165 train_time:621101ms step_avg:248.44ms x-lambda: 0.8810663819313049 lambdas: [-0.05455648899078369, -0.044442735612392426, -0.09275505691766739, 0.013972152024507523, -0.2837928831577301] skip-layers: [14, 13, 12, 11, 10]
step:2625/5550 val_loss:3.122926 train_time:652404ms step_avg:248.54ms x-lambda: 0.87735915184021 lambdas: [-0.05708484351634979, -0.048977330327034, -0.09623018652200699, 0.016212649643421173, -0.2839779555797577] skip-layers: [14, 13, 12, 11, 10]
step:2750/5550 val_loss:3.112138 train_time:684785ms step_avg:249.01ms x-lambda: 0.877478837966919 lambdas: [-0.056793585419654846, -0.05149396136403084, -0.09816327691078186, 0.018604841083288193, -0.28145164251327515] skip-layers: [14, 13, 12, 11, 10]
step:2875/5550 val_loss:3.102094 train_time:717223ms step_avg:249.47ms x-lambda: 0.8774897456169128 lambdas: [-0.05743318796157837, -0.0540260411798954, -0.10083483159542084, 0.022213930264115334, -0.2802579700946808] skip-layers: [14, 13, 12, 11, 10]
step:3000/5550 val_loss:3.091389 train_time:748583ms step_avg:249.53ms x-lambda: 0.8769102096557617 lambdas: [-0.05809175968170166, -0.056802429258823395, -0.10241569578647614, 0.02454635128378868, -0.2789858281612396] skip-layers: [14, 13, 12, 11, 10]
step:3125/5550 val_loss:3.080535 train_time:784212ms step_avg:250.95ms x-lambda: 0.8770371675491333 lambdas: [-0.058725882321596146, -0.059822894632816315, -0.10473691672086716, 0.026714226230978966, -0.28057387471199036] skip-layers: [14, 13, 12, 11, 10]
step:3250/5550 val_loss:3.069245 train_time:816586ms step_avg:251.26ms x-lambda: 0.878016471862793 lambdas: [-0.05872213840484619, -0.06252433359622955, -0.10581215471029282, 0.028660975396633148, -0.2786644399166107] skip-layers: [14, 13, 12, 11, 10]
step:3375/5550 val_loss:3.060200 train_time:847868ms step_avg:251.22ms x-lambda: 0.8796228170394897 lambdas: [-0.05907730385661125, -0.06531941145658493, -0.10798470675945282, 0.03080807998776436, -0.2798340320587158] skip-layers: [14, 13, 12, 11, 10]
step:3500/5550 val_loss:3.051822 train_time:882546ms step_avg:252.16ms x-lambda: 0.8800086379051208 lambdas: [-0.05961322784423828, -0.06812608987092972, -0.10985817760229111, 0.03198206424713135, -0.27756109833717346] skip-layers: [14, 13, 12, 11, 10]
step:3625/5550 val_loss:3.043392 train_time:913891ms step_avg:252.11ms x-lambda: 0.8819737434387207 lambdas: [-0.059098467230796814, -0.06969068199396133, -0.11106661707162857, 0.03326797112822533, -0.27702805399894714] skip-layers: [14, 13, 12, 11, 10]
step:3750/5550 val_loss:3.033573 train_time:945151ms step_avg:252.04ms x-lambda: 0.883466362953186 lambdas: [-0.0586862750351429, -0.07084071636199951, -0.11109397560358047, 0.034814734011888504, -0.2753180265426636] skip-layers: [14, 13, 12, 11, 10]
step:3875/5550 val_loss:3.024815 train_time:976545ms step_avg:252.01ms x-lambda: 0.8883339762687683 lambdas: [-0.057197388261556625, -0.07215475291013718, -0.11231069266796112, 0.036969009786844254, -0.27596792578697205] skip-layers: [14, 13, 12, 11, 10]
step:4000/5550 val_loss:3.015472 train_time:1007937ms step_avg:251.98ms x-lambda: 0.8904522061347961 lambdas: [-0.05841195955872536, -0.07462864369153976, -0.11282049119472504, 0.03833898901939392, -0.2765617072582245] skip-layers: [14, 13, 12, 11, 10]
step:4125/5550 val_loss:3.006151 train_time:1040481ms step_avg:252.24ms x-lambda: 0.8944650888442993 lambdas: [-0.05697283148765564, -0.07607623934745789, -0.11383261531591415, 0.03865256905555725, -0.2751343250274658] skip-layers: [14, 13, 12, 11, 10]
step:4250/5550 val_loss:2.997895 train_time:1072039ms step_avg:252.24ms x-lambda: 0.8980647921562195 lambdas: [-0.05665889382362366, -0.07726629078388214, -0.11371969431638718, 0.03986595943570137, -0.2759820222854614] skip-layers: [14, 13, 12, 11, 10]
step:4375/5550 val_loss:2.988514 train_time:1106718ms step_avg:252.96ms x-lambda: 0.9008013010025024 lambdas: [-0.05738913267850876, -0.07999526709318161, -0.11560550332069397, 0.04021802172064781, -0.2763397693634033] skip-layers: [14, 13, 12, 11, 10]
step:4500/5550 val_loss:2.980421 train_time:1141478ms step_avg:253.66ms x-lambda: 0.9060747623443604 lambdas: [-0.056998904794454575, -0.08143579214811325, -0.11623299866914749, 0.04117676615715027, -0.2761724293231964] skip-layers: [14, 13, 12, 11, 10]
step:4625/5550 val_loss:2.971204 train_time:1173279ms step_avg:253.68ms x-lambda: 0.9109209775924683 lambdas: [-0.05516998469829559, -0.08223491907119751, -0.116275854408741, 0.04215020686388016, -0.27703356742858887] skip-layers: [14, 13, 12, 11, 10]
step:4750/5550 val_loss:2.961684 train_time:1208530ms step_avg:254.43ms x-lambda: 0.9162807464599609 lambdas: [-0.05464775115251541, -0.08272967487573624, -0.11629631370306015, 0.04357071965932846, -0.2775309383869171] skip-layers: [14, 13, 12, 11, 10]
step:4875/5550 val_loss:2.952887 train_time:1240630ms step_avg:254.49ms x-lambda: 0.921108067035675 lambdas: [-0.05455400422215462, -0.08401955664157867, -0.11760631948709488, 0.04390581697225571, -0.27868497371673584] skip-layers: [14, 13, 12, 11, 10]
step:5000/5550 val_loss:2.944720 train_time:1272811ms step_avg:254.56ms x-lambda: 0.9275707006454468 lambdas: [-0.05382708087563515, -0.08527041226625443, -0.11814258247613907, 0.04536346718668938, -0.2788920998573303] skip-layers: [14, 13, 12, 11, 10]
step:5125/5550 val_loss:2.937161 train_time:1305153ms step_avg:254.66ms x-lambda: 0.9327629208564758 lambdas: [-0.053853731602430344, -0.08613133430480957, -0.11825963109731674, 0.046219293028116226, -0.2806597650051117] skip-layers: [14, 13, 12, 11, 10]
step:5250/5550 val_loss:2.929924 train_time:1339744ms step_avg:255.19ms x-lambda: 0.9373834729194641 lambdas: [-0.05370515584945679, -0.08718840777873993, -0.11866866052150726, 0.04676540940999985, -0.2806335687637329] skip-layers: [14, 13, 12, 11, 10]
step:5375/5550 val_loss:2.923557 train_time:1372399ms step_avg:255.33ms x-lambda: 0.9418490529060364 lambdas: [-0.053433675318956375, -0.08763094991445541, -0.11929310113191605, 0.04768677055835724, -0.28244709968566895] skip-layers: [14, 13, 12, 11, 10]
step:5500/5550 val_loss:2.918739 train_time:1405284ms step_avg:255.51ms x-lambda: 0.9448723196983337 lambdas: [-0.0527944453060627, -0.08805625140666962, -0.11946284770965576, 0.048138588666915894, -0.28257808089256287] skip-layers: [14, 13, 12, 11, 10]
step:5550/5550 val_loss:2.917552 train_time:1420708ms step_avg:255.98ms x-lambda: 0.9454688429832458 lambdas: [-0.052743684500455856, -0.08792446553707123, -0.11945199966430664, 0.04820401966571808, -0.2831731140613556] skip-layers: [14, 13, 12, 11, 10]

## 8000-add-skip-multiple-5-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4]
step:125/5550 val_loss:4.266359 train_time:28707ms step_avg:229.65ms x-lambda: 1.0716431140899658 lambdas: [0.09009110182523727, 0.01012747548520565, -0.010840578004717827, -0.028499167412519455, 0.10924974083900452] skip-layers: [0, 1, 2, 3, 4]
step:250/5550 val_loss:3.852451 train_time:57595ms step_avg:230.38ms x-lambda: 1.0347062349319458 lambdas: [0.08118316531181335, -0.03335466608405113, -0.06958852708339691, -0.12528084218502045, 0.15782828629016876] skip-layers: [0, 1, 2, 3, 4]
step:375/5550 val_loss:3.671538 train_time:86939ms step_avg:231.84ms x-lambda: 1.000925064086914 lambdas: [0.06671387702226639, -0.042372800409793854, -0.08627244085073471, -0.17717225849628448, 0.1544734388589859] skip-layers: [0, 1, 2, 3, 4]
step:500/5550 val_loss:3.555977 train_time:116675ms step_avg:233.35ms x-lambda: 0.9601941704750061 lambdas: [0.059685345739126205, -0.04105718433856964, -0.09095266461372375, -0.20115558803081512, 0.14906977117061615] skip-layers: [0, 1, 2, 3, 4]
step:625/5550 val_loss:3.479744 train_time:147488ms step_avg:235.98ms x-lambda: 0.9172921776771545 lambdas: [0.054088935256004333, -0.03613530099391937, -0.0905904471874237, -0.20907890796661377, 0.1435362845659256] skip-layers: [0, 1, 2, 3, 4]
step:750/5550 val_loss:3.426018 train_time:177695ms step_avg:236.93ms x-lambda: 0.8793219923973083 lambdas: [0.048736393451690674, -0.03317566215991974, -0.0906052365899086, -0.20938515663146973, 0.1349346935749054] skip-layers: [0, 1, 2, 3, 4]
step:875/5550 val_loss:3.380755 train_time:208887ms step_avg:238.73ms x-lambda: 0.8401959538459778 lambdas: [0.04424208775162697, -0.02849762514233589, -0.08690866082906723, -0.20219776034355164, 0.127222940325737] skip-layers: [0, 1, 2, 3, 4]
step:1000/5550 val_loss:3.348569 train_time:239453ms step_avg:239.45ms x-lambda: 0.8052945733070374 lambdas: [0.03875809907913208, -0.026589106768369675, -0.08495035022497177, -0.1928587406873703, 0.11495203524827957] skip-layers: [0, 1, 2, 3, 4]
step:1125/5550 val_loss:3.318797 train_time:270083ms step_avg:240.07ms x-lambda: 0.7747997045516968 lambdas: [0.03489234298467636, -0.02382577583193779, -0.08182654529809952, -0.18142357468605042, 0.10532888770103455] skip-layers: [0, 1, 2, 3, 4]
step:1250/5550 val_loss:3.292451 train_time:300869ms step_avg:240.70ms x-lambda: 0.7504344582557678 lambdas: [0.035412512719631195, -0.019715992733836174, -0.07633418589830399, -0.16732145845890045, 0.09914736449718475] skip-layers: [0, 1, 2, 3, 4]
step:1375/5550 val_loss:3.273298 train_time:331792ms step_avg:241.30ms x-lambda: 0.7237038016319275 lambdas: [0.031103061512112617, -0.020007401704788208, -0.07548976689577103, -0.15936538577079773, 0.08789688348770142] skip-layers: [0, 1, 2, 3, 4]
step:1500/5550 val_loss:3.253659 train_time:362727ms step_avg:241.82ms x-lambda: 0.7030941247940063 lambdas: [0.03010871820151806, -0.01773752272129059, -0.07352928072214127, -0.1496792882680893, 0.08212436735630035] skip-layers: [0, 1, 2, 3, 4]
step:1625/5550 val_loss:3.237250 train_time:393742ms step_avg:242.30ms x-lambda: 0.685385525226593 lambdas: [0.02899070642888546, -0.015559691935777664, -0.06910815834999084, -0.13877931237220764, 0.0771327093243599] skip-layers: [0, 1, 2, 3, 4]
step:1750/5550 val_loss:3.221732 train_time:425937ms step_avg:243.39ms x-lambda: 0.6672053337097168 lambdas: [0.0278555229306221, -0.01292736828327179, -0.06555002927780151, -0.12922611832618713, 0.07068294286727905] skip-layers: [0, 1, 2, 3, 4]
step:1875/5550 val_loss:3.205657 train_time:456989ms step_avg:243.73ms x-lambda: 0.6562239527702332 lambdas: [0.02801956795156002, -0.009733125567436218, -0.06230619549751282, -0.11956724524497986, 0.06660551577806473] skip-layers: [0, 1, 2, 3, 4]
step:2000/5550 val_loss:3.188539 train_time:488278ms step_avg:244.14ms x-lambda: 0.6410646438598633 lambdas: [0.026003029197454453, -0.010474812239408493, -0.061692386865615845, -0.11359260976314545, 0.061311572790145874] skip-layers: [0, 1, 2, 3, 4]
step:2125/5550 val_loss:3.173488 train_time:519633ms step_avg:244.53ms x-lambda: 0.6315270066261292 lambdas: [0.024186713621020317, -0.010656844824552536, -0.060749951750040054, -0.10929055511951447, 0.05632498487830162] skip-layers: [0, 1, 2, 3, 4]
step:2250/5550 val_loss:3.158962 train_time:550997ms step_avg:244.89ms x-lambda: 0.6251029968261719 lambdas: [0.02424200251698494, -0.010367709212005138, -0.059200216084718704, -0.10252413153648376, 0.05142431706190109] skip-layers: [0, 1, 2, 3, 4]
step:2375/5550 val_loss:3.148357 train_time:583432ms step_avg:245.66ms x-lambda: 0.6166045665740967 lambdas: [0.02231038734316826, -0.009848805144429207, -0.058536097407341, -0.09802117198705673, 0.04845589026808739] skip-layers: [0, 1, 2, 3, 4]
step:2500/5550 val_loss:3.136665 train_time:614732ms step_avg:245.89ms x-lambda: 0.6120810508728027 lambdas: [0.023391906172037125, -0.008271174505352974, -0.056081999093294144, -0.09516352415084839, 0.047786690294742584] skip-layers: [0, 1, 2, 3, 4]
step:2625/5550 val_loss:3.125758 train_time:647139ms step_avg:246.53ms x-lambda: 0.6097191572189331 lambdas: [0.02307962253689766, -0.007591817993670702, -0.05468157306313515, -0.08934754878282547, 0.04480458050966263] skip-layers: [0, 1, 2, 3, 4]
step:2750/5550 val_loss:3.113808 train_time:679515ms step_avg:247.10ms x-lambda: 0.6045472025871277 lambdas: [0.021649960428476334, -0.006573349237442017, -0.05313500761985779, -0.0867592990398407, 0.0425272211432457] skip-layers: [0, 1, 2, 3, 4]
step:2875/5550 val_loss:3.104690 train_time:710767ms step_avg:247.22ms x-lambda: 0.601883590221405 lambdas: [0.02165098302066326, -0.007495948113501072, -0.051730986684560776, -0.0825667455792427, 0.03966641053557396] skip-layers: [0, 1, 2, 3, 4]
step:3000/5550 val_loss:3.093432 train_time:742099ms step_avg:247.37ms x-lambda: 0.5995044112205505 lambdas: [0.020212551578879356, -0.007171310018748045, -0.05163520202040672, -0.08096478879451752, 0.039270371198654175] skip-layers: [0, 1, 2, 3, 4]
step:3125/5550 val_loss:3.082559 train_time:773434ms step_avg:247.50ms x-lambda: 0.5985110998153687 lambdas: [0.02022840827703476, -0.006941649597138166, -0.05218920856714249, -0.08017916977405548, 0.036981210112571716] skip-layers: [0, 1, 2, 3, 4]
step:3250/5550 val_loss:3.071134 train_time:806853ms step_avg:248.26ms x-lambda: 0.5996459722518921 lambdas: [0.019811255857348442, -0.006060592830181122, -0.05071093887090683, -0.07657317072153091, 0.03612557798624039] skip-layers: [0, 1, 2, 3, 4]
step:3375/5550 val_loss:3.063146 train_time:840385ms step_avg:249.00ms x-lambda: 0.6000330448150635 lambdas: [0.018137488514184952, -0.0072921933606266975, -0.050937164574861526, -0.07666317373514175, 0.0342252179980278] skip-layers: [0, 1, 2, 3, 4]
step:3500/5550 val_loss:3.054856 train_time:871715ms step_avg:249.06ms x-lambda: 0.5994684100151062 lambdas: [0.017574097961187363, -0.007167653646320105, -0.05019426718354225, -0.07397115230560303, 0.0322008915245533] skip-layers: [0, 1, 2, 3, 4]
step:3625/5550 val_loss:3.045105 train_time:903018ms step_avg:249.11ms x-lambda: 0.6029112339019775 lambdas: [0.01917969435453415, -0.005874390713870525, -0.04858950898051262, -0.07236216962337494, 0.03185032308101654] skip-layers: [0, 1, 2, 3, 4]
step:3750/5550 val_loss:3.035398 train_time:935328ms step_avg:249.42ms x-lambda: 0.6030475497245789 lambdas: [0.019367065280675888, -0.006193808279931545, -0.04749143496155739, -0.07084184139966965, 0.031739648431539536] skip-layers: [0, 1, 2, 3, 4]
step:3875/5550 val_loss:3.026948 train_time:966692ms step_avg:249.47ms x-lambda: 0.6106550097465515 lambdas: [0.01888040080666542, -0.0043840366415679455, -0.04801182448863983, -0.0695212259888649, 0.03090282343327999] skip-layers: [0, 1, 2, 3, 4]
step:4000/5550 val_loss:3.017116 train_time:998046ms step_avg:249.51ms x-lambda: 0.6128948330879211 lambdas: [0.018392149358987808, -0.004230454098433256, -0.047096796333789825, -0.06738394498825073, 0.029562735930085182] skip-layers: [0, 1, 2, 3, 4]
step:4125/5550 val_loss:3.008227 train_time:1030566ms step_avg:249.83ms x-lambda: 0.618566632270813 lambdas: [0.01799563504755497, -0.00598424207419157, -0.0468788705766201, -0.06681462377309799, 0.02791106328368187] skip-layers: [0, 1, 2, 3, 4]
step:4250/5550 val_loss:2.999731 train_time:1062142ms step_avg:249.92ms x-lambda: 0.621198832988739 lambdas: [0.01734558492898941, -0.005465311463922262, -0.046239085495471954, -0.06480620056390762, 0.028002426028251648] skip-layers: [0, 1, 2, 3, 4]
step:4375/5550 val_loss:2.990796 train_time:1093801ms step_avg:250.01ms x-lambda: 0.6258368492126465 lambdas: [0.018795471638441086, -0.005489443428814411, -0.0467844158411026, -0.06499537825584412, 0.02749621495604515] skip-layers: [0, 1, 2, 3, 4]
step:4500/5550 val_loss:2.982722 train_time:1128705ms step_avg:250.82ms x-lambda: 0.6307133436203003 lambdas: [0.018159540370106697, -0.006362944841384888, -0.04542205110192299, -0.06448771804571152, 0.026415305212140083] skip-layers: [0, 1, 2, 3, 4]
step:4625/5550 val_loss:2.973111 train_time:1160520ms step_avg:250.92ms x-lambda: 0.6381708979606628 lambdas: [0.01682598516345024, -0.005825659725815058, -0.04482497274875641, -0.06374966353178024, 0.02579951100051403] skip-layers: [0, 1, 2, 3, 4]
step:4750/5550 val_loss:2.963859 train_time:1192493ms step_avg:251.05ms x-lambda: 0.6459779143333435 lambdas: [0.01843482255935669, -0.004034137818962336, -0.04617000371217728, -0.061606019735336304, 0.026381047442555428] skip-layers: [0, 1, 2, 3, 4]
step:4875/5550 val_loss:2.955067 train_time:1225801ms step_avg:251.45ms x-lambda: 0.6525369882583618 lambdas: [0.017874471843242645, -0.004554583225399256, -0.04530913755297661, -0.06241980567574501, 0.025366635993123055] skip-layers: [0, 1, 2, 3, 4]
step:5000/5550 val_loss:2.946796 train_time:1257968ms step_avg:251.59ms x-lambda: 0.6603971123695374 lambdas: [0.01703209988772869, -0.0048475079238414764, -0.045603685081005096, -0.061419807374477386, 0.02561994083225727] skip-layers: [0, 1, 2, 3, 4]
step:5125/5550 val_loss:2.939210 train_time:1291301ms step_avg:251.96ms x-lambda: 0.6683746576309204 lambdas: [0.017408542335033417, -0.00401889206841588, -0.04408535733819008, -0.060633789747953415, 0.025916002690792084] skip-layers: [0, 1, 2, 3, 4]
step:5250/5550 val_loss:2.932046 train_time:1323833ms step_avg:252.16ms x-lambda: 0.6759262084960938 lambdas: [0.016615519300103188, -0.004133994225412607, -0.04454676806926727, -0.059954509139060974, 0.024446459487080574] skip-layers: [0, 1, 2, 3, 4]
step:5375/5550 val_loss:2.925625 train_time:1356452ms step_avg:252.36ms x-lambda: 0.6852308511734009 lambdas: [0.01708206720650196, -0.0036054833326488733, -0.043896134942770004, -0.06046275794506073, 0.02430632710456848] skip-layers: [0, 1, 2, 3, 4]
step:5500/5550 val_loss:2.920841 train_time:1390374ms step_avg:252.80ms x-lambda: 0.6906929612159729 lambdas: [0.01708180643618107, -0.0049155093729496, -0.04465965926647186, -0.0597236268222332, 0.024615857750177383] skip-layers: [0, 1, 2, 3, 4]
step:5550/5550 val_loss:2.919676 train_time:1403618ms step_avg:252.90ms x-lambda: 0.6922534704208374 lambdas: [0.016765659675002098, -0.004489703103899956, -0.044509418308734894, -0.05972394347190857, 0.02477933280169964] skip-layers: [0, 1, 2, 3, 4]

## 8000-add-skip-multiple-5-method-random-0

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:0.54ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [2, 0, 6, 9, 11]
step:125/5550 val_loss:4.264972 train_time:28702ms step_avg:229.61ms x-lambda: 1.1062883138656616 lambdas: [0.032713163644075394, 0.0007948404527269304, 0.014429043978452682, 0.02280728705227375, 0.024583572521805763] skip-layers: [2, 0, 6, 9, 11]
step:250/5550 val_loss:3.857624 train_time:57588ms step_avg:230.35ms x-lambda: 1.081295371055603 lambdas: [-0.010670085437595844, -0.01407061330974102, -0.002301332075148821, -0.023523593321442604, -0.010447521694004536] skip-layers: [2, 0, 6, 9, 11]
step:375/5550 val_loss:3.679636 train_time:86939ms step_avg:231.84ms x-lambda: 1.010201334953308 lambdas: [-0.01766885258257389, -0.015824103727936745, -0.005507122725248337, -0.02942321076989174, -0.01865941658616066] skip-layers: [2, 0, 6, 9, 11]
step:500/5550 val_loss:3.565579 train_time:116727ms step_avg:233.45ms x-lambda: 0.9438551664352417 lambdas: [-0.021712303161621094, -0.01886739768087864, -0.010016660206019878, -0.029990706592798233, -0.02121572569012642] skip-layers: [2, 0, 6, 9, 11]
step:625/5550 val_loss:3.485600 train_time:146732ms step_avg:234.77ms x-lambda: 0.8890318870544434 lambdas: [-0.02015812136232853, -0.017853932455182076, -0.009372524917125702, -0.026485858485102654, -0.019270362332463264] skip-layers: [2, 0, 6, 9, 11]
step:750/5550 val_loss:3.433067 train_time:176965ms step_avg:235.95ms x-lambda: 0.8443785309791565 lambdas: [-0.02321602776646614, -0.020524268969893456, -0.01210416853427887, -0.028130104765295982, -0.019857265055179596] skip-layers: [2, 0, 6, 9, 11]
step:875/5550 val_loss:3.385612 train_time:207300ms step_avg:236.91ms x-lambda: 0.8017798662185669 lambdas: [-0.020565543323755264, -0.016938988119363785, -0.010949276387691498, -0.024113329127430916, -0.01724696159362793] skip-layers: [2, 0, 6, 9, 11]
step:1000/5550 val_loss:3.352427 train_time:237916ms step_avg:237.92ms x-lambda: 0.7640195488929749 lambdas: [-0.02078390121459961, -0.017350656911730766, -0.011698083020746708, -0.02480166405439377, -0.01736525259912014] skip-layers: [2, 0, 6, 9, 11]
step:1125/5550 val_loss:3.323412 train_time:271747ms step_avg:241.55ms x-lambda: 0.7314009070396423 lambdas: [-0.02045370824635029, -0.0167703814804554, -0.01065460778772831, -0.02363256737589836, -0.016797777265310287] skip-layers: [2, 0, 6, 9, 11]
step:1250/5550 val_loss:3.297509 train_time:303558ms step_avg:242.85ms x-lambda: 0.7093330025672913 lambdas: [-0.01745763048529625, -0.013455672189593315, -0.008516327477991581, -0.019874153658747673, -0.012948594056069851] skip-layers: [2, 0, 6, 9, 11]
step:1375/5550 val_loss:3.276552 train_time:334546ms step_avg:243.31ms x-lambda: 0.6851423382759094 lambdas: [-0.017405938357114792, -0.01360445935279131, -0.008421936072409153, -0.018504971638321877, -0.015132980421185493] skip-layers: [2, 0, 6, 9, 11]
step:1500/5550 val_loss:3.258252 train_time:365537ms step_avg:243.69ms x-lambda: 0.6637636423110962 lambdas: [-0.018413009122014046, -0.014804788865149021, -0.011578993871808052, -0.020252689719200134, -0.01463843509554863] skip-layers: [2, 0, 6, 9, 11]
step:1625/5550 val_loss:3.242897 train_time:399721ms step_avg:245.98ms x-lambda: 0.6479775309562683 lambdas: [-0.014611097052693367, -0.010798166505992413, -0.006444775499403477, -0.015507896430790424, -0.011200699023902416] skip-layers: [2, 0, 6, 9, 11]
step:1750/5550 val_loss:3.225507 train_time:430758ms step_avg:246.15ms x-lambda: 0.6283664703369141 lambdas: [-0.01613130047917366, -0.011619473807513714, -0.0074613275937736034, -0.017247145995497704, -0.012037626467645168] skip-layers: [2, 0, 6, 9, 11]
step:1875/5550 val_loss:3.208829 train_time:461862ms step_avg:246.33ms x-lambda: 0.6196785569190979 lambdas: [-0.013743238523602486, -0.009136982262134552, -0.006020088214427233, -0.014893747866153717, -0.009812912903726101] skip-layers: [2, 0, 6, 9, 11]
step:2000/5550 val_loss:3.191405 train_time:493212ms step_avg:246.61ms x-lambda: 0.6036357283592224 lambdas: [-0.014358065091073513, -0.010488850064575672, -0.007097138557583094, -0.01551947183907032, -0.009741513058543205] skip-layers: [2, 0, 6, 9, 11]
step:2125/5550 val_loss:3.176407 train_time:525565ms step_avg:247.32ms x-lambda: 0.5984143614768982 lambdas: [-0.014424639753997326, -0.01037032064050436, -0.006614364217966795, -0.01452531386166811, -0.010845404118299484] skip-layers: [2, 0, 6, 9, 11]
step:2250/5550 val_loss:3.163400 train_time:556893ms step_avg:247.51ms x-lambda: 0.59319669008255 lambdas: [-0.01293946523219347, -0.00950255524367094, -0.005673583596944809, -0.014199447818100452, -0.009884294122457504] skip-layers: [2, 0, 6, 9, 11]
step:2375/5550 val_loss:3.152248 train_time:589363ms step_avg:248.15ms x-lambda: 0.5843170285224915 lambdas: [-0.014089561067521572, -0.00981961376965046, -0.006901917513459921, -0.01475229486823082, -0.01107106264680624] skip-layers: [2, 0, 6, 9, 11]
step:2500/5550 val_loss:3.139323 train_time:620674ms step_avg:248.27ms x-lambda: 0.5819863677024841 lambdas: [-0.013131330721080303, -0.008358531631529331, -0.005553442053496838, -0.013259033672511578, -0.008641193620860577] skip-layers: [2, 0, 6, 9, 11]
step:2625/5550 val_loss:3.127602 train_time:651970ms step_avg:248.37ms x-lambda: 0.5777818560600281 lambdas: [-0.012415495701134205, -0.008521736599504948, -0.005665650591254234, -0.012846166267991066, -0.009045327082276344] skip-layers: [2, 0, 6, 9, 11]
step:2750/5550 val_loss:3.117542 train_time:683235ms step_avg:248.45ms x-lambda: 0.5731984376907349 lambdas: [-0.01225521694868803, -0.008150708861649036, -0.006393022835254669, -0.013278516009449959, -0.00902821309864521] skip-layers: [2, 0, 6, 9, 11]
step:2875/5550 val_loss:3.107426 train_time:715653ms step_avg:248.92ms x-lambda: 0.573314905166626 lambdas: [-0.012160110287368298, -0.00697451364248991, -0.005694126710295677, -0.012899473309516907, -0.008711547590792179] skip-layers: [2, 0, 6, 9, 11]
step:3000/5550 val_loss:3.096344 train_time:747008ms step_avg:249.00ms x-lambda: 0.5719721913337708 lambdas: [-0.012829702347517014, -0.008814176544547081, -0.005634763278067112, -0.01274621207267046, -0.009807477705180645] skip-layers: [2, 0, 6, 9, 11]
step:3125/5550 val_loss:3.085621 train_time:778338ms step_avg:249.07ms x-lambda: 0.5721142888069153 lambdas: [-0.012597372755408287, -0.007775596808642149, -0.005584673024713993, -0.013349838554859161, -0.008631379343569279] skip-layers: [2, 0, 6, 9, 11]
step:3250/5550 val_loss:3.074592 train_time:809607ms step_avg:249.11ms x-lambda: 0.5738024115562439 lambdas: [-0.011370470747351646, -0.0067253196612000465, -0.004059952683746815, -0.01192641444504261, -0.007706217467784882] skip-layers: [2, 0, 6, 9, 11]
step:3375/5550 val_loss:3.065444 train_time:845097ms step_avg:250.40ms x-lambda: 0.5748602747917175 lambdas: [-0.012269525788724422, -0.008113033138215542, -0.004974693525582552, -0.011621975339949131, -0.00925850123167038] skip-layers: [2, 0, 6, 9, 11]
step:3500/5550 val_loss:3.056530 train_time:876440ms step_avg:250.41ms x-lambda: 0.5745002627372742 lambdas: [-0.011738047935068607, -0.0066655417904257774, -0.005519090685993433, -0.012851892039179802, -0.009096963331103325] skip-layers: [2, 0, 6, 9, 11]
step:3625/5550 val_loss:3.047479 train_time:907770ms step_avg:250.42ms x-lambda: 0.5778920650482178 lambdas: [-0.01095976959913969, -0.007166367955505848, -0.004722275771200657, -0.011537628248333931, -0.008402026258409023] skip-layers: [2, 0, 6, 9, 11]
step:3750/5550 val_loss:3.038001 train_time:939082ms step_avg:250.42ms x-lambda: 0.5789778828620911 lambdas: [-0.010959370993077755, -0.005933978594839573, -0.004792860243469477, -0.011770053766667843, -0.008486378006637096] skip-layers: [2, 0, 6, 9, 11]
step:3875/5550 val_loss:3.029409 train_time:971472ms step_avg:250.70ms x-lambda: 0.5865461826324463 lambdas: [-0.010925520211458206, -0.005913917440921068, -0.004822119604796171, -0.011197916232049465, -0.007854324765503407] skip-layers: [2, 0, 6, 9, 11]
step:4000/5550 val_loss:3.019983 train_time:1002835ms step_avg:250.71ms x-lambda: 0.5870848894119263 lambdas: [-0.01065085269510746, -0.007453819736838341, -0.004959371872246265, -0.010528657585382462, -0.006704601924866438] skip-layers: [2, 0, 6, 9, 11]
step:4125/5550 val_loss:3.010851 train_time:1034246ms step_avg:250.73ms x-lambda: 0.5940848588943481 lambdas: [-0.010354269295930862, -0.005922421347349882, -0.0045139784924685955, -0.010142615996301174, -0.0071848551742732525] skip-layers: [2, 0, 6, 9, 11]
step:4250/5550 val_loss:3.002613 train_time:1066903ms step_avg:251.04ms x-lambda: 0.5980381965637207 lambdas: [-0.01030875276774168, -0.006914791185408831, -0.004041098058223724, -0.010546775534749031, -0.007380193565040827] skip-layers: [2, 0, 6, 9, 11]
step:4375/5550 val_loss:2.993435 train_time:1102644ms step_avg:252.03ms x-lambda: 0.602087140083313 lambdas: [-0.011171838268637657, -0.007317391689866781, -0.00518957432359457, -0.01066056452691555, -0.008346731774508953] skip-layers: [2, 0, 6, 9, 11]
step:4500/5550 val_loss:2.985184 train_time:1136285ms step_avg:252.51ms x-lambda: 0.6073107123374939 lambdas: [-0.009981559589505196, -0.006556110456585884, -0.005980733782052994, -0.010408343747258186, -0.007305930834263563] skip-layers: [2, 0, 6, 9, 11]
step:4625/5550 val_loss:2.975361 train_time:1168097ms step_avg:252.56ms x-lambda: 0.614804744720459 lambdas: [-0.009657597169280052, -0.006420559715479612, -0.004736797418445349, -0.010589134879410267, -0.0064369626343250275] skip-layers: [2, 0, 6, 9, 11]
step:4750/5550 val_loss:2.966155 train_time:1200102ms step_avg:252.65ms x-lambda: 0.6221831440925598 lambdas: [-0.0098639614880085, -0.006304985377937555, -0.0034199466463178396, -0.009366846643388271, -0.006787667516618967] skip-layers: [2, 0, 6, 9, 11]
step:4875/5550 val_loss:2.957540 train_time:1233420ms step_avg:253.01ms x-lambda: 0.6287859082221985 lambdas: [-0.009803460910916328, -0.0055574760772287846, -0.004594400990754366, -0.010176473297178745, -0.007023863028734922] skip-layers: [2, 0, 6, 9, 11]
step:5000/5550 val_loss:2.949232 train_time:1265638ms step_avg:253.13ms x-lambda: 0.6354553699493408 lambdas: [-0.01015479490160942, -0.006280763074755669, -0.004469935782253742, -0.009754191152751446, -0.0055134836584329605] skip-layers: [2, 0, 6, 9, 11]
step:5125/5550 val_loss:2.941547 train_time:1299170ms step_avg:253.50ms x-lambda: 0.6430919170379639 lambdas: [-0.008762256242334843, -0.0057485164143145084, -0.0037536323070526123, -0.009839754551649094, -0.006614771671593189] skip-layers: [2, 0, 6, 9, 11]
step:5250/5550 val_loss:2.934321 train_time:1332825ms step_avg:253.87ms x-lambda: 0.6499513983726501 lambdas: [-0.009191480465233326, -0.006124116480350494, -0.0041851806454360485, -0.009330329485237598, -0.006363355088979006] skip-layers: [2, 0, 6, 9, 11]
step:5375/5550 val_loss:2.927958 train_time:1365492ms step_avg:254.05ms x-lambda: 0.6581477522850037 lambdas: [-0.009307022206485271, -0.005421721376478672, -0.003850448876619339, -0.009792582131922245, -0.006341654807329178] skip-layers: [2, 0, 6, 9, 11]
step:5500/5550 val_loss:2.923174 train_time:1400665ms step_avg:254.67ms x-lambda: 0.6631251573562622 lambdas: [-0.00938550103455782, -0.006210018880665302, -0.0037670673336833715, -0.009409829042851925, -0.006862044334411621] skip-layers: [2, 0, 6, 9, 11]
step:5550/5550 val_loss:2.921976 train_time:1414849ms step_avg:254.93ms x-lambda: 0.6643219590187073 lambdas: [-0.009204220958054066, -0.006143846083432436, -0.004314027726650238, -0.009862263686954975, -0.006615606136620045] skip-layers: [2, 0, 6, 9, 11]

## 8000-add-skip-multiple-5-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.31ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6]
step:125/5550 val_loss:4.273887 train_time:28737ms step_avg:229.89ms x-lambda: 1.0473023653030396 lambdas: [0.030962251126766205, -0.0008124744053930044, 0.0496365986764431, 0.043458011001348495, 0.055350467562675476] skip-layers: [1, 2, 7, 14, 6]
step:250/5550 val_loss:3.847309 train_time:57644ms step_avg:230.58ms x-lambda: 1.0283631086349487 lambdas: [-0.020020226016640663, -0.07336009293794632, 0.04248370975255966, 0.035228319466114044, 0.040420908480882645] skip-layers: [1, 2, 7, 14, 6]
step:375/5550 val_loss:3.673322 train_time:86964ms step_avg:231.90ms x-lambda: 1.0051180124282837 lambdas: [-0.03535093739628792, -0.10453508049249649, 0.029162071645259857, 0.024544253945350647, 0.006485234946012497] skip-layers: [1, 2, 7, 14, 6]
step:500/5550 val_loss:3.557015 train_time:116698ms step_avg:233.40ms x-lambda: 0.9786846041679382 lambdas: [-0.04044458270072937, -0.12178236991167068, 0.023472627624869347, 0.004205386620014906, -0.01983758807182312] skip-layers: [1, 2, 7, 14, 6]
step:625/5550 val_loss:3.479813 train_time:147637ms step_avg:236.22ms x-lambda: 0.9542649388313293 lambdas: [-0.03690518066287041, -0.12708334624767303, 0.025148820132017136, -0.014357751235365868, -0.03218841925263405] skip-layers: [1, 2, 7, 14, 6]
step:750/5550 val_loss:3.425747 train_time:177882ms step_avg:237.18ms x-lambda: 0.9315881729125977 lambdas: [-0.03380503132939339, -0.12963387370109558, 0.02409268729388714, -0.033172477036714554, -0.040526773780584335] skip-layers: [1, 2, 7, 14, 6]
step:875/5550 val_loss:3.382963 train_time:208248ms step_avg:238.00ms x-lambda: 0.9073373079299927 lambdas: [-0.028887128457427025, -0.12712392210960388, 0.024294134229421616, -0.05143624171614647, -0.04340261593461037] skip-layers: [1, 2, 7, 14, 6]
step:1000/5550 val_loss:3.347429 train_time:238870ms step_avg:238.87ms x-lambda: 0.8871376514434814 lambdas: [-0.024844447150826454, -0.12188179790973663, 0.023148084059357643, -0.0672193169593811, -0.04587985575199127] skip-layers: [1, 2, 7, 14, 6]
step:1125/5550 val_loss:3.318543 train_time:269533ms step_avg:239.58ms x-lambda: 0.8667035102844238 lambdas: [-0.025186801329255104, -0.11931406706571579, 0.02039140649139881, -0.08528811484575272, -0.047728992998600006] skip-layers: [1, 2, 7, 14, 6]
step:1250/5550 val_loss:3.295414 train_time:301375ms step_avg:241.10ms x-lambda: 0.8547999262809753 lambdas: [-0.019784636795520782, -0.11132436990737915, 0.02216748706996441, -0.09543191641569138, -0.04577680304646492] skip-layers: [1, 2, 7, 14, 6]
step:1375/5550 val_loss:3.272302 train_time:332358ms step_avg:241.71ms x-lambda: 0.8375431895256042 lambdas: [-0.019355259835720062, -0.10764281451702118, 0.019386447966098785, -0.10787571221590042, -0.04684792831540108] skip-layers: [1, 2, 7, 14, 6]
step:1500/5550 val_loss:3.253510 train_time:363287ms step_avg:242.19ms x-lambda: 0.8247436285018921 lambdas: [-0.01796228066086769, -0.10366751253604889, 0.017794763669371605, -0.11817135661840439, -0.04703819751739502] skip-layers: [1, 2, 7, 14, 6]
step:1625/5550 val_loss:3.237272 train_time:394363ms step_avg:242.68ms x-lambda: 0.810928463935852 lambdas: [-0.01633519120514393, -0.0985635295510292, 0.016717951744794846, -0.12735241651535034, -0.046416811645030975] skip-layers: [1, 2, 7, 14, 6]
step:1750/5550 val_loss:3.221029 train_time:425396ms step_avg:243.08ms x-lambda: 0.7983564138412476 lambdas: [-0.015352830290794373, -0.09407230466604233, 0.018581338226795197, -0.1362740844488144, -0.04509644955396652] skip-layers: [1, 2, 7, 14, 6]
step:1875/5550 val_loss:3.205858 train_time:456443ms step_avg:243.44ms x-lambda: 0.7943155169487 lambdas: [-0.01208901684731245, -0.0877893716096878, 0.0191327054053545, -0.13994307816028595, -0.041861847043037415] skip-layers: [1, 2, 7, 14, 6]
step:2000/5550 val_loss:3.189128 train_time:488832ms step_avg:244.42ms x-lambda: 0.7856512069702148 lambdas: [-0.011567970737814903, -0.08532703667879105, 0.016809482127428055, -0.14899969100952148, -0.041583351790905] skip-layers: [1, 2, 7, 14, 6]
step:2125/5550 val_loss:3.173748 train_time:520177ms step_avg:244.79ms x-lambda: 0.7814272046089172 lambdas: [-0.011724707670509815, -0.08406422287225723, 0.015123668126761913, -0.15558069944381714, -0.04246952384710312] skip-layers: [1, 2, 7, 14, 6]
step:2250/5550 val_loss:3.159848 train_time:552635ms step_avg:245.62ms x-lambda: 0.7774702310562134 lambdas: [-0.011432136408984661, -0.08051211386919022, 0.014307230710983276, -0.16171279549598694, -0.04093707725405693] skip-layers: [1, 2, 7, 14, 6]
step:2375/5550 val_loss:3.148576 train_time:585033ms step_avg:246.33ms x-lambda: 0.773772656917572 lambdas: [-0.011560477316379547, -0.07761462032794952, 0.013527385890483856, -0.16648045182228088, -0.04061354696750641] skip-layers: [1, 2, 7, 14, 6]
step:2500/5550 val_loss:3.136883 train_time:620421ms step_avg:248.17ms x-lambda: 0.7729101181030273 lambdas: [-0.009173093363642693, -0.07563041895627975, 0.013482572510838509, -0.17174959182739258, -0.03960275650024414] skip-layers: [1, 2, 7, 14, 6]
step:2625/5550 val_loss:3.124684 train_time:651770ms step_avg:248.29ms x-lambda: 0.7714426517486572 lambdas: [-0.009043420664966106, -0.07353813201189041, 0.013371236622333527, -0.17525149881839752, -0.03940388187766075] skip-layers: [1, 2, 7, 14, 6]
step:2750/5550 val_loss:3.113462 train_time:684113ms step_avg:248.77ms x-lambda: 0.7715415954589844 lambdas: [-0.008273022249341011, -0.0713224709033966, 0.013309324160218239, -0.17920705676078796, -0.03730093315243721] skip-layers: [1, 2, 7, 14, 6]
step:2875/5550 val_loss:3.104746 train_time:715438ms step_avg:248.85ms x-lambda: 0.771446943283081 lambdas: [-0.008621317334473133, -0.06945327669382095, 0.012224952690303326, -0.1845713108778, -0.037974778562784195] skip-layers: [1, 2, 7, 14, 6]
step:3000/5550 val_loss:3.094264 train_time:746822ms step_avg:248.94ms x-lambda: 0.7726693153381348 lambdas: [-0.01019112765789032, -0.06949078291654587, 0.010451633483171463, -0.18929815292358398, -0.03797274827957153] skip-layers: [1, 2, 7, 14, 6]
step:3125/5550 val_loss:3.082763 train_time:778165ms step_avg:249.01ms x-lambda: 0.774285614490509 lambdas: [-0.0085322055965662, -0.06848561763763428, 0.010659109801054, -0.19394847750663757, -0.03769445791840553] skip-layers: [1, 2, 7, 14, 6]
step:3250/5550 val_loss:3.071655 train_time:809479ms step_avg:249.07ms x-lambda: 0.7794243693351746 lambdas: [-0.007008255459368229, -0.06626541912555695, 0.011797559447586536, -0.19642280042171478, -0.03595319390296936] skip-layers: [1, 2, 7, 14, 6]
step:3375/5550 val_loss:3.062804 train_time:840789ms step_avg:249.12ms x-lambda: 0.7819719314575195 lambdas: [-0.008050232194364071, -0.06709150224924088, 0.010735796764492989, -0.20089974999427795, -0.0355168953537941] skip-layers: [1, 2, 7, 14, 6]
step:3500/5550 val_loss:3.053857 train_time:874282ms step_avg:249.79ms x-lambda: 0.7849656939506531 lambdas: [-0.008336344733834267, -0.065762460231781, 0.00909197237342596, -0.2056356966495514, -0.03683949261903763] skip-layers: [1, 2, 7, 14, 6]
step:3625/5550 val_loss:3.045556 train_time:907535ms step_avg:250.35ms x-lambda: 0.7909975647926331 lambdas: [-0.007897540926933289, -0.06446796655654907, 0.009542597457766533, -0.2093801200389862, -0.03558110445737839] skip-layers: [1, 2, 7, 14, 6]
step:3750/5550 val_loss:3.035605 train_time:938836ms step_avg:250.36ms x-lambda: 0.7939558029174805 lambdas: [-0.007023411802947521, -0.06374796479940414, 0.00936566386371851, -0.21457481384277344, -0.03391729295253754] skip-layers: [1, 2, 7, 14, 6]
step:3875/5550 val_loss:3.026922 train_time:970217ms step_avg:250.38ms x-lambda: 0.8036817908287048 lambdas: [-0.005975274369120598, -0.062458619475364685, 0.00909574143588543, -0.21686804294586182, -0.03431496024131775] skip-layers: [1, 2, 7, 14, 6]
step:4000/5550 val_loss:3.017124 train_time:1001581ms step_avg:250.40ms x-lambda: 0.8105324506759644 lambdas: [-0.007309264037758112, -0.06228528171777725, 0.008667374029755592, -0.2228691428899765, -0.03443939611315727] skip-layers: [1, 2, 7, 14, 6]
step:4125/5550 val_loss:3.007896 train_time:1032986ms step_avg:250.42ms x-lambda: 0.8175109624862671 lambdas: [-0.005731746554374695, -0.062178779393434525, 0.008503691293299198, -0.22726167738437653, -0.033334214240312576] skip-layers: [1, 2, 7, 14, 6]
step:4250/5550 val_loss:2.999885 train_time:1065598ms step_avg:250.73ms x-lambda: 0.8247652053833008 lambdas: [-0.006039968691766262, -0.06050177663564682, 0.008480296470224857, -0.23139336705207825, -0.03393852338194847] skip-layers: [1, 2, 7, 14, 6]
step:4375/5550 val_loss:2.990782 train_time:1097226ms step_avg:250.79ms x-lambda: 0.8318057656288147 lambdas: [-0.0070327045395970345, -0.061484258621931076, 0.007182470988482237, -0.2369321584701538, -0.034280914813280106] skip-layers: [1, 2, 7, 14, 6]
step:4500/5550 val_loss:2.982608 train_time:1128964ms step_avg:250.88ms x-lambda: 0.8406510949134827 lambdas: [-0.005980355199426413, -0.05976566672325134, 0.007076991256326437, -0.2407611906528473, -0.033122241497039795] skip-layers: [1, 2, 7, 14, 6]
step:4625/5550 val_loss:2.973392 train_time:1160802ms step_avg:250.98ms x-lambda: 0.8496694564819336 lambdas: [-0.00587905989959836, -0.06076265871524811, 0.006412825547158718, -0.24348768591880798, -0.03385975584387779] skip-layers: [1, 2, 7, 14, 6]
step:4750/5550 val_loss:2.964116 train_time:1192801ms step_avg:251.12ms x-lambda: 0.8582648634910583 lambdas: [-0.004741381853818893, -0.05957656726241112, 0.0073947906494140625, -0.24780604243278503, -0.03196079283952713] skip-layers: [1, 2, 7, 14, 6]
step:4875/5550 val_loss:2.955197 train_time:1225977ms step_avg:251.48ms x-lambda: 0.8672154545783997 lambdas: [-0.006229929625988007, -0.05754127353429794, 0.005377073306590319, -0.25154849886894226, -0.03210088983178139] skip-layers: [1, 2, 7, 14, 6]
step:5000/5550 val_loss:2.946906 train_time:1261486ms step_avg:252.30ms x-lambda: 0.8764925003051758 lambdas: [-0.005748499650508165, -0.058480050414800644, 0.005693560466170311, -0.25482481718063354, -0.03254401683807373] skip-layers: [1, 2, 7, 14, 6]
step:5125/5550 val_loss:2.939489 train_time:1293851ms step_avg:252.46ms x-lambda: 0.8844574093818665 lambdas: [-0.005809936672449112, -0.058420658111572266, 0.0062799532897770405, -0.2570831775665283, -0.03151644393801689] skip-layers: [1, 2, 7, 14, 6]
step:5250/5550 val_loss:2.932122 train_time:1326419ms step_avg:252.65ms x-lambda: 0.8918430805206299 lambdas: [-0.006045799236744642, -0.05796772986650467, 0.0053195045329630375, -0.260267972946167, -0.030936339870095253] skip-layers: [1, 2, 7, 14, 6]
step:5375/5550 val_loss:2.925663 train_time:1359101ms step_avg:252.86ms x-lambda: 0.8996778130531311 lambdas: [-0.005384922958910465, -0.05799168720841408, 0.00477984081953764, -0.26214247941970825, -0.03054828755557537] skip-layers: [1, 2, 7, 14, 6]
step:5500/5550 val_loss:2.920901 train_time:1392062ms step_avg:253.10ms x-lambda: 0.9049546718597412 lambdas: [-0.005818936973810196, -0.058020368218421936, 0.0045293839648365974, -0.2629895508289337, -0.03060663305222988] skip-layers: [1, 2, 7, 14, 6]
step:5550/5550 val_loss:2.919703 train_time:1405327ms step_avg:253.21ms x-lambda: 0.9058361649513245 lambdas: [-0.005730424076318741, -0.058165278285741806, 0.0040799775160849094, -0.26325786113739014, -0.030755024403333664] skip-layers: [1, 2, 7, 14, 6]

## 8000-add-skip-multiple-6-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3]
step:125/5550 val_loss:4.250829 train_time:28736ms step_avg:229.89ms x-lambda: 1.033126950263977 lambdas: [0.03819969668984413, 0.04900536313652992, 0.03544677421450615, 0.0804249569773674, 0.03713918477296829, -0.04298895224928856] skip-layers: [11, 10, 8, 4, 9, 3]
step:250/5550 val_loss:3.860744 train_time:57614ms step_avg:230.46ms x-lambda: 0.9757651686668396 lambdas: [0.02618071436882019, 0.046886149793863297, 0.0006421408616006374, 0.13489103317260742, -0.008850290440022945, -0.16947518289089203] skip-layers: [11, 10, 8, 4, 9, 3]
step:375/5550 val_loss:3.679593 train_time:86896ms step_avg:231.72ms x-lambda: 0.9624905586242676 lambdas: [0.020817432552576065, 0.02853975258767605, -0.016831884160637856, 0.14759384095668793, -0.0580226331949234, -0.236970454454422] skip-layers: [11, 10, 8, 4, 9, 3]
step:500/5550 val_loss:3.564747 train_time:117621ms step_avg:235.24ms x-lambda: 0.9545560479164124 lambdas: [0.013712515123188496, 0.0061554331332445145, -0.014410052448511124, 0.14980106055736542, -0.09346187114715576, -0.2635490298271179] skip-layers: [11, 10, 8, 4, 9, 3]
step:625/5550 val_loss:3.485771 train_time:147592ms step_avg:236.15ms x-lambda: 0.9382944107055664 lambdas: [0.0013899418991059065, -0.019389191642403603, -0.007536175660789013, 0.146335631608963, -0.12098310142755508, -0.27632397413253784] skip-layers: [11, 10, 8, 4, 9, 3]
step:750/5550 val_loss:3.431468 train_time:177833ms step_avg:237.11ms x-lambda: 0.9270724058151245 lambdas: [-0.010149621404707432, -0.040728285908699036, 0.0016813463298603892, 0.14199383556842804, -0.13418133556842804, -0.2758336663246155] skip-layers: [11, 10, 8, 4, 9, 3]
step:875/5550 val_loss:3.384563 train_time:208172ms step_avg:237.91ms x-lambda: 0.9108914732933044 lambdas: [-0.022101234644651413, -0.05963193625211716, 0.008845847100019455, 0.1373964101076126, -0.13986742496490479, -0.26748543977737427] skip-layers: [11, 10, 8, 4, 9, 3]
step:1000/5550 val_loss:3.348961 train_time:239884ms step_avg:239.88ms x-lambda: 0.894720196723938 lambdas: [-0.0346849262714386, -0.07786599546670914, 0.014791171066462994, 0.1305447369813919, -0.14086389541625977, -0.2558666169643402] skip-layers: [11, 10, 8, 4, 9, 3]
step:1125/5550 val_loss:3.318858 train_time:271717ms step_avg:241.53ms x-lambda: 0.8786095976829529 lambdas: [-0.04690496623516083, -0.09416499733924866, 0.01673963852226734, 0.12271043658256531, -0.13683049380779266, -0.24348682165145874] skip-layers: [11, 10, 8, 4, 9, 3]
step:1250/5550 val_loss:3.293252 train_time:303678ms step_avg:242.94ms x-lambda: 0.8628689050674438 lambdas: [-0.057834379374980927, -0.10768142342567444, 0.020647702738642693, 0.115216463804245, -0.13089878857135773, -0.2304420918226242] skip-layers: [11, 10, 8, 4, 9, 3]
step:1375/5550 val_loss:3.272823 train_time:334646ms step_avg:243.38ms x-lambda: 0.8488704562187195 lambdas: [-0.0667530819773674, -0.11955834180116653, 0.01990850456058979, 0.10995503515005112, -0.12613646686077118, -0.21545492112636566] skip-layers: [11, 10, 8, 4, 9, 3]
step:1500/5550 val_loss:3.252784 train_time:365605ms step_avg:243.74ms x-lambda: 0.8361387252807617 lambdas: [-0.07301764190196991, -0.1291835606098175, 0.0230154637247324, 0.10395447909832001, -0.11909140646457672, -0.20409102737903595] skip-layers: [11, 10, 8, 4, 9, 3]
step:1625/5550 val_loss:3.238015 train_time:396627ms step_avg:244.08ms x-lambda: 0.8219616413116455 lambdas: [-0.08001041412353516, -0.1382140964269638, 0.02491849474608898, 0.09870708733797073, -0.11212849617004395, -0.18992266058921814] skip-layers: [11, 10, 8, 4, 9, 3]
step:1750/5550 val_loss:3.221107 train_time:428607ms step_avg:244.92ms x-lambda: 0.8078513741493225 lambdas: [-0.08675751835107803, -0.1449088156223297, 0.024975012987852097, 0.09062905609607697, -0.10599441826343536, -0.17919033765792847] skip-layers: [11, 10, 8, 4, 9, 3]
step:1875/5550 val_loss:3.203571 train_time:460675ms step_avg:245.69ms x-lambda: 0.7968382239341736 lambdas: [-0.09115913510322571, -0.15108540654182434, 0.02492745779454708, 0.08557707816362381, -0.10190698504447937, -0.1672622561454773] skip-layers: [11, 10, 8, 4, 9, 3]
step:2000/5550 val_loss:3.187862 train_time:494227ms step_avg:247.11ms x-lambda: 0.7870451807975769 lambdas: [-0.09457649290561676, -0.15381193161010742, 0.023852523416280746, 0.08124484866857529, -0.09614567458629608, -0.15671426057815552] skip-layers: [11, 10, 8, 4, 9, 3]
step:2125/5550 val_loss:3.173388 train_time:525558ms step_avg:247.32ms x-lambda: 0.7795859575271606 lambdas: [-0.0982980877161026, -0.15800803899765015, 0.02498144470155239, 0.07686584442853928, -0.09311781078577042, -0.14953045547008514] skip-layers: [11, 10, 8, 4, 9, 3]
step:2250/5550 val_loss:3.159215 train_time:556877ms step_avg:247.50ms x-lambda: 0.7727643251419067 lambdas: [-0.10089657455682755, -0.1602666676044464, 0.02410561963915825, 0.07183488458395004, -0.08961571753025055, -0.14274033904075623] skip-layers: [11, 10, 8, 4, 9, 3]
step:2375/5550 val_loss:3.147516 train_time:588231ms step_avg:247.68ms x-lambda: 0.7658964991569519 lambdas: [-0.10193537175655365, -0.1603744775056839, 0.02522198297083378, 0.069487564265728, -0.08636797219514847, -0.1352665275335312] skip-layers: [11, 10, 8, 4, 9, 3]
step:2500/5550 val_loss:3.136149 train_time:619550ms step_avg:247.82ms x-lambda: 0.7591705322265625 lambdas: [-0.1030658408999443, -0.1613641083240509, 0.022994594648480415, 0.06597673892974854, -0.08382351696491241, -0.13020820915699005] skip-layers: [11, 10, 8, 4, 9, 3]
step:2625/5550 val_loss:3.124444 train_time:653117ms step_avg:248.81ms x-lambda: 0.7518823742866516 lambdas: [-0.10484522581100464, -0.16414985060691833, 0.023135365918278694, 0.06218438223004341, -0.08270768076181412, -0.12536033987998962] skip-layers: [11, 10, 8, 4, 9, 3]
step:2750/5550 val_loss:3.113977 train_time:686497ms step_avg:249.64ms x-lambda: 0.7503790855407715 lambdas: [-0.10487526655197144, -0.1630622148513794, 0.02384776435792446, 0.06262116134166718, -0.07848019897937775, -0.11913435906171799] skip-layers: [11, 10, 8, 4, 9, 3]
step:2875/5550 val_loss:3.104599 train_time:717813ms step_avg:249.67ms x-lambda: 0.745829164981842 lambdas: [-0.10652687400579453, -0.1656046211719513, 0.02444726973772049, 0.058723434805870056, -0.07734911888837814, -0.11488443613052368] skip-layers: [11, 10, 8, 4, 9, 3]
step:3000/5550 val_loss:3.093602 train_time:750331ms step_avg:250.11ms x-lambda: 0.7440170645713806 lambdas: [-0.1055973470211029, -0.1651158630847931, 0.023597214370965958, 0.05765770003199577, -0.07461726665496826, -0.10973405838012695] skip-layers: [11, 10, 8, 4, 9, 3]
step:3125/5550 val_loss:3.082599 train_time:781685ms step_avg:250.14ms x-lambda: 0.7412658333778381 lambdas: [-0.10731856524944305, -0.16810563206672668, 0.022099696099758148, 0.053024206310510635, -0.07527090609073639, -0.1081172302365303] skip-layers: [11, 10, 8, 4, 9, 3]
step:3250/5550 val_loss:3.070750 train_time:813014ms step_avg:250.16ms x-lambda: 0.7406312227249146 lambdas: [-0.10655996948480606, -0.16631528735160828, 0.0230974443256855, 0.052909545600414276, -0.07406152039766312, -0.10474743694067001] skip-layers: [11, 10, 8, 4, 9, 3]
step:3375/5550 val_loss:3.062563 train_time:844338ms step_avg:250.17ms x-lambda: 0.7390940189361572 lambdas: [-0.10830347239971161, -0.1674804389476776, 0.022591492161154747, 0.05197535827755928, -0.07197771221399307, -0.10459573566913605] skip-layers: [11, 10, 8, 4, 9, 3]
step:3500/5550 val_loss:3.053574 train_time:875720ms step_avg:250.21ms x-lambda: 0.73776775598526 lambdas: [-0.1084805279970169, -0.16844940185546875, 0.021997658535838127, 0.04894278943538666, -0.07212697714567184, -0.10036294907331467] skip-layers: [11, 10, 8, 4, 9, 3]
step:3625/5550 val_loss:3.044627 train_time:907057ms step_avg:250.22ms x-lambda: 0.7383222579956055 lambdas: [-0.10743487626314163, -0.1678636223077774, 0.0220131017267704, 0.04730495065450668, -0.0680336058139801, -0.09847962856292725] skip-layers: [11, 10, 8, 4, 9, 3]
step:3750/5550 val_loss:3.034946 train_time:938391ms step_avg:250.24ms x-lambda: 0.7387073040008545 lambdas: [-0.10828607529401779, -0.16809627413749695, 0.023196563124656677, 0.047955457121133804, -0.06884946674108505, -0.0954349935054779] skip-layers: [11, 10, 8, 4, 9, 3]
step:3875/5550 val_loss:3.026143 train_time:969829ms step_avg:250.28ms x-lambda: 0.7431182265281677 lambdas: [-0.10781698673963547, -0.1689077466726303, 0.022229252383112907, 0.047117676585912704, -0.06791741400957108, -0.09294477105140686] skip-layers: [11, 10, 8, 4, 9, 3]
step:4000/5550 val_loss:3.016793 train_time:1002224ms step_avg:250.56ms x-lambda: 0.7444038987159729 lambdas: [-0.10765934735536575, -0.17005452513694763, 0.020518217235803604, 0.04556834697723389, -0.06688177585601807, -0.09190715104341507] skip-layers: [11, 10, 8, 4, 9, 3]
step:4125/5550 val_loss:3.007374 train_time:1034796ms step_avg:250.86ms x-lambda: 0.7465099692344666 lambdas: [-0.10802856832742691, -0.16919772326946259, 0.021946020424365997, 0.04425128549337387, -0.06621621549129486, -0.08959931135177612] skip-layers: [11, 10, 8, 4, 9, 3]
step:4250/5550 val_loss:2.999111 train_time:1066430ms step_avg:250.92ms x-lambda: 0.7510916590690613 lambdas: [-0.10787405073642731, -0.16950936615467072, 0.02178601361811161, 0.0447593554854393, -0.0664108470082283, -0.08894486725330353] skip-layers: [11, 10, 8, 4, 9, 3]
step:4375/5550 val_loss:2.989999 train_time:1098094ms step_avg:250.99ms x-lambda: 0.7520858645439148 lambdas: [-0.10949066281318665, -0.1718755066394806, 0.02132784202694893, 0.04264761880040169, -0.06683360040187836, -0.08866073191165924] skip-layers: [11, 10, 8, 4, 9, 3]
step:4500/5550 val_loss:2.981740 train_time:1129825ms step_avg:251.07ms x-lambda: 0.7564176321029663 lambdas: [-0.10881040245294571, -0.17200186848640442, 0.020505085587501526, 0.04180882126092911, -0.0664115771651268, -0.08634205907583237] skip-layers: [11, 10, 8, 4, 9, 3]
step:4625/5550 val_loss:2.972130 train_time:1161666ms step_avg:251.17ms x-lambda: 0.7630911469459534 lambdas: [-0.10833214968442917, -0.17074543237686157, 0.020100226625800133, 0.040673431009054184, -0.06603579968214035, -0.08599641174077988] skip-layers: [11, 10, 8, 4, 9, 3]
step:4750/5550 val_loss:2.962896 train_time:1193692ms step_avg:251.30ms x-lambda: 0.7673286199569702 lambdas: [-0.10771283507347107, -0.17162862420082092, 0.02063809521496296, 0.04163328558206558, -0.06636146456003189, -0.08379790186882019] skip-layers: [11, 10, 8, 4, 9, 3]
step:4875/5550 val_loss:2.954164 train_time:1225838ms step_avg:251.45ms x-lambda: 0.7720044851303101 lambdas: [-0.10774392634630203, -0.17312198877334595, 0.02013307623565197, 0.04094201326370239, -0.06569333374500275, -0.08310582488775253] skip-layers: [11, 10, 8, 4, 9, 3]
step:5000/5550 val_loss:2.946024 train_time:1260129ms step_avg:252.03ms x-lambda: 0.7786096334457397 lambdas: [-0.10868832468986511, -0.17443716526031494, 0.019127367064356804, 0.040737029165029526, -0.06487441062927246, -0.0831439346075058] skip-layers: [11, 10, 8, 4, 9, 3]
step:5125/5550 val_loss:2.938316 train_time:1292483ms step_avg:252.19ms x-lambda: 0.7826417088508606 lambdas: [-0.10804334282875061, -0.1752168983221054, 0.020326415076851845, 0.040363650768995285, -0.06560693681240082, -0.08192456513643265] skip-layers: [11, 10, 8, 4, 9, 3]
step:5250/5550 val_loss:2.931140 train_time:1327240ms step_avg:252.81ms x-lambda: 0.7873597741127014 lambdas: [-0.1081460565328598, -0.17448332905769348, 0.019334983080625534, 0.038494259119033813, -0.06624019891023636, -0.08079879730939865] skip-layers: [11, 10, 8, 4, 9, 3]
step:5375/5550 val_loss:2.924685 train_time:1359891ms step_avg:253.00ms x-lambda: 0.7923223376274109 lambdas: [-0.10799723863601685, -0.17590194940567017, 0.01884997822344303, 0.03886942192912102, -0.06564079225063324, -0.08052408695220947] skip-layers: [11, 10, 8, 4, 9, 3]
step:5500/5550 val_loss:2.919945 train_time:1392807ms step_avg:253.24ms x-lambda: 0.7957211136817932 lambdas: [-0.10799549520015717, -0.17599202692508698, 0.01873166859149933, 0.039498258382081985, -0.06608309596776962, -0.08083710074424744] skip-layers: [11, 10, 8, 4, 9, 3]
step:5550/5550 val_loss:2.918792 train_time:1406067ms step_avg:253.35ms x-lambda: 0.796420693397522 lambdas: [-0.10792288184165955, -0.17630980908870697, 0.018295420333743095, 0.03944774344563484, -0.06624619662761688, -0.08062966167926788] skip-layers: [11, 10, 8, 4, 9, 3]

## 8000-add-skip-multiple-6-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.18ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5]
step:125/5550 val_loss:4.258719 train_time:29902ms step_avg:239.22ms x-lambda: 1.0544679164886475 lambdas: [0.07520365715026855, 0.011299456469714642, -0.021475326269865036, -0.04004351422190666, 0.09623576700687408, 0.0756116509437561] skip-layers: [0, 1, 2, 3, 4, 5]
step:250/5550 val_loss:3.847583 train_time:58842ms step_avg:235.37ms x-lambda: 1.0178141593933105 lambdas: [0.06434007734060287, -0.02382262423634529, -0.07581879198551178, -0.14015842974185944, 0.1335873156785965, 0.07042110711336136] skip-layers: [0, 1, 2, 3, 4, 5]
step:375/5550 val_loss:3.674549 train_time:88218ms step_avg:235.25ms x-lambda: 0.9856133460998535 lambdas: [0.052988987416028976, -0.028586644679307938, -0.08688871562480927, -0.18827448785305023, 0.1342364400625229, 0.045206621289253235] skip-layers: [0, 1, 2, 3, 4, 5]
step:500/5550 val_loss:3.559206 train_time:117985ms step_avg:235.97ms x-lambda: 0.9466524720191956 lambdas: [0.04767387732863426, -0.02516079694032669, -0.08720605075359344, -0.20857471227645874, 0.13618223369121552, 0.027991684153676033] skip-layers: [0, 1, 2, 3, 4, 5]
step:625/5550 val_loss:3.481535 train_time:147975ms step_avg:236.76ms x-lambda: 0.9006897211074829 lambdas: [0.040796831250190735, -0.02345873787999153, -0.08723147213459015, -0.21820084750652313, 0.13421781361103058, 0.013026082888245583] skip-layers: [0, 1, 2, 3, 4, 5]
step:750/5550 val_loss:3.428847 train_time:178236ms step_avg:237.65ms x-lambda: 0.8680847883224487 lambdas: [0.03781263157725334, -0.01885806955397129, -0.08354871720075607, -0.215293288230896, 0.1334814876317978, 0.0058123767375946045] skip-layers: [0, 1, 2, 3, 4, 5]
step:875/5550 val_loss:3.384390 train_time:208637ms step_avg:238.44ms x-lambda: 0.8317104578018188 lambdas: [0.035610757768154144, -0.014103460125625134, -0.07874730229377747, -0.20790743827819824, 0.13036873936653137, 0.0016909567639231682] skip-layers: [0, 1, 2, 3, 4, 5]
step:1000/5550 val_loss:3.348006 train_time:239277ms step_avg:239.28ms x-lambda: 0.7980313301086426 lambdas: [0.031387995928525925, -0.01297435350716114, -0.07685229927301407, -0.19991202652454376, 0.12112639844417572, -0.004567480646073818] skip-layers: [0, 1, 2, 3, 4, 5]
step:1125/5550 val_loss:3.320190 train_time:269946ms step_avg:239.95ms x-lambda: 0.7696607708930969 lambdas: [0.03026183694601059, -0.009939688257873058, -0.07235540449619293, -0.18648064136505127, 0.11558923125267029, -0.004885395988821983] skip-layers: [0, 1, 2, 3, 4, 5]
step:1250/5550 val_loss:3.295461 train_time:300766ms step_avg:240.61ms x-lambda: 0.7442359328269958 lambdas: [0.029175279662013054, -0.008552223443984985, -0.07019060105085373, -0.1765257865190506, 0.1070089042186737, -0.0059200674295425415] skip-layers: [0, 1, 2, 3, 4, 5]
step:1375/5550 val_loss:3.272658 train_time:335150ms step_avg:243.75ms x-lambda: 0.7174651026725769 lambdas: [0.026253607124090195, -0.007806331384927034, -0.06723207235336304, -0.16529780626296997, 0.09821511059999466, -0.008356711827218533] skip-layers: [0, 1, 2, 3, 4, 5]
step:1500/5550 val_loss:3.256058 train_time:367340ms step_avg:244.89ms x-lambda: 0.6991522312164307 lambdas: [0.023570386692881584, -0.008521154522895813, -0.06696764379739761, -0.1578773558139801, 0.09050127863883972, -0.010510261170566082] skip-layers: [0, 1, 2, 3, 4, 5]
step:1625/5550 val_loss:3.237230 train_time:398421ms step_avg:245.18ms x-lambda: 0.6794345378875732 lambdas: [0.02485269494354725, -0.007295516785234213, -0.06337501108646393, -0.146635964512825, 0.08585458993911743, -0.009394621476531029] skip-layers: [0, 1, 2, 3, 4, 5]
step:1750/5550 val_loss:3.223347 train_time:431551ms step_avg:246.60ms x-lambda: 0.6622810959815979 lambdas: [0.02323818765580654, -0.004492397420108318, -0.05935060605406761, -0.1363229751586914, 0.08178602159023285, -0.009007730521261692] skip-layers: [0, 1, 2, 3, 4, 5]
step:1875/5550 val_loss:3.204090 train_time:463794ms step_avg:247.36ms x-lambda: 0.6492777466773987 lambdas: [0.02118838019669056, -0.005436320323497057, -0.05908592417836189, -0.13040271401405334, 0.07497135549783707, -0.011048449203372002] skip-layers: [0, 1, 2, 3, 4, 5]
step:2000/5550 val_loss:3.188531 train_time:497201ms step_avg:248.60ms x-lambda: 0.6364184617996216 lambdas: [0.020730286836624146, -0.0033470888156443834, -0.056549157947301865, -0.12163034081459045, 0.07120389491319656, -0.009730988182127476] skip-layers: [0, 1, 2, 3, 4, 5]
step:2125/5550 val_loss:3.173970 train_time:529773ms step_avg:249.30ms x-lambda: 0.6296896934509277 lambdas: [0.019524255767464638, -0.003174230456352234, -0.05547468736767769, -0.11674001812934875, 0.06704361736774445, -0.010758426040410995] skip-layers: [0, 1, 2, 3, 4, 5]
step:2250/5550 val_loss:3.159744 train_time:561120ms step_avg:249.39ms x-lambda: 0.6208072304725647 lambdas: [0.019100811332464218, -0.0037269634194672108, -0.054094038903713226, -0.11011931300163269, 0.06351857632398605, -0.010927889496088028] skip-layers: [0, 1, 2, 3, 4, 5]
step:2375/5550 val_loss:3.148236 train_time:593581ms step_avg:249.93ms x-lambda: 0.6157909631729126 lambdas: [0.01921083778142929, -0.003129442920908332, -0.05152422934770584, -0.10369031131267548, 0.06070539355278015, -0.010613851249217987] skip-layers: [0, 1, 2, 3, 4, 5]
step:2500/5550 val_loss:3.137250 train_time:624953ms step_avg:249.98ms x-lambda: 0.608447790145874 lambdas: [0.019795365631580353, -0.001651240629144013, -0.05111294239759445, -0.09938115626573563, 0.05841594561934471, -0.010703688487410545] skip-layers: [0, 1, 2, 3, 4, 5]
step:2625/5550 val_loss:3.126100 train_time:656321ms step_avg:250.03ms x-lambda: 0.6063901782035828 lambdas: [0.019571779295802116, -0.002022789791226387, -0.04985639080405235, -0.09509875625371933, 0.0556558258831501, -0.010536662302911282] skip-layers: [0, 1, 2, 3, 4, 5]
step:2750/5550 val_loss:3.114638 train_time:689768ms step_avg:250.82ms x-lambda: 0.6023033857345581 lambdas: [0.017359307035803795, -0.0011199741857126355, -0.04875370115041733, -0.09277310222387314, 0.054394278675317764, -0.010357001796364784] skip-layers: [0, 1, 2, 3, 4, 5]
step:2875/5550 val_loss:3.105107 train_time:723169ms step_avg:251.54ms x-lambda: 0.5995983481407166 lambdas: [0.019252007827162743, -0.001255690585821867, -0.047915019094944, -0.0894615575671196, 0.051306646317243576, -0.011507431976497173] skip-layers: [0, 1, 2, 3, 4, 5]
step:3000/5550 val_loss:3.093924 train_time:755525ms step_avg:251.84ms x-lambda: 0.5995232462882996 lambdas: [0.017121020704507828, -0.002269984921440482, -0.04728947952389717, -0.08622564375400543, 0.04960937052965164, -0.011128743179142475] skip-layers: [0, 1, 2, 3, 4, 5]
step:3125/5550 val_loss:3.083539 train_time:786945ms step_avg:251.82ms x-lambda: 0.5962681174278259 lambdas: [0.01666252873837948, -0.0035111154429614544, -0.04802759736776352, -0.08617694675922394, 0.04735461622476578, -0.011881198734045029] skip-layers: [0, 1, 2, 3, 4, 5]
step:3250/5550 val_loss:3.071595 train_time:819401ms step_avg:252.12ms x-lambda: 0.5990428328514099 lambdas: [0.016394276171922684, -0.0014514961512759328, -0.0468427911400795, -0.08096636086702347, 0.04596400633454323, -0.010665744543075562] skip-layers: [0, 1, 2, 3, 4, 5]
step:3375/5550 val_loss:3.063235 train_time:850757ms step_avg:252.08ms x-lambda: 0.5988949537277222 lambdas: [0.01454857736825943, -0.0020776260644197464, -0.0472138449549675, -0.08163869380950928, 0.045207805931568146, -0.012269465252757072] skip-layers: [0, 1, 2, 3, 4, 5]
step:3500/5550 val_loss:3.053964 train_time:882136ms step_avg:252.04ms x-lambda: 0.599238932132721 lambdas: [0.015746450051665306, -0.001561923767440021, -0.04540302976965904, -0.07832834869623184, 0.04364412650465965, -0.01179205346852541] skip-layers: [0, 1, 2, 3, 4, 5]
step:3625/5550 val_loss:3.045453 train_time:914571ms step_avg:252.30ms x-lambda: 0.6032409071922302 lambdas: [0.0162761602550745, -0.000901660299859941, -0.04512635990977287, -0.07627461850643158, 0.044365886598825455, -0.01189380045980215] skip-layers: [0, 1, 2, 3, 4, 5]
step:3750/5550 val_loss:3.035735 train_time:947119ms step_avg:252.57ms x-lambda: 0.6027234196662903 lambdas: [0.017204467207193375, -0.001857380149886012, -0.044003602117300034, -0.073697030544281, 0.044307827949523926, -0.010719853453338146] skip-layers: [0, 1, 2, 3, 4, 5]
step:3875/5550 val_loss:3.026767 train_time:978571ms step_avg:252.53ms x-lambda: 0.6100325584411621 lambdas: [0.016283152624964714, -0.001754064578562975, -0.044099658727645874, -0.07375607639551163, 0.041902389377355576, -0.012300756759941578] skip-layers: [0, 1, 2, 3, 4, 5]
step:4000/5550 val_loss:3.017338 train_time:1009970ms step_avg:252.49ms x-lambda: 0.6144707798957825 lambdas: [0.01660999096930027, -0.0007008550455793738, -0.04228878393769264, -0.07207349687814713, 0.04135484620928764, -0.010850480757653713] skip-layers: [0, 1, 2, 3, 4, 5]
step:4125/5550 val_loss:3.008173 train_time:1044820ms step_avg:253.29ms x-lambda: 0.6189597249031067 lambdas: [0.016386352479457855, -0.0007941952208057046, -0.04418075829744339, -0.07045560330152512, 0.03933876007795334, -0.011393271386623383] skip-layers: [0, 1, 2, 3, 4, 5]
step:4250/5550 val_loss:2.999805 train_time:1079503ms step_avg:254.00ms x-lambda: 0.6229477524757385 lambdas: [0.015336957760155201, -0.0021551342215389013, -0.04262427240610123, -0.06879691034555435, 0.040177375078201294, -0.011234859935939312] skip-layers: [0, 1, 2, 3, 4, 5]
step:4375/5550 val_loss:2.990596 train_time:1111183ms step_avg:253.98ms x-lambda: 0.6272956728935242 lambdas: [0.015751736238598824, -0.002442479133605957, -0.04336179047822952, -0.06946518272161484, 0.038991108536720276, -0.012739043682813644] skip-layers: [0, 1, 2, 3, 4, 5]
step:4500/5550 val_loss:2.982280 train_time:1143829ms step_avg:254.18ms x-lambda: 0.634532630443573 lambdas: [0.015514892525970936, -0.001870626350864768, -0.04261685162782669, -0.0679519847035408, 0.038418594747781754, -0.01228057686239481] skip-layers: [0, 1, 2, 3, 4, 5]
step:4625/5550 val_loss:2.972938 train_time:1178833ms step_avg:254.88ms x-lambda: 0.6417983770370483 lambdas: [0.015303634107112885, -0.0019424828933551908, -0.041834231466054916, -0.06706196814775467, 0.03755267709493637, -0.01330077275633812] skip-layers: [0, 1, 2, 3, 4, 5]
step:4750/5550 val_loss:2.963687 train_time:1211876ms step_avg:255.13ms x-lambda: 0.6479466557502747 lambdas: [0.015909772366285324, -0.0003123011556454003, -0.04226363077759743, -0.06603848189115524, 0.03842509165406227, -0.011990776285529137] skip-layers: [0, 1, 2, 3, 4, 5]
step:4875/5550 val_loss:2.954700 train_time:1244037ms step_avg:255.19ms x-lambda: 0.6551976203918457 lambdas: [0.014490154571831226, -0.0010536650661379099, -0.0422808900475502, -0.06557174772024155, 0.038125935941934586, -0.012887044809758663] skip-layers: [0, 1, 2, 3, 4, 5]
step:5000/5550 val_loss:2.946549 train_time:1276289ms step_avg:255.26ms x-lambda: 0.6631085276603699 lambdas: [0.014232886955142021, -0.0018249998101964593, -0.04172659292817116, -0.06571323424577713, 0.03779338672757149, -0.01264901366084814] skip-layers: [0, 1, 2, 3, 4, 5]
step:5125/5550 val_loss:2.939085 train_time:1309495ms step_avg:255.51ms x-lambda: 0.6712216734886169 lambdas: [0.014956844970583916, -0.0007254958618432283, -0.040848951786756516, -0.06331824511289597, 0.03709490969777107, -0.012557180598378181] skip-layers: [0, 1, 2, 3, 4, 5]
step:5250/5550 val_loss:2.931956 train_time:1343171ms step_avg:255.84ms x-lambda: 0.6793973445892334 lambdas: [0.014415006153285503, -0.0015447938349097967, -0.04170873388648033, -0.06325002759695053, 0.03708993270993233, -0.012395900674164295] skip-layers: [0, 1, 2, 3, 4, 5]
step:5375/5550 val_loss:2.925385 train_time:1375917ms step_avg:255.98ms x-lambda: 0.6873171925544739 lambdas: [0.014862826094031334, -0.0014133010990917683, -0.04115946218371391, -0.06338510662317276, 0.03634290769696236, -0.013209622353315353] skip-layers: [0, 1, 2, 3, 4, 5]
step:5500/5550 val_loss:2.920556 train_time:1408881ms step_avg:256.16ms x-lambda: 0.6930859684944153 lambdas: [0.014286722987890244, -0.0007366929785348475, -0.04140741005539894, -0.06355103850364685, 0.03650927543640137, -0.01251260470598936] skip-layers: [0, 1, 2, 3, 4, 5]
step:5550/5550 val_loss:2.919378 train_time:1422147ms step_avg:256.24ms x-lambda: 0.6941905617713928 lambdas: [0.014512328431010246, -0.001000307034701109, -0.04167475551366806, -0.06325193494558334, 0.036438051611185074, -0.012904767878353596] skip-layers: [0, 1, 2, 3, 4, 5]

## 8000-add-skip-multiple-6-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [8, 5, 2, 12, 11, 7]
step:125/5550 val_loss:4.272930 train_time:29757ms step_avg:238.06ms x-lambda: 1.094300627708435 lambdas: [0.009712085127830505, -0.01805429346859455, -0.019294770434498787, 0.07861964404582977, 0.016954924911260605, 0.03282582387328148] skip-layers: [8, 5, 2, 12, 11, 7]
step:250/5550 val_loss:3.854186 train_time:58729ms step_avg:234.92ms x-lambda: 1.0630686283111572 lambdas: [-0.009941520169377327, -0.00695948489010334, -0.056623443961143494, 0.008126440457999706, -0.00020011013839393854, 0.010221341624855995] skip-layers: [8, 5, 2, 12, 11, 7]
step:375/5550 val_loss:3.678921 train_time:88064ms step_avg:234.84ms x-lambda: 1.0110512971878052 lambdas: [-0.013642393983900547, -0.0019211478065699339, -0.04963664337992668, -0.01785174012184143, -0.009018114767968655, -0.004255669191479683] skip-layers: [8, 5, 2, 12, 11, 7]
step:500/5550 val_loss:3.560470 train_time:117847ms step_avg:235.69ms x-lambda: 0.9621443748474121 lambdas: [-0.01797429658472538, -0.007983329705893993, -0.04778365418314934, -0.0332803837954998, -0.01595199480652809, -0.013445781543850899] skip-layers: [8, 5, 2, 12, 11, 7]
step:625/5550 val_loss:3.482316 train_time:147847ms step_avg:236.56ms x-lambda: 0.9153035283088684 lambdas: [-0.01814386248588562, -0.009727573953568935, -0.04187753051519394, -0.03561290726065636, -0.015594281256198883, -0.013593168929219246] skip-layers: [8, 5, 2, 12, 11, 7]
step:750/5550 val_loss:3.429989 train_time:178132ms step_avg:237.51ms x-lambda: 0.8694400787353516 lambdas: [-0.017123794183135033, -0.01160498894751072, -0.03819961100816727, -0.03430983051657677, -0.015126732178032398, -0.014204036444425583] skip-layers: [8, 5, 2, 12, 11, 7]
step:875/5550 val_loss:3.384372 train_time:210546ms step_avg:240.62ms x-lambda: 0.8251567482948303 lambdas: [-0.01702270656824112, -0.01182524673640728, -0.035167478024959564, -0.032575156539678574, -0.015371057204902172, -0.013535491190850735] skip-layers: [8, 5, 2, 12, 11, 7]
step:1000/5550 val_loss:3.349072 train_time:241201ms step_avg:241.20ms x-lambda: 0.7913911938667297 lambdas: [-0.01413806714117527, -0.009750306606292725, -0.02981720305979252, -0.030103184282779694, -0.01307303924113512, -0.012524724937975407] skip-layers: [8, 5, 2, 12, 11, 7]
step:1125/5550 val_loss:3.319848 train_time:271919ms step_avg:241.71ms x-lambda: 0.7602896094322205 lambdas: [-0.015277438797056675, -0.010795840062201023, -0.027612611651420593, -0.028125930577516556, -0.012657353654503822, -0.011089520528912544] skip-layers: [8, 5, 2, 12, 11, 7]
step:1250/5550 val_loss:3.294956 train_time:305057ms step_avg:244.05ms x-lambda: 0.7341574430465698 lambdas: [-0.013501960784196854, -0.008783940225839615, -0.024282433092594147, -0.0259360633790493, -0.011072428897023201, -0.009690748527646065] skip-layers: [8, 5, 2, 12, 11, 7]
step:1375/5550 val_loss:3.273375 train_time:336049ms step_avg:244.40ms x-lambda: 0.7098474502563477 lambdas: [-0.013081851415336132, -0.009747090749442577, -0.02296002395451069, -0.024313433095812798, -0.011559656821191311, -0.009858591482043266] skip-layers: [8, 5, 2, 12, 11, 7]
step:1500/5550 val_loss:3.256751 train_time:368105ms step_avg:245.40ms x-lambda: 0.6884443163871765 lambdas: [-0.014987833797931671, -0.011278349906206131, -0.02320508286356926, -0.0253825131803751, -0.012372837401926517, -0.011147079057991505] skip-layers: [8, 5, 2, 12, 11, 7]
step:1625/5550 val_loss:3.238516 train_time:399185ms step_avg:245.65ms x-lambda: 0.671080470085144 lambdas: [-0.011151662096381187, -0.007445833645761013, -0.01949976570904255, -0.022309182211756706, -0.010271682403981686, -0.008327968418598175] skip-layers: [8, 5, 2, 12, 11, 7]
step:1750/5550 val_loss:3.224246 train_time:430249ms step_avg:245.86ms x-lambda: 0.652800440788269 lambdas: [-0.012721400707960129, -0.009282024577260017, -0.019352583214640617, -0.02373635768890381, -0.011630671098828316, -0.010499303229153156] skip-layers: [8, 5, 2, 12, 11, 7]
step:1875/5550 val_loss:3.205731 train_time:464745ms step_avg:247.86ms x-lambda: 0.6423571109771729 lambdas: [-0.010898344218730927, -0.007144305855035782, -0.015757441520690918, -0.01890985108911991, -0.007997285574674606, -0.007527771405875683] skip-layers: [8, 5, 2, 12, 11, 7]
step:2000/5550 val_loss:3.189577 train_time:496117ms step_avg:248.06ms x-lambda: 0.6295129656791687 lambdas: [-0.009679976850748062, -0.006778151728212833, -0.01638474129140377, -0.018191881477832794, -0.00878671184182167, -0.006936573423445225] skip-layers: [8, 5, 2, 12, 11, 7]
step:2125/5550 val_loss:3.174750 train_time:530757ms step_avg:249.77ms x-lambda: 0.6199131011962891 lambdas: [-0.010929415933787823, -0.008265037089586258, -0.01613912545144558, -0.01950986683368683, -0.008603443391621113, -0.008114814758300781] skip-layers: [8, 5, 2, 12, 11, 7]
step:2250/5550 val_loss:3.160186 train_time:562107ms step_avg:249.83ms x-lambda: 0.6125844717025757 lambdas: [-0.01010081171989441, -0.007621404714882374, -0.015152025036513805, -0.018585069105029106, -0.008563264273107052, -0.00857638567686081] skip-layers: [8, 5, 2, 12, 11, 7]
step:2375/5550 val_loss:3.149300 train_time:593504ms step_avg:249.90ms x-lambda: 0.6083619594573975 lambdas: [-0.009557281620800495, -0.005973289720714092, -0.013252037577331066, -0.016943521797657013, -0.007255240809172392, -0.006829858757555485] skip-layers: [8, 5, 2, 12, 11, 7]
step:2500/5550 val_loss:3.136544 train_time:624905ms step_avg:249.96ms x-lambda: 0.6032947897911072 lambdas: [-0.009713171981275082, -0.006279573775827885, -0.012726735323667526, -0.017372025176882744, -0.007629784289747477, -0.006404094863682985] skip-layers: [8, 5, 2, 12, 11, 7]
step:2625/5550 val_loss:3.125393 train_time:657281ms step_avg:250.39ms x-lambda: 0.5997928380966187 lambdas: [-0.008674219250679016, -0.006442185025662184, -0.011525195091962814, -0.01618964970111847, -0.007591008674353361, -0.00707938801497221] skip-layers: [8, 5, 2, 12, 11, 7]
step:2750/5550 val_loss:3.114543 train_time:689814ms step_avg:250.84ms x-lambda: 0.5951456427574158 lambdas: [-0.009044921025633812, -0.007118476089090109, -0.012017972767353058, -0.015676595270633698, -0.007465003523975611, -0.007773899473249912] skip-layers: [8, 5, 2, 12, 11, 7]
step:2875/5550 val_loss:3.104955 train_time:721168ms step_avg:250.84ms x-lambda: 0.593695878982544 lambdas: [-0.008872448466718197, -0.006508390884846449, -0.011424330063164234, -0.01497261319309473, -0.006338906940072775, -0.007191597484052181] skip-layers: [8, 5, 2, 12, 11, 7]
step:3000/5550 val_loss:3.094144 train_time:753583ms step_avg:251.19ms x-lambda: 0.5947064161300659 lambdas: [-0.008991502225399017, -0.0048108468763530254, -0.011966235935688019, -0.014890133403241634, -0.00693892315030098, -0.005543493665754795] skip-layers: [8, 5, 2, 12, 11, 7]
step:3125/5550 val_loss:3.083104 train_time:785962ms step_avg:251.51ms x-lambda: 0.5910763144493103 lambdas: [-0.00837453082203865, -0.006683654617518187, -0.010521951131522655, -0.01518841739743948, -0.007857279852032661, -0.006759453099220991] skip-layers: [8, 5, 2, 12, 11, 7]
step:3250/5550 val_loss:3.071845 train_time:819355ms step_avg:252.11ms x-lambda: 0.5935603976249695 lambdas: [-0.008277330547571182, -0.0052568609826266766, -0.01057418156415224, -0.014812813140451908, -0.007442535366863012, -0.0062775686383247375] skip-layers: [8, 5, 2, 12, 11, 7]
step:3375/5550 val_loss:3.063809 train_time:850691ms step_avg:252.06ms x-lambda: 0.5923269391059875 lambdas: [-0.00834975391626358, -0.005963051691651344, -0.012723018415272236, -0.014319266192615032, -0.007669875398278236, -0.005321606062352657] skip-layers: [8, 5, 2, 12, 11, 7]
step:3500/5550 val_loss:3.054515 train_time:883150ms step_avg:252.33ms x-lambda: 0.5926254391670227 lambdas: [-0.009160928428173065, -0.006435112562030554, -0.010925468988716602, -0.014991634525358677, -0.00843935925513506, -0.007949532940983772] skip-layers: [8, 5, 2, 12, 11, 7]
step:3625/5550 val_loss:3.045155 train_time:914521ms step_avg:252.28ms x-lambda: 0.5966256856918335 lambdas: [-0.0075542256236076355, -0.005472699645906687, -0.010197213850915432, -0.014136203564703465, -0.0068310038186609745, -0.005536718759685755] skip-layers: [8, 5, 2, 12, 11, 7]
step:3750/5550 val_loss:3.036063 train_time:945877ms step_avg:252.23ms x-lambda: 0.5978828072547913 lambdas: [-0.008082459680736065, -0.005187028553336859, -0.009579614736139774, -0.014480742625892162, -0.006685723550617695, -0.00661119818687439] skip-layers: [8, 5, 2, 12, 11, 7]
step:3875/5550 val_loss:3.027287 train_time:977339ms step_avg:252.22ms x-lambda: 0.6054086685180664 lambdas: [-0.00818842276930809, -0.005485977046191692, -0.009722989052534103, -0.01371331699192524, -0.006847870536148548, -0.005372210405766964] skip-layers: [8, 5, 2, 12, 11, 7]
step:4000/5550 val_loss:3.017235 train_time:1008736ms step_avg:252.18ms x-lambda: 0.6086443662643433 lambdas: [-0.008323322981595993, -0.005141019821166992, -0.009778597392141819, -0.01277216523885727, -0.0069961994886398315, -0.0053843301720917225] skip-layers: [8, 5, 2, 12, 11, 7]
step:4125/5550 val_loss:3.008552 train_time:1040213ms step_avg:252.17ms x-lambda: 0.6123164892196655 lambdas: [-0.007646291516721249, -0.004071416798979044, -0.009361044503748417, -0.012137816287577152, -0.005762971471995115, -0.005981598049402237] skip-layers: [8, 5, 2, 12, 11, 7]
step:4250/5550 val_loss:2.999877 train_time:1071829ms step_avg:252.20ms x-lambda: 0.6172221899032593 lambdas: [-0.007239997386932373, -0.005321837961673737, -0.009851576760411263, -0.012813934125006199, -0.006074969656765461, -0.005573544185608625] skip-layers: [8, 5, 2, 12, 11, 7]
step:4375/5550 val_loss:2.991250 train_time:1104678ms step_avg:252.50ms x-lambda: 0.618969202041626 lambdas: [-0.007943425327539444, -0.005309759639203548, -0.010460938327014446, -0.014269322156906128, -0.0071302372962236404, -0.0062915184535086155] skip-layers: [8, 5, 2, 12, 11, 7]
step:4500/5550 val_loss:2.982638 train_time:1136405ms step_avg:252.53ms x-lambda: 0.62581866979599 lambdas: [-0.007053806446492672, -0.005210477393120527, -0.009145243093371391, -0.012117474339902401, -0.006801866460591555, -0.006707748863846064] skip-layers: [8, 5, 2, 12, 11, 7]
step:4625/5550 val_loss:2.973364 train_time:1169363ms step_avg:252.84ms x-lambda: 0.6347512602806091 lambdas: [-0.008582975715398788, -0.006422239355742931, -0.010154136456549168, -0.01274043321609497, -0.006437827832996845, -0.006013407837599516] skip-layers: [8, 5, 2, 12, 11, 7]
step:4750/5550 val_loss:2.964018 train_time:1203561ms step_avg:253.38ms x-lambda: 0.6399840712547302 lambdas: [-0.006946844048798084, -0.0044694021344184875, -0.007459759712219238, -0.01237424835562706, -0.004263509996235371, -0.0054160309955477715] skip-layers: [8, 5, 2, 12, 11, 7]
step:4875/5550 val_loss:2.955165 train_time:1236574ms step_avg:253.66ms x-lambda: 0.6472204327583313 lambdas: [-0.007858655415475368, -0.0045479475520551205, -0.008575566112995148, -0.011504734866321087, -0.005727964919060469, -0.005240510683506727] skip-layers: [8, 5, 2, 12, 11, 7]
step:5000/5550 val_loss:2.946985 train_time:1272176ms step_avg:254.44ms x-lambda: 0.6549294590950012 lambdas: [-0.007067549508064985, -0.004435280337929726, -0.008310665376484394, -0.01242705900222063, -0.006492427084594965, -0.006132054608315229] skip-layers: [8, 5, 2, 12, 11, 7]
step:5125/5550 val_loss:2.939206 train_time:1305743ms step_avg:254.78ms x-lambda: 0.6622960567474365 lambdas: [-0.00673421286046505, -0.005184101406484842, -0.007875884883105755, -0.012067338451743126, -0.006001909729093313, -0.005150054581463337] skip-layers: [8, 5, 2, 12, 11, 7]
step:5250/5550 val_loss:2.932095 train_time:1338326ms step_avg:254.92ms x-lambda: 0.6694579124450684 lambdas: [-0.0071677458472549915, -0.0048657795414328575, -0.008251413702964783, -0.011622212827205658, -0.005405812989920378, -0.005871743895113468] skip-layers: [8, 5, 2, 12, 11, 7]
step:5375/5550 val_loss:2.925655 train_time:1372219ms step_avg:255.30ms x-lambda: 0.6779379844665527 lambdas: [-0.007493474055081606, -0.004391348455101252, -0.007237114943563938, -0.012184282764792442, -0.006150792818516493, -0.005526290740817785] skip-layers: [8, 5, 2, 12, 11, 7]
step:5500/5550 val_loss:2.920841 train_time:1407286ms step_avg:255.87ms x-lambda: 0.6828557252883911 lambdas: [-0.007759396918118, -0.004754122346639633, -0.007594431284815073, -0.012246811762452126, -0.005576299969106913, -0.005725497845560312] skip-layers: [8, 5, 2, 12, 11, 7]
step:5550/5550 val_loss:2.919645 train_time:1420551ms step_avg:255.96ms x-lambda: 0.6840049028396606 lambdas: [-0.00722518702968955, -0.004761979915201664, -0.008234974928200245, -0.011924258433282375, -0.005739364307373762, -0.00594092532992363] skip-layers: [8, 5, 2, 12, 11, 7]

## 8000-add-skip-multiple-6-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5]
step:125/5550 val_loss:4.269403 train_time:28792ms step_avg:230.34ms x-lambda: 1.0415891408920288 lambdas: [0.03249349445104599, -0.01463531143963337, 0.0466734915971756, 0.037076130509376526, 0.04837318882346153, 0.060773782432079315] skip-layers: [1, 2, 7, 14, 6, 5]
step:250/5550 val_loss:3.854610 train_time:58934ms step_avg:235.74ms x-lambda: 1.0038065910339355 lambdas: [-0.012606058269739151, -0.10757119953632355, 0.038885585963726044, 0.025171294808387756, 0.02167556621134281, 0.06122355908155441] skip-layers: [1, 2, 7, 14, 6, 5]
step:375/5550 val_loss:3.672246 train_time:88375ms step_avg:235.67ms x-lambda: 0.9732498526573181 lambdas: [-0.020299702882766724, -0.14801210165023804, 0.029800986871123314, 0.023591173812747, -0.011311681009829044, 0.04192236810922623] skip-layers: [1, 2, 7, 14, 6, 5]
step:500/5550 val_loss:3.557246 train_time:118242ms step_avg:236.48ms x-lambda: 0.9476670622825623 lambdas: [-0.017605481669306755, -0.16867420077323914, 0.028114493936300278, 0.014113928191363811, -0.03276297077536583, 0.02915177121758461] skip-layers: [1, 2, 7, 14, 6, 5]
step:625/5550 val_loss:3.479514 train_time:148320ms step_avg:237.31ms x-lambda: 0.9197843074798584 lambdas: [-0.013477630913257599, -0.18263699114322662, 0.027174733579158783, -0.0019047318492084742, -0.04661594703793526, 0.021762918680906296] skip-layers: [1, 2, 7, 14, 6, 5]
step:750/5550 val_loss:3.427412 train_time:179599ms step_avg:239.47ms x-lambda: 0.8993679881095886 lambdas: [-0.007127986755222082, -0.1878795027732849, 0.027688778936862946, -0.01440154854208231, -0.051973797380924225, 0.019300410524010658] skip-layers: [1, 2, 7, 14, 6, 5]
step:875/5550 val_loss:3.381182 train_time:210036ms step_avg:240.04ms x-lambda: 0.8757450580596924 lambdas: [-0.0012553639244288206, -0.18679136037826538, 0.027075152844190598, -0.029317550361156464, -0.054318781942129135, 0.01707308739423752] skip-layers: [1, 2, 7, 14, 6, 5]
step:1000/5550 val_loss:3.346930 train_time:240704ms step_avg:240.70ms x-lambda: 0.8553991913795471 lambdas: [0.004729380831122398, -0.1833684891462326, 0.026368172839283943, -0.04274750128388405, -0.0546821728348732, 0.01694333925843239] skip-layers: [1, 2, 7, 14, 6, 5]
step:1125/5550 val_loss:3.317825 train_time:272264ms step_avg:242.01ms x-lambda: 0.8365466594696045 lambdas: [0.005690924823284149, -0.1798633337020874, 0.023699263110756874, -0.05688267573714256, -0.05676841363310814, 0.013773265294730663] skip-layers: [1, 2, 7, 14, 6, 5]
step:1250/5550 val_loss:3.294852 train_time:303095ms step_avg:242.48ms x-lambda: 0.8227558135986328 lambdas: [0.009440310299396515, -0.17298489809036255, 0.025814516469836235, -0.06689904630184174, -0.054308902472257614, 0.015147756785154343] skip-layers: [1, 2, 7, 14, 6, 5]
step:1375/5550 val_loss:3.273273 train_time:339305ms step_avg:246.77ms x-lambda: 0.8061983585357666 lambdas: [0.011330080218613148, -0.16590915620326996, 0.02217208966612816, -0.07740044593811035, -0.05526835098862648, 0.012337224557995796] skip-layers: [1, 2, 7, 14, 6, 5]
step:1500/5550 val_loss:3.255207 train_time:370302ms step_avg:246.87ms x-lambda: 0.7927370071411133 lambdas: [0.009524372406303883, -0.16201061010360718, 0.02002507634460926, -0.08784947544336319, -0.057579487562179565, 0.009010049514472485] skip-layers: [1, 2, 7, 14, 6, 5]
step:1625/5550 val_loss:3.236858 train_time:401391ms step_avg:247.01ms x-lambda: 0.781967282295227 lambdas: [0.012240896001458168, -0.15286748111248016, 0.022187614813447, -0.09417986869812012, -0.05332307517528534, 0.011044956743717194] skip-layers: [1, 2, 7, 14, 6, 5]
step:1750/5550 val_loss:3.220899 train_time:432469ms step_avg:247.13ms x-lambda: 0.7680599689483643 lambdas: [0.011720461770892143, -0.14836353063583374, 0.02017112262547016, -0.10483893752098083, -0.05322927236557007, 0.009438099339604378] skip-layers: [1, 2, 7, 14, 6, 5]
step:1875/5550 val_loss:3.204568 train_time:463594ms step_avg:247.25ms x-lambda: 0.7635996341705322 lambdas: [0.013193274848163128, -0.14135600626468658, 0.021778544411063194, -0.10889466851949692, -0.05073678120970726, 0.011398534290492535] skip-layers: [1, 2, 7, 14, 6, 5]
step:2000/5550 val_loss:3.188037 train_time:496103ms step_avg:248.05ms x-lambda: 0.7543957233428955 lambdas: [0.01302720420062542, -0.13603489100933075, 0.019172269850969315, -0.1176697239279747, -0.05023423582315445, 0.010349778458476067] skip-layers: [1, 2, 7, 14, 6, 5]
step:2125/5550 val_loss:3.173668 train_time:528576ms step_avg:248.74ms x-lambda: 0.750275731086731 lambdas: [0.012530959211289883, -0.13216672837734222, 0.01808706857264042, -0.12316662073135376, -0.04963649436831474, 0.009125069715082645] skip-layers: [1, 2, 7, 14, 6, 5]
step:2250/5550 val_loss:3.159450 train_time:559945ms step_avg:248.86ms x-lambda: 0.7464059591293335 lambdas: [0.012401429936289787, -0.1275145560503006, 0.017813241109251976, -0.12898658215999603, -0.049823105335235596, 0.00773194245994091] skip-layers: [1, 2, 7, 14, 6, 5]
step:2375/5550 val_loss:3.148345 train_time:591362ms step_avg:248.99ms x-lambda: 0.7427549362182617 lambdas: [0.012862504459917545, -0.12321962416172028, 0.017075615003705025, -0.13475589454174042, -0.047614455223083496, 0.007402168586850166] skip-layers: [1, 2, 7, 14, 6, 5]
step:2500/5550 val_loss:3.136763 train_time:622732ms step_avg:249.09ms x-lambda: 0.74275803565979 lambdas: [0.01377827674150467, -0.11937553435564041, 0.016469363123178482, -0.13818563520908356, -0.044890254735946655, 0.007214363664388657] skip-layers: [1, 2, 7, 14, 6, 5]
step:2625/5550 val_loss:3.125214 train_time:656410ms step_avg:250.06ms x-lambda: 0.7396869659423828 lambdas: [0.012548481114208698, -0.1168932169675827, 0.014757339842617512, -0.14346952736377716, -0.04655659943819046, 0.0077192834578454494] skip-layers: [1, 2, 7, 14, 6, 5]
step:2750/5550 val_loss:3.114544 train_time:687751ms step_avg:250.09ms x-lambda: 0.7404573559761047 lambdas: [0.013944774866104126, -0.11324696987867355, 0.016532685607671738, -0.146832674741745, -0.04314982891082764, 0.008405586704611778] skip-layers: [1, 2, 7, 14, 6, 5]
step:2875/5550 val_loss:3.104820 train_time:719088ms step_avg:250.12ms x-lambda: 0.7408413290977478 lambdas: [0.012802427634596825, -0.10908408463001251, 0.014414601027965546, -0.15104258060455322, -0.043476544320583344, 0.007576419971883297] skip-layers: [1, 2, 7, 14, 6, 5]
step:3000/5550 val_loss:3.094259 train_time:750492ms step_avg:250.16ms x-lambda: 0.7416697144508362 lambdas: [0.01162679959088564, -0.10773619264364243, 0.013889797963202, -0.1549263745546341, -0.04412307217717171, 0.006401730701327324] skip-layers: [1, 2, 7, 14, 6, 5]
step:3125/5550 val_loss:3.083464 train_time:781896ms step_avg:250.21ms x-lambda: 0.7422078251838684 lambdas: [0.012138952501118183, -0.10751096159219742, 0.012968039140105247, -0.15938003361225128, -0.04359173774719238, 0.005725666414946318] skip-layers: [1, 2, 7, 14, 6, 5]
step:3250/5550 val_loss:3.071770 train_time:813269ms step_avg:250.24ms x-lambda: 0.7471686005592346 lambdas: [0.011874605901539326, -0.10326974838972092, 0.013713189400732517, -0.1622486114501953, -0.04275095835328102, 0.006348905153572559] skip-layers: [1, 2, 7, 14, 6, 5]
step:3375/5550 val_loss:3.063560 train_time:844616ms step_avg:250.26ms x-lambda: 0.749325692653656 lambdas: [0.011533577926456928, -0.10239630937576294, 0.012412234209477901, -0.16618715226650238, -0.041685041040182114, 0.006236847024410963] skip-layers: [1, 2, 7, 14, 6, 5]
step:3500/5550 val_loss:3.054513 train_time:876023ms step_avg:250.29ms x-lambda: 0.7529223561286926 lambdas: [0.01132901106029749, -0.09980583190917969, 0.013884738087654114, -0.17000038921833038, -0.04230961576104164, 0.004506558179855347] skip-layers: [1, 2, 7, 14, 6, 5]
step:3625/5550 val_loss:3.045989 train_time:908516ms step_avg:250.63ms x-lambda: 0.7583140730857849 lambdas: [0.011532483622431755, -0.09896987676620483, 0.01163023617118597, -0.17339392006397247, -0.039906058460474014, 0.005407721735537052] skip-layers: [1, 2, 7, 14, 6, 5]
step:3750/5550 val_loss:3.036398 train_time:940934ms step_avg:250.92ms x-lambda: 0.7616140246391296 lambdas: [0.01243781577795744, -0.09699644893407822, 0.013149715960025787, -0.17718505859375, -0.0404965914785862, 0.0070282090455293655] skip-layers: [1, 2, 7, 14, 6, 5]
step:3875/5550 val_loss:3.027709 train_time:974410ms step_avg:251.46ms x-lambda: 0.7701255679130554 lambdas: [0.012043536640703678, -0.0945701152086258, 0.010978312231600285, -0.17849239706993103, -0.039597999304533005, 0.00593666173517704] skip-layers: [1, 2, 7, 14, 6, 5]
step:4000/5550 val_loss:3.018421 train_time:1005848ms step_avg:251.46ms x-lambda: 0.7759977579116821 lambdas: [0.012568246573209763, -0.09364650398492813, 0.01086642686277628, -0.18247774243354797, -0.03926079720258713, 0.006763719022274017] skip-layers: [1, 2, 7, 14, 6, 5]
step:4125/5550 val_loss:3.008801 train_time:1038353ms step_avg:251.72ms x-lambda: 0.7834020256996155 lambdas: [0.011379261501133442, -0.09230885654687881, 0.011696593835949898, -0.18673570454120636, -0.037909068167209625, 0.005693704355508089] skip-layers: [1, 2, 7, 14, 6, 5]
step:4250/5550 val_loss:3.000646 train_time:1070051ms step_avg:251.78ms x-lambda: 0.789953351020813 lambdas: [0.011525396257638931, -0.09209410101175308, 0.011622932739555836, -0.19047023355960846, -0.038836777210235596, 0.006369619630277157] skip-layers: [1, 2, 7, 14, 6, 5]
step:4375/5550 val_loss:2.991432 train_time:1102845ms step_avg:252.08ms x-lambda: 0.7958616614341736 lambdas: [0.011256463825702667, -0.09175766259431839, 0.010625668801367283, -0.19489341974258423, -0.03813652694225311, 0.0036953261587768793] skip-layers: [1, 2, 7, 14, 6, 5]
step:4500/5550 val_loss:2.983455 train_time:1136805ms step_avg:252.62ms x-lambda: 0.8044769167900085 lambdas: [0.01105589047074318, -0.09009630978107452, 0.010259074158966541, -0.1974998563528061, -0.038290251046419144, 0.004336511716246605] skip-layers: [1, 2, 7, 14, 6, 5]
step:4625/5550 val_loss:2.974281 train_time:1170817ms step_avg:253.15ms x-lambda: 0.81517094373703 lambdas: [0.0100283557549119, -0.08927154541015625, 0.008586704730987549, -0.20012639462947845, -0.039092741906642914, 0.003914802800863981] skip-layers: [1, 2, 7, 14, 6, 5]
step:4750/5550 val_loss:2.964973 train_time:1202875ms step_avg:253.24ms x-lambda: 0.822733461856842 lambdas: [0.01095402892678976, -0.08831683546304703, 0.010127915069460869, -0.20418024063110352, -0.03734653815627098, 0.005569417029619217] skip-layers: [1, 2, 7, 14, 6, 5]
step:4875/5550 val_loss:2.956056 train_time:1235012ms step_avg:253.34ms x-lambda: 0.8316723704338074 lambdas: [0.01176351960748434, -0.08745715022087097, 0.008692510426044464, -0.20749840140342712, -0.03700243681669235, 0.0038940708618611097] skip-layers: [1, 2, 7, 14, 6, 5]
step:5000/5550 val_loss:2.947851 train_time:1270503ms step_avg:254.10ms x-lambda: 0.8414795398712158 lambdas: [0.011130568571388721, -0.08733192086219788, 0.00838212389498949, -0.21033793687820435, -0.03666715696454048, 0.0040735346265137196] skip-layers: [1, 2, 7, 14, 6, 5]
step:5125/5550 val_loss:2.940290 train_time:1302911ms step_avg:254.23ms x-lambda: 0.8503218293190002 lambdas: [0.011321917176246643, -0.08617109060287476, 0.008397518657147884, -0.21261140704154968, -0.035780441015958786, 0.004596593324095011] skip-layers: [1, 2, 7, 14, 6, 5]
step:5250/5550 val_loss:2.932994 train_time:1335494ms step_avg:254.38ms x-lambda: 0.8579341769218445 lambdas: [0.010492578148841858, -0.08568961918354034, 0.008267655037343502, -0.21505047380924225, -0.03553036227822304, 0.003955410327762365] skip-layers: [1, 2, 7, 14, 6, 5]
step:5375/5550 val_loss:2.926558 train_time:1370329ms step_avg:254.94ms x-lambda: 0.8666825294494629 lambdas: [0.010831955820322037, -0.08508139103651047, 0.007976029068231583, -0.21586757898330688, -0.03574912250041962, 0.003798452904447913] skip-layers: [1, 2, 7, 14, 6, 5]
step:5500/5550 val_loss:2.921799 train_time:1406438ms step_avg:255.72ms x-lambda: 0.87163907289505 lambdas: [0.010338397696614265, -0.08544892817735672, 0.0075505138374865055, -0.21626663208007812, -0.03496617451310158, 0.0036332421004772186] skip-layers: [1, 2, 7, 14, 6, 5]
step:5550/5550 val_loss:2.920623 train_time:1421728ms step_avg:256.17ms x-lambda: 0.8728266954421997 lambdas: [0.010286189615726471, -0.08565317094326019, 0.006912713870406151, -0.21644003689289093, -0.03507797047495842, 0.003808412468060851] skip-layers: [1, 2, 7, 14, 6, 5]
