# Results: Multiple latents added

## 8000-add-skip-multiple-2-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [11, 10]
step:125/5550 val_loss:4.260118 train_time:28552ms step_avg:228.42ms x-lambda: 1.0494449138641357 lambdas: [0.06435445696115494, 0.07647373527288437] skip-layers: [11, 10]
step:250/5550 val_loss:3.852296 train_time:58375ms step_avg:233.50ms x-lambda: 0.9841328859329224 lambdas: [0.037230174988508224, 0.0578872412443161] skip-layers: [11, 10]
step:375/5550 val_loss:3.677218 train_time:88677ms step_avg:236.47ms x-lambda: 0.9680787920951843 lambdas: [0.011940455064177513, 0.0015431006904691458] skip-layers: [11, 10]
step:500/5550 val_loss:3.559587 train_time:118289ms step_avg:236.58ms x-lambda: 0.9522125720977783 lambdas: [-0.00907343253493309, -0.05514099448919296] skip-layers: [11, 10]
step:625/5550 val_loss:3.482390 train_time:148111ms step_avg:236.98ms x-lambda: 0.9379776120185852 lambdas: [-0.020941659808158875, -0.09955878555774689] skip-layers: [11, 10]
step:750/5550 val_loss:3.429797 train_time:181373ms step_avg:241.83ms x-lambda: 0.9210300445556641 lambdas: [-0.030674481764435768, -0.1374158263206482] skip-layers: [11, 10]
step:875/5550 val_loss:3.382771 train_time:211554ms step_avg:241.78ms x-lambda: 0.904874324798584 lambdas: [-0.03556593507528305, -0.16690786182880402] skip-layers: [11, 10]
step:1000/5550 val_loss:3.347808 train_time:243082ms step_avg:243.08ms x-lambda: 0.8894418478012085 lambdas: [-0.03786215931177139, -0.1902882307767868] skip-layers: [11, 10]
step:1125/5550 val_loss:3.319516 train_time:273571ms step_avg:243.17ms x-lambda: 0.8722665309906006 lambdas: [-0.03999707102775574, -0.21265634894371033] skip-layers: [11, 10]
step:1250/5550 val_loss:3.292939 train_time:304237ms step_avg:243.39ms x-lambda: 0.860691249370575 lambdas: [-0.037929557263851166, -0.22530406713485718] skip-layers: [11, 10]
step:1375/5550 val_loss:3.270904 train_time:336142ms step_avg:244.47ms x-lambda: 0.8418571352958679 lambdas: [-0.03722791373729706, -0.23903211951255798] skip-layers: [11, 10]
step:1500/5550 val_loss:3.253137 train_time:368089ms step_avg:245.39ms x-lambda: 0.826492965221405 lambdas: [-0.03687911853194237, -0.251534104347229] skip-layers: [11, 10]
step:1625/5550 val_loss:3.238040 train_time:400178ms step_avg:246.26ms x-lambda: 0.8099939227104187 lambdas: [-0.03271370753645897, -0.2602120041847229] skip-layers: [11, 10]
step:1750/5550 val_loss:3.220700 train_time:431024ms step_avg:246.30ms x-lambda: 0.7980974912643433 lambdas: [-0.028769273310899734, -0.2639766335487366] skip-layers: [11, 10]
step:1875/5550 val_loss:3.202976 train_time:461951ms step_avg:246.37ms x-lambda: 0.7875993251800537 lambdas: [-0.02516946569085121, -0.2699486017227173] skip-layers: [11, 10]
step:2000/5550 val_loss:3.187079 train_time:493075ms step_avg:246.54ms x-lambda: 0.7730662226676941 lambdas: [-0.022099100053310394, -0.2745365500450134] skip-layers: [11, 10]
step:2125/5550 val_loss:3.172670 train_time:525424ms step_avg:247.26ms x-lambda: 0.7644621729850769 lambdas: [-0.0197710283100605, -0.2786172926425934] skip-layers: [11, 10]
step:2250/5550 val_loss:3.157483 train_time:556614ms step_avg:247.38ms x-lambda: 0.7571346163749695 lambdas: [-0.01657584309577942, -0.2814725637435913] skip-layers: [11, 10]
step:2375/5550 val_loss:3.146708 train_time:591092ms step_avg:248.88ms x-lambda: 0.7501256465911865 lambdas: [-0.012249812483787537, -0.2818249464035034] skip-layers: [11, 10]
step:2500/5550 val_loss:3.135623 train_time:622285ms step_avg:248.91ms x-lambda: 0.7417415380477905 lambdas: [-0.00967254489660263, -0.2834200859069824] skip-layers: [11, 10]
step:2625/5550 val_loss:3.123552 train_time:653415ms step_avg:248.92ms x-lambda: 0.7357239127159119 lambdas: [-0.007536574732512236, -0.28496861457824707] skip-layers: [11, 10]
step:2750/5550 val_loss:3.112425 train_time:687714ms step_avg:250.08ms x-lambda: 0.7302332520484924 lambdas: [-0.005033496767282486, -0.28640103340148926] skip-layers: [11, 10]
step:2875/5550 val_loss:3.103103 train_time:718876ms step_avg:250.04ms x-lambda: 0.7264649868011475 lambdas: [-0.0017005116678774357, -0.28644949197769165] skip-layers: [11, 10]
step:3000/5550 val_loss:3.091649 train_time:752321ms step_avg:250.77ms x-lambda: 0.7225647568702698 lambdas: [-7.252139039337635e-05, -0.2881435751914978] skip-layers: [11, 10]
step:3125/5550 val_loss:3.080803 train_time:785703ms step_avg:251.42ms x-lambda: 0.7195106744766235 lambdas: [0.0008494702633470297, -0.28874698281288147] skip-layers: [11, 10]
step:3250/5550 val_loss:3.069235 train_time:816842ms step_avg:251.34ms x-lambda: 0.719166100025177 lambdas: [0.003341814037412405, -0.28895482420921326] skip-layers: [11, 10]
step:3375/5550 val_loss:3.061130 train_time:847986ms step_avg:251.26ms x-lambda: 0.7170857787132263 lambdas: [0.005489509552717209, -0.29133671522140503] skip-layers: [11, 10]
step:3500/5550 val_loss:3.051857 train_time:879173ms step_avg:251.19ms x-lambda: 0.7158034443855286 lambdas: [0.0062484173104166985, -0.290528267621994] skip-layers: [11, 10]
step:3625/5550 val_loss:3.042915 train_time:911483ms step_avg:251.44ms x-lambda: 0.7157261967658997 lambdas: [0.008076002821326256, -0.2905011475086212] skip-layers: [11, 10]
step:3750/5550 val_loss:3.033459 train_time:942649ms step_avg:251.37ms x-lambda: 0.717269241809845 lambdas: [0.00900631956756115, -0.28964632749557495] skip-layers: [11, 10]
step:3875/5550 val_loss:3.024678 train_time:976003ms step_avg:251.87ms x-lambda: 0.7210036516189575 lambdas: [0.01102032046765089, -0.29245609045028687] skip-layers: [11, 10]
step:4000/5550 val_loss:3.015457 train_time:1007225ms step_avg:251.81ms x-lambda: 0.7213815450668335 lambdas: [0.011979123577475548, -0.2914511263370514] skip-layers: [11, 10]
step:4125/5550 val_loss:3.006187 train_time:1038451ms step_avg:251.75ms x-lambda: 0.7247418761253357 lambdas: [0.013729836791753769, -0.29269325733184814] skip-layers: [11, 10]
step:4250/5550 val_loss:2.998001 train_time:1069910ms step_avg:251.74ms x-lambda: 0.7279546856880188 lambdas: [0.013745937496423721, -0.2929306924343109] skip-layers: [11, 10]
step:4375/5550 val_loss:2.988824 train_time:1101441ms step_avg:251.76ms x-lambda: 0.7302743792533875 lambdas: [0.013986730016767979, -0.29450827836990356] skip-layers: [11, 10]
step:4500/5550 val_loss:2.980301 train_time:1134166ms step_avg:252.04ms x-lambda: 0.7348468899726868 lambdas: [0.015047854743897915, -0.29518023133277893] skip-layers: [11, 10]
step:4625/5550 val_loss:2.971037 train_time:1165876ms step_avg:252.08ms x-lambda: 0.7420129776000977 lambdas: [0.01542761828750372, -0.2954801321029663] skip-layers: [11, 10]
step:4750/5550 val_loss:2.961789 train_time:1197737ms step_avg:252.16ms x-lambda: 0.7464194297790527 lambdas: [0.016415413469076157, -0.29638808965682983] skip-layers: [11, 10]
step:4875/5550 val_loss:2.953018 train_time:1229742ms step_avg:252.25ms x-lambda: 0.7514529228210449 lambdas: [0.017339283600449562, -0.29814621806144714] skip-layers: [11, 10]
step:5000/5550 val_loss:2.944859 train_time:1262851ms step_avg:252.57ms x-lambda: 0.7578006982803345 lambdas: [0.018056420609354973, -0.2987178862094879] skip-layers: [11, 10]
step:5125/5550 val_loss:2.937287 train_time:1295059ms step_avg:252.69ms x-lambda: 0.7633615136146545 lambdas: [0.018424462527036667, -0.30087271332740784] skip-layers: [11, 10]
step:5250/5550 val_loss:2.930190 train_time:1328556ms step_avg:253.06ms x-lambda: 0.7687625885009766 lambdas: [0.018855487927794456, -0.30079385638237] skip-layers: [11, 10]
step:5375/5550 val_loss:2.923626 train_time:1363295ms step_avg:253.64ms x-lambda: 0.7748658657073975 lambdas: [0.019191799685359, -0.3021552264690399] skip-layers: [11, 10]
step:5500/5550 val_loss:2.918827 train_time:1396018ms step_avg:253.82ms x-lambda: 0.7789164781570435 lambdas: [0.019819999113678932, -0.30264267325401306] skip-layers: [11, 10]
step:5550/5550 val_loss:2.917641 train_time:1410298ms step_avg:254.11ms x-lambda: 0.7796132564544678 lambdas: [0.019991762936115265, -0.3033408522605896] skip-layers: [11, 10]

## 8000-add-skip-multiple-2-method-btw-1

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [11, 10]
step:125/5550 val_loss:4.260901 train_time:28533ms step_avg:228.27ms x-lambda: 1.0574805736541748 lambdas: [0.06668134778738022, 0.07399550825357437] skip-layers: [11, 10]
step:250/5550 val_loss:3.853384 train_time:57242ms step_avg:228.97ms x-lambda: 1.0064411163330078 lambdas: [0.03633961081504822, 0.043152593076229095] skip-layers: [11, 10]
step:375/5550 val_loss:3.676846 train_time:86442ms step_avg:230.51ms x-lambda: 0.9903998374938965 lambdas: [0.011585856787860394, -0.01808764412999153] skip-layers: [11, 10]
step:500/5550 val_loss:3.562594 train_time:116006ms step_avg:232.01ms x-lambda: 0.9751916527748108 lambdas: [-0.0074414415284991264, -0.07766488194465637] skip-layers: [11, 10]
step:625/5550 val_loss:3.483558 train_time:145789ms step_avg:233.26ms x-lambda: 0.9619582295417786 lambdas: [-0.019057374447584152, -0.1272224485874176] skip-layers: [11, 10]
step:750/5550 val_loss:3.430508 train_time:175898ms step_avg:234.53ms x-lambda: 0.9488825798034668 lambdas: [-0.023885447531938553, -0.16744525730609894] skip-layers: [11, 10]
step:875/5550 val_loss:3.385681 train_time:206135ms step_avg:235.58ms x-lambda: 0.9316364526748657 lambdas: [-0.02754884772002697, -0.20087465643882751] skip-layers: [11, 10]
step:1000/5550 val_loss:3.350697 train_time:236599ms step_avg:236.60ms x-lambda: 0.9159334897994995 lambdas: [-0.031389664858579636, -0.22984814643859863] skip-layers: [11, 10]
step:1125/5550 val_loss:3.319973 train_time:267757ms step_avg:238.01ms x-lambda: 0.8992794156074524 lambdas: [-0.03136175125837326, -0.25231409072875977] skip-layers: [11, 10]
step:1250/5550 val_loss:3.295528 train_time:299161ms step_avg:239.33ms x-lambda: 0.8865606784820557 lambdas: [-0.027571002021431923, -0.266535222530365] skip-layers: [11, 10]
step:1375/5550 val_loss:3.273605 train_time:329911ms step_avg:239.94ms x-lambda: 0.868080198764801 lambdas: [-0.02535093203186989, -0.2809578478336334] skip-layers: [11, 10]
step:1500/5550 val_loss:3.253445 train_time:360665ms step_avg:240.44ms x-lambda: 0.8547984957695007 lambdas: [-0.020976554602384567, -0.29155248403549194] skip-layers: [11, 10]
step:1625/5550 val_loss:3.238336 train_time:392615ms step_avg:241.61ms x-lambda: 0.8362042903900146 lambdas: [-0.01718778721988201, -0.3015180230140686] skip-layers: [11, 10]
step:1750/5550 val_loss:3.222440 train_time:424547ms step_avg:242.60ms x-lambda: 0.8204765319824219 lambdas: [-0.014206230640411377, -0.30884578824043274] skip-layers: [11, 10]
step:1875/5550 val_loss:3.203633 train_time:455481ms step_avg:242.92ms x-lambda: 0.8068656325340271 lambdas: [-0.009291933849453926, -0.31364312767982483] skip-layers: [11, 10]
step:2000/5550 val_loss:3.187464 train_time:487652ms step_avg:243.83ms x-lambda: 0.7935529351234436 lambdas: [-0.0048820627853274345, -0.31596627831459045] skip-layers: [11, 10]
step:2125/5550 val_loss:3.173324 train_time:518784ms step_avg:244.13ms x-lambda: 0.7838772535324097 lambdas: [-0.0019660654943436384, -0.32124054431915283] skip-layers: [11, 10]
step:2250/5550 val_loss:3.159331 train_time:551044ms step_avg:244.91ms x-lambda: 0.7758169174194336 lambdas: [0.0027375693898648024, -0.321201354265213] skip-layers: [11, 10]
step:2375/5550 val_loss:3.147183 train_time:582222ms step_avg:245.15ms x-lambda: 0.7662393450737 lambdas: [0.005200206767767668, -0.3229479491710663] skip-layers: [11, 10]
step:2500/5550 val_loss:3.136450 train_time:614462ms step_avg:245.78ms x-lambda: 0.758723795413971 lambdas: [0.008917825296521187, -0.3237142860889435] skip-layers: [11, 10]
step:2625/5550 val_loss:3.124733 train_time:648819ms step_avg:247.17ms x-lambda: 0.7524063587188721 lambdas: [0.011395959183573723, -0.3244720995426178] skip-layers: [11, 10]
step:2750/5550 val_loss:3.113028 train_time:679955ms step_avg:247.26ms x-lambda: 0.745544970035553 lambdas: [0.012304818257689476, -0.3246852159500122] skip-layers: [11, 10]
step:2875/5550 val_loss:3.103998 train_time:713078ms step_avg:248.03ms x-lambda: 0.7417479157447815 lambdas: [0.015794947743415833, -0.32525527477264404] skip-layers: [11, 10]
step:3000/5550 val_loss:3.092236 train_time:745399ms step_avg:248.47ms x-lambda: 0.7380446791648865 lambdas: [0.018463177606463432, -0.3251001834869385] skip-layers: [11, 10]
step:3125/5550 val_loss:3.081511 train_time:777657ms step_avg:248.85ms x-lambda: 0.7337607741355896 lambdas: [0.018944161012768745, -0.326505184173584] skip-layers: [11, 10]
step:3250/5550 val_loss:3.070253 train_time:809826ms step_avg:249.18ms x-lambda: 0.733624279499054 lambdas: [0.02222406305372715, -0.3261064887046814] skip-layers: [11, 10]
step:3375/5550 val_loss:3.061992 train_time:841933ms step_avg:249.46ms x-lambda: 0.7304957509040833 lambdas: [0.022945741191506386, -0.32746589183807373] skip-layers: [11, 10]
step:3500/5550 val_loss:3.052600 train_time:873121ms step_avg:249.46ms x-lambda: 0.7289108037948608 lambdas: [0.024449961259961128, -0.3248463571071625] skip-layers: [11, 10]
step:3625/5550 val_loss:3.044408 train_time:908404ms step_avg:250.59ms x-lambda: 0.7286638617515564 lambdas: [0.027106156572699547, -0.32489874958992004] skip-layers: [11, 10]
step:3750/5550 val_loss:3.034481 train_time:940695ms step_avg:250.85ms x-lambda: 0.7290119528770447 lambdas: [0.028510883450508118, -0.3233857750892639] skip-layers: [11, 10]
step:3875/5550 val_loss:3.025978 train_time:971942ms step_avg:250.82ms x-lambda: 0.7355549931526184 lambdas: [0.030125580728054047, -0.3271944224834442] skip-layers: [11, 10]
step:4000/5550 val_loss:3.016117 train_time:1006217ms step_avg:251.55ms x-lambda: 0.7351629137992859 lambdas: [0.03141627088189125, -0.325266569852829] skip-layers: [11, 10]
step:4125/5550 val_loss:3.006439 train_time:1037486ms step_avg:251.51ms x-lambda: 0.7379802465438843 lambdas: [0.03208867460489273, -0.3258052170276642] skip-layers: [11, 10]
step:4250/5550 val_loss:2.998228 train_time:1070039ms step_avg:251.77ms x-lambda: 0.7406708598136902 lambdas: [0.0329551063477993, -0.32728272676467896] skip-layers: [11, 10]
step:4375/5550 val_loss:2.989170 train_time:1102579ms step_avg:252.02ms x-lambda: 0.7418773174285889 lambdas: [0.03348788619041443, -0.327522337436676] skip-layers: [11, 10]
step:4500/5550 val_loss:2.980971 train_time:1134127ms step_avg:252.03ms x-lambda: 0.747016966342926 lambdas: [0.03432104364037514, -0.32743018865585327] skip-layers: [11, 10]
step:4625/5550 val_loss:2.971476 train_time:1166906ms step_avg:252.30ms x-lambda: 0.7531640529632568 lambdas: [0.03467859700322151, -0.32936355471611023] skip-layers: [11, 10]
step:4750/5550 val_loss:2.962186 train_time:1199741ms step_avg:252.58ms x-lambda: 0.757854163646698 lambdas: [0.03586225211620331, -0.33031418919563293] skip-layers: [11, 10]
step:4875/5550 val_loss:2.953396 train_time:1232805ms step_avg:252.88ms x-lambda: 0.7627427577972412 lambdas: [0.037510037422180176, -0.33185964822769165] skip-layers: [11, 10]
step:5000/5550 val_loss:2.945096 train_time:1264864ms step_avg:252.97ms x-lambda: 0.7693153619766235 lambdas: [0.038287125527858734, -0.3334605395793915] skip-layers: [11, 10]
step:5125/5550 val_loss:2.937568 train_time:1298220ms step_avg:253.31ms x-lambda: 0.7747709155082703 lambdas: [0.03901800885796547, -0.3349185883998871] skip-layers: [11, 10]
step:5250/5550 val_loss:2.930445 train_time:1330574ms step_avg:253.44ms x-lambda: 0.7800903916358948 lambdas: [0.039249129593372345, -0.3351052701473236] skip-layers: [11, 10]
step:5375/5550 val_loss:2.923943 train_time:1364171ms step_avg:253.80ms x-lambda: 0.7864841222763062 lambdas: [0.03996630758047104, -0.33666306734085083] skip-layers: [11, 10]
step:5500/5550 val_loss:2.919153 train_time:1397968ms step_avg:254.18ms x-lambda: 0.7902753353118896 lambdas: [0.0402495414018631, -0.33697643876075745] skip-layers: [11, 10]
step:5550/5550 val_loss:2.917946 train_time:1411169ms step_avg:254.26ms x-lambda: 0.7911221385002136 lambdas: [0.04036382958292961, -0.33735254406929016] skip-layers: [11, 10]

## 8000-add-skip-multiple-2-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [14, 13]
step:125/5550 val_loss:4.260280 train_time:28531ms step_avg:228.25ms x-lambda: 1.064366102218628 lambdas: [0.057757411152124405, 0.06480863690376282] skip-layers: [14, 13]
step:250/5550 val_loss:3.853284 train_time:57283ms step_avg:229.13ms x-lambda: 0.9986088871955872 lambdas: [0.01446889340877533, 0.03701376914978027] skip-layers: [14, 13]
step:375/5550 val_loss:3.677904 train_time:86462ms step_avg:230.57ms x-lambda: 0.9550095796585083 lambdas: [-0.0059531801380217075, 0.0156747717410326] skip-layers: [14, 13]
step:500/5550 val_loss:3.562188 train_time:117090ms step_avg:234.18ms x-lambda: 0.9315032362937927 lambdas: [-0.023837527260184288, -0.008061228320002556] skip-layers: [14, 13]
step:625/5550 val_loss:3.483756 train_time:147909ms step_avg:236.65ms x-lambda: 0.90778648853302 lambdas: [-0.04175791144371033, -0.03336654603481293] skip-layers: [14, 13]
step:750/5550 val_loss:3.429993 train_time:177995ms step_avg:237.33ms x-lambda: 0.8956899642944336 lambdas: [-0.05168610066175461, -0.053253330290317535] skip-layers: [14, 13]
step:875/5550 val_loss:3.384447 train_time:209414ms step_avg:239.33ms x-lambda: 0.8792915940284729 lambdas: [-0.05870913341641426, -0.07120776176452637] skip-layers: [14, 13]
step:1000/5550 val_loss:3.348421 train_time:240857ms step_avg:240.86ms x-lambda: 0.8659036159515381 lambdas: [-0.06529621034860611, -0.09013484418392181] skip-layers: [14, 13]
step:1125/5550 val_loss:3.319889 train_time:272492ms step_avg:242.22ms x-lambda: 0.8562027812004089 lambdas: [-0.06873922795057297, -0.10490383952856064] skip-layers: [14, 13]
step:1250/5550 val_loss:3.294917 train_time:304116ms step_avg:243.29ms x-lambda: 0.8466006517410278 lambdas: [-0.07198569178581238, -0.1200709342956543] skip-layers: [14, 13]
step:1375/5550 val_loss:3.275172 train_time:336035ms step_avg:244.39ms x-lambda: 0.8375115394592285 lambdas: [-0.07429042458534241, -0.13439543545246124] skip-layers: [14, 13]
step:1500/5550 val_loss:3.256184 train_time:366829ms step_avg:244.55ms x-lambda: 0.8325230479240417 lambdas: [-0.07199255377054214, -0.14401192963123322] skip-layers: [14, 13]
step:1625/5550 val_loss:3.240898 train_time:397716ms step_avg:244.75ms x-lambda: 0.8236042857170105 lambdas: [-0.07235449552536011, -0.15613391995429993] skip-layers: [14, 13]
step:1750/5550 val_loss:3.224366 train_time:428584ms step_avg:244.91ms x-lambda: 0.8146304488182068 lambdas: [-0.07418496161699295, -0.16885541379451752] skip-layers: [14, 13]
step:1875/5550 val_loss:3.206145 train_time:460656ms step_avg:245.68ms x-lambda: 0.8134023547172546 lambdas: [-0.07116653025150299, -0.17604997754096985] skip-layers: [14, 13]
step:2000/5550 val_loss:3.190193 train_time:491827ms step_avg:245.91ms x-lambda: 0.8088297247886658 lambdas: [-0.07149123400449753, -0.1873389184474945] skip-layers: [14, 13]
step:2125/5550 val_loss:3.175781 train_time:523000ms step_avg:246.12ms x-lambda: 0.806866466999054 lambdas: [-0.07008667290210724, -0.1965264528989792] skip-layers: [14, 13]
step:2250/5550 val_loss:3.161342 train_time:555306ms step_avg:246.80ms x-lambda: 0.8067318797111511 lambdas: [-0.06913518160581589, -0.20656590163707733] skip-layers: [14, 13]
step:2375/5550 val_loss:3.149740 train_time:591977ms step_avg:249.25ms x-lambda: 0.8074769377708435 lambdas: [-0.06680286675691605, -0.21573209762573242] skip-layers: [14, 13]
step:2500/5550 val_loss:3.137908 train_time:626313ms step_avg:250.53ms x-lambda: 0.809230625629425 lambdas: [-0.06526470929384232, -0.22320981323719025] skip-layers: [14, 13]
step:2625/5550 val_loss:3.127109 train_time:658469ms step_avg:250.85ms x-lambda: 0.8106725215911865 lambdas: [-0.0632878765463829, -0.23183123767375946] skip-layers: [14, 13]
step:2750/5550 val_loss:3.115447 train_time:691720ms step_avg:251.53ms x-lambda: 0.812151312828064 lambdas: [-0.06262142211198807, -0.24130256474018097] skip-layers: [14, 13]
step:2875/5550 val_loss:3.105675 train_time:724998ms step_avg:252.17ms x-lambda: 0.8144330382347107 lambdas: [-0.06085054576396942, -0.24870818853378296] skip-layers: [14, 13]
step:3000/5550 val_loss:3.094880 train_time:757207ms step_avg:252.40ms x-lambda: 0.8185297250747681 lambdas: [-0.05839484557509422, -0.25608816742897034] skip-layers: [14, 13]
step:3125/5550 val_loss:3.083783 train_time:788395ms step_avg:252.29ms x-lambda: 0.8207640051841736 lambdas: [-0.05807929113507271, -0.2637718617916107] skip-layers: [14, 13]
step:3250/5550 val_loss:3.072480 train_time:820697ms step_avg:252.52ms x-lambda: 0.826232373714447 lambdas: [-0.05519057810306549, -0.2708306312561035] skip-layers: [14, 13]
step:3375/5550 val_loss:3.063691 train_time:851785ms step_avg:252.38ms x-lambda: 0.8292471170425415 lambdas: [-0.05432865768671036, -0.2777560353279114] skip-layers: [14, 13]
step:3500/5550 val_loss:3.055121 train_time:884041ms step_avg:252.58ms x-lambda: 0.8323469758033752 lambdas: [-0.05224220082163811, -0.2846779525279999] skip-layers: [14, 13]
step:3625/5550 val_loss:3.046435 train_time:916327ms step_avg:252.78ms x-lambda: 0.8381826281547546 lambdas: [-0.04978001490235329, -0.2905491292476654] skip-layers: [14, 13]
step:3750/5550 val_loss:3.036337 train_time:947483ms step_avg:252.66ms x-lambda: 0.8424800038337708 lambdas: [-0.04781150445342064, -0.29644256830215454] skip-layers: [14, 13]
step:3875/5550 val_loss:3.028005 train_time:979841ms step_avg:252.86ms x-lambda: 0.8506889939308167 lambdas: [-0.04416031017899513, -0.30134209990501404] skip-layers: [14, 13]
step:4000/5550 val_loss:3.018487 train_time:1012049ms step_avg:253.01ms x-lambda: 0.8564274907112122 lambdas: [-0.043531373143196106, -0.3076418340206146] skip-layers: [14, 13]
step:4125/5550 val_loss:3.009227 train_time:1046551ms step_avg:253.71ms x-lambda: 0.8637865781784058 lambdas: [-0.04157496616244316, -0.31359800696372986] skip-layers: [14, 13]
step:4250/5550 val_loss:3.001017 train_time:1078012ms step_avg:253.65ms x-lambda: 0.8680006265640259 lambdas: [-0.04055385664105415, -0.3186052739620209] skip-layers: [14, 13]
step:4375/5550 val_loss:2.991637 train_time:1110533ms step_avg:253.84ms x-lambda: 0.8741406798362732 lambdas: [-0.039867743849754333, -0.3233039975166321] skip-layers: [14, 13]
step:4500/5550 val_loss:2.983426 train_time:1146380ms step_avg:254.75ms x-lambda: 0.8809259533882141 lambdas: [-0.037923119962215424, -0.3278160095214844] skip-layers: [14, 13]
step:4625/5550 val_loss:2.974274 train_time:1182456ms step_avg:255.67ms x-lambda: 0.8876212239265442 lambdas: [-0.035326674580574036, -0.3313677906990051] skip-layers: [14, 13]
step:4750/5550 val_loss:2.964815 train_time:1214282ms step_avg:255.64ms x-lambda: 0.8948732018470764 lambdas: [-0.03416607528924942, -0.33425241708755493] skip-layers: [14, 13]
step:4875/5550 val_loss:2.955830 train_time:1247376ms step_avg:255.87ms x-lambda: 0.9012800455093384 lambdas: [-0.03295081853866577, -0.3376224637031555] skip-layers: [14, 13]
step:5000/5550 val_loss:2.947818 train_time:1279429ms step_avg:255.89ms x-lambda: 0.9092828631401062 lambdas: [-0.031223686411976814, -0.34114745259284973] skip-layers: [14, 13]
step:5125/5550 val_loss:2.940137 train_time:1311637ms step_avg:255.93ms x-lambda: 0.9160402417182922 lambdas: [-0.02997155487537384, -0.343195378780365] skip-layers: [14, 13]
step:5250/5550 val_loss:2.932924 train_time:1346243ms step_avg:256.43ms x-lambda: 0.921593189239502 lambdas: [-0.02962120994925499, -0.34623879194259644] skip-layers: [14, 13]
step:5375/5550 val_loss:2.926523 train_time:1382027ms step_avg:257.12ms x-lambda: 0.9278513789176941 lambdas: [-0.02858327329158783, -0.34785932302474976] skip-layers: [14, 13]
step:5500/5550 val_loss:2.921696 train_time:1414797ms step_avg:257.24ms x-lambda: 0.9315034747123718 lambdas: [-0.027399256825447083, -0.34822186827659607] skip-layers: [14, 13]
step:5550/5550 val_loss:2.920460 train_time:1427992ms step_avg:257.30ms x-lambda: 0.9322582483291626 lambdas: [-0.02742256410419941, -0.34874317049980164] skip-layers: [14, 13]

## 8000-add-skip-multiple-2-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [0, 1]
step:125/5550 val_loss:4.255004 train_time:28570ms step_avg:228.56ms x-lambda: 1.1016608476638794 lambdas: [0.09298108518123627, 0.03681633993983269] skip-layers: [0, 1]
step:250/5550 val_loss:3.843181 train_time:58330ms step_avg:233.32ms x-lambda: 1.0507768392562866 lambdas: [0.05347559601068497, -0.0449603796005249] skip-layers: [0, 1]
step:375/5550 val_loss:3.674299 train_time:87524ms step_avg:233.40ms x-lambda: 0.998785674571991 lambdas: [0.04132753238081932, -0.0715327039361] skip-layers: [0, 1]
step:500/5550 val_loss:3.557582 train_time:117115ms step_avg:234.23ms x-lambda: 0.9424699544906616 lambdas: [0.033160507678985596, -0.0860212966799736] skip-layers: [0, 1]
step:625/5550 val_loss:3.479420 train_time:146901ms step_avg:235.04ms x-lambda: 0.8915643095970154 lambdas: [0.03260278329253197, -0.08991020917892456] skip-layers: [0, 1]
step:750/5550 val_loss:3.429198 train_time:176983ms step_avg:235.98ms x-lambda: 0.8493243455886841 lambdas: [0.030066976323723793, -0.09413255006074905] skip-layers: [0, 1]
step:875/5550 val_loss:3.382458 train_time:207186ms step_avg:236.78ms x-lambda: 0.8101376891136169 lambdas: [0.029011493548750877, -0.09248650819063187] skip-layers: [0, 1]
step:1000/5550 val_loss:3.347166 train_time:237646ms step_avg:237.65ms x-lambda: 0.7771593928337097 lambdas: [0.02929743379354477, -0.08945368975400925] skip-layers: [0, 1]
step:1125/5550 val_loss:3.319221 train_time:268152ms step_avg:238.36ms x-lambda: 0.7479606866836548 lambdas: [0.026851844042539597, -0.08764934539794922] skip-layers: [0, 1]
step:1250/5550 val_loss:3.294492 train_time:300966ms step_avg:240.77ms x-lambda: 0.7252474427223206 lambdas: [0.028547927737236023, -0.08285249769687653] skip-layers: [0, 1]
step:1375/5550 val_loss:3.273416 train_time:331806ms step_avg:241.31ms x-lambda: 0.6995199918746948 lambdas: [0.02428208664059639, -0.081593357026577] skip-layers: [0, 1]
step:1500/5550 val_loss:3.255881 train_time:362632ms step_avg:241.75ms x-lambda: 0.6822142004966736 lambdas: [0.0250509325414896, -0.07721123844385147] skip-layers: [0, 1]
step:1625/5550 val_loss:3.237963 train_time:393548ms step_avg:242.18ms x-lambda: 0.6610972881317139 lambdas: [0.023734958842396736, -0.07505122572183609] skip-layers: [0, 1]
step:1750/5550 val_loss:3.223220 train_time:426653ms step_avg:243.80ms x-lambda: 0.6458138823509216 lambdas: [0.024372754618525505, -0.07029645889997482] skip-layers: [0, 1]
step:1875/5550 val_loss:3.203943 train_time:457626ms step_avg:244.07ms x-lambda: 0.6341240406036377 lambdas: [0.02275894023478031, -0.06844556331634521] skip-layers: [0, 1]
step:2000/5550 val_loss:3.189396 train_time:488835ms step_avg:244.42ms x-lambda: 0.6226385235786438 lambdas: [0.02320783957839012, -0.06514455378055573] skip-layers: [0, 1]
step:2125/5550 val_loss:3.174632 train_time:522079ms step_avg:245.68ms x-lambda: 0.6143935322761536 lambdas: [0.022321784868836403, -0.06337826699018478] skip-layers: [0, 1]
step:2250/5550 val_loss:3.160724 train_time:556512ms step_avg:247.34ms x-lambda: 0.6073980927467346 lambdas: [0.02163529396057129, -0.06113569810986519] skip-layers: [0, 1]
step:2375/5550 val_loss:3.149476 train_time:591784ms step_avg:249.17ms x-lambda: 0.6000683903694153 lambdas: [0.02174951508641243, -0.060060299932956696] skip-layers: [0, 1]
step:2500/5550 val_loss:3.137633 train_time:622949ms step_avg:249.18ms x-lambda: 0.5973846912384033 lambdas: [0.021526651456952095, -0.05745372548699379] skip-layers: [0, 1]
step:2625/5550 val_loss:3.125587 train_time:656328ms step_avg:250.03ms x-lambda: 0.5926951169967651 lambdas: [0.019451677799224854, -0.0581161305308342] skip-layers: [0, 1]
step:2750/5550 val_loss:3.115042 train_time:688467ms step_avg:250.35ms x-lambda: 0.5906435251235962 lambdas: [0.01929854229092598, -0.056102849543094635] skip-layers: [0, 1]
step:2875/5550 val_loss:3.105255 train_time:719669ms step_avg:250.32ms x-lambda: 0.5881187915802002 lambdas: [0.01997499354183674, -0.05371873453259468] skip-layers: [0, 1]
step:3000/5550 val_loss:3.094403 train_time:755121ms step_avg:251.71ms x-lambda: 0.5868383049964905 lambdas: [0.018398454412817955, -0.053060512989759445] skip-layers: [0, 1]
step:3125/5550 val_loss:3.083029 train_time:787403ms step_avg:251.97ms x-lambda: 0.58609938621521 lambdas: [0.019775966182351112, -0.05249805375933647] skip-layers: [0, 1]
step:3250/5550 val_loss:3.072273 train_time:820732ms step_avg:252.53ms x-lambda: 0.5882421731948853 lambdas: [0.01930359937250614, -0.051976483315229416] skip-layers: [0, 1]
step:3375/5550 val_loss:3.063335 train_time:851887ms step_avg:252.41ms x-lambda: 0.5885835289955139 lambdas: [0.018518483266234398, -0.051518891006708145] skip-layers: [0, 1]
step:3500/5550 val_loss:3.054448 train_time:883109ms step_avg:252.32ms x-lambda: 0.5900207757949829 lambdas: [0.018004870042204857, -0.05172266811132431] skip-layers: [0, 1]
step:3625/5550 val_loss:3.045863 train_time:914309ms step_avg:252.22ms x-lambda: 0.594231903553009 lambdas: [0.017166826874017715, -0.050741761922836304] skip-layers: [0, 1]
step:3750/5550 val_loss:3.036172 train_time:946544ms step_avg:252.41ms x-lambda: 0.595531165599823 lambdas: [0.01897778920829296, -0.04888799786567688] skip-layers: [0, 1]
step:3875/5550 val_loss:3.027527 train_time:977802ms step_avg:252.34ms x-lambda: 0.6030335426330566 lambdas: [0.018527735024690628, -0.04800289124250412] skip-layers: [0, 1]
step:4000/5550 val_loss:3.018047 train_time:1011230ms step_avg:252.81ms x-lambda: 0.6048490405082703 lambdas: [0.017687510699033737, -0.04792371392250061] skip-layers: [0, 1]
step:4125/5550 val_loss:3.008865 train_time:1043474ms step_avg:252.96ms x-lambda: 0.6109626293182373 lambdas: [0.019019734114408493, -0.04729890823364258] skip-layers: [0, 1]
step:4250/5550 val_loss:3.000579 train_time:1074945ms step_avg:252.93ms x-lambda: 0.6141009330749512 lambdas: [0.017895223572850227, -0.04677757993340492] skip-layers: [0, 1]
step:4375/5550 val_loss:2.991262 train_time:1110663ms step_avg:253.87ms x-lambda: 0.6185916066169739 lambdas: [0.018010679632425308, -0.04763871803879738] skip-layers: [0, 1]
step:4500/5550 val_loss:2.982696 train_time:1142220ms step_avg:253.83ms x-lambda: 0.624687910079956 lambdas: [0.018118593841791153, -0.04654676094651222] skip-layers: [0, 1]
step:4625/5550 val_loss:2.973326 train_time:1173925ms step_avg:253.82ms x-lambda: 0.6348931789398193 lambdas: [0.016234304755926132, -0.04691702127456665] skip-layers: [0, 1]
step:4750/5550 val_loss:2.964102 train_time:1205774ms step_avg:253.85ms x-lambda: 0.640739917755127 lambdas: [0.01824270188808441, -0.04556220769882202] skip-layers: [0, 1]
step:4875/5550 val_loss:2.955076 train_time:1237770ms step_avg:253.90ms x-lambda: 0.6473108530044556 lambdas: [0.01770072989165783, -0.04621736705303192] skip-layers: [0, 1]
step:5000/5550 val_loss:2.947106 train_time:1269815ms step_avg:253.96ms x-lambda: 0.6561946272850037 lambdas: [0.01750355213880539, -0.04600933566689491] skip-layers: [0, 1]
step:5125/5550 val_loss:2.939454 train_time:1303205ms step_avg:254.28ms x-lambda: 0.6630135178565979 lambdas: [0.016645174473524094, -0.04500916600227356] skip-layers: [0, 1]
step:5250/5550 val_loss:2.932181 train_time:1335636ms step_avg:254.41ms x-lambda: 0.6716610193252563 lambdas: [0.01651698537170887, -0.044995833188295364] skip-layers: [0, 1]
step:5375/5550 val_loss:2.925706 train_time:1372518ms step_avg:255.35ms x-lambda: 0.6803640127182007 lambdas: [0.017723942175507545, -0.045587632805109024] skip-layers: [0, 1]
step:5500/5550 val_loss:2.920925 train_time:1407475ms step_avg:255.90ms x-lambda: 0.6870072484016418 lambdas: [0.016926441341638565, -0.045070815831422806] skip-layers: [0, 1]
step:5550/5550 val_loss:2.919730 train_time:1421824ms step_avg:256.18ms x-lambda: 0.6881504058837891 lambdas: [0.016929995268583298, -0.04462744668126106] skip-layers: [0, 1]

## 8000-add-skip-multiple-2-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [10, 1]
step:125/5550 val_loss:4.255990 train_time:28595ms step_avg:228.76ms x-lambda: 1.1198556423187256 lambdas: [0.04655391350388527, 0.007445622701197863] skip-layers: [10, 1]
step:250/5550 val_loss:3.852877 train_time:57368ms step_avg:229.47ms x-lambda: 1.0553269386291504 lambdas: [-0.021328050643205643, -0.017985135316848755] skip-layers: [10, 1]
step:375/5550 val_loss:3.677291 train_time:86609ms step_avg:230.96ms x-lambda: 0.9737616777420044 lambdas: [-0.025246206670999527, -0.015829242765903473] skip-layers: [10, 1]
step:500/5550 val_loss:3.562736 train_time:116267ms step_avg:232.53ms x-lambda: 0.9088780879974365 lambdas: [-0.02560555376112461, -0.01761879213154316] skip-layers: [10, 1]
step:625/5550 val_loss:3.483697 train_time:146158ms step_avg:233.85ms x-lambda: 0.8568658232688904 lambdas: [-0.022924358025193214, -0.013900436460971832] skip-layers: [10, 1]
step:750/5550 val_loss:3.431328 train_time:176255ms step_avg:235.01ms x-lambda: 0.8134022951126099 lambdas: [-0.023391801863908768, -0.015951115638017654] skip-layers: [10, 1]
step:875/5550 val_loss:3.384733 train_time:206486ms step_avg:235.98ms x-lambda: 0.7750836610794067 lambdas: [-0.02158610336482525, -0.014834537170827389] skip-layers: [10, 1]
step:1000/5550 val_loss:3.350805 train_time:238172ms step_avg:238.17ms x-lambda: 0.7389868497848511 lambdas: [-0.02251424454152584, -0.015596145763993263] skip-layers: [10, 1]
step:1125/5550 val_loss:3.320482 train_time:269789ms step_avg:239.81ms x-lambda: 0.7108231782913208 lambdas: [-0.018856357783079147, -0.013790920376777649] skip-layers: [10, 1]
step:1250/5550 val_loss:3.296337 train_time:301499ms step_avg:241.20ms x-lambda: 0.6887335777282715 lambdas: [-0.01866791397333145, -0.01339706126600504] skip-layers: [10, 1]
step:1375/5550 val_loss:3.275297 train_time:334462ms step_avg:243.24ms x-lambda: 0.6648662686347961 lambdas: [-0.017203468829393387, -0.012080611661076546] skip-layers: [10, 1]
step:1500/5550 val_loss:3.254962 train_time:365329ms step_avg:243.55ms x-lambda: 0.6475274562835693 lambdas: [-0.01818898878991604, -0.013099497184157372] skip-layers: [10, 1]
step:1625/5550 val_loss:3.239879 train_time:396255ms step_avg:243.85ms x-lambda: 0.6322579383850098 lambdas: [-0.015516056679189205, -0.01069082785397768] skip-layers: [10, 1]
step:1750/5550 val_loss:3.223609 train_time:428216ms step_avg:244.69ms x-lambda: 0.6137701869010925 lambdas: [-0.014933326281607151, -0.010093748569488525] skip-layers: [10, 1]
step:1875/5550 val_loss:3.206310 train_time:460201ms step_avg:245.44ms x-lambda: 0.6020640730857849 lambdas: [-0.014283680357038975, -0.01059283409267664] skip-layers: [10, 1]
step:2000/5550 val_loss:3.191019 train_time:492445ms step_avg:246.22ms x-lambda: 0.5924275517463684 lambdas: [-0.011856567114591599, -0.009638464078307152] skip-layers: [10, 1]
step:2125/5550 val_loss:3.175752 train_time:525692ms step_avg:247.38ms x-lambda: 0.586895763874054 lambdas: [-0.012403711676597595, -0.008608974516391754] skip-layers: [10, 1]
step:2250/5550 val_loss:3.162178 train_time:556876ms step_avg:247.50ms x-lambda: 0.5792202949523926 lambdas: [-0.011433546431362629, -0.009183593094348907] skip-layers: [10, 1]
step:2375/5550 val_loss:3.151364 train_time:588103ms step_avg:247.62ms x-lambda: 0.5733506083488464 lambdas: [-0.011883514001965523, -0.008792639710009098] skip-layers: [10, 1]
step:2500/5550 val_loss:3.139077 train_time:623574ms step_avg:249.43ms x-lambda: 0.5701061487197876 lambdas: [-0.00965317152440548, -0.007355131208896637] skip-layers: [10, 1]
step:2625/5550 val_loss:3.127608 train_time:656992ms step_avg:250.28ms x-lambda: 0.5659604668617249 lambdas: [-0.01201329380273819, -0.009088854305446148] skip-layers: [10, 1]
step:2750/5550 val_loss:3.115904 train_time:688116ms step_avg:250.22ms x-lambda: 0.564324140548706 lambdas: [-0.01132242288440466, -0.008120594546198845] skip-layers: [10, 1]
step:2875/5550 val_loss:3.106276 train_time:719288ms step_avg:250.19ms x-lambda: 0.5634312033653259 lambdas: [-0.011150655336678028, -0.00681083370000124] skip-layers: [10, 1]
step:3000/5550 val_loss:3.095371 train_time:750489ms step_avg:250.16ms x-lambda: 0.5614372491836548 lambdas: [-0.009874558076262474, -0.008939502760767937] skip-layers: [10, 1]
step:3125/5550 val_loss:3.085376 train_time:782707ms step_avg:250.47ms x-lambda: 0.5607061386108398 lambdas: [-0.010358846746385098, -0.008058941923081875] skip-layers: [10, 1]
step:3250/5550 val_loss:3.073242 train_time:814973ms step_avg:250.76ms x-lambda: 0.5628712177276611 lambdas: [-0.008352350443601608, -0.00676905270665884] skip-layers: [10, 1]
step:3375/5550 val_loss:3.064237 train_time:847129ms step_avg:251.00ms x-lambda: 0.5640112161636353 lambdas: [-0.008817637339234352, -0.006874992977827787] skip-layers: [10, 1]
step:3500/5550 val_loss:3.055724 train_time:878365ms step_avg:250.96ms x-lambda: 0.5638636946678162 lambdas: [-0.009260345250368118, -0.007705934811383486] skip-layers: [10, 1]
step:3625/5550 val_loss:3.046824 train_time:910707ms step_avg:251.23ms x-lambda: 0.5669675469398499 lambdas: [-0.007717570755630732, -0.006469142157584429] skip-layers: [10, 1]
step:3750/5550 val_loss:3.037447 train_time:943013ms step_avg:251.47ms x-lambda: 0.5682920813560486 lambdas: [-0.008589197881519794, -0.006108857225626707] skip-layers: [10, 1]
step:3875/5550 val_loss:3.028622 train_time:974304ms step_avg:251.43ms x-lambda: 0.5749770998954773 lambdas: [-0.007923993282020092, -0.006327612791210413] skip-layers: [10, 1]
step:4000/5550 val_loss:3.019091 train_time:1005555ms step_avg:251.39ms x-lambda: 0.5776076316833496 lambdas: [-0.007016753312200308, -0.005707398056983948] skip-layers: [10, 1]
step:4125/5550 val_loss:3.009697 train_time:1041084ms step_avg:252.38ms x-lambda: 0.5827036499977112 lambdas: [-0.007446112111210823, -0.004916543141007423] skip-layers: [10, 1]
step:4250/5550 val_loss:3.001485 train_time:1079881ms step_avg:254.09ms x-lambda: 0.5858929753303528 lambdas: [-0.007846486754715443, -0.0051696342416107655] skip-layers: [10, 1]
step:4375/5550 val_loss:2.992156 train_time:1112446ms step_avg:254.27ms x-lambda: 0.5891894102096558 lambdas: [-0.0077233570627868176, -0.006829211488366127] skip-layers: [10, 1]
step:4500/5550 val_loss:2.983882 train_time:1147392ms step_avg:254.98ms x-lambda: 0.596791684627533 lambdas: [-0.007401666603982449, -0.005693061742931604] skip-layers: [10, 1]
step:4625/5550 val_loss:2.974472 train_time:1180146ms step_avg:255.17ms x-lambda: 0.6033484935760498 lambdas: [-0.007137589622288942, -0.005641300231218338] skip-layers: [10, 1]
step:4750/5550 val_loss:2.965147 train_time:1211987ms step_avg:255.16ms x-lambda: 0.6101590991020203 lambdas: [-0.007443211507052183, -0.005485669244080782] skip-layers: [10, 1]
step:4875/5550 val_loss:2.956321 train_time:1243962ms step_avg:255.17ms x-lambda: 0.6168756484985352 lambdas: [-0.00753131415694952, -0.004916550125926733] skip-layers: [10, 1]
step:5000/5550 val_loss:2.948262 train_time:1278182ms step_avg:255.64ms x-lambda: 0.6236948370933533 lambdas: [-0.006387685425579548, -0.006141084246337414] skip-layers: [10, 1]
step:5125/5550 val_loss:2.940773 train_time:1310394ms step_avg:255.69ms x-lambda: 0.6321291327476501 lambdas: [-0.006152668967843056, -0.005300461780279875] skip-layers: [10, 1]
step:5250/5550 val_loss:2.933423 train_time:1342828ms step_avg:255.78ms x-lambda: 0.6393657922744751 lambdas: [-0.007077396847307682, -0.004855428822338581] skip-layers: [10, 1]
step:5375/5550 val_loss:2.926919 train_time:1379560ms step_avg:256.66ms x-lambda: 0.6484992504119873 lambdas: [-0.006787391379475594, -0.005649981088936329] skip-layers: [10, 1]
step:5500/5550 val_loss:2.922115 train_time:1412344ms step_avg:256.79ms x-lambda: 0.6531569361686707 lambdas: [-0.006826285272836685, -0.005330119747668505] skip-layers: [10, 1]
step:5550/5550 val_loss:2.920901 train_time:1425544ms step_avg:256.85ms x-lambda: 0.654700756072998 lambdas: [-0.006860857829451561, -0.005299043375998735] skip-layers: [10, 1]

## 8000-add-skip-multiple-2-method-random-1

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:0.61ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [8, 9]
step:125/5550 val_loss:4.257397 train_time:28549ms step_avg:228.39ms x-lambda: 1.117966890335083 lambdas: [0.051564984023571014, 0.011184468865394592] skip-layers: [8, 9]
step:250/5550 val_loss:3.858760 train_time:57243ms step_avg:228.97ms x-lambda: 1.0806549787521362 lambdas: [-0.014559327624738216, -0.011924549005925655] skip-layers: [8, 9]
step:375/5550 val_loss:3.683836 train_time:86368ms step_avg:230.31ms x-lambda: 1.0100411176681519 lambdas: [-0.023442775011062622, -0.016196606680750847] skip-layers: [8, 9]
step:500/5550 val_loss:3.565917 train_time:117042ms step_avg:234.08ms x-lambda: 0.9428117871284485 lambdas: [-0.02536594308912754, -0.018740428611636162] skip-layers: [8, 9]
step:625/5550 val_loss:3.487209 train_time:146807ms step_avg:234.89ms x-lambda: 0.8899114727973938 lambdas: [-0.02333325520157814, -0.01774606853723526] skip-layers: [8, 9]
step:750/5550 val_loss:3.435595 train_time:176882ms step_avg:235.84ms x-lambda: 0.8459276556968689 lambdas: [-0.02407863177359104, -0.018377719447016716] skip-layers: [8, 9]
step:875/5550 val_loss:3.388180 train_time:207053ms step_avg:236.63ms x-lambda: 0.8066847920417786 lambdas: [-0.020745202898979187, -0.01621539518237114] skip-layers: [8, 9]
step:1000/5550 val_loss:3.352556 train_time:237512ms step_avg:237.51ms x-lambda: 0.7698466777801514 lambdas: [-0.020216912031173706, -0.015984833240509033] skip-layers: [8, 9]
step:1125/5550 val_loss:3.324114 train_time:267987ms step_avg:238.21ms x-lambda: 0.7403929829597473 lambdas: [-0.01883518695831299, -0.014607067219913006] skip-layers: [8, 9]
step:1250/5550 val_loss:3.298180 train_time:298642ms step_avg:238.91ms x-lambda: 0.7162218689918518 lambdas: [-0.017179114744067192, -0.011986587196588516] skip-layers: [8, 9]
step:1375/5550 val_loss:3.276538 train_time:330487ms step_avg:240.35ms x-lambda: 0.692997395992279 lambdas: [-0.01844213157892227, -0.01357900071889162] skip-layers: [8, 9]
step:1500/5550 val_loss:3.257908 train_time:362267ms step_avg:241.51ms x-lambda: 0.6730103492736816 lambdas: [-0.01717008277773857, -0.014256271533668041] skip-layers: [8, 9]
step:1625/5550 val_loss:3.243342 train_time:393106ms step_avg:241.91ms x-lambda: 0.6566045880317688 lambdas: [-0.013776367530226707, -0.011225470341742039] skip-layers: [8, 9]
step:1750/5550 val_loss:3.225835 train_time:423974ms step_avg:242.27ms x-lambda: 0.6378552913665771 lambdas: [-0.014810236170887947, -0.010823546908795834] skip-layers: [8, 9]
step:1875/5550 val_loss:3.207577 train_time:454870ms step_avg:242.60ms x-lambda: 0.62722247838974 lambdas: [-0.01491636410355568, -0.011096730828285217] skip-layers: [8, 9]
step:2000/5550 val_loss:3.192235 train_time:487041ms step_avg:243.52ms x-lambda: 0.6154342293739319 lambdas: [-0.01375049352645874, -0.011169200763106346] skip-layers: [8, 9]
step:2125/5550 val_loss:3.177515 train_time:519387ms step_avg:244.42ms x-lambda: 0.6089540719985962 lambdas: [-0.01266567874699831, -0.009485390968620777] skip-layers: [8, 9]
step:2250/5550 val_loss:3.163658 train_time:554671ms step_avg:246.52ms x-lambda: 0.6034303903579712 lambdas: [-0.011459160596132278, -0.008504881523549557] skip-layers: [8, 9]
step:2375/5550 val_loss:3.152332 train_time:585828ms step_avg:246.66ms x-lambda: 0.5969723463058472 lambdas: [-0.012213461101055145, -0.008906777948141098] skip-layers: [8, 9]
step:2500/5550 val_loss:3.140367 train_time:616988ms step_avg:246.80ms x-lambda: 0.5915678143501282 lambdas: [-0.01144068967550993, -0.00774140702560544] skip-layers: [8, 9]
step:2625/5550 val_loss:3.128645 train_time:649184ms step_avg:247.31ms x-lambda: 0.5883122086524963 lambdas: [-0.012530982494354248, -0.009581286460161209] skip-layers: [8, 9]
step:2750/5550 val_loss:3.117405 train_time:680297ms step_avg:247.38ms x-lambda: 0.5838395953178406 lambdas: [-0.012052292935550213, -0.008457680232822895] skip-layers: [8, 9]
step:2875/5550 val_loss:3.107763 train_time:711426ms step_avg:247.45ms x-lambda: 0.5850623846054077 lambdas: [-0.011213227175176144, -0.007953237742185593] skip-layers: [8, 9]
step:3000/5550 val_loss:3.097205 train_time:742631ms step_avg:247.54ms x-lambda: 0.5837492942810059 lambdas: [-0.011680776253342628, -0.008767015300691128] skip-layers: [8, 9]
step:3125/5550 val_loss:3.086536 train_time:774819ms step_avg:247.94ms x-lambda: 0.5830995440483093 lambdas: [-0.010488908737897873, -0.0074956961907446384] skip-layers: [8, 9]
step:3250/5550 val_loss:3.075312 train_time:805967ms step_avg:247.99ms x-lambda: 0.5844576358795166 lambdas: [-0.00973935890942812, -0.007346148602664471] skip-layers: [8, 9]
step:3375/5550 val_loss:3.066724 train_time:837108ms step_avg:248.03ms x-lambda: 0.5847874283790588 lambdas: [-0.011113947257399559, -0.007487835828214884] skip-layers: [8, 9]
step:3500/5550 val_loss:3.056989 train_time:873398ms step_avg:249.54ms x-lambda: 0.5872266888618469 lambdas: [-0.010392879135906696, -0.006879150401800871] skip-layers: [8, 9]
step:3625/5550 val_loss:3.048111 train_time:905721ms step_avg:249.85ms x-lambda: 0.5901256203651428 lambdas: [-0.010519658215343952, -0.00686132675036788] skip-layers: [8, 9]
step:3750/5550 val_loss:3.039122 train_time:938003ms step_avg:250.13ms x-lambda: 0.5897581577301025 lambdas: [-0.009743794798851013, -0.006268268916755915] skip-layers: [8, 9]
step:3875/5550 val_loss:3.029887 train_time:971404ms step_avg:250.68ms x-lambda: 0.5987979173660278 lambdas: [-0.010133420117199421, -0.006124134641140699] skip-layers: [8, 9]
step:4000/5550 val_loss:3.020565 train_time:1003644ms step_avg:250.91ms x-lambda: 0.6016576886177063 lambdas: [-0.009645786136388779, -0.006527080200612545] skip-layers: [8, 9]
step:4125/5550 val_loss:3.011258 train_time:1034892ms step_avg:250.88ms x-lambda: 0.6070111989974976 lambdas: [-0.008828622289001942, -0.00693672988563776] skip-layers: [8, 9]
step:4250/5550 val_loss:3.003202 train_time:1066321ms step_avg:250.90ms x-lambda: 0.6113064289093018 lambdas: [-0.009857315570116043, -0.0068063922226428986] skip-layers: [8, 9]
step:4375/5550 val_loss:2.993758 train_time:1097805ms step_avg:250.93ms x-lambda: 0.6141029596328735 lambdas: [-0.01069166325032711, -0.0066285450011491776] skip-layers: [8, 9]
step:4500/5550 val_loss:2.985298 train_time:1129331ms step_avg:250.96ms x-lambda: 0.6199358105659485 lambdas: [-0.008489885367453098, -0.00719424057751894] skip-layers: [8, 9]
step:4625/5550 val_loss:2.976195 train_time:1163356ms step_avg:251.54ms x-lambda: 0.6302366852760315 lambdas: [-0.01101306825876236, -0.0068515995517373085] skip-layers: [8, 9]
step:4750/5550 val_loss:2.966769 train_time:1195184ms step_avg:251.62ms x-lambda: 0.6352810859680176 lambdas: [-0.008301680907607079, -0.006618819665163755] skip-layers: [8, 9]
step:4875/5550 val_loss:2.957740 train_time:1228169ms step_avg:251.93ms x-lambda: 0.641823410987854 lambdas: [-0.008513050153851509, -0.005723207723349333] skip-layers: [8, 9]
step:5000/5550 val_loss:2.949708 train_time:1262450ms step_avg:252.49ms x-lambda: 0.6506547927856445 lambdas: [-0.008516306057572365, -0.005910593084990978] skip-layers: [8, 9]
step:5125/5550 val_loss:2.942001 train_time:1294638ms step_avg:252.61ms x-lambda: 0.6584683060646057 lambdas: [-0.009085231460630894, -0.006136882118880749] skip-layers: [8, 9]
step:5250/5550 val_loss:2.934732 train_time:1328058ms step_avg:252.96ms x-lambda: 0.6660038232803345 lambdas: [-0.008779251947999, -0.00635784026235342] skip-layers: [8, 9]
step:5375/5550 val_loss:2.928265 train_time:1362615ms step_avg:253.51ms x-lambda: 0.6758407354354858 lambdas: [-0.009141025133430958, -0.006158967036753893] skip-layers: [8, 9]
step:5500/5550 val_loss:2.923501 train_time:1395352ms step_avg:253.70ms x-lambda: 0.6811103820800781 lambdas: [-0.008399023674428463, -0.006118588615208864] skip-layers: [8, 9]
step:5550/5550 val_loss:2.922289 train_time:1408533ms step_avg:253.79ms x-lambda: 0.6827089786529541 lambdas: [-0.008677071891725063, -0.00604415824636817] skip-layers: [8, 9]

## 8000-add-skip-multiple-2-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0] skip-layers: [1, 2]
step:125/5550 val_loss:4.260612 train_time:29669ms step_avg:237.35ms x-lambda: 1.1211915016174316 lambdas: [0.05863358825445175, 0.0231002364307642] skip-layers: [1, 2]
step:250/5550 val_loss:3.850017 train_time:59410ms step_avg:237.64ms x-lambda: 1.07895827293396 lambdas: [0.006505413446575403, -0.07385292649269104] skip-layers: [1, 2]
step:375/5550 val_loss:3.677182 train_time:88608ms step_avg:236.29ms x-lambda: 1.0273785591125488 lambdas: [-0.004273341968655586, -0.11625075340270996] skip-layers: [1, 2]
step:500/5550 val_loss:3.559137 train_time:118238ms step_avg:236.48ms x-lambda: 0.9712557792663574 lambdas: [-0.0076308040879666805, -0.14254383742809296] skip-layers: [1, 2]
step:625/5550 val_loss:3.479642 train_time:148096ms step_avg:236.95ms x-lambda: 0.9206607937812805 lambdas: [-0.004098204895853996, -0.1561603546142578] skip-layers: [1, 2]
step:750/5550 val_loss:3.428686 train_time:178205ms step_avg:237.61ms x-lambda: 0.8760627508163452 lambdas: [-0.001893376698717475, -0.16460344195365906] skip-layers: [1, 2]
step:875/5550 val_loss:3.384106 train_time:208414ms step_avg:238.19ms x-lambda: 0.8364055752754211 lambdas: [0.003076059278100729, -0.16440539062023163] skip-layers: [1, 2]
step:1000/5550 val_loss:3.348408 train_time:238873ms step_avg:238.87ms x-lambda: 0.7990299463272095 lambdas: [0.005215500947088003, -0.16377313435077667] skip-layers: [1, 2]
step:1125/5550 val_loss:3.317796 train_time:270540ms step_avg:240.48ms x-lambda: 0.7685781121253967 lambdas: [0.007632076740264893, -0.15950645506381989] skip-layers: [1, 2]
step:1250/5550 val_loss:3.292158 train_time:301213ms step_avg:240.97ms x-lambda: 0.7406120896339417 lambdas: [0.008496700786054134, -0.1566224843263626] skip-layers: [1, 2]
step:1375/5550 val_loss:3.272012 train_time:333064ms step_avg:242.23ms x-lambda: 0.7148016095161438 lambdas: [0.009087180718779564, -0.15164491534233093] skip-layers: [1, 2]
step:1500/5550 val_loss:3.252890 train_time:364929ms step_avg:243.29ms x-lambda: 0.695378839969635 lambdas: [0.011091233231127262, -0.14514467120170593] skip-layers: [1, 2]
step:1625/5550 val_loss:3.237734 train_time:397056ms step_avg:244.34ms x-lambda: 0.6743354797363281 lambdas: [0.011511432006955147, -0.13971173763275146] skip-layers: [1, 2]
step:1750/5550 val_loss:3.221475 train_time:429068ms step_avg:245.18ms x-lambda: 0.6542114615440369 lambdas: [0.011298133991658688, -0.1351080983877182] skip-layers: [1, 2]
step:1875/5550 val_loss:3.202425 train_time:459989ms step_avg:245.33ms x-lambda: 0.6415488719940186 lambdas: [0.01021425612270832, -0.13138540089130402] skip-layers: [1, 2]
step:2000/5550 val_loss:3.187620 train_time:491155ms step_avg:245.58ms x-lambda: 0.627933144569397 lambdas: [0.012049451470375061, -0.1255258172750473] skip-layers: [1, 2]
step:2125/5550 val_loss:3.172679 train_time:523368ms step_avg:246.29ms x-lambda: 0.6206826567649841 lambdas: [0.012161982245743275, -0.1220124140381813] skip-layers: [1, 2]
step:2250/5550 val_loss:3.158624 train_time:556646ms step_avg:247.40ms x-lambda: 0.6114456057548523 lambdas: [0.01200459711253643, -0.117802195250988] skip-layers: [1, 2]
step:2375/5550 val_loss:3.147614 train_time:589002ms step_avg:248.00ms x-lambda: 0.6054351329803467 lambdas: [0.011236943304538727, -0.11517006903886795] skip-layers: [1, 2]
step:2500/5550 val_loss:3.135654 train_time:620210ms step_avg:248.08ms x-lambda: 0.600616991519928 lambdas: [0.013070429675281048, -0.11043546348810196] skip-layers: [1, 2]
step:2625/5550 val_loss:3.123578 train_time:651352ms step_avg:248.13ms x-lambda: 0.5945058465003967 lambdas: [0.010360515676438808, -0.1098998486995697] skip-layers: [1, 2]
step:2750/5550 val_loss:3.112902 train_time:683579ms step_avg:248.57ms x-lambda: 0.5932701826095581 lambdas: [0.011853882111608982, -0.10569402575492859] skip-layers: [1, 2]
step:2875/5550 val_loss:3.103771 train_time:714722ms step_avg:248.60ms x-lambda: 0.592045783996582 lambdas: [0.012495456263422966, -0.1014222800731659] skip-layers: [1, 2]
step:3000/5550 val_loss:3.092142 train_time:748025ms step_avg:249.34ms x-lambda: 0.5896982550621033 lambdas: [0.010151711292564869, -0.10064589232206345] skip-layers: [1, 2]
step:3125/5550 val_loss:3.081846 train_time:779235ms step_avg:249.36ms x-lambda: 0.587489902973175 lambdas: [0.010940088890492916, -0.10161557048559189] skip-layers: [1, 2]
step:3250/5550 val_loss:3.069941 train_time:810393ms step_avg:249.35ms x-lambda: 0.5891602039337158 lambdas: [0.01267988234758377, -0.09797462821006775] skip-layers: [1, 2]
step:3375/5550 val_loss:3.061251 train_time:841547ms step_avg:249.35ms x-lambda: 0.5907455086708069 lambdas: [0.01089912187308073, -0.09696350991725922] skip-layers: [1, 2]
step:3500/5550 val_loss:3.052486 train_time:873921ms step_avg:249.69ms x-lambda: 0.5894826650619507 lambdas: [0.010663771070539951, -0.09567181766033173] skip-layers: [1, 2]
step:3625/5550 val_loss:3.044139 train_time:905125ms step_avg:249.69ms x-lambda: 0.5940417051315308 lambdas: [0.010529066435992718, -0.09426414221525192] skip-layers: [1, 2]
step:3750/5550 val_loss:3.034079 train_time:936298ms step_avg:249.68ms x-lambda: 0.5952340960502625 lambdas: [0.012148866429924965, -0.0914735272526741] skip-layers: [1, 2]
step:3875/5550 val_loss:3.025394 train_time:972851ms step_avg:251.06ms x-lambda: 0.6012076735496521 lambdas: [0.010728446766734123, -0.0914212092757225] skip-layers: [1, 2]
step:4000/5550 val_loss:3.015807 train_time:1004018ms step_avg:251.00ms x-lambda: 0.6045243740081787 lambdas: [0.010805869475007057, -0.08988562226295471] skip-layers: [1, 2]
step:4125/5550 val_loss:3.006888 train_time:1035233ms step_avg:250.97ms x-lambda: 0.609803318977356 lambdas: [0.011265715584158897, -0.09028586745262146] skip-layers: [1, 2]
step:4250/5550 val_loss:2.998576 train_time:1067888ms step_avg:251.27ms x-lambda: 0.6128250360488892 lambdas: [0.010418185032904148, -0.08926433324813843] skip-layers: [1, 2]
step:4375/5550 val_loss:2.989265 train_time:1104845ms step_avg:252.54ms x-lambda: 0.6151880025863647 lambdas: [0.009625263512134552, -0.08768941462039948] skip-layers: [1, 2]
step:4500/5550 val_loss:2.981233 train_time:1137440ms step_avg:252.76ms x-lambda: 0.6222938299179077 lambdas: [0.010181738995015621, -0.08668575435876846] skip-layers: [1, 2]
step:4625/5550 val_loss:2.971767 train_time:1169090ms step_avg:252.78ms x-lambda: 0.6304633617401123 lambdas: [0.009748900309205055, -0.08636154979467392] skip-layers: [1, 2]
step:4750/5550 val_loss:2.962572 train_time:1200892ms step_avg:252.82ms x-lambda: 0.6371793746948242 lambdas: [0.010508210398256779, -0.08691795915365219] skip-layers: [1, 2]
step:4875/5550 val_loss:2.953652 train_time:1232839ms step_avg:252.89ms x-lambda: 0.642814576625824 lambdas: [0.0099929915741086, -0.08634985983371735] skip-layers: [1, 2]
step:5000/5550 val_loss:2.945561 train_time:1268254ms step_avg:253.65ms x-lambda: 0.6506894826889038 lambdas: [0.010335938073694706, -0.08563148230314255] skip-layers: [1, 2]
step:5125/5550 val_loss:2.937800 train_time:1300458ms step_avg:253.75ms x-lambda: 0.6581144332885742 lambdas: [0.009786183945834637, -0.08473655581474304] skip-layers: [1, 2]
step:5250/5550 val_loss:2.930613 train_time:1335049ms step_avg:254.30ms x-lambda: 0.6643733382225037 lambdas: [0.009374773129820824, -0.08458305895328522] skip-layers: [1, 2]
step:5375/5550 val_loss:2.924151 train_time:1369722ms step_avg:254.83ms x-lambda: 0.6736637949943542 lambdas: [0.009688368067145348, -0.08411169052124023] skip-layers: [1, 2]
step:5500/5550 val_loss:2.919403 train_time:1404744ms step_avg:255.41ms x-lambda: 0.6781696081161499 lambdas: [0.00966324470937252, -0.08432283252477646] skip-layers: [1, 2]
step:5550/5550 val_loss:2.918208 train_time:1417954ms step_avg:255.49ms x-lambda: 0.679875373840332 lambdas: [0.009696964174509048, -0.08423059433698654] skip-layers: [1, 2]

## 8000-add-skip-multiple-3-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.10ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [11, 10, 8]
step:125/5550 val_loss:4.271165 train_time:29738ms step_avg:237.91ms x-lambda: 1.0451020002365112 lambdas: [0.05469987541437149, 0.0618092343211174, 0.049006931483745575] skip-layers: [11, 10, 8]
step:250/5550 val_loss:3.858192 train_time:58521ms step_avg:234.08ms x-lambda: 0.996446967124939 lambdas: [0.03750980645418167, 0.046026408672332764, -0.011518174782395363] skip-layers: [11, 10, 8]
step:375/5550 val_loss:3.678921 train_time:88502ms step_avg:236.01ms x-lambda: 0.9832924604415894 lambdas: [0.02154548652470112, -0.004406235180795193, -0.046628545969724655] skip-layers: [11, 10, 8]
step:500/5550 val_loss:3.562320 train_time:118114ms step_avg:236.23ms x-lambda: 0.9632687568664551 lambdas: [0.003452801378443837, -0.05969619005918503, -0.06019384413957596] skip-layers: [11, 10, 8]
step:625/5550 val_loss:3.483944 train_time:149039ms step_avg:238.46ms x-lambda: 0.9478176236152649 lambdas: [-0.008190648630261421, -0.10661587119102478, -0.058053478598594666] skip-layers: [11, 10, 8]
step:750/5550 val_loss:3.430632 train_time:179152ms step_avg:238.87ms x-lambda: 0.9299180507659912 lambdas: [-0.02032078243792057, -0.15039129555225372, -0.054048653692007065] skip-layers: [11, 10, 8]
step:875/5550 val_loss:3.385013 train_time:209378ms step_avg:239.29ms x-lambda: 0.9167428016662598 lambdas: [-0.025174135342240334, -0.18387629091739655, -0.044797055423259735] skip-layers: [11, 10, 8]
step:1000/5550 val_loss:3.348687 train_time:241861ms step_avg:241.86ms x-lambda: 0.9021693468093872 lambdas: [-0.028787462040781975, -0.211873397231102, -0.03768601268529892] skip-layers: [11, 10, 8]
step:1125/5550 val_loss:3.319681 train_time:272396ms step_avg:242.13ms x-lambda: 0.8846174478530884 lambdas: [-0.03277112916111946, -0.2383742332458496, -0.0354611761868] skip-layers: [11, 10, 8]
step:1250/5550 val_loss:3.294958 train_time:305164ms step_avg:244.13ms x-lambda: 0.8737729787826538 lambdas: [-0.031058819964528084, -0.2552848160266876, -0.02783551625907421] skip-layers: [11, 10, 8]
step:1375/5550 val_loss:3.272354 train_time:336035ms step_avg:244.39ms x-lambda: 0.856689453125 lambdas: [-0.031428415328264236, -0.2722799479961395, -0.024711446836590767] skip-layers: [11, 10, 8]
step:1500/5550 val_loss:3.252763 train_time:367761ms step_avg:245.17ms x-lambda: 0.8443902134895325 lambdas: [-0.02804068848490715, -0.2844245135784149, -0.02211388573050499] skip-layers: [11, 10, 8]
step:1625/5550 val_loss:3.237024 train_time:398698ms step_avg:245.35ms x-lambda: 0.8299432396888733 lambdas: [-0.02491041272878647, -0.2960762083530426, -0.01691083237528801] skip-layers: [11, 10, 8]
step:1750/5550 val_loss:3.221364 train_time:430797ms step_avg:246.17ms x-lambda: 0.8137130737304688 lambdas: [-0.02342485636472702, -0.30541670322418213, -0.016533298417925835] skip-layers: [11, 10, 8]
step:1875/5550 val_loss:3.203259 train_time:464993ms step_avg:248.00ms x-lambda: 0.8040931224822998 lambdas: [-0.017583072185516357, -0.30977487564086914, -0.013404441997408867] skip-layers: [11, 10, 8]
step:2000/5550 val_loss:3.187394 train_time:498408ms step_avg:249.20ms x-lambda: 0.7897270321846008 lambdas: [-0.01418287679553032, -0.3159220516681671, -0.01223104540258646] skip-layers: [11, 10, 8]
step:2125/5550 val_loss:3.173413 train_time:529625ms step_avg:249.24ms x-lambda: 0.7799172401428223 lambdas: [-0.011354383081197739, -0.32117605209350586, -0.012051146477460861] skip-layers: [11, 10, 8]
step:2250/5550 val_loss:3.159070 train_time:560844ms step_avg:249.26ms x-lambda: 0.7718494534492493 lambdas: [-0.007366310339421034, -0.3244338631629944, -0.010531595908105373] skip-layers: [11, 10, 8]
step:2375/5550 val_loss:3.147089 train_time:593122ms step_avg:249.74ms x-lambda: 0.7639039158821106 lambdas: [-0.0033481826540082693, -0.3268890082836151, -0.008999884128570557] skip-layers: [11, 10, 8]
step:2500/5550 val_loss:3.136298 train_time:626473ms step_avg:250.59ms x-lambda: 0.7575745582580566 lambdas: [0.0007583298720419407, -0.32747480273246765, -0.008535703644156456] skip-layers: [11, 10, 8]
step:2625/5550 val_loss:3.123674 train_time:658761ms step_avg:250.96ms x-lambda: 0.7507921457290649 lambdas: [0.003598942421376705, -0.3308477997779846, -0.00851942878216505] skip-layers: [11, 10, 8]
step:2750/5550 val_loss:3.114019 train_time:691788ms step_avg:251.56ms x-lambda: 0.7437977194786072 lambdas: [0.0052165258675813675, -0.33353081345558167, -0.00771418958902359] skip-layers: [11, 10, 8]
step:2875/5550 val_loss:3.103997 train_time:722930ms step_avg:251.45ms x-lambda: 0.7412635684013367 lambdas: [0.010042226873338223, -0.3331741690635681, -0.00743861636146903] skip-layers: [11, 10, 8]
step:3000/5550 val_loss:3.092984 train_time:757382ms step_avg:252.46ms x-lambda: 0.7384766340255737 lambdas: [0.013674210757017136, -0.33290228247642517, -0.006997372023761272] skip-layers: [11, 10, 8]
step:3125/5550 val_loss:3.081674 train_time:788602ms step_avg:252.35ms x-lambda: 0.7345973253250122 lambdas: [0.014672099612653255, -0.3359377980232239, -0.0066857002675533295] skip-layers: [11, 10, 8]
step:3250/5550 val_loss:3.069678 train_time:819767ms step_avg:252.24ms x-lambda: 0.73344886302948 lambdas: [0.01714889332652092, -0.3367275297641754, -0.006683303974568844] skip-layers: [11, 10, 8]
step:3375/5550 val_loss:3.061566 train_time:850955ms step_avg:252.13ms x-lambda: 0.7321234345436096 lambdas: [0.018724994733929634, -0.33844664692878723, -0.006199861876666546] skip-layers: [11, 10, 8]
step:3500/5550 val_loss:3.052878 train_time:885409ms step_avg:252.97ms x-lambda: 0.7293409705162048 lambdas: [0.020440537482500076, -0.3376946747303009, -0.0059355478733778] skip-layers: [11, 10, 8]
step:3625/5550 val_loss:3.043484 train_time:916593ms step_avg:252.85ms x-lambda: 0.7313195466995239 lambdas: [0.025178173556923866, -0.3382357954978943, -0.005305677652359009] skip-layers: [11, 10, 8]
step:3750/5550 val_loss:3.034424 train_time:947753ms step_avg:252.73ms x-lambda: 0.7296048998832703 lambdas: [0.025390123948454857, -0.3393571972846985, -0.005214034114032984] skip-layers: [11, 10, 8]
step:3875/5550 val_loss:3.025366 train_time:980072ms step_avg:252.92ms x-lambda: 0.7334780693054199 lambdas: [0.028617609292268753, -0.3395991027355194, -0.005662010982632637] skip-layers: [11, 10, 8]
step:4000/5550 val_loss:3.016271 train_time:1012419ms step_avg:253.10ms x-lambda: 0.7339763045310974 lambdas: [0.030271757394075394, -0.3414934575557709, -0.005908792372792959] skip-layers: [11, 10, 8]
step:4125/5550 val_loss:3.006727 train_time:1044794ms step_avg:253.28ms x-lambda: 0.7384654879570007 lambdas: [0.031680669635534286, -0.3415100574493408, -0.004654823802411556] skip-layers: [11, 10, 8]
step:4250/5550 val_loss:2.998824 train_time:1076228ms step_avg:253.23ms x-lambda: 0.7399025559425354 lambdas: [0.03325797617435455, -0.3434522747993469, -0.006173689849674702] skip-layers: [11, 10, 8]
step:4375/5550 val_loss:2.989058 train_time:1108848ms step_avg:253.45ms x-lambda: 0.7429533004760742 lambdas: [0.034510571509599686, -0.3447571396827698, -0.0056455060839653015] skip-layers: [11, 10, 8]
step:4500/5550 val_loss:2.981020 train_time:1140417ms step_avg:253.43ms x-lambda: 0.7471726536750793 lambdas: [0.035473525524139404, -0.34562671184539795, -0.006407622247934341] skip-layers: [11, 10, 8]
step:4625/5550 val_loss:2.971882 train_time:1172114ms step_avg:253.43ms x-lambda: 0.7525571584701538 lambdas: [0.036689866334199905, -0.3463093638420105, -0.006869092117995024] skip-layers: [11, 10, 8]
step:4750/5550 val_loss:2.962324 train_time:1205185ms step_avg:253.72ms x-lambda: 0.7574707865715027 lambdas: [0.038155097514390945, -0.3475137948989868, -0.006512099876999855] skip-layers: [11, 10, 8]
step:4875/5550 val_loss:2.953480 train_time:1239297ms step_avg:254.21ms x-lambda: 0.7621797323226929 lambdas: [0.03933703526854515, -0.3496633768081665, -0.005859394557774067] skip-layers: [11, 10, 8]
step:5000/5550 val_loss:2.945396 train_time:1271377ms step_avg:254.28ms x-lambda: 0.7683535814285278 lambdas: [0.0405062697827816, -0.3509817123413086, -0.00751621974632144] skip-layers: [11, 10, 8]
step:5125/5550 val_loss:2.937745 train_time:1306942ms step_avg:255.01ms x-lambda: 0.7733632326126099 lambdas: [0.04168908670544624, -0.3526088297367096, -0.006764731369912624] skip-layers: [11, 10, 8]
step:5250/5550 val_loss:2.930599 train_time:1340560ms step_avg:255.34ms x-lambda: 0.7774222493171692 lambdas: [0.04193546250462532, -0.35349035263061523, -0.006710823159664869] skip-layers: [11, 10, 8]
step:5375/5550 val_loss:2.924103 train_time:1374217ms step_avg:255.67ms x-lambda: 0.7833094596862793 lambdas: [0.04262397438287735, -0.3545296788215637, -0.007580919191241264] skip-layers: [11, 10, 8]
step:5500/5550 val_loss:2.919306 train_time:1407046ms step_avg:255.83ms x-lambda: 0.7873693108558655 lambdas: [0.043178316205739975, -0.3545331656932831, -0.007491551339626312] skip-layers: [11, 10, 8]
step:5550/5550 val_loss:2.918104 train_time:1420275ms step_avg:255.91ms x-lambda: 0.7880128026008606 lambdas: [0.043147020041942596, -0.3550761342048645, -0.0077491565607488155] skip-layers: [11, 10, 8]

## 8000-add-skip-multiple-3-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [14, 13, 12]
step:125/5550 val_loss:4.260652 train_time:28823ms step_avg:230.58ms x-lambda: 1.0507932901382446 lambdas: [0.04480874165892601, 0.04984993115067482, 0.0527668334543705] skip-layers: [14, 13, 12]
step:250/5550 val_loss:3.854989 train_time:58773ms step_avg:235.09ms x-lambda: 1.001105546951294 lambdas: [0.008677925914525986, 0.022005503997206688, 0.024598155170679092] skip-layers: [14, 13, 12]
step:375/5550 val_loss:3.678688 train_time:88185ms step_avg:235.16ms x-lambda: 0.9726953506469727 lambdas: [-0.00513565493747592, 0.0050689163617789745, -0.001658828929066658] skip-layers: [14, 13, 12]
step:500/5550 val_loss:3.561437 train_time:118723ms step_avg:237.45ms x-lambda: 0.9530139565467834 lambdas: [-0.021469559520483017, -0.015598366968333721, -0.03255882486701012] skip-layers: [14, 13, 12]
step:625/5550 val_loss:3.482908 train_time:148714ms step_avg:237.94ms x-lambda: 0.9426864981651306 lambdas: [-0.031831588596105576, -0.03100566752254963, -0.05776730924844742] skip-layers: [14, 13, 12]
step:750/5550 val_loss:3.431978 train_time:178984ms step_avg:238.65ms x-lambda: 0.9342324137687683 lambdas: [-0.041140127927064896, -0.046260081231594086, -0.0819554403424263] skip-layers: [14, 13, 12]
step:875/5550 val_loss:3.385350 train_time:210226ms step_avg:240.26ms x-lambda: 0.926428496837616 lambdas: [-0.047438181936740875, -0.06063675880432129, -0.10472047328948975] skip-layers: [14, 13, 12]
step:1000/5550 val_loss:3.350661 train_time:240865ms step_avg:240.86ms x-lambda: 0.9210488200187683 lambdas: [-0.04953053593635559, -0.07076685130596161, -0.12216634303331375] skip-layers: [14, 13, 12]
step:1125/5550 val_loss:3.321528 train_time:271548ms step_avg:241.38ms x-lambda: 0.9180676937103271 lambdas: [-0.05310611426830292, -0.08273981511592865, -0.13928528130054474] skip-layers: [14, 13, 12]
step:1250/5550 val_loss:3.296837 train_time:302332ms step_avg:241.87ms x-lambda: 0.9178616404533386 lambdas: [-0.05356009677052498, -0.09229815006256104, -0.1526651382446289] skip-layers: [14, 13, 12]
step:1375/5550 val_loss:3.275228 train_time:333306ms step_avg:242.40ms x-lambda: 0.9148725271224976 lambdas: [-0.05640528351068497, -0.10431350767612457, -0.16751736402511597] skip-layers: [14, 13, 12]
step:1500/5550 val_loss:3.254278 train_time:365273ms step_avg:243.52ms x-lambda: 0.9158275723457336 lambdas: [-0.05579180642962456, -0.11460408568382263, -0.17920328676700592] skip-layers: [14, 13, 12]
step:1625/5550 val_loss:3.238809 train_time:397473ms step_avg:244.60ms x-lambda: 0.9163815975189209 lambdas: [-0.055746063590049744, -0.1248404011130333, -0.18967820703983307] skip-layers: [14, 13, 12]
step:1750/5550 val_loss:3.223333 train_time:428484ms step_avg:244.85ms x-lambda: 0.9167212247848511 lambdas: [-0.0569031648337841, -0.13556671142578125, -0.20024718344211578] skip-layers: [14, 13, 12]
step:1875/5550 val_loss:3.206064 train_time:459576ms step_avg:245.11ms x-lambda: 0.9206163883209229 lambdas: [-0.05625505372881889, -0.1443711519241333, -0.20771144330501556] skip-layers: [14, 13, 12]
step:2000/5550 val_loss:3.190133 train_time:490852ms step_avg:245.43ms x-lambda: 0.9206079840660095 lambdas: [-0.05792625620961189, -0.15553559362888336, -0.21654708683490753] skip-layers: [14, 13, 12]
step:2125/5550 val_loss:3.175530 train_time:522160ms step_avg:245.72ms x-lambda: 0.9255202412605286 lambdas: [-0.056881122291088104, -0.16526788473129272, -0.22344079613685608] skip-layers: [14, 13, 12]
step:2250/5550 val_loss:3.161172 train_time:553451ms step_avg:245.98ms x-lambda: 0.9318128824234009 lambdas: [-0.05587035045027733, -0.1735994964838028, -0.22848841547966003] skip-layers: [14, 13, 12]
step:2375/5550 val_loss:3.149861 train_time:584759ms step_avg:246.21ms x-lambda: 0.9343903660774231 lambdas: [-0.057056378573179245, -0.18311281502246857, -0.23400817811489105] skip-layers: [14, 13, 12]
step:2500/5550 val_loss:3.137821 train_time:617074ms step_avg:246.83ms x-lambda: 0.9392883777618408 lambdas: [-0.05472680926322937, -0.18989646434783936, -0.23742569983005524] skip-layers: [14, 13, 12]
step:2625/5550 val_loss:3.126381 train_time:649416ms step_avg:247.40ms x-lambda: 0.942344069480896 lambdas: [-0.05465833097696304, -0.19876141846179962, -0.24152693152427673] skip-layers: [14, 13, 12]
step:2750/5550 val_loss:3.114953 train_time:681788ms step_avg:247.92ms x-lambda: 0.9466971158981323 lambdas: [-0.05353119969367981, -0.20659996569156647, -0.2448517382144928] skip-layers: [14, 13, 12]
step:2875/5550 val_loss:3.105659 train_time:713064ms step_avg:248.02ms x-lambda: 0.9515978097915649 lambdas: [-0.052726782858371735, -0.21325361728668213, -0.2465892881155014] skip-layers: [14, 13, 12]
step:3000/5550 val_loss:3.094271 train_time:745548ms step_avg:248.52ms x-lambda: 0.9556899666786194 lambdas: [-0.05154343694448471, -0.22050979733467102, -0.24904851615428925] skip-layers: [14, 13, 12]
step:3125/5550 val_loss:3.083359 train_time:778729ms step_avg:249.19ms x-lambda: 0.9600005149841309 lambdas: [-0.05140683054924011, -0.22624285519123077, -0.2504698932170868] skip-layers: [14, 13, 12]
step:3250/5550 val_loss:3.072554 train_time:811036ms step_avg:249.55ms x-lambda: 0.9652891755104065 lambdas: [-0.04987800493836403, -0.23199120163917542, -0.2522943913936615] skip-layers: [14, 13, 12]
step:3375/5550 val_loss:3.063304 train_time:842282ms step_avg:249.57ms x-lambda: 0.9712293148040771 lambdas: [-0.04842079430818558, -0.2386627346277237, -0.2545758783817291] skip-layers: [14, 13, 12]
step:3500/5550 val_loss:3.054529 train_time:874771ms step_avg:249.93ms x-lambda: 0.9753686785697937 lambdas: [-0.04835880920290947, -0.24492381513118744, -0.25624555349349976] skip-layers: [14, 13, 12]
step:3625/5550 val_loss:3.045774 train_time:906073ms step_avg:249.95ms x-lambda: 0.9814480543136597 lambdas: [-0.04584367200732231, -0.24914231896400452, -0.2569274604320526] skip-layers: [14, 13, 12]
step:3750/5550 val_loss:3.036288 train_time:939609ms step_avg:250.56ms x-lambda: 0.9862624406814575 lambdas: [-0.04515744000673294, -0.2542659342288971, -0.25747883319854736] skip-layers: [14, 13, 12]
step:3875/5550 val_loss:3.027560 train_time:970975ms step_avg:250.57ms x-lambda: 0.9935178756713867 lambdas: [-0.042816709727048874, -0.2595798969268799, -0.2587589919567108] skip-layers: [14, 13, 12]
step:4000/5550 val_loss:3.017956 train_time:1002335ms step_avg:250.58ms x-lambda: 0.9997097849845886 lambdas: [-0.0417802631855011, -0.263988733291626, -0.2600307762622833] skip-layers: [14, 13, 12]
step:4125/5550 val_loss:3.009170 train_time:1035751ms step_avg:251.09ms x-lambda: 1.0061390399932861 lambdas: [-0.040274728089571, -0.26924213767051697, -0.26029151678085327] skip-layers: [14, 13, 12]
step:4250/5550 val_loss:3.000399 train_time:1067358ms step_avg:251.14ms x-lambda: 1.0114296674728394 lambdas: [-0.03932049497961998, -0.27355262637138367, -0.26263466477394104] skip-layers: [14, 13, 12]
step:4375/5550 val_loss:2.991199 train_time:1098987ms step_avg:251.20ms x-lambda: 1.0160139799118042 lambdas: [-0.039138492196798325, -0.2790985703468323, -0.2642768919467926] skip-layers: [14, 13, 12]
step:4500/5550 val_loss:2.982964 train_time:1130645ms step_avg:251.25ms x-lambda: 1.022911548614502 lambdas: [-0.03629625588655472, -0.28228873014450073, -0.26520174741744995] skip-layers: [14, 13, 12]
step:4625/5550 val_loss:2.973695 train_time:1162444ms step_avg:251.34ms x-lambda: 1.029956340789795 lambdas: [-0.03390420973300934, -0.2848961651325226, -0.2662760615348816] skip-layers: [14, 13, 12]
step:4750/5550 val_loss:2.964394 train_time:1197238ms step_avg:252.05ms x-lambda: 1.0365543365478516 lambdas: [-0.03257456794381142, -0.28788167238235474, -0.2667384147644043] skip-layers: [14, 13, 12]
step:4875/5550 val_loss:2.955408 train_time:1230392ms step_avg:252.39ms x-lambda: 1.0416557788848877 lambdas: [-0.031984925270080566, -0.29150858521461487, -0.2677420675754547] skip-layers: [14, 13, 12]
step:5000/5550 val_loss:2.947292 train_time:1263666ms step_avg:252.73ms x-lambda: 1.0481607913970947 lambdas: [-0.03059229999780655, -0.2939720153808594, -0.2687559127807617] skip-layers: [14, 13, 12]
step:5125/5550 val_loss:2.939631 train_time:1297080ms step_avg:253.09ms x-lambda: 1.0535725355148315 lambdas: [-0.029155677184462547, -0.29585930705070496, -0.2700605094432831] skip-layers: [14, 13, 12]
step:5250/5550 val_loss:2.932342 train_time:1330803ms step_avg:253.49ms x-lambda: 1.0580238103866577 lambdas: [-0.028427666053175926, -0.2975793182849884, -0.2704400420188904] skip-layers: [14, 13, 12]
step:5375/5550 val_loss:2.925927 train_time:1364481ms step_avg:253.86ms x-lambda: 1.0628509521484375 lambdas: [-0.027155626565217972, -0.2991350293159485, -0.27181142568588257] skip-layers: [14, 13, 12]
step:5500/5550 val_loss:2.921058 train_time:1399234ms step_avg:254.41ms x-lambda: 1.066249132156372 lambdas: [-0.026363825425505638, -0.2999471127986908, -0.2719677686691284] skip-layers: [14, 13, 12]
step:5550/5550 val_loss:2.919857 train_time:1412466ms step_avg:254.50ms x-lambda: 1.0667906999588013 lambdas: [-0.026320919394493103, -0.30042341351509094, -0.2723868191242218] skip-layers: [14, 13, 12]

## 8000-add-skip-multiple-3-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [0, 1, 2]
step:125/5550 val_loss:4.268699 train_time:29943ms step_avg:239.54ms x-lambda: 1.1064560413360596 lambdas: [0.10412200540304184, 0.023072395473718643, 0.005163755267858505] skip-layers: [0, 1, 2]
step:250/5550 val_loss:3.850702 train_time:58916ms step_avg:235.66ms x-lambda: 1.0761715173721313 lambdas: [0.07925740629434586, -0.04448780417442322, -0.08066702634096146] skip-layers: [0, 1, 2]
step:375/5550 val_loss:3.677320 train_time:88344ms step_avg:235.58ms x-lambda: 1.0237908363342285 lambdas: [0.06434556841850281, -0.06177380308508873, -0.11352210491895676] skip-layers: [0, 1, 2]
step:500/5550 val_loss:3.558494 train_time:118137ms step_avg:236.27ms x-lambda: 0.9683924913406372 lambdas: [0.05499932914972305, -0.06740401685237885, -0.13390982151031494] skip-layers: [0, 1, 2]
step:625/5550 val_loss:3.481472 train_time:148148ms step_avg:237.04ms x-lambda: 0.9179671406745911 lambdas: [0.05210905522108078, -0.06460033357143402, -0.1433052122592926] skip-layers: [0, 1, 2]
step:750/5550 val_loss:3.430520 train_time:178428ms step_avg:237.90ms x-lambda: 0.8742250204086304 lambdas: [0.047430217266082764, -0.061566658318042755, -0.14999952912330627] skip-layers: [0, 1, 2]
step:875/5550 val_loss:3.383912 train_time:210998ms step_avg:241.14ms x-lambda: 0.8348439931869507 lambdas: [0.045154497027397156, -0.05407057702541351, -0.1495259553194046] skip-layers: [0, 1, 2]
step:1000/5550 val_loss:3.348799 train_time:241642ms step_avg:241.64ms x-lambda: 0.7990400791168213 lambdas: [0.04115217179059982, -0.049252718687057495, -0.14823028445243835] skip-layers: [0, 1, 2]
step:1125/5550 val_loss:3.320368 train_time:272332ms step_avg:242.07ms x-lambda: 0.7676337957382202 lambdas: [0.036734867841005325, -0.04540758952498436, -0.14655208587646484] skip-layers: [0, 1, 2]
step:1250/5550 val_loss:3.293674 train_time:304201ms step_avg:243.36ms x-lambda: 0.7450128197669983 lambdas: [0.037260305136442184, -0.03916241228580475, -0.1397969126701355] skip-layers: [0, 1, 2]
step:1375/5550 val_loss:3.272516 train_time:335168ms step_avg:243.76ms x-lambda: 0.7193191051483154 lambdas: [0.03373619541525841, -0.035603124648332596, -0.1350909024477005] skip-layers: [0, 1, 2]
step:1500/5550 val_loss:3.253676 train_time:366114ms step_avg:244.08ms x-lambda: 0.7005296945571899 lambdas: [0.033267825841903687, -0.031429875642061234, -0.1290796399116516] skip-layers: [0, 1, 2]
step:1625/5550 val_loss:3.238250 train_time:397156ms step_avg:244.40ms x-lambda: 0.6778078675270081 lambdas: [0.029117846861481667, -0.031189268454909325, -0.12709148228168488] skip-layers: [0, 1, 2]
step:1750/5550 val_loss:3.222889 train_time:429238ms step_avg:245.28ms x-lambda: 0.6597299575805664 lambdas: [0.029318952932953835, -0.026671960949897766, -0.12106326222419739] skip-layers: [0, 1, 2]
step:1875/5550 val_loss:3.205486 train_time:460318ms step_avg:245.50ms x-lambda: 0.6494386196136475 lambdas: [0.02964797243475914, -0.024363819509744644, -0.11502553522586823] skip-layers: [0, 1, 2]
step:2000/5550 val_loss:3.189738 train_time:491591ms step_avg:245.80ms x-lambda: 0.6351905465126038 lambdas: [0.028169043362140656, -0.02325659990310669, -0.11177472770214081] skip-layers: [0, 1, 2]
step:2125/5550 val_loss:3.175195 train_time:522938ms step_avg:246.09ms x-lambda: 0.6260861158370972 lambdas: [0.026644064113497734, -0.021240318194031715, -0.1080615222454071] skip-layers: [0, 1, 2]
step:2250/5550 val_loss:3.160688 train_time:555345ms step_avg:246.82ms x-lambda: 0.6177524924278259 lambdas: [0.02537481114268303, -0.021708354353904724, -0.10583595931529999] skip-layers: [0, 1, 2]
step:2375/5550 val_loss:3.148941 train_time:587740ms step_avg:247.47ms x-lambda: 0.6101877093315125 lambdas: [0.02510160394012928, -0.01915472000837326, -0.1018059179186821] skip-layers: [0, 1, 2]
step:2500/5550 val_loss:3.137293 train_time:620130ms step_avg:248.05ms x-lambda: 0.6051031947135925 lambdas: [0.025700954720377922, -0.018221748992800713, -0.09924193471670151] skip-layers: [0, 1, 2]
step:2625/5550 val_loss:3.126325 train_time:652493ms step_avg:248.57ms x-lambda: 0.601115882396698 lambdas: [0.023591114208102226, -0.018266769126057625, -0.09680101275444031] skip-layers: [0, 1, 2]
step:2750/5550 val_loss:3.114883 train_time:683741ms step_avg:248.63ms x-lambda: 0.597861647605896 lambdas: [0.022872526198625565, -0.01743725873529911, -0.09530433267354965] skip-layers: [0, 1, 2]
step:2875/5550 val_loss:3.104896 train_time:717236ms step_avg:249.47ms x-lambda: 0.5959752202033997 lambdas: [0.0233123991638422, -0.01582302711904049, -0.09242868423461914] skip-layers: [0, 1, 2]
step:3000/5550 val_loss:3.094509 train_time:751669ms step_avg:250.56ms x-lambda: 0.5938875079154968 lambdas: [0.021791189908981323, -0.015683334320783615, -0.0894421637058258] skip-layers: [0, 1, 2]
step:3125/5550 val_loss:3.084198 train_time:786108ms step_avg:251.55ms x-lambda: 0.5919455885887146 lambdas: [0.02184673584997654, -0.015417419373989105, -0.09023816138505936] skip-layers: [0, 1, 2]
step:3250/5550 val_loss:3.073020 train_time:819602ms step_avg:252.19ms x-lambda: 0.5935471057891846 lambdas: [0.02223600074648857, -0.014566440135240555, -0.08788697421550751] skip-layers: [0, 1, 2]
step:3375/5550 val_loss:3.063935 train_time:850864ms step_avg:252.11ms x-lambda: 0.5934121012687683 lambdas: [0.02077423967421055, -0.01450437307357788, -0.08660831302404404] skip-layers: [0, 1, 2]
step:3500/5550 val_loss:3.055053 train_time:882226ms step_avg:252.06ms x-lambda: 0.5935429334640503 lambdas: [0.02022368647158146, -0.014487228356301785, -0.08556866645812988] skip-layers: [0, 1, 2]
step:3625/5550 val_loss:3.046599 train_time:913565ms step_avg:252.02ms x-lambda: 0.5983969569206238 lambdas: [0.020879177376627922, -0.012673448771238327, -0.08384809643030167] skip-layers: [0, 1, 2]
step:3750/5550 val_loss:3.037062 train_time:944895ms step_avg:251.97ms x-lambda: 0.5978170037269592 lambdas: [0.021625535562634468, -0.014341435395181179, -0.08274287730455399] skip-layers: [0, 1, 2]
step:3875/5550 val_loss:3.027774 train_time:978369ms step_avg:252.48ms x-lambda: 0.6036780476570129 lambdas: [0.02096138708293438, -0.013210763223469257, -0.08213582634925842] skip-layers: [0, 1, 2]
step:4000/5550 val_loss:3.018405 train_time:1009728ms step_avg:252.43ms x-lambda: 0.6084628701210022 lambdas: [0.020514052361249924, -0.013082853518426418, -0.07967407256364822] skip-layers: [0, 1, 2]
step:4125/5550 val_loss:3.009242 train_time:1043177ms step_avg:252.89ms x-lambda: 0.6122738122940063 lambdas: [0.020840974524617195, -0.012539342045783997, -0.08048007637262344] skip-layers: [0, 1, 2]
step:4250/5550 val_loss:3.001318 train_time:1074753ms step_avg:252.88ms x-lambda: 0.6160668730735779 lambdas: [0.020124215632677078, -0.01253742165863514, -0.07870590686798096] skip-layers: [0, 1, 2]
step:4375/5550 val_loss:2.991587 train_time:1106383ms step_avg:252.89ms x-lambda: 0.619382381439209 lambdas: [0.019173137843608856, -0.012561487033963203, -0.07929389178752899] skip-layers: [0, 1, 2]
step:4500/5550 val_loss:2.983665 train_time:1138047ms step_avg:252.90ms x-lambda: 0.6261618137359619 lambdas: [0.01994648016989231, -0.011884759180247784, -0.07831618189811707] skip-layers: [0, 1, 2]
step:4625/5550 val_loss:2.974651 train_time:1169834ms step_avg:252.94ms x-lambda: 0.6341893076896667 lambdas: [0.018456019461154938, -0.01256419438868761, -0.0776715874671936] skip-layers: [0, 1, 2]
step:4750/5550 val_loss:2.965093 train_time:1202793ms step_avg:253.22ms x-lambda: 0.639872133731842 lambdas: [0.01998547650873661, -0.01129086036235094, -0.077619269490242] skip-layers: [0, 1, 2]
step:4875/5550 val_loss:2.956166 train_time:1234884ms step_avg:253.31ms x-lambda: 0.6474642753601074 lambdas: [0.0192251093685627, -0.010631663724780083, -0.07723153382539749] skip-layers: [0, 1, 2]
step:5000/5550 val_loss:2.948038 train_time:1268069ms step_avg:253.61ms x-lambda: 0.6540293097496033 lambdas: [0.018667886033654213, -0.011513348668813705, -0.0766986757516861] skip-layers: [0, 1, 2]
step:5125/5550 val_loss:2.940520 train_time:1302673ms step_avg:254.18ms x-lambda: 0.6613844037055969 lambdas: [0.019495192915201187, -0.010481960140168667, -0.07571657747030258] skip-layers: [0, 1, 2]
step:5250/5550 val_loss:2.933326 train_time:1338380ms step_avg:254.93ms x-lambda: 0.6685647368431091 lambdas: [0.018267780542373657, -0.01016273908317089, -0.07666154205799103] skip-layers: [0, 1, 2]
step:5375/5550 val_loss:2.926851 train_time:1371028ms step_avg:255.08ms x-lambda: 0.6766547560691833 lambdas: [0.019378507509827614, -0.010969352908432484, -0.07590664178133011] skip-layers: [0, 1, 2]
step:5500/5550 val_loss:2.922029 train_time:1404669ms step_avg:255.39ms x-lambda: 0.6822488903999329 lambdas: [0.018792275339365005, -0.010848280042409897, -0.07549355924129486] skip-layers: [0, 1, 2]
step:5550/5550 val_loss:2.920861 train_time:1417912ms step_avg:255.48ms x-lambda: 0.6840242147445679 lambdas: [0.01872703991830349, -0.010932277888059616, -0.07580306380987167] skip-layers: [0, 1, 2]

## 8000-add-skip-multiple-3-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.32ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [3, 10, 13]
step:125/5550 val_loss:4.267186 train_time:28606ms step_avg:228.85ms x-lambda: 1.1284747123718262 lambdas: [0.019299877807497978, 0.030067723244428635, 0.014951836317777634] skip-layers: [3, 10, 13]
step:250/5550 val_loss:3.852465 train_time:57346ms step_avg:229.39ms x-lambda: 1.1167097091674805 lambdas: [-0.022020360454916954, -0.022635875269770622, -0.012305193580687046] skip-layers: [3, 10, 13]
step:375/5550 val_loss:3.677476 train_time:86581ms step_avg:230.88ms x-lambda: 1.0520195960998535 lambdas: [-0.02846548706293106, -0.02992885187268257, -0.01893201470375061] skip-layers: [3, 10, 13]
step:500/5550 val_loss:3.559562 train_time:116196ms step_avg:232.39ms x-lambda: 0.9914032816886902 lambdas: [-0.027296191081404686, -0.02978169545531273, -0.017685549333691597] skip-layers: [3, 10, 13]
step:625/5550 val_loss:3.481310 train_time:146034ms step_avg:233.65ms x-lambda: 0.9300756454467773 lambdas: [-0.028346220031380653, -0.029715586453676224, -0.019688233733177185] skip-layers: [3, 10, 13]
step:750/5550 val_loss:3.428607 train_time:176163ms step_avg:234.88ms x-lambda: 0.885727047920227 lambdas: [-0.025525318458676338, -0.02624012902379036, -0.01705513522028923] skip-layers: [3, 10, 13]
step:875/5550 val_loss:3.383345 train_time:206373ms step_avg:235.85ms x-lambda: 0.8386269211769104 lambdas: [-0.02175077609717846, -0.02375194802880287, -0.016132161021232605] skip-layers: [3, 10, 13]
step:1000/5550 val_loss:3.348299 train_time:237785ms step_avg:237.79ms x-lambda: 0.7992262840270996 lambdas: [-0.021679528057575226, -0.02274153381586075, -0.015614522621035576] skip-layers: [3, 10, 13]
step:1125/5550 val_loss:3.320244 train_time:268285ms step_avg:238.48ms x-lambda: 0.7652378678321838 lambdas: [-0.022425085306167603, -0.02407398819923401, -0.016415197402238846] skip-layers: [3, 10, 13]
step:1250/5550 val_loss:3.294704 train_time:301168ms step_avg:240.93ms x-lambda: 0.7398870587348938 lambdas: [-0.01884736865758896, -0.019733978435397148, -0.013638456352055073] skip-layers: [3, 10, 13]
step:1375/5550 val_loss:3.274443 train_time:333124ms step_avg:242.27ms x-lambda: 0.713808000087738 lambdas: [-0.01875007152557373, -0.019063957035541534, -0.013224199414253235] skip-layers: [3, 10, 13]
step:1500/5550 val_loss:3.258820 train_time:364012ms step_avg:242.67ms x-lambda: 0.6932961940765381 lambdas: [-0.018304971978068352, -0.018369430676102638, -0.013760600239038467] skip-layers: [3, 10, 13]
step:1625/5550 val_loss:3.239953 train_time:395985ms step_avg:243.68ms x-lambda: 0.6753974556922913 lambdas: [-0.015511573292315006, -0.016045842319726944, -0.01137228962033987] skip-layers: [3, 10, 13]
step:1750/5550 val_loss:3.224442 train_time:426945ms step_avg:243.97ms x-lambda: 0.6546304821968079 lambdas: [-0.014240942895412445, -0.01579705812036991, -0.010083548724651337] skip-layers: [3, 10, 13]
step:1875/5550 val_loss:3.206370 train_time:459059ms step_avg:244.83ms x-lambda: 0.6420980095863342 lambdas: [-0.014107750728726387, -0.015411294996738434, -0.011714943684637547] skip-layers: [3, 10, 13]
step:2000/5550 val_loss:3.189598 train_time:492289ms step_avg:246.14ms x-lambda: 0.628791868686676 lambdas: [-0.013862074352800846, -0.013743633404374123, -0.010419118218123913] skip-layers: [3, 10, 13]
step:2125/5550 val_loss:3.175206 train_time:524648ms step_avg:246.89ms x-lambda: 0.6213684678077698 lambdas: [-0.01256604678928852, -0.012978345155715942, -0.010426148772239685] skip-layers: [3, 10, 13]
step:2250/5550 val_loss:3.161689 train_time:558056ms step_avg:248.02ms x-lambda: 0.6138473153114319 lambdas: [-0.012259960174560547, -0.012956958264112473, -0.010415008291602135] skip-layers: [3, 10, 13]
step:2375/5550 val_loss:3.150254 train_time:589310ms step_avg:248.13ms x-lambda: 0.6058916449546814 lambdas: [-0.012724680826067924, -0.012975333258509636, -0.0091606630012393] skip-layers: [3, 10, 13]
step:2500/5550 val_loss:3.138563 train_time:622410ms step_avg:248.96ms x-lambda: 0.6010472774505615 lambdas: [-0.011363319121301174, -0.01127071026712656, -0.007923005148768425] skip-layers: [3, 10, 13]
step:2625/5550 val_loss:3.126338 train_time:653571ms step_avg:248.98ms x-lambda: 0.5971155166625977 lambdas: [-0.010897637344896793, -0.012443876825273037, -0.009081370197236538] skip-layers: [3, 10, 13]
step:2750/5550 val_loss:3.115474 train_time:684777ms step_avg:249.01ms x-lambda: 0.5936664938926697 lambdas: [-0.010927800089120865, -0.011476912535727024, -0.008621934801340103] skip-layers: [3, 10, 13]
step:2875/5550 val_loss:3.106085 train_time:718158ms step_avg:249.79ms x-lambda: 0.5931040644645691 lambdas: [-0.010981491766870022, -0.010222123935818672, -0.008569849655032158] skip-layers: [3, 10, 13]
step:3000/5550 val_loss:3.095333 train_time:751509ms step_avg:250.50ms x-lambda: 0.5928906798362732 lambdas: [-0.01033480279147625, -0.010513560846447945, -0.008442902006208897] skip-layers: [3, 10, 13]
step:3125/5550 val_loss:3.085462 train_time:784892ms step_avg:251.17ms x-lambda: 0.5901521444320679 lambdas: [-0.011418748646974564, -0.011892426759004593, -0.007164475508034229] skip-layers: [3, 10, 13]
step:3250/5550 val_loss:3.072685 train_time:816100ms step_avg:251.11ms x-lambda: 0.5920755863189697 lambdas: [-0.009178460575640202, -0.00969398207962513, -0.006488824728876352] skip-layers: [3, 10, 13]
step:3375/5550 val_loss:3.064533 train_time:847292ms step_avg:251.05ms x-lambda: 0.5925390124320984 lambdas: [-0.009509793482720852, -0.01048748753964901, -0.0069758594036102295] skip-layers: [3, 10, 13]
step:3500/5550 val_loss:3.055603 train_time:878548ms step_avg:251.01ms x-lambda: 0.5915383696556091 lambdas: [-0.010629077441990376, -0.010966680012643337, -0.007819372229278088] skip-layers: [3, 10, 13]
step:3625/5550 val_loss:3.047040 train_time:909762ms step_avg:250.97ms x-lambda: 0.5949691534042358 lambdas: [-0.01018130499869585, -0.009051068685948849, -0.007974900305271149] skip-layers: [3, 10, 13]
step:3750/5550 val_loss:3.037344 train_time:940953ms step_avg:250.92ms x-lambda: 0.59699946641922 lambdas: [-0.008561457507312298, -0.009271567687392235, -0.006413835566490889] skip-layers: [3, 10, 13]
step:3875/5550 val_loss:3.028523 train_time:972247ms step_avg:250.90ms x-lambda: 0.6027039289474487 lambdas: [-0.009199708700180054, -0.008870319463312626, -0.006809133104979992] skip-layers: [3, 10, 13]
step:4000/5550 val_loss:3.018894 train_time:1003513ms step_avg:250.88ms x-lambda: 0.607697606086731 lambdas: [-0.00788508728146553, -0.007369327358901501, -0.006160768214613199] skip-layers: [3, 10, 13]
step:4125/5550 val_loss:3.009651 train_time:1034830ms step_avg:250.87ms x-lambda: 0.612725019454956 lambdas: [-0.00744426716119051, -0.008881916292011738, -0.006353437900543213] skip-layers: [3, 10, 13]
step:4250/5550 val_loss:3.001423 train_time:1067520ms step_avg:251.18ms x-lambda: 0.6160513758659363 lambdas: [-0.008834343403577805, -0.007453119847923517, -0.006482252851128578] skip-layers: [3, 10, 13]
step:4375/5550 val_loss:2.992047 train_time:1099084ms step_avg:251.22ms x-lambda: 0.6198275089263916 lambdas: [-0.010246790945529938, -0.007950692437589169, -0.006480975076556206] skip-layers: [3, 10, 13]
step:4500/5550 val_loss:2.983716 train_time:1131716ms step_avg:251.49ms x-lambda: 0.6259564757347107 lambdas: [-0.008664562366902828, -0.008760702796280384, -0.006274454295635223] skip-layers: [3, 10, 13]
step:4625/5550 val_loss:2.974273 train_time:1163434ms step_avg:251.55ms x-lambda: 0.6339909434318542 lambdas: [-0.0077034602873027325, -0.007951568812131882, -0.006296955980360508] skip-layers: [3, 10, 13]
step:4750/5550 val_loss:2.965264 train_time:1195264ms step_avg:251.63ms x-lambda: 0.6415165662765503 lambdas: [-0.007157346233725548, -0.006908903829753399, -0.005945929326117039] skip-layers: [3, 10, 13]
step:4875/5550 val_loss:2.956345 train_time:1227304ms step_avg:251.75ms x-lambda: 0.648353099822998 lambdas: [-0.008084830828011036, -0.007676429580897093, -0.006486239843070507] skip-layers: [3, 10, 13]
step:5000/5550 val_loss:2.948108 train_time:1259406ms step_avg:251.88ms x-lambda: 0.6556594967842102 lambdas: [-0.007736428175121546, -0.008353806100785732, -0.005426426883786917] skip-layers: [3, 10, 13]
step:5125/5550 val_loss:2.940546 train_time:1293711ms step_avg:252.43ms x-lambda: 0.6642200946807861 lambdas: [-0.00798895861953497, -0.007986575365066528, -0.005000729579478502] skip-layers: [3, 10, 13]
step:5250/5550 val_loss:2.933280 train_time:1327243ms step_avg:252.81ms x-lambda: 0.6704416871070862 lambdas: [-0.008388529531657696, -0.007559577934443951, -0.005609879735857248] skip-layers: [3, 10, 13]
step:5375/5550 val_loss:2.926775 train_time:1359810ms step_avg:252.99ms x-lambda: 0.6799247860908508 lambdas: [-0.0073363445699214935, -0.007259097415953875, -0.005591010209172964] skip-layers: [3, 10, 13]
step:5500/5550 val_loss:2.921981 train_time:1395981ms step_avg:253.81ms x-lambda: 0.6854314804077148 lambdas: [-0.00743310060352087, -0.007177166640758514, -0.00569757167249918] skip-layers: [3, 10, 13]
step:5550/5550 val_loss:2.920777 train_time:1409197ms step_avg:253.91ms x-lambda: 0.6869142055511475 lambdas: [-0.007664380595088005, -0.007413012441247702, -0.005427300464361906] skip-layers: [3, 10, 13]

## 8000-add-skip-multiple-3-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0] skip-layers: [1, 2, 7]
step:125/5550 val_loss:4.272185 train_time:28599ms step_avg:228.79ms x-lambda: 1.0835206508636475 lambdas: [0.0514630563557148, 0.011201445944607258, 0.08416114002466202] skip-layers: [1, 2, 7]
step:250/5550 val_loss:3.850803 train_time:58456ms step_avg:233.82ms x-lambda: 1.055290937423706 lambdas: [-0.004224090371280909, -0.08578815311193466, 0.0680740475654602] skip-layers: [1, 2, 7]
step:375/5550 val_loss:3.676290 train_time:87620ms step_avg:233.65ms x-lambda: 1.013196587562561 lambdas: [-0.014268665574491024, -0.12453577667474747, 0.041152093559503555] skip-layers: [1, 2, 7]
step:500/5550 val_loss:3.559390 train_time:120153ms step_avg:240.31ms x-lambda: 0.9648464918136597 lambdas: [-0.016634704545140266, -0.14855141937732697, 0.02055063471198082] skip-layers: [1, 2, 7]
step:625/5550 val_loss:3.481150 train_time:150030ms step_avg:240.05ms x-lambda: 0.9191187620162964 lambdas: [-0.010636950843036175, -0.15905091166496277, 0.01143704354763031] skip-layers: [1, 2, 7]
step:750/5550 val_loss:3.428440 train_time:180893ms step_avg:241.19ms x-lambda: 0.8789994120597839 lambdas: [-0.007135198451578617, -0.16491062939167023, 0.003677129512652755] skip-layers: [1, 2, 7]
step:875/5550 val_loss:3.382682 train_time:213131ms step_avg:243.58ms x-lambda: 0.8385433554649353 lambdas: [-0.0022569047287106514, -0.16515490412712097, 0.000370799214579165] skip-layers: [1, 2, 7]
step:1000/5550 val_loss:3.348623 train_time:243628ms step_avg:243.63ms x-lambda: 0.8046159744262695 lambdas: [0.0005673440173268318, -0.16375915706157684, -0.005372696556150913] skip-layers: [1, 2, 7]
step:1125/5550 val_loss:3.319263 train_time:274152ms step_avg:243.69ms x-lambda: 0.7719421982765198 lambdas: [0.001490019029006362, -0.16067005693912506, -0.009298611432313919] skip-layers: [1, 2, 7]
step:1250/5550 val_loss:3.294445 train_time:305850ms step_avg:244.68ms x-lambda: 0.7487726807594299 lambdas: [0.0052553885616362095, -0.15371733903884888, -0.007473111152648926] skip-layers: [1, 2, 7]
step:1375/5550 val_loss:3.271988 train_time:336726ms step_avg:244.89ms x-lambda: 0.7233746647834778 lambdas: [0.005842880345880985, -0.14907948672771454, -0.01019604317843914] skip-layers: [1, 2, 7]
step:1500/5550 val_loss:3.252628 train_time:368615ms step_avg:245.74ms x-lambda: 0.704917848110199 lambdas: [0.00713897030800581, -0.14254233241081238, -0.009992558509111404] skip-layers: [1, 2, 7]
step:1625/5550 val_loss:3.236788 train_time:400564ms step_avg:246.50ms x-lambda: 0.6813904643058777 lambdas: [0.006875438150018454, -0.1383143961429596, -0.01197783276438713] skip-layers: [1, 2, 7]
step:1750/5550 val_loss:3.221444 train_time:431460ms step_avg:246.55ms x-lambda: 0.6641936898231506 lambdas: [0.008651290088891983, -0.13007114827632904, -0.0114115746691823] skip-layers: [1, 2, 7]
step:1875/5550 val_loss:3.202739 train_time:462419ms step_avg:246.62ms x-lambda: 0.6509442329406738 lambdas: [0.006925270892679691, -0.1267615407705307, -0.013703739270567894] skip-layers: [1, 2, 7]
step:2000/5550 val_loss:3.188154 train_time:494642ms step_avg:247.32ms x-lambda: 0.6381998658180237 lambdas: [0.008507976308465004, -0.12080363929271698, -0.013389522209763527] skip-layers: [1, 2, 7]
step:2125/5550 val_loss:3.173811 train_time:527009ms step_avg:248.00ms x-lambda: 0.6271530985832214 lambdas: [0.007929475978016853, -0.11778830736875534, -0.01473456434905529] skip-layers: [1, 2, 7]
step:2250/5550 val_loss:3.159624 train_time:558190ms step_avg:248.08ms x-lambda: 0.619636595249176 lambdas: [0.007684390991926193, -0.1135028824210167, -0.015318457037210464] skip-layers: [1, 2, 7]
step:2375/5550 val_loss:3.147911 train_time:591561ms step_avg:249.08ms x-lambda: 0.6124275326728821 lambdas: [0.007307657040655613, -0.11022722721099854, -0.015228178352117538] skip-layers: [1, 2, 7]
step:2500/5550 val_loss:3.136921 train_time:622731ms step_avg:249.09ms x-lambda: 0.6072481870651245 lambdas: [0.008678021840751171, -0.1051032766699791, -0.015613393858075142] skip-layers: [1, 2, 7]
step:2625/5550 val_loss:3.124841 train_time:653898ms step_avg:249.10ms x-lambda: 0.6027408242225647 lambdas: [0.00852961465716362, -0.10369381308555603, -0.01575634442269802] skip-layers: [1, 2, 7]
step:2750/5550 val_loss:3.113960 train_time:685033ms step_avg:249.10ms x-lambda: 0.5996596217155457 lambdas: [0.007978636771440506, -0.1010364294052124, -0.015929101034998894] skip-layers: [1, 2, 7]
step:2875/5550 val_loss:3.104159 train_time:716210ms step_avg:249.12ms x-lambda: 0.5955531597137451 lambdas: [0.008397689089179039, -0.09842231124639511, -0.016239317134022713] skip-layers: [1, 2, 7]
step:3000/5550 val_loss:3.093904 train_time:748474ms step_avg:249.49ms x-lambda: 0.596030592918396 lambdas: [0.009355447255074978, -0.09438682347536087, -0.016921143978834152] skip-layers: [1, 2, 7]
step:3125/5550 val_loss:3.082651 train_time:780819ms step_avg:249.86ms x-lambda: 0.5937356948852539 lambdas: [0.008384044282138348, -0.09446191787719727, -0.0169951394200325] skip-layers: [1, 2, 7]
step:3250/5550 val_loss:3.071312 train_time:814177ms step_avg:250.52ms x-lambda: 0.5954186320304871 lambdas: [0.009126432240009308, -0.09168937802314758, -0.015360433608293533] skip-layers: [1, 2, 7]
step:3375/5550 val_loss:3.062791 train_time:845320ms step_avg:250.47ms x-lambda: 0.5944546461105347 lambdas: [0.007612330839037895, -0.09151821583509445, -0.01676361821591854] skip-layers: [1, 2, 7]
step:3500/5550 val_loss:3.053842 train_time:876542ms step_avg:250.44ms x-lambda: 0.5940226316452026 lambdas: [0.007205807603895664, -0.08961986750364304, -0.01754746399819851] skip-layers: [1, 2, 7]
step:3625/5550 val_loss:3.044717 train_time:908835ms step_avg:250.71ms x-lambda: 0.598142147064209 lambdas: [0.008686480112373829, -0.08792871981859207, -0.018121639266610146] skip-layers: [1, 2, 7]
step:3750/5550 val_loss:3.035423 train_time:943434ms step_avg:251.58ms x-lambda: 0.5982605218887329 lambdas: [0.009318666532635689, -0.08679124712944031, -0.01688573509454727] skip-layers: [1, 2, 7]
step:3875/5550 val_loss:3.026352 train_time:975857ms step_avg:251.83ms x-lambda: 0.6044014096260071 lambdas: [0.009002928622066975, -0.08524390310049057, -0.01895054057240486] skip-layers: [1, 2, 7]
step:4000/5550 val_loss:3.016930 train_time:1009256ms step_avg:252.31ms x-lambda: 0.6070564985275269 lambdas: [0.008038638159632683, -0.08435343950986862, -0.01808456890285015] skip-layers: [1, 2, 7]
step:4125/5550 val_loss:3.007957 train_time:1041633ms step_avg:252.52ms x-lambda: 0.6134867072105408 lambdas: [0.007890624925494194, -0.08399833738803864, -0.017771903425455093] skip-layers: [1, 2, 7]
step:4250/5550 val_loss:2.999419 train_time:1073147ms step_avg:252.51ms x-lambda: 0.6164885759353638 lambdas: [0.007872004993259907, -0.082943856716156, -0.018602309748530388] skip-layers: [1, 2, 7]
step:4375/5550 val_loss:2.990587 train_time:1109115ms step_avg:253.51ms x-lambda: 0.6195852160453796 lambdas: [0.007983412593603134, -0.0828651711344719, -0.019032660871744156] skip-layers: [1, 2, 7]
step:4500/5550 val_loss:2.982253 train_time:1140716ms step_avg:253.49ms x-lambda: 0.62493896484375 lambdas: [0.00861316453665495, -0.08125260472297668, -0.01845921389758587] skip-layers: [1, 2, 7]
step:4625/5550 val_loss:2.972865 train_time:1172371ms step_avg:253.49ms x-lambda: 0.6342259645462036 lambdas: [0.008423554711043835, -0.08023250848054886, -0.019472092390060425] skip-layers: [1, 2, 7]
step:4750/5550 val_loss:2.963565 train_time:1206466ms step_avg:253.99ms x-lambda: 0.6403363347053528 lambdas: [0.008059456013143063, -0.08041532337665558, -0.018183834850788116] skip-layers: [1, 2, 7]
step:4875/5550 val_loss:2.954726 train_time:1238470ms step_avg:254.05ms x-lambda: 0.6468042135238647 lambdas: [0.008113082498311996, -0.07936335355043411, -0.020678861066699028] skip-layers: [1, 2, 7]
step:5000/5550 val_loss:2.946665 train_time:1270554ms step_avg:254.11ms x-lambda: 0.652980625629425 lambdas: [0.008274132385849953, -0.07909086346626282, -0.020642200484871864] skip-layers: [1, 2, 7]
step:5125/5550 val_loss:2.938929 train_time:1303839ms step_avg:254.41ms x-lambda: 0.6619722843170166 lambdas: [0.007974057458341122, -0.07735058665275574, -0.01985565759241581] skip-layers: [1, 2, 7]
step:5250/5550 val_loss:2.931791 train_time:1336295ms step_avg:254.53ms x-lambda: 0.6683117747306824 lambdas: [0.007302765268832445, -0.07769689708948135, -0.020763874053955078] skip-layers: [1, 2, 7]
step:5375/5550 val_loss:2.925322 train_time:1372075ms step_avg:255.27ms x-lambda: 0.6767796874046326 lambdas: [0.007668815087527037, -0.07762905955314636, -0.02060440555214882] skip-layers: [1, 2, 7]
step:5500/5550 val_loss:2.920475 train_time:1405958ms step_avg:255.63ms x-lambda: 0.6819291114807129 lambdas: [0.007484620437026024, -0.07762281596660614, -0.0205039381980896] skip-layers: [1, 2, 7]
step:5550/5550 val_loss:2.919298 train_time:1420327ms step_avg:255.91ms x-lambda: 0.6831473112106323 lambdas: [0.0077132112346589565, -0.07760194689035416, -0.020768750458955765] skip-layers: [1, 2, 7]

## 8000-add-skip-multiple-4-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4]
step:125/5550 val_loss:4.253181 train_time:28649ms step_avg:229.19ms x-lambda: 1.028296709060669 lambdas: [0.03853879123926163, 0.047515224665403366, 0.03464799001812935, 0.08132896572351456] skip-layers: [11, 10, 8, 4]
step:250/5550 val_loss:3.850143 train_time:57508ms step_avg:230.03ms x-lambda: 0.9863881468772888 lambdas: [0.011925121769309044, 0.020925050601363182, -0.005267263390123844, 0.08845440298318863] skip-layers: [11, 10, 8, 4]
step:375/5550 val_loss:3.679093 train_time:86757ms step_avg:231.35ms x-lambda: 0.9891849160194397 lambdas: [-0.007479934487491846, -0.0277415718883276, -0.02684902958571911, 0.056335434317588806] skip-layers: [11, 10, 8, 4]
step:500/5550 val_loss:3.562669 train_time:116498ms step_avg:233.00ms x-lambda: 0.9782859086990356 lambdas: [-0.02622523158788681, -0.07413431257009506, -0.03413977846503258, 0.0318230576813221] skip-layers: [11, 10, 8, 4]
step:625/5550 val_loss:3.483146 train_time:146463ms step_avg:234.34ms x-lambda: 0.9679756760597229 lambdas: [-0.03884351626038551, -0.11279439181089401, -0.029573410749435425, 0.019284164533019066] skip-layers: [11, 10, 8, 4]
step:750/5550 val_loss:3.429493 train_time:176706ms step_avg:235.61ms x-lambda: 0.9580584168434143 lambdas: [-0.05034475401043892, -0.1452489048242569, -0.02511291392147541, 0.01085206214338541] skip-layers: [11, 10, 8, 4]
step:875/5550 val_loss:3.384728 train_time:207024ms step_avg:236.60ms x-lambda: 0.9397879838943481 lambdas: [-0.06150885671377182, -0.17326626181602478, -0.01934584230184555, 0.004312209784984589] skip-layers: [11, 10, 8, 4]
step:1000/5550 val_loss:3.349533 train_time:237606ms step_avg:237.61ms x-lambda: 0.9262447953224182 lambdas: [-0.06645113974809647, -0.1920686960220337, -0.013674331828951836, 0.004367112182080746] skip-layers: [11, 10, 8, 4]
step:1125/5550 val_loss:3.318109 train_time:268192ms step_avg:238.39ms x-lambda: 0.9110462665557861 lambdas: [-0.07415442913770676, -0.2099488526582718, -0.00966726802289486, -0.000598011480178684] skip-layers: [11, 10, 8, 4]
step:1250/5550 val_loss:3.293850 train_time:300095ms step_avg:240.08ms x-lambda: 0.8977408409118652 lambdas: [-0.07780654728412628, -0.22028331458568573, -0.005331095308065414, 0.0006915570702403784] skip-layers: [11, 10, 8, 4]
step:1375/5550 val_loss:3.271996 train_time:332122ms step_avg:241.54ms x-lambda: 0.8797719478607178 lambdas: [-0.08301014453172684, -0.2305338829755783, -0.004690078087151051, -0.00263269548304379] skip-layers: [11, 10, 8, 4]
step:1500/5550 val_loss:3.252919 train_time:363035ms step_avg:242.02ms x-lambda: 0.8668206930160522 lambdas: [-0.08710739761590958, -0.2381313592195511, -0.0033143889158964157, -0.00496993213891983] skip-layers: [11, 10, 8, 4]
step:1625/5550 val_loss:3.236759 train_time:394039ms step_avg:242.49ms x-lambda: 0.8520835638046265 lambdas: [-0.0886477679014206, -0.2412545382976532, -0.00019157017231918871, -0.002922599669545889] skip-layers: [11, 10, 8, 4]
step:1750/5550 val_loss:3.220460 train_time:427066ms step_avg:244.04ms x-lambda: 0.8381295204162598 lambdas: [-0.09212245047092438, -0.2451385110616684, 0.0006864077877253294, -0.0060063013806939125] skip-layers: [11, 10, 8, 4]
step:1875/5550 val_loss:3.202939 train_time:458140ms step_avg:244.34ms x-lambda: 0.8259211778640747 lambdas: [-0.09399745613336563, -0.246064692735672, 0.0022457565646618605, -0.006676072254776955] skip-layers: [11, 10, 8, 4]
step:2000/5550 val_loss:3.187746 train_time:489410ms step_avg:244.70ms x-lambda: 0.8152629733085632 lambdas: [-0.09446519613265991, -0.24546760320663452, 0.004861438646912575, -0.005075653083622456] skip-layers: [11, 10, 8, 4]
step:2125/5550 val_loss:3.172286 train_time:521792ms step_avg:245.55ms x-lambda: 0.8076366186141968 lambdas: [-0.09577394276857376, -0.2462494969367981, 0.0029310877434909344, -0.005174699705094099] skip-layers: [11, 10, 8, 4]
step:2250/5550 val_loss:3.158892 train_time:557415ms step_avg:247.74ms x-lambda: 0.8014088869094849 lambdas: [-0.09733042120933533, -0.24595949053764343, 0.0028989771381020546, -0.006559181492775679] skip-layers: [11, 10, 8, 4]
step:2375/5550 val_loss:3.147761 train_time:594087ms step_avg:250.14ms x-lambda: 0.7908099889755249 lambdas: [-0.09827204048633575, -0.24348677694797516, 0.003532948438078165, -0.006842041853815317] skip-layers: [11, 10, 8, 4]
step:2500/5550 val_loss:3.135829 train_time:625383ms step_avg:250.15ms x-lambda: 0.786112368106842 lambdas: [-0.09780840575695038, -0.24221815168857574, 0.005080899223685265, -0.00546011608093977] skip-layers: [11, 10, 8, 4]
step:2625/5550 val_loss:3.124204 train_time:656591ms step_avg:250.13ms x-lambda: 0.7795149683952332 lambdas: [-0.0979146659374237, -0.24170586466789246, 0.005827418062835932, -0.0073532299138605595] skip-layers: [11, 10, 8, 4]
step:2750/5550 val_loss:3.112606 train_time:688911ms step_avg:250.51ms x-lambda: 0.7750285863876343 lambdas: [-0.09948523342609406, -0.23947978019714355, 0.00504359882324934, -0.007210303097963333] skip-layers: [11, 10, 8, 4]
step:2875/5550 val_loss:3.103705 train_time:720156ms step_avg:250.49ms x-lambda: 0.7703827619552612 lambdas: [-0.09863503277301788, -0.2383616864681244, 0.004477315116673708, -0.006879006512463093] skip-layers: [11, 10, 8, 4]
step:3000/5550 val_loss:3.092597 train_time:751452ms step_avg:250.48ms x-lambda: 0.7698014974594116 lambdas: [-0.0981307327747345, -0.23744551837444305, 0.005327207036316395, -0.0068404534831643105] skip-layers: [11, 10, 8, 4]
step:3125/5550 val_loss:3.081916 train_time:782742ms step_avg:250.48ms x-lambda: 0.7655152678489685 lambdas: [-0.10038620233535767, -0.23827239871025085, 0.0044376845471560955, -0.007910938002169132] skip-layers: [11, 10, 8, 4]
step:3250/5550 val_loss:3.069975 train_time:813991ms step_avg:250.46ms x-lambda: 0.7663502097129822 lambdas: [-0.09799148887395859, -0.23522593080997467, 0.005154276732355356, -0.00784264039248228] skip-layers: [11, 10, 8, 4]
step:3375/5550 val_loss:3.061306 train_time:846268ms step_avg:250.75ms x-lambda: 0.7639603018760681 lambdas: [-0.09831515699625015, -0.23603922128677368, 0.004979274235665798, -0.008516260422766209] skip-layers: [11, 10, 8, 4]
step:3500/5550 val_loss:3.052193 train_time:877578ms step_avg:250.74ms x-lambda: 0.7623688578605652 lambdas: [-0.09952843189239502, -0.23331031203269958, 0.005159167107194662, -0.0082295723259449] skip-layers: [11, 10, 8, 4]
step:3625/5550 val_loss:3.043738 train_time:911058ms step_avg:251.33ms x-lambda: 0.7641695737838745 lambdas: [-0.09815807640552521, -0.2308434247970581, 0.004727147985249758, -0.008925529196858406] skip-layers: [11, 10, 8, 4]
step:3750/5550 val_loss:3.034187 train_time:943435ms step_avg:251.58ms x-lambda: 0.7632062435150146 lambdas: [-0.09910432994365692, -0.23094671964645386, 0.0058496142737567425, -0.007735523860901594] skip-layers: [11, 10, 8, 4]
step:3875/5550 val_loss:3.025117 train_time:974806ms step_avg:251.56ms x-lambda: 0.7683290243148804 lambdas: [-0.09792224317789078, -0.2308994084596634, 0.00497023668140173, -0.008169109001755714] skip-layers: [11, 10, 8, 4]
step:4000/5550 val_loss:3.015825 train_time:1007169ms step_avg:251.79ms x-lambda: 0.7695551514625549 lambdas: [-0.09733042865991592, -0.22981341183185577, 0.005224922671914101, -0.0081865219399333] skip-layers: [11, 10, 8, 4]
step:4125/5550 val_loss:3.006523 train_time:1038582ms step_avg:251.78ms x-lambda: 0.7719829082489014 lambdas: [-0.09737064689397812, -0.22964324057102203, 0.005556107498705387, -0.007503338158130646] skip-layers: [11, 10, 8, 4]
step:4250/5550 val_loss:2.998628 train_time:1070186ms step_avg:251.81ms x-lambda: 0.776818037033081 lambdas: [-0.09708429872989655, -0.2301972508430481, 0.00462551973760128, -0.00839327648282051] skip-layers: [11, 10, 8, 4]
step:4375/5550 val_loss:2.989306 train_time:1101824ms step_avg:251.85ms x-lambda: 0.7788499593734741 lambdas: [-0.09807374328374863, -0.23127765953540802, 0.004062446299940348, -0.009081658907234669] skip-layers: [11, 10, 8, 4]
step:4500/5550 val_loss:2.981011 train_time:1137770ms step_avg:252.84ms x-lambda: 0.7828851938247681 lambdas: [-0.09767557680606842, -0.2310103327035904, 0.004020277876406908, -0.008164732716977596] skip-layers: [11, 10, 8, 4]
step:4625/5550 val_loss:2.971615 train_time:1170706ms step_avg:253.13ms x-lambda: 0.7893067002296448 lambdas: [-0.09726613014936447, -0.22937728464603424, 0.003390587167814374, -0.010373865254223347] skip-layers: [11, 10, 8, 4]
step:4750/5550 val_loss:2.962410 train_time:1204784ms step_avg:253.64ms x-lambda: 0.7948523163795471 lambdas: [-0.09706892818212509, -0.23049142956733704, 0.003979790490120649, -0.0073641398921608925] skip-layers: [11, 10, 8, 4]
step:4875/5550 val_loss:2.953499 train_time:1237978ms step_avg:253.94ms x-lambda: 0.8003972172737122 lambdas: [-0.09660061448812485, -0.2311054915189743, 0.003508335677906871, -0.00816014688462019] skip-layers: [11, 10, 8, 4]
step:5000/5550 val_loss:2.945419 train_time:1272005ms step_avg:254.40ms x-lambda: 0.8070151209831238 lambdas: [-0.09670823067426682, -0.23155218362808228, 0.0031217460054904222, -0.008631096221506596] skip-layers: [11, 10, 8, 4]
step:5125/5550 val_loss:2.937772 train_time:1304328ms step_avg:254.50ms x-lambda: 0.813026487827301 lambdas: [-0.09632337093353271, -0.23261189460754395, 0.0030776248313486576, -0.008898616768419743] skip-layers: [11, 10, 8, 4]
step:5250/5550 val_loss:2.930582 train_time:1340148ms step_avg:255.27ms x-lambda: 0.8174304962158203 lambdas: [-0.09691820293664932, -0.2319263517856598, 0.002381579950451851, -0.008577484637498856] skip-layers: [11, 10, 8, 4]
step:5375/5550 val_loss:2.924090 train_time:1372788ms step_avg:255.40ms x-lambda: 0.823767364025116 lambdas: [-0.09658925235271454, -0.23389026522636414, 0.001999658765271306, -0.008694726973772049] skip-layers: [11, 10, 8, 4]
step:5500/5550 val_loss:2.919321 train_time:1405651ms step_avg:255.57ms x-lambda: 0.8279781937599182 lambdas: [-0.0959368497133255, -0.23358574509620667, 0.0022034328430891037, -0.009205462411046028] skip-layers: [11, 10, 8, 4]
step:5550/5550 val_loss:2.918114 train_time:1418892ms step_avg:255.66ms x-lambda: 0.8287822008132935 lambdas: [-0.09589733928442001, -0.2340214103460312, 0.0017598075792193413, -0.008761690929532051] skip-layers: [11, 10, 8, 4]

## 8000-add-skip-multiple-4-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.12ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11]
step:125/5550 val_loss:4.263803 train_time:28628ms step_avg:229.03ms x-lambda: 1.0413451194763184 lambdas: [0.035125669091939926, 0.0406842976808548, 0.04422539845108986, 0.04725686460733414] skip-layers: [14, 13, 12, 11]
step:250/5550 val_loss:3.853429 train_time:57424ms step_avg:229.70ms x-lambda: 0.9937204122543335 lambdas: [0.011860484257340431, 0.026355380192399025, 0.02714851312339306, 0.025949131697416306] skip-layers: [14, 13, 12, 11]
step:375/5550 val_loss:3.676628 train_time:86714ms step_avg:231.24ms x-lambda: 0.9774311780929565 lambdas: [0.001953961793333292, 0.011352467350661755, -0.0004600540269166231, -0.0165438000112772] skip-layers: [14, 13, 12, 11]
step:500/5550 val_loss:3.561399 train_time:116439ms step_avg:232.88ms x-lambda: 0.9750711917877197 lambdas: [-0.0036343149840831757, 0.0018472245428711176, -0.022128188982605934, -0.05377430468797684] skip-layers: [14, 13, 12, 11]
step:625/5550 val_loss:3.481845 train_time:146358ms step_avg:234.17ms x-lambda: 0.9668205380439758 lambdas: [-0.01194967795163393, -0.00864425953477621, -0.04354231804609299, -0.09037616103887558] skip-layers: [14, 13, 12, 11]
step:750/5550 val_loss:3.430506 train_time:176571ms step_avg:235.43ms x-lambda: 0.966060221195221 lambdas: [-0.013943069614470005, -0.0128750866279006, -0.05770344287157059, -0.11890935152769089] skip-layers: [14, 13, 12, 11]
step:875/5550 val_loss:3.383381 train_time:206848ms step_avg:236.40ms x-lambda: 0.9637912511825562 lambdas: [-0.015024429187178612, -0.016496997326612473, -0.07070965319871902, -0.1448708474636078] skip-layers: [14, 13, 12, 11]
step:1000/5550 val_loss:3.348026 train_time:237409ms step_avg:237.41ms x-lambda: 0.9573988318443298 lambdas: [-0.018015656620264053, -0.02132725715637207, -0.08395839482545853, -0.1700560599565506] skip-layers: [14, 13, 12, 11]
step:1125/5550 val_loss:3.319688 train_time:269047ms step_avg:239.15ms x-lambda: 0.9534882307052612 lambdas: [-0.01964610442519188, -0.024017317220568657, -0.09370826184749603, -0.18998275697231293] skip-layers: [14, 13, 12, 11]
step:1250/5550 val_loss:3.293712 train_time:300845ms step_avg:240.68ms x-lambda: 0.9517830610275269 lambdas: [-0.01773441769182682, -0.02377663366496563, -0.09944821149110794, -0.20420904457569122] skip-layers: [14, 13, 12, 11]
step:1375/5550 val_loss:3.273399 train_time:331700ms step_avg:241.24ms x-lambda: 0.9448832869529724 lambdas: [-0.019706901162862778, -0.0273832269012928, -0.10838072001934052, -0.22004079818725586] skip-layers: [14, 13, 12, 11]
step:1500/5550 val_loss:3.255509 train_time:363650ms step_avg:242.43ms x-lambda: 0.941584050655365 lambdas: [-0.019982483237981796, -0.029682453721761703, -0.11554205417633057, -0.23302845656871796] skip-layers: [14, 13, 12, 11]
step:1625/5550 val_loss:3.236706 train_time:394616ms step_avg:242.84ms x-lambda: 0.9377609491348267 lambdas: [-0.018382718786597252, -0.029401760548353195, -0.1189582422375679, -0.24058353900909424] skip-layers: [14, 13, 12, 11]
step:1750/5550 val_loss:3.221802 train_time:425566ms step_avg:243.18ms x-lambda: 0.9331509470939636 lambdas: [-0.018727239221334457, -0.031067125499248505, -0.1237345039844513, -0.24930475652217865] skip-layers: [14, 13, 12, 11]
step:1875/5550 val_loss:3.204410 train_time:456553ms step_avg:243.49ms x-lambda: 0.9289979934692383 lambdas: [-0.018086867406964302, -0.03218517079949379, -0.12816068530082703, -0.2559139132499695] skip-layers: [14, 13, 12, 11]
step:2000/5550 val_loss:3.187888 train_time:488975ms step_avg:244.49ms x-lambda: 0.9255903959274292 lambdas: [-0.01898624375462532, -0.034640468657016754, -0.13182155787944794, -0.2619606852531433] skip-layers: [14, 13, 12, 11]
step:2125/5550 val_loss:3.173573 train_time:521424ms step_avg:245.38ms x-lambda: 0.9236798286437988 lambdas: [-0.018566474318504333, -0.0355939157307148, -0.13506478071212769, -0.2661862373352051] skip-layers: [14, 13, 12, 11]
step:2250/5550 val_loss:3.159102 train_time:552679ms step_avg:245.64ms x-lambda: 0.9221048355102539 lambdas: [-0.01810857281088829, -0.03689420223236084, -0.13784044981002808, -0.2687607705593109] skip-layers: [14, 13, 12, 11]
step:2375/5550 val_loss:3.147382 train_time:583957ms step_avg:245.88ms x-lambda: 0.9194204807281494 lambdas: [-0.01773792877793312, -0.038366932421922684, -0.1392805129289627, -0.2709499001502991] skip-layers: [14, 13, 12, 11]
step:2500/5550 val_loss:3.135865 train_time:615180ms step_avg:246.07ms x-lambda: 0.9180801510810852 lambdas: [-0.017301445826888084, -0.03957459703087807, -0.1417180746793747, -0.27257582545280457] skip-layers: [14, 13, 12, 11]
step:2625/5550 val_loss:3.124631 train_time:648572ms step_avg:247.07ms x-lambda: 0.9176527857780457 lambdas: [-0.016041861847043037, -0.039926137775182724, -0.14343012869358063, -0.2735161781311035] skip-layers: [14, 13, 12, 11]
step:2750/5550 val_loss:3.113799 train_time:679808ms step_avg:247.20ms x-lambda: 0.9154682755470276 lambdas: [-0.015793485566973686, -0.041460294276475906, -0.1464228332042694, -0.2763291001319885] skip-layers: [14, 13, 12, 11]
step:2875/5550 val_loss:3.104169 train_time:711040ms step_avg:247.32ms x-lambda: 0.9150018095970154 lambdas: [-0.015564155764877796, -0.041912276297807693, -0.14678867161273956, -0.27580389380455017] skip-layers: [14, 13, 12, 11]
step:3000/5550 val_loss:3.092978 train_time:742272ms step_avg:247.42ms x-lambda: 0.9137290716171265 lambdas: [-0.014353104867041111, -0.04352732375264168, -0.14858748018741608, -0.27666351199150085] skip-layers: [14, 13, 12, 11]
step:3125/5550 val_loss:3.081918 train_time:773515ms step_avg:247.52ms x-lambda: 0.9134346842765808 lambdas: [-0.014795704744756222, -0.045380812138319016, -0.15072032809257507, -0.27818572521209717] skip-layers: [14, 13, 12, 11]
step:3250/5550 val_loss:3.070231 train_time:806879ms step_avg:248.27ms x-lambda: 0.914677619934082 lambdas: [-0.013600527308881283, -0.04513297230005264, -0.1506471335887909, -0.27797096967697144] skip-layers: [14, 13, 12, 11]
step:3375/5550 val_loss:3.061786 train_time:840338ms step_avg:248.99ms x-lambda: 0.9155720472335815 lambdas: [-0.013127235695719719, -0.04677891731262207, -0.15255065262317657, -0.27883756160736084] skip-layers: [14, 13, 12, 11]
step:3500/5550 val_loss:3.052846 train_time:872747ms step_avg:249.36ms x-lambda: 0.9163213968276978 lambdas: [-0.012284308671951294, -0.04809197783470154, -0.15436458587646484, -0.2805418372154236] skip-layers: [14, 13, 12, 11]
step:3625/5550 val_loss:3.044086 train_time:904020ms step_avg:249.38ms x-lambda: 0.9189660549163818 lambdas: [-0.010583254508674145, -0.048050496727228165, -0.15519391000270844, -0.2798757255077362] skip-layers: [14, 13, 12, 11]
step:3750/5550 val_loss:3.034837 train_time:935259ms step_avg:249.40ms x-lambda: 0.9197335839271545 lambdas: [-0.009617299772799015, -0.047981712967157364, -0.15552973747253418, -0.2802342176437378] skip-layers: [14, 13, 12, 11]
step:3875/5550 val_loss:3.025939 train_time:967751ms step_avg:249.74ms x-lambda: 0.9231515526771545 lambdas: [-0.0074247270822525024, -0.04797694832086563, -0.15613168478012085, -0.28024494647979736] skip-layers: [14, 13, 12, 11]
step:4000/5550 val_loss:3.016170 train_time:1000180ms step_avg:250.05ms x-lambda: 0.9260435700416565 lambdas: [-0.007325665559619665, -0.0496971532702446, -0.15781043469905853, -0.28086400032043457] skip-layers: [14, 13, 12, 11]
step:4125/5550 val_loss:3.007068 train_time:1032615ms step_avg:250.33ms x-lambda: 0.9294301867485046 lambdas: [-0.0055125500075519085, -0.04994741827249527, -0.15805914998054504, -0.2814391851425171] skip-layers: [14, 13, 12, 11]
step:4250/5550 val_loss:2.998574 train_time:1066197ms step_avg:250.87ms x-lambda: 0.9330771565437317 lambdas: [-0.0036225789226591587, -0.05023133009672165, -0.15969237685203552, -0.28374677896499634] skip-layers: [14, 13, 12, 11]
step:4375/5550 val_loss:2.989576 train_time:1099944ms step_avg:251.42ms x-lambda: 0.9360432624816895 lambdas: [-0.0035762495826929808, -0.05170932412147522, -0.16093841195106506, -0.2842619717121124] skip-layers: [14, 13, 12, 11]
step:4500/5550 val_loss:2.981573 train_time:1131559ms step_avg:251.46ms x-lambda: 0.9404779076576233 lambdas: [-0.0018195963930338621, -0.052234649658203125, -0.16246937215328217, -0.285089910030365] skip-layers: [14, 13, 12, 11]
step:4625/5550 val_loss:2.971755 train_time:1163332ms step_avg:251.53ms x-lambda: 0.9456034302711487 lambdas: [-0.00018905299657490104, -0.052319757640361786, -0.16220848262310028, -0.28398096561431885] skip-layers: [14, 13, 12, 11]
step:4750/5550 val_loss:2.962763 train_time:1195273ms step_avg:251.64ms x-lambda: 0.9509781002998352 lambdas: [0.0011433459585532546, -0.05269572511315346, -0.16317082941532135, -0.284537136554718] skip-layers: [14, 13, 12, 11]
step:4875/5550 val_loss:2.953913 train_time:1228444ms step_avg:251.99ms x-lambda: 0.9553008079528809 lambdas: [0.002734867623075843, -0.05324292182922363, -0.16376900672912598, -0.2861745357513428] skip-layers: [14, 13, 12, 11]
step:5000/5550 val_loss:2.945724 train_time:1261727ms step_avg:252.35ms x-lambda: 0.9610192179679871 lambdas: [0.0035130989272147417, -0.053020939230918884, -0.164556622505188, -0.2866854667663574] skip-layers: [14, 13, 12, 11]
step:5125/5550 val_loss:2.938011 train_time:1294000ms step_avg:252.49ms x-lambda: 0.9651554226875305 lambdas: [0.004485889803618193, -0.053504038602113724, -0.16521809995174408, -0.28770712018013] skip-layers: [14, 13, 12, 11]
step:5250/5550 val_loss:2.930913 train_time:1327544ms step_avg:252.87ms x-lambda: 0.9696485996246338 lambdas: [0.0051412093453109264, -0.05373163893818855, -0.16587592661380768, -0.2875615060329437] skip-layers: [14, 13, 12, 11]
step:5375/5550 val_loss:2.924440 train_time:1361297ms step_avg:253.26ms x-lambda: 0.9740946888923645 lambdas: [0.006338987033814192, -0.05381500720977783, -0.16666212677955627, -0.28821903467178345] skip-layers: [14, 13, 12, 11]
step:5500/5550 val_loss:2.919585 train_time:1395284ms step_avg:253.69ms x-lambda: 0.9770370721817017 lambdas: [0.0072533125057816505, -0.05365542322397232, -0.16693250834941864, -0.2885391116142273] skip-layers: [14, 13, 12, 11]
step:5550/5550 val_loss:2.918405 train_time:1408517ms step_avg:253.79ms x-lambda: 0.9775353670120239 lambdas: [0.007310487795621157, -0.053806014358997345, -0.16709744930267334, -0.28884243965148926] skip-layers: [14, 13, 12, 11]

## 8000-add-skip-multiple-4-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3]
step:125/5550 val_loss:4.268120 train_time:28635ms step_avg:229.08ms x-lambda: 1.1084953546524048 lambdas: [0.0958959236741066, 0.014968270435929298, 0.003728719661012292, 0.003303682431578636] skip-layers: [0, 1, 2, 3]
step:250/5550 val_loss:3.847856 train_time:58642ms step_avg:234.57ms x-lambda: 1.1016042232513428 lambdas: [0.0798792839050293, -0.04140033200383186, -0.06150153651833534, -0.07507205754518509] skip-layers: [0, 1, 2, 3]
step:375/5550 val_loss:3.673652 train_time:87900ms step_avg:234.40ms x-lambda: 1.0632578134536743 lambdas: [0.06569474190473557, -0.0527663417160511, -0.07873266935348511, -0.1088673323392868] skip-layers: [0, 1, 2, 3]
step:500/5550 val_loss:3.556560 train_time:117569ms step_avg:235.14ms x-lambda: 1.0113351345062256 lambdas: [0.05475064739584923, -0.055650494992733, -0.08956920355558395, -0.12782339751720428] skip-layers: [0, 1, 2, 3]
step:625/5550 val_loss:3.478379 train_time:147462ms step_avg:235.94ms x-lambda: 0.9615374803543091 lambdas: [0.05104627087712288, -0.04999628663063049, -0.09189172834157944, -0.12872406840324402] skip-layers: [0, 1, 2, 3]
step:750/5550 val_loss:3.427139 train_time:177609ms step_avg:236.81ms x-lambda: 0.9139321446418762 lambdas: [0.04381340742111206, -0.04814264923334122, -0.09671877324581146, -0.12819555401802063] skip-layers: [0, 1, 2, 3]
step:875/5550 val_loss:3.378213 train_time:207874ms step_avg:237.57ms x-lambda: 0.8698462843894958 lambdas: [0.04125060886144638, -0.041003379970788956, -0.09435738623142242, -0.11939732730388641] skip-layers: [0, 1, 2, 3]
step:1000/5550 val_loss:3.346592 train_time:239587ms step_avg:239.59ms x-lambda: 0.8286334276199341 lambdas: [0.03648926317691803, -0.03755500167608261, -0.09363771229982376, -0.11241143196821213] skip-layers: [0, 1, 2, 3]
step:1125/5550 val_loss:3.315557 train_time:272230ms step_avg:241.98ms x-lambda: 0.7932304739952087 lambdas: [0.0344482883810997, -0.0324782133102417, -0.09183541685342789, -0.1043156087398529] skip-layers: [0, 1, 2, 3]
step:1250/5550 val_loss:3.292992 train_time:302958ms step_avg:242.37ms x-lambda: 0.7656360268592834 lambdas: [0.034088291227817535, -0.028861993923783302, -0.08815880119800568, -0.09691047668457031] skip-layers: [0, 1, 2, 3]
step:1375/5550 val_loss:3.271291 train_time:333843ms step_avg:242.80ms x-lambda: 0.7326552867889404 lambdas: [0.028631556779146194, -0.028160234913229942, -0.08681274950504303, -0.09287494421005249] skip-layers: [0, 1, 2, 3]
step:1500/5550 val_loss:3.253970 train_time:365754ms step_avg:243.84ms x-lambda: 0.7117443680763245 lambdas: [0.0269304271787405, -0.02662496827542782, -0.08466266095638275, -0.08733102679252625] skip-layers: [0, 1, 2, 3]
step:1625/5550 val_loss:3.237025 train_time:396752ms step_avg:244.15ms x-lambda: 0.6899246573448181 lambdas: [0.027746187523007393, -0.021791566163301468, -0.07937049120664597, -0.08105800300836563] skip-layers: [0, 1, 2, 3]
step:1750/5550 val_loss:3.221067 train_time:427726ms step_avg:244.41ms x-lambda: 0.6700146794319153 lambdas: [0.02640758454799652, -0.019825054332613945, -0.07591361552476883, -0.07546942681074142] skip-layers: [0, 1, 2, 3]
step:1875/5550 val_loss:3.201821 train_time:459894ms step_avg:245.28ms x-lambda: 0.6544256806373596 lambdas: [0.024504179134964943, -0.019151506945490837, -0.07338361442089081, -0.0722661167383194] skip-layers: [0, 1, 2, 3]
step:2000/5550 val_loss:3.187563 train_time:491107ms step_avg:245.55ms x-lambda: 0.6400766372680664 lambdas: [0.023808985948562622, -0.017541706562042236, -0.0710398480296135, -0.06872492283582687] skip-layers: [0, 1, 2, 3]
step:2125/5550 val_loss:3.172232 train_time:524498ms step_avg:246.82ms x-lambda: 0.6301204562187195 lambdas: [0.02338700369000435, -0.016622958704829216, -0.06956558674573898, -0.0670844316482544] skip-layers: [0, 1, 2, 3]
step:2250/5550 val_loss:3.158030 train_time:556947ms step_avg:247.53ms x-lambda: 0.6214160323143005 lambdas: [0.023046689108014107, -0.015398849733173847, -0.06552539020776749, -0.06302323192358017] skip-layers: [0, 1, 2, 3]
step:2375/5550 val_loss:3.147118 train_time:588259ms step_avg:247.69ms x-lambda: 0.6122077703475952 lambdas: [0.020861448720097542, -0.015496578998863697, -0.06512320786714554, -0.06167776510119438] skip-layers: [0, 1, 2, 3]
step:2500/5550 val_loss:3.135271 train_time:621587ms step_avg:248.63ms x-lambda: 0.6074655652046204 lambdas: [0.021929757669568062, -0.013032041490077972, -0.062431689351797104, -0.05866724252700806] skip-layers: [0, 1, 2, 3]
step:2625/5550 val_loss:3.123259 train_time:652794ms step_avg:248.68ms x-lambda: 0.6031491756439209 lambdas: [0.020475704222917557, -0.013883359730243683, -0.06200818717479706, -0.057499051094055176] skip-layers: [0, 1, 2, 3]
step:2750/5550 val_loss:3.112705 train_time:683946ms step_avg:248.71ms x-lambda: 0.5994594693183899 lambdas: [0.019954916089773178, -0.013590192422270775, -0.060031142085790634, -0.05601157620549202] skip-layers: [0, 1, 2, 3]
step:2875/5550 val_loss:3.103080 train_time:716367ms step_avg:249.17ms x-lambda: 0.5959159731864929 lambdas: [0.020352445542812347, -0.012062760069966316, -0.0582960769534111, -0.05306911841034889] skip-layers: [0, 1, 2, 3]
step:3000/5550 val_loss:3.092278 train_time:747685ms step_avg:249.23ms x-lambda: 0.59422367811203 lambdas: [0.018645398318767548, -0.012782539241015911, -0.05690532177686691, -0.05200602486729622] skip-layers: [0, 1, 2, 3]
step:3125/5550 val_loss:3.081370 train_time:782268ms step_avg:250.33ms x-lambda: 0.5920597910881042 lambdas: [0.018936768174171448, -0.01313159242272377, -0.05721081793308258, -0.0522032305598259] skip-layers: [0, 1, 2, 3]
step:3250/5550 val_loss:3.070107 train_time:813550ms step_avg:250.32ms x-lambda: 0.5935714840888977 lambdas: [0.01924448274075985, -0.011058155447244644, -0.05493125692009926, -0.0495721735060215] skip-layers: [0, 1, 2, 3]
step:3375/5550 val_loss:3.061660 train_time:844786ms step_avg:250.31ms x-lambda: 0.5937683582305908 lambdas: [0.017753705382347107, -0.011903766542673111, -0.05470071732997894, -0.05015498772263527] skip-layers: [0, 1, 2, 3]
step:3500/5550 val_loss:3.052488 train_time:876077ms step_avg:250.31ms x-lambda: 0.5934227108955383 lambdas: [0.017914902418851852, -0.012006942182779312, -0.05401775613427162, -0.04783624783158302] skip-layers: [0, 1, 2, 3]
step:3625/5550 val_loss:3.043987 train_time:907347ms step_avg:250.30ms x-lambda: 0.5972778797149658 lambdas: [0.01718880608677864, -0.01075869332998991, -0.05333328619599342, -0.047551628202199936] skip-layers: [0, 1, 2, 3]
step:3750/5550 val_loss:3.033999 train_time:939729ms step_avg:250.59ms x-lambda: 0.5965689420700073 lambdas: [0.017730403691530228, -0.009950594045221806, -0.051508355885744095, -0.04559161886572838] skip-layers: [0, 1, 2, 3]
step:3875/5550 val_loss:3.025539 train_time:974394ms step_avg:251.46ms x-lambda: 0.6037991046905518 lambdas: [0.01739523373544216, -0.010161256417632103, -0.05033538490533829, -0.04588455334305763] skip-layers: [0, 1, 2, 3]
step:4000/5550 val_loss:3.016221 train_time:1005691ms step_avg:251.42ms x-lambda: 0.605462372303009 lambdas: [0.01771453395485878, -0.010491053573787212, -0.05092751607298851, -0.04520437866449356] skip-layers: [0, 1, 2, 3]
step:4125/5550 val_loss:3.006884 train_time:1037070ms step_avg:251.41ms x-lambda: 0.6111856698989868 lambdas: [0.018267454579472542, -0.010527309030294418, -0.051031213253736496, -0.045590683817863464] skip-layers: [0, 1, 2, 3]
step:4250/5550 val_loss:2.998608 train_time:1068661ms step_avg:251.45ms x-lambda: 0.6150883436203003 lambdas: [0.017227141186594963, -0.00970106478780508, -0.048746414482593536, -0.04407539591193199] skip-layers: [0, 1, 2, 3]
step:4375/5550 val_loss:2.989455 train_time:1101462ms step_avg:251.76ms x-lambda: 0.6184192895889282 lambdas: [0.017922358587384224, -0.010143902152776718, -0.04967388138175011, -0.04379401355981827] skip-layers: [0, 1, 2, 3]
step:4500/5550 val_loss:2.981335 train_time:1135325ms step_avg:252.29ms x-lambda: 0.6242997646331787 lambdas: [0.01723274402320385, -0.00964831467717886, -0.0492241196334362, -0.04250174015760422] skip-layers: [0, 1, 2, 3]
step:4625/5550 val_loss:2.972050 train_time:1170296ms step_avg:253.04ms x-lambda: 0.6314198970794678 lambdas: [0.015757976099848747, -0.009342332370579243, -0.04770936444401741, -0.04357195273041725] skip-layers: [0, 1, 2, 3]
step:4750/5550 val_loss:2.962763 train_time:1202212ms step_avg:253.10ms x-lambda: 0.6383771300315857 lambdas: [0.0170629620552063, -0.007960936054587364, -0.04796813428401947, -0.04190585017204285] skip-layers: [0, 1, 2, 3]
step:4875/5550 val_loss:2.953824 train_time:1234218ms step_avg:253.17ms x-lambda: 0.644209086894989 lambdas: [0.01672143116593361, -0.008056733757257462, -0.04714639484882355, -0.042157284915447235] skip-layers: [0, 1, 2, 3]
step:5000/5550 val_loss:2.945754 train_time:1267406ms step_avg:253.48ms x-lambda: 0.6519907712936401 lambdas: [0.016228830441832542, -0.008951948955655098, -0.047868214547634125, -0.04221140965819359] skip-layers: [0, 1, 2, 3]
step:5125/5550 val_loss:2.938099 train_time:1299694ms step_avg:253.60ms x-lambda: 0.660229504108429 lambdas: [0.01689022220671177, -0.008054031990468502, -0.04719359427690506, -0.04093974083662033] skip-layers: [0, 1, 2, 3]
step:5250/5550 val_loss:2.931026 train_time:1333260ms step_avg:253.95ms x-lambda: 0.6668869853019714 lambdas: [0.01621248759329319, -0.008276385255157948, -0.047254521399736404, -0.04137658700346947] skip-layers: [0, 1, 2, 3]
step:5375/5550 val_loss:2.924539 train_time:1365850ms step_avg:254.11ms x-lambda: 0.6743927001953125 lambdas: [0.017155639827251434, -0.008913467638194561, -0.04709852114319801, -0.04130043089389801] skip-layers: [0, 1, 2, 3]
step:5500/5550 val_loss:2.919673 train_time:1398673ms step_avg:254.30ms x-lambda: 0.680705726146698 lambdas: [0.01670757308602333, -0.008940319530665874, -0.047018151730298996, -0.04087242856621742] skip-layers: [0, 1, 2, 3]
step:5550/5550 val_loss:2.918516 train_time:1411922ms step_avg:254.40ms x-lambda: 0.6818865537643433 lambdas: [0.016545074060559273, -0.008759411983191967, -0.04698120430111885, -0.041054617613554] skip-layers: [0, 1, 2, 3]

## 8000-add-skip-multiple-4-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [3, 5, 6, 11]
step:125/5550 val_loss:4.259625 train_time:28927ms step_avg:231.42ms x-lambda: 1.0882768630981445 lambdas: [0.0024556685239076614, 0.008192239329218864, 0.025233177468180656, 0.06931179761886597] skip-layers: [3, 5, 6, 11]
step:250/5550 val_loss:3.854371 train_time:57967ms step_avg:231.87ms x-lambda: 1.0561505556106567 lambdas: [-0.011224573478102684, -0.009080905467271805, -0.013869939371943474, 0.0088186739012599] skip-layers: [3, 5, 6, 11]
step:375/5550 val_loss:3.680265 train_time:87433ms step_avg:233.15ms x-lambda: 0.99802565574646 lambdas: [-0.008747505955398083, -0.010850892402231693, -0.015542438253760338, -0.01878371089696884] skip-layers: [3, 5, 6, 11]
step:500/5550 val_loss:3.563729 train_time:117319ms step_avg:234.64ms x-lambda: 0.9375501871109009 lambdas: [-0.010598570108413696, -0.014271490275859833, -0.0180185716599226, -0.026417944580316544] skip-layers: [3, 5, 6, 11]
step:625/5550 val_loss:3.486396 train_time:147387ms step_avg:235.82ms x-lambda: 0.8878584504127502 lambdas: [-0.00855786819010973, -0.01106999721378088, -0.01631774567067623, -0.025507796555757523] skip-layers: [3, 5, 6, 11]
step:750/5550 val_loss:3.431621 train_time:177753ms step_avg:237.00ms x-lambda: 0.8461715579032898 lambdas: [-0.009205786511301994, -0.012256484478712082, -0.015627624467015266, -0.025489643216133118] skip-layers: [3, 5, 6, 11]
step:875/5550 val_loss:3.386072 train_time:208229ms step_avg:237.98ms x-lambda: 0.8069354295730591 lambdas: [-0.008084219880402088, -0.011759192682802677, -0.013802220113575459, -0.023359743878245354] skip-layers: [3, 5, 6, 11]
step:1000/5550 val_loss:3.352139 train_time:238915ms step_avg:238.92ms x-lambda: 0.7729333639144897 lambdas: [-0.009899374097585678, -0.012545481324195862, -0.01569516584277153, -0.022826673462986946] skip-layers: [3, 5, 6, 11]
step:1125/5550 val_loss:3.321753 train_time:269661ms step_avg:239.70ms x-lambda: 0.7447378635406494 lambdas: [-0.009756281971931458, -0.011888455599546432, -0.014555027708411217, -0.021231602877378464] skip-layers: [3, 5, 6, 11]
step:1250/5550 val_loss:3.297454 train_time:301266ms step_avg:241.01ms x-lambda: 0.7227818369865417 lambdas: [-0.007246605586260557, -0.008732398971915245, -0.011529898270964622, -0.017770331352949142] skip-layers: [3, 5, 6, 11]
step:1375/5550 val_loss:3.274349 train_time:333080ms step_avg:242.24ms x-lambda: 0.6985822319984436 lambdas: [-0.008166631683707237, -0.009943836368620396, -0.012005612254142761, -0.017179938033223152] skip-layers: [3, 5, 6, 11]
step:1500/5550 val_loss:3.255481 train_time:364125ms step_avg:242.75ms x-lambda: 0.6808270215988159 lambdas: [-0.006811321713030338, -0.009399555623531342, -0.011049645952880383, -0.015258497558534145] skip-layers: [3, 5, 6, 11]
step:1625/5550 val_loss:3.240881 train_time:396389ms step_avg:243.93ms x-lambda: 0.6612384915351868 lambdas: [-0.00698742875829339, -0.009592162445187569, -0.010759002529084682, -0.016617290675640106] skip-layers: [3, 5, 6, 11]
step:1750/5550 val_loss:3.223922 train_time:428590ms step_avg:244.91ms x-lambda: 0.6448677182197571 lambdas: [-0.0068630618043243885, -0.009061915799975395, -0.009790413081645966, -0.014796077273786068] skip-layers: [3, 5, 6, 11]
step:1875/5550 val_loss:3.206188 train_time:460758ms step_avg:245.74ms x-lambda: 0.635761022567749 lambdas: [-0.006765998899936676, -0.007128954865038395, -0.00778790470212698, -0.013139058835804462] skip-layers: [3, 5, 6, 11]
step:2000/5550 val_loss:3.191467 train_time:492079ms step_avg:246.04ms x-lambda: 0.6218641996383667 lambdas: [-0.008019674569368362, -0.010994261130690575, -0.010981819592416286, -0.014755398035049438] skip-layers: [3, 5, 6, 11]
step:2125/5550 val_loss:3.175738 train_time:523426ms step_avg:246.32ms x-lambda: 0.6155751347541809 lambdas: [-0.006819076370447874, -0.008770192041993141, -0.009904328733682632, -0.013970337808132172] skip-layers: [3, 5, 6, 11]
step:2250/5550 val_loss:3.161850 train_time:557734ms step_avg:247.88ms x-lambda: 0.6088102459907532 lambdas: [-0.006655407603830099, -0.00824735313653946, -0.009088277816772461, -0.013429036363959312] skip-layers: [3, 5, 6, 11]
step:2375/5550 val_loss:3.149905 train_time:591336ms step_avg:248.98ms x-lambda: 0.603335440158844 lambdas: [-0.006286649964749813, -0.007321685552597046, -0.008794174529612064, -0.0119149349629879] skip-layers: [3, 5, 6, 11]
step:2500/5550 val_loss:3.139328 train_time:625943ms step_avg:250.38ms x-lambda: 0.5979097485542297 lambdas: [-0.005387180019170046, -0.0068252356722950935, -0.007218752522021532, -0.011895593255758286] skip-layers: [3, 5, 6, 11]
step:2625/5550 val_loss:3.127081 train_time:657268ms step_avg:250.39ms x-lambda: 0.5948776006698608 lambdas: [-0.006959254387766123, -0.008573039434850216, -0.009378273971378803, -0.012251386418938637] skip-layers: [3, 5, 6, 11]
step:2750/5550 val_loss:3.116237 train_time:688623ms step_avg:250.41ms x-lambda: 0.5926141738891602 lambdas: [-0.005153078585863113, -0.007069170009344816, -0.007984193041920662, -0.011714591644704342] skip-layers: [3, 5, 6, 11]
step:2875/5550 val_loss:3.106215 train_time:720005ms step_avg:250.44ms x-lambda: 0.5912557244300842 lambdas: [-0.005736681167036295, -0.006842272821813822, -0.007393457926809788, -0.010994493961334229] skip-layers: [3, 5, 6, 11]
step:3000/5550 val_loss:3.095356 train_time:754697ms step_avg:251.57ms x-lambda: 0.5906875133514404 lambdas: [-0.005206333007663488, -0.005792325362563133, -0.007596250157803297, -0.011310282163321972] skip-layers: [3, 5, 6, 11]
step:3125/5550 val_loss:3.084675 train_time:786103ms step_avg:251.55ms x-lambda: 0.5883667469024658 lambdas: [-0.00476135965436697, -0.007145094685256481, -0.008094131015241146, -0.010933893732726574] skip-layers: [3, 5, 6, 11]
step:3250/5550 val_loss:3.073217 train_time:822971ms step_avg:253.22ms x-lambda: 0.592255711555481 lambdas: [-0.004323398228734732, -0.006688818335533142, -0.006952921859920025, -0.009792556054890156] skip-layers: [3, 5, 6, 11]
step:3375/5550 val_loss:3.065147 train_time:855394ms step_avg:253.45ms x-lambda: 0.5914050936698914 lambdas: [-0.004903994966298342, -0.007320736069232225, -0.007328685838729143, -0.009932274930179119] skip-layers: [3, 5, 6, 11]
step:3500/5550 val_loss:3.055842 train_time:887658ms step_avg:253.62ms x-lambda: 0.5925696492195129 lambdas: [-0.006118197925388813, -0.006771284155547619, -0.007390022277832031, -0.01035474892705679] skip-layers: [3, 5, 6, 11]
step:3625/5550 val_loss:3.046685 train_time:921156ms step_avg:254.11ms x-lambda: 0.5968548059463501 lambdas: [-0.004830691963434219, -0.005827176850289106, -0.006478569004684687, -0.009103692136704922] skip-layers: [3, 5, 6, 11]
step:3750/5550 val_loss:3.037172 train_time:952530ms step_avg:254.01ms x-lambda: 0.596219003200531 lambdas: [-0.004186362028121948, -0.006010926328599453, -0.006626887712627649, -0.009215114638209343] skip-layers: [3, 5, 6, 11]
step:3875/5550 val_loss:3.027933 train_time:985157ms step_avg:254.23ms x-lambda: 0.6037755608558655 lambdas: [-0.004236496053636074, -0.006118117831647396, -0.006891705095767975, -0.009653463959693909] skip-layers: [3, 5, 6, 11]
step:4000/5550 val_loss:3.018501 train_time:1017582ms step_avg:254.40ms x-lambda: 0.6080885529518127 lambdas: [-0.004018755163997412, -0.0050987787544727325, -0.005319186020642519, -0.00828279834240675] skip-layers: [3, 5, 6, 11]
step:4125/5550 val_loss:3.009754 train_time:1050164ms step_avg:254.59ms x-lambda: 0.6137257218360901 lambdas: [-0.0040474021807312965, -0.005430832039564848, -0.005591056775301695, -0.007959538139402866] skip-layers: [3, 5, 6, 11]
step:4250/5550 val_loss:3.001090 train_time:1081801ms step_avg:254.54ms x-lambda: 0.6185572743415833 lambdas: [-0.0046747056767344475, -0.005148863419890404, -0.006219214294105768, -0.008990351110696793] skip-layers: [3, 5, 6, 11]
step:4375/5550 val_loss:2.991922 train_time:1113503ms step_avg:254.52ms x-lambda: 0.621112585067749 lambdas: [-0.005648478865623474, -0.006125331856310368, -0.0072772991843521595, -0.009153475053608418] skip-layers: [3, 5, 6, 11]
step:4500/5550 val_loss:2.984012 train_time:1146327ms step_avg:254.74ms x-lambda: 0.6272560358047485 lambdas: [-0.003638287540525198, -0.006749470718204975, -0.006510596256703138, -0.009112553671002388] skip-layers: [3, 5, 6, 11]
step:4625/5550 val_loss:2.974297 train_time:1181692ms step_avg:255.50ms x-lambda: 0.6362882256507874 lambdas: [-0.004302620887756348, -0.005441281478852034, -0.006394015625119209, -0.008507070131599903] skip-layers: [3, 5, 6, 11]
step:4750/5550 val_loss:2.965080 train_time:1214784ms step_avg:255.74ms x-lambda: 0.6433023810386658 lambdas: [-0.004005608148872852, -0.005068913102149963, -0.005111861974000931, -0.0089342650026083] skip-layers: [3, 5, 6, 11]
step:4875/5550 val_loss:2.956116 train_time:1246974ms step_avg:255.79ms x-lambda: 0.6496587991714478 lambdas: [-0.004048679489642382, -0.005453132092952728, -0.006028274539858103, -0.008432013913989067] skip-layers: [3, 5, 6, 11]
step:5000/5550 val_loss:2.947813 train_time:1280278ms step_avg:256.06ms x-lambda: 0.6586260199546814 lambdas: [-0.004400379024446011, -0.005774662829935551, -0.005140988156199455, -0.008818927221000195] skip-layers: [3, 5, 6, 11]
step:5125/5550 val_loss:2.940235 train_time:1312628ms step_avg:256.12ms x-lambda: 0.666801929473877 lambdas: [-0.004457623697817326, -0.004986715968698263, -0.0059606279246509075, -0.008143861778080463] skip-layers: [3, 5, 6, 11]
step:5250/5550 val_loss:2.933086 train_time:1346244ms step_avg:256.43ms x-lambda: 0.6727862358093262 lambdas: [-0.00424590427428484, -0.005428980104625225, -0.00644349493086338, -0.0074677844531834126] skip-layers: [3, 5, 6, 11]
step:5375/5550 val_loss:2.926733 train_time:1379979ms step_avg:256.74ms x-lambda: 0.6818122267723083 lambdas: [-0.0041850898414850235, -0.004702853038907051, -0.005619548726826906, -0.008431000635027885] skip-layers: [3, 5, 6, 11]
step:5500/5550 val_loss:2.921939 train_time:1412905ms step_avg:256.89ms x-lambda: 0.688137412071228 lambdas: [-0.004318923689424992, -0.005500448867678642, -0.006039439234882593, -0.008154389448463917] skip-layers: [3, 5, 6, 11]
step:5550/5550 val_loss:2.920759 train_time:1426146ms step_avg:256.96ms x-lambda: 0.6889890432357788 lambdas: [-0.004293006379157305, -0.005617890041321516, -0.0062638698145747185, -0.008065427653491497] skip-layers: [3, 5, 6, 11]

## 8000-add-skip-multiple-4-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14]
step:125/5550 val_loss:4.268082 train_time:28643ms step_avg:229.14ms x-lambda: 1.0584660768508911 lambdas: [0.03310512378811836, 0.008362345397472382, 0.06199543550610542, 0.0511980801820755] skip-layers: [1, 2, 7, 14]
step:250/5550 val_loss:3.854198 train_time:57427ms step_avg:229.71ms x-lambda: 1.0204405784606934 lambdas: [-0.01670580357313156, -0.06251995265483856, 0.056187137961387634, 0.030307579785585403] skip-layers: [1, 2, 7, 14]
step:375/5550 val_loss:3.678445 train_time:86619ms step_avg:230.98ms x-lambda: 0.9849180579185486 lambdas: [-0.02889513224363327, -0.09669562429189682, 0.032477688044309616, 0.01247705053538084] skip-layers: [1, 2, 7, 14]
step:500/5550 val_loss:3.563190 train_time:116270ms step_avg:232.54ms x-lambda: 0.9546724557876587 lambdas: [-0.03166523575782776, -0.11873625218868256, 0.01466770563274622, -0.008406700566411018] skip-layers: [1, 2, 7, 14]
step:625/5550 val_loss:3.482645 train_time:146147ms step_avg:233.84ms x-lambda: 0.9280619621276855 lambdas: [-0.027427151799201965, -0.13014580309391022, 0.0058783600106835365, -0.02723989076912403] skip-layers: [1, 2, 7, 14]
step:750/5550 val_loss:3.432330 train_time:176304ms step_avg:235.07ms x-lambda: 0.9038954377174377 lambdas: [-0.02528052218258381, -0.1390930414199829, -0.0015586446970701218, -0.044782642275094986] skip-layers: [1, 2, 7, 14]
step:875/5550 val_loss:3.385022 train_time:206596ms step_avg:236.11ms x-lambda: 0.8788577914237976 lambdas: [-0.020387077704072, -0.1413893848657608, -0.005249476991593838, -0.06136289983987808] skip-layers: [1, 2, 7, 14]
step:1000/5550 val_loss:3.349957 train_time:238284ms step_avg:238.28ms x-lambda: 0.8589152693748474 lambdas: [-0.01435144990682602, -0.13835376501083374, -0.006515195593237877, -0.0733550488948822] skip-layers: [1, 2, 7, 14]
step:1125/5550 val_loss:3.319967 train_time:268900ms step_avg:239.02ms x-lambda: 0.8384868502616882 lambdas: [-0.013224251568317413, -0.13706566393375397, -0.010176141746342182, -0.08710198849439621] skip-layers: [1, 2, 7, 14]
step:1250/5550 val_loss:3.295357 train_time:300825ms step_avg:240.66ms x-lambda: 0.8252725601196289 lambdas: [-0.009024152532219887, -0.13194729387760162, -0.010041230358183384, -0.09612242877483368] skip-layers: [1, 2, 7, 14]
step:1375/5550 val_loss:3.274131 train_time:331691ms step_avg:241.23ms x-lambda: 0.8067691326141357 lambdas: [-0.008715955540537834, -0.12935347855091095, -0.014398230239748955, -0.10674997419118881] skip-layers: [1, 2, 7, 14]
step:1500/5550 val_loss:3.254319 train_time:362533ms step_avg:241.69ms x-lambda: 0.7958005666732788 lambdas: [-0.005210853181779385, -0.12339984625577927, -0.01384607795625925, -0.11262352764606476] skip-layers: [1, 2, 7, 14]
step:1625/5550 val_loss:3.239376 train_time:394621ms step_avg:242.84ms x-lambda: 0.7794979214668274 lambdas: [-0.005312541499733925, -0.12076670676469803, -0.014518051408231258, -0.12112219631671906] skip-layers: [1, 2, 7, 14]
step:1750/5550 val_loss:3.223155 train_time:425596ms step_avg:243.20ms x-lambda: 0.7680928111076355 lambdas: [-0.0024114518892019987, -0.11338704079389572, -0.013623341917991638, -0.12654627859592438] skip-layers: [1, 2, 7, 14]
step:1875/5550 val_loss:3.205174 train_time:457751ms step_avg:244.13ms x-lambda: 0.7615606784820557 lambdas: [-0.0017933649942278862, -0.10911218822002411, -0.013695615343749523, -0.13055309653282166] skip-layers: [1, 2, 7, 14]
step:2000/5550 val_loss:3.188650 train_time:490194ms step_avg:245.10ms x-lambda: 0.7494889497756958 lambdas: [-0.002384953200817108, -0.10648620873689651, -0.015678631141781807, -0.13740693032741547] skip-layers: [1, 2, 7, 14]
step:2125/5550 val_loss:3.174362 train_time:522596ms step_avg:245.93ms x-lambda: 0.7442516088485718 lambdas: [-0.0017256017308682203, -0.10347329080104828, -0.015801485627889633, -0.14015385508537292] skip-layers: [1, 2, 7, 14]
step:2250/5550 val_loss:3.160067 train_time:557106ms step_avg:247.60ms x-lambda: 0.740388810634613 lambdas: [-0.001474401680752635, -0.10005796700716019, -0.016561435535550117, -0.14447849988937378] skip-layers: [1, 2, 7, 14]
step:2375/5550 val_loss:3.148040 train_time:589553ms step_avg:248.23ms x-lambda: 0.7351070046424866 lambdas: [-0.0002617100835777819, -0.0971054956316948, -0.016939816996455193, -0.14697392284870148] skip-layers: [1, 2, 7, 14]
step:2500/5550 val_loss:3.136673 train_time:621931ms step_avg:248.77ms x-lambda: 0.7333997488021851 lambdas: [-6.225908873602748e-05, -0.09365846961736679, -0.017315225675702095, -0.14912493526935577] skip-layers: [1, 2, 7, 14]
step:2625/5550 val_loss:3.125156 train_time:653164ms step_avg:248.82ms x-lambda: 0.7300125360488892 lambdas: [0.0005270621040835977, -0.09190592914819717, -0.017051421105861664, -0.15137402713298798] skip-layers: [1, 2, 7, 14]
step:2750/5550 val_loss:3.114031 train_time:684406ms step_avg:248.87ms x-lambda: 0.7288746237754822 lambdas: [0.0007048011175356805, -0.0901128426194191, -0.016992514953017235, -0.1541796624660492] skip-layers: [1, 2, 7, 14]
step:2875/5550 val_loss:3.104190 train_time:717819ms step_avg:249.68ms x-lambda: 0.7291343212127686 lambdas: [0.0005652479594573379, -0.08565861731767654, -0.018053535372018814, -0.15610149502754211] skip-layers: [1, 2, 7, 14]
step:3000/5550 val_loss:3.093164 train_time:750217ms step_avg:250.07ms x-lambda: 0.7285937070846558 lambdas: [0.00023081491235643625, -0.08634842187166214, -0.018492305651307106, -0.15832433104515076] skip-layers: [1, 2, 7, 14]
step:3125/5550 val_loss:3.082752 train_time:781473ms step_avg:250.07ms x-lambda: 0.7281774878501892 lambdas: [0.0006866400362923741, -0.08437883853912354, -0.019528113305568695, -0.16234245896339417] skip-layers: [1, 2, 7, 14]
step:3250/5550 val_loss:3.071389 train_time:812708ms step_avg:250.06ms x-lambda: 0.7309076189994812 lambdas: [0.0013336425181478262, -0.08198805153369904, -0.01857227459549904, -0.16266101598739624] skip-layers: [1, 2, 7, 14]
step:3375/5550 val_loss:3.063298 train_time:846058ms step_avg:250.68ms x-lambda: 0.7322050929069519 lambdas: [0.00032050604932010174, -0.08271973580121994, -0.019520441070199013, -0.1668936014175415] skip-layers: [1, 2, 7, 14]
step:3500/5550 val_loss:3.054389 train_time:877361ms step_avg:250.67ms x-lambda: 0.734308660030365 lambdas: [-2.325093373656273e-05, -0.0812678262591362, -0.019876038655638695, -0.169056236743927] skip-layers: [1, 2, 7, 14]
step:3625/5550 val_loss:3.045259 train_time:908633ms step_avg:250.66ms x-lambda: 0.7392320036888123 lambdas: [0.0008815524051897228, -0.07917062193155289, -0.0199396051466465, -0.16930003464221954] skip-layers: [1, 2, 7, 14]
step:3750/5550 val_loss:3.035358 train_time:940901ms step_avg:250.91ms x-lambda: 0.7421119809150696 lambdas: [0.0013201299589127302, -0.0773572027683258, -0.01911761611700058, -0.17278645932674408] skip-layers: [1, 2, 7, 14]
step:3875/5550 val_loss:3.026567 train_time:972210ms step_avg:250.89ms x-lambda: 0.7489216923713684 lambdas: [0.0010624545393511653, -0.07668730616569519, -0.02049192786216736, -0.1748104840517044] skip-layers: [1, 2, 7, 14]
step:4000/5550 val_loss:3.017170 train_time:1003525ms step_avg:250.88ms x-lambda: 0.7552423477172852 lambdas: [0.0013885193038731813, -0.07552158087491989, -0.020069491118192673, -0.17777135968208313] skip-layers: [1, 2, 7, 14]
step:4125/5550 val_loss:3.008195 train_time:1034868ms step_avg:250.88ms x-lambda: 0.7611814141273499 lambdas: [0.0016604221891611814, -0.07547448575496674, -0.02032609097659588, -0.18066522479057312] skip-layers: [1, 2, 7, 14]
step:4250/5550 val_loss:2.999575 train_time:1066445ms step_avg:250.93ms x-lambda: 0.7683151364326477 lambdas: [0.0019035600125789642, -0.0740218460559845, -0.020772390067577362, -0.18259263038635254] skip-layers: [1, 2, 7, 14]
step:4375/5550 val_loss:2.990376 train_time:1098029ms step_avg:250.98ms x-lambda: 0.7726355791091919 lambdas: [0.0006780013209208846, -0.07444340735673904, -0.02085920237004757, -0.18680904805660248] skip-layers: [1, 2, 7, 14]
step:4500/5550 val_loss:2.982345 train_time:1131981ms step_avg:251.55ms x-lambda: 0.7804512977600098 lambdas: [0.0015099769225344062, -0.07279989868402481, -0.021772507578134537, -0.18882673978805542] skip-layers: [1, 2, 7, 14]
step:4625/5550 val_loss:2.973006 train_time:1165905ms step_avg:252.09ms x-lambda: 0.7903685569763184 lambdas: [0.000847492425236851, -0.07308317720890045, -0.02343258447945118, -0.19006161391735077] skip-layers: [1, 2, 7, 14]
step:4750/5550 val_loss:2.963511 train_time:1197877ms step_avg:252.18ms x-lambda: 0.7965825796127319 lambdas: [0.0019224408315494657, -0.07234702259302139, -0.020921118557453156, -0.19216397404670715] skip-layers: [1, 2, 7, 14]
step:4875/5550 val_loss:2.954779 train_time:1231009ms step_avg:252.51ms x-lambda: 0.803902804851532 lambdas: [0.0014974011573940516, -0.0724436491727829, -0.021882612258195877, -0.19481001794338226] skip-layers: [1, 2, 7, 14]
step:5000/5550 val_loss:2.946423 train_time:1265325ms step_avg:253.06ms x-lambda: 0.8130961060523987 lambdas: [0.0019264204893261194, -0.07138203084468842, -0.0221745353192091, -0.19754986464977264] skip-layers: [1, 2, 7, 14]
step:5125/5550 val_loss:2.938834 train_time:1298827ms step_avg:253.43ms x-lambda: 0.8208680748939514 lambdas: [0.0022117258049547672, -0.0704779103398323, -0.022022012621164322, -0.1984422206878662] skip-layers: [1, 2, 7, 14]
step:5250/5550 val_loss:2.931577 train_time:1331336ms step_avg:253.59ms x-lambda: 0.8280312418937683 lambdas: [0.0017980090342462063, -0.06920665502548218, -0.02264297567307949, -0.20008787512779236] skip-layers: [1, 2, 7, 14]
step:5375/5550 val_loss:2.925110 train_time:1363944ms step_avg:253.76ms x-lambda: 0.8359595537185669 lambdas: [0.001178403734229505, -0.06949848681688309, -0.02313232608139515, -0.20078164339065552] skip-layers: [1, 2, 7, 14]
step:5500/5550 val_loss:2.920264 train_time:1396808ms step_avg:253.97ms x-lambda: 0.8412323594093323 lambdas: [0.0013795646373182535, -0.0696856826543808, -0.02274530939757824, -0.2010376900434494] skip-layers: [1, 2, 7, 14]
step:5550/5550 val_loss:2.919125 train_time:1410052ms step_avg:254.06ms x-lambda: 0.8420391082763672 lambdas: [0.001353160128928721, -0.06982698291540146, -0.022944828495383263, -0.201232448220253] skip-layers: [1, 2, 7, 14]

## 8000-add-skip-multiple-5-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.32ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9]
step:125/5550 val_loss:4.262244 train_time:28701ms step_avg:229.61ms x-lambda: 1.0295835733413696 lambdas: [0.03586205840110779, 0.04287983477115631, 0.03067583590745926, 0.07163266092538834, 0.03108026459813118] skip-layers: [11, 10, 8, 4, 9]
step:250/5550 val_loss:3.858093 train_time:57571ms step_avg:230.28ms x-lambda: 1.017382025718689 lambdas: [0.01693108305335045, 0.02567400597035885, 0.0008232876425608993, 0.0800708681344986, -0.017799613997340202] skip-layers: [11, 10, 8, 4, 9]
step:375/5550 val_loss:3.675654 train_time:86859ms step_avg:231.62ms x-lambda: 1.027439832687378 lambdas: [0.00035171268973499537, -0.01516981516033411, -0.009136931970715523, 0.04121746867895126, -0.06693542003631592] skip-layers: [11, 10, 8, 4, 9]
step:500/5550 val_loss:3.562229 train_time:117605ms step_avg:235.21ms x-lambda: 1.0226880311965942 lambdas: [-0.014893871732056141, -0.052721861749887466, -0.008142128586769104, 0.008035850711166859, -0.0998738557100296] skip-layers: [11, 10, 8, 4, 9]
step:625/5550 val_loss:3.481192 train_time:147518ms step_avg:236.03ms x-lambda: 1.0157318115234375 lambdas: [-0.026136821135878563, -0.0817183330655098, 0.001588788814842701, -0.012552792206406593, -0.11808957904577255] skip-layers: [11, 10, 8, 4, 9]
step:750/5550 val_loss:3.428587 train_time:178877ms step_avg:238.50ms x-lambda: 1.0021555423736572 lambdas: [-0.03848207741975784, -0.10819465667009354, 0.004594533238559961, -0.027291296049952507, -0.12959440052509308] skip-layers: [11, 10, 8, 4, 9]
step:875/5550 val_loss:3.382618 train_time:210273ms step_avg:240.31ms x-lambda: 0.9871076345443726 lambdas: [-0.04675346612930298, -0.12689916789531708, 0.01142595149576664, -0.03238142281770706, -0.1306941658258438] skip-layers: [11, 10, 8, 4, 9]
step:1000/5550 val_loss:3.347365 train_time:240854ms step_avg:240.85ms x-lambda: 0.967798113822937 lambdas: [-0.057943955063819885, -0.1446555256843567, 0.01318043377250433, -0.03506343811750412, -0.12773942947387695] skip-layers: [11, 10, 8, 4, 9]
step:1125/5550 val_loss:3.318305 train_time:271493ms step_avg:241.33ms x-lambda: 0.9504174590110779 lambdas: [-0.0654957965016365, -0.16104841232299805, 0.015500812791287899, -0.03562447056174278, -0.12328526377677917] skip-layers: [11, 10, 8, 4, 9]
step:1250/5550 val_loss:3.294055 train_time:302300ms step_avg:241.84ms x-lambda: 0.9342988729476929 lambdas: [-0.07144879549741745, -0.17191915214061737, 0.01796942576766014, -0.03388101980090141, -0.11436046659946442] skip-layers: [11, 10, 8, 4, 9]
step:1375/5550 val_loss:3.271829 train_time:334427ms step_avg:243.22ms x-lambda: 0.9142832159996033 lambdas: [-0.0784829780459404, -0.18336668610572815, 0.01569138467311859, -0.03299650177359581, -0.10835323482751846] skip-layers: [11, 10, 8, 4, 9]
step:1500/5550 val_loss:3.251124 train_time:365421ms step_avg:243.61ms x-lambda: 0.8980357646942139 lambdas: [-0.08417973667383194, -0.1919311285018921, 0.016809780150651932, -0.030900945886969566, -0.10061729699373245] skip-layers: [11, 10, 8, 4, 9]
step:1625/5550 val_loss:3.236740 train_time:396409ms step_avg:243.94ms x-lambda: 0.8817946314811707 lambdas: [-0.08659906685352325, -0.19859282672405243, 0.018728280439972878, -0.02737213857471943, -0.09273034334182739] skip-layers: [11, 10, 8, 4, 9]
step:1750/5550 val_loss:3.219996 train_time:427409ms step_avg:244.23ms x-lambda: 0.8638834357261658 lambdas: [-0.09018568694591522, -0.20520609617233276, 0.017651481553912163, -0.027720872312784195, -0.08653145283460617] skip-layers: [11, 10, 8, 4, 9]
step:1875/5550 val_loss:3.202667 train_time:459627ms step_avg:245.13ms x-lambda: 0.8490186929702759 lambdas: [-0.09259012341499329, -0.2110370397567749, 0.01661129854619503, -0.0266867708414793, -0.08227889239788055] skip-layers: [11, 10, 8, 4, 9]
step:2000/5550 val_loss:3.187290 train_time:490917ms step_avg:245.46ms x-lambda: 0.8365883231163025 lambdas: [-0.09359315782785416, -0.2129342257976532, 0.01750064641237259, -0.023907411843538284, -0.0750957652926445] skip-layers: [11, 10, 8, 4, 9]
step:2125/5550 val_loss:3.171875 train_time:522230ms step_avg:245.76ms x-lambda: 0.8259105086326599 lambdas: [-0.09482713788747787, -0.21663038432598114, 0.01654212921857834, -0.02345173805952072, -0.07206295430660248] skip-layers: [11, 10, 8, 4, 9]
step:2250/5550 val_loss:3.158163 train_time:554656ms step_avg:246.51ms x-lambda: 0.816328763961792 lambdas: [-0.09463144838809967, -0.21782800555229187, 0.015753895044326782, -0.023010486736893654, -0.06865426152944565] skip-layers: [11, 10, 8, 4, 9]
step:2375/5550 val_loss:3.146656 train_time:587029ms step_avg:247.17ms x-lambda: 0.8064632415771484 lambdas: [-0.09584712982177734, -0.21943585574626923, 0.014946780167520046, -0.023109130561351776, -0.064914271235466] skip-layers: [11, 10, 8, 4, 9]
step:2500/5550 val_loss:3.134973 train_time:619414ms step_avg:247.77ms x-lambda: 0.7987090945243835 lambdas: [-0.09495346993207932, -0.21919451653957367, 0.014947771094739437, -0.021621286869049072, -0.062477268278598785] skip-layers: [11, 10, 8, 4, 9]
step:2625/5550 val_loss:3.123710 train_time:652810ms step_avg:248.69ms x-lambda: 0.7908835411071777 lambdas: [-0.0950900986790657, -0.22077110409736633, 0.014983086846768856, -0.022044522687792778, -0.059475336223840714] skip-layers: [11, 10, 8, 4, 9]
step:2750/5550 val_loss:3.112588 train_time:684104ms step_avg:248.76ms x-lambda: 0.7866097092628479 lambdas: [-0.09358061105012894, -0.21934252977371216, 0.015674488618969917, -0.019151980057358742, -0.05534978583455086] skip-layers: [11, 10, 8, 4, 9]
step:2875/5550 val_loss:3.102950 train_time:716423ms step_avg:249.19ms x-lambda: 0.7814438939094543 lambdas: [-0.09220000356435776, -0.21979308128356934, 0.015219894237816334, -0.017796263098716736, -0.053916189819574356] skip-layers: [11, 10, 8, 4, 9]
step:3000/5550 val_loss:3.091998 train_time:749855ms step_avg:249.95ms x-lambda: 0.7763278484344482 lambdas: [-0.0928349643945694, -0.21968583762645721, 0.014262164011597633, -0.019714947789907455, -0.05250374600291252] skip-layers: [11, 10, 8, 4, 9]
step:3125/5550 val_loss:3.080812 train_time:782306ms step_avg:250.34ms x-lambda: 0.7737353444099426 lambdas: [-0.09322106838226318, -0.22031952440738678, 0.013476391322910786, -0.018565461039543152, -0.05186435952782631] skip-layers: [11, 10, 8, 4, 9]
step:3250/5550 val_loss:3.069113 train_time:815741ms step_avg:251.00ms x-lambda: 0.7720016241073608 lambdas: [-0.09139793366193771, -0.21879000961780548, 0.013902531005442142, -0.018516559153795242, -0.05030377209186554] skip-layers: [11, 10, 8, 4, 9]
step:3375/5550 val_loss:3.061440 train_time:847027ms step_avg:250.97ms x-lambda: 0.7707503437995911 lambdas: [-0.09119594842195511, -0.21993017196655273, 0.01236665528267622, -0.01905267871916294, -0.04929577559232712] skip-layers: [11, 10, 8, 4, 9]
step:3500/5550 val_loss:3.052042 train_time:880398ms step_avg:251.54ms x-lambda: 0.7681490182876587 lambdas: [-0.09258635342121124, -0.2185567170381546, 0.013544077053666115, -0.019228937104344368, -0.04799232259392738] skip-layers: [11, 10, 8, 4, 9]
step:3625/5550 val_loss:3.042769 train_time:911730ms step_avg:251.51ms x-lambda: 0.7676158547401428 lambdas: [-0.09145250916481018, -0.21750515699386597, 0.013057887554168701, -0.018612567335367203, -0.04633843153715134] skip-layers: [11, 10, 8, 4, 9]
step:3750/5550 val_loss:3.033571 train_time:943024ms step_avg:251.47ms x-lambda: 0.7684771418571472 lambdas: [-0.0910499319434166, -0.21757371723651886, 0.013686315156519413, -0.018656564876437187, -0.04463792219758034] skip-layers: [11, 10, 8, 4, 9]
step:3875/5550 val_loss:3.024648 train_time:974403ms step_avg:251.46ms x-lambda: 0.7715029716491699 lambdas: [-0.09010303020477295, -0.21932247281074524, 0.01242585014551878, -0.01767406053841114, -0.04392118379473686] skip-layers: [11, 10, 8, 4, 9]
step:4000/5550 val_loss:3.015140 train_time:1009069ms step_avg:252.27ms x-lambda: 0.7734888792037964 lambdas: [-0.0893855094909668, -0.21862894296646118, 0.013139749877154827, -0.01766388677060604, -0.04451696574687958] skip-layers: [11, 10, 8, 4, 9]
step:4125/5550 val_loss:3.005743 train_time:1041583ms step_avg:252.51ms x-lambda: 0.77479487657547 lambdas: [-0.08963426202535629, -0.21859660744667053, 0.012515037320554256, -0.017369680106639862, -0.04216081649065018] skip-layers: [11, 10, 8, 4, 9]
step:4250/5550 val_loss:2.997760 train_time:1073225ms step_avg:252.52ms x-lambda: 0.7773392796516418 lambdas: [-0.08809321373701096, -0.21843396127223969, 0.012207573279738426, -0.0171988345682621, -0.042545534670352936] skip-layers: [11, 10, 8, 4, 9]
step:4375/5550 val_loss:2.988493 train_time:1107086ms step_avg:253.05ms x-lambda: 0.7791227698326111 lambdas: [-0.08989576250314713, -0.2199392020702362, 0.011629772372543812, -0.017191903665661812, -0.043371327221393585] skip-layers: [11, 10, 8, 4, 9]
step:4500/5550 val_loss:2.980341 train_time:1138756ms step_avg:253.06ms x-lambda: 0.7845807671546936 lambdas: [-0.08951732516288757, -0.21888256072998047, 0.011253785341978073, -0.01757144369184971, -0.04213975742459297] skip-layers: [11, 10, 8, 4, 9]
step:4625/5550 val_loss:2.970983 train_time:1170553ms step_avg:253.09ms x-lambda: 0.7899633646011353 lambdas: [-0.08962121605873108, -0.21958959102630615, 0.010959410108625889, -0.01914176717400551, -0.040526267141103745] skip-layers: [11, 10, 8, 4, 9]
step:4750/5550 val_loss:2.961814 train_time:1202488ms step_avg:253.16ms x-lambda: 0.7941770553588867 lambdas: [-0.08839516341686249, -0.21956199407577515, 0.012300335802137852, -0.016714878380298615, -0.041107676923274994] skip-layers: [11, 10, 8, 4, 9]
step:4875/5550 val_loss:2.952728 train_time:1235585ms step_avg:253.45ms x-lambda: 0.7990366220474243 lambdas: [-0.08786098659038544, -0.2207917422056198, 0.010999496094882488, -0.01659330353140831, -0.041259896010160446] skip-layers: [11, 10, 8, 4, 9]
step:5000/5550 val_loss:2.944696 train_time:1267804ms step_avg:253.56ms x-lambda: 0.8051172494888306 lambdas: [-0.08809593319892883, -0.22225110232830048, 0.010513361543416977, -0.01698828861117363, -0.041563063859939575] skip-layers: [11, 10, 8, 4, 9]
step:5125/5550 val_loss:2.937110 train_time:1300157ms step_avg:253.69ms x-lambda: 0.8107547163963318 lambdas: [-0.08765316754579544, -0.22277860343456268, 0.010905012488365173, -0.01710999570786953, -0.04118506610393524] skip-layers: [11, 10, 8, 4, 9]
step:5250/5550 val_loss:2.929931 train_time:1332701ms step_avg:253.85ms x-lambda: 0.8143563270568848 lambdas: [-0.08778322488069534, -0.22240455448627472, 0.009528744965791702, -0.016686752438545227, -0.040350332856178284] skip-layers: [11, 10, 8, 4, 9]
step:5375/5550 val_loss:2.923515 train_time:1365346ms step_avg:254.02ms x-lambda: 0.8200239539146423 lambdas: [-0.08756736665964127, -0.22344611585140228, 0.009551186114549637, -0.01655414141714573, -0.04114064201712608] skip-layers: [11, 10, 8, 4, 9]
step:5500/5550 val_loss:2.918711 train_time:1399315ms step_avg:254.42ms x-lambda: 0.8230002522468567 lambdas: [-0.08706342428922653, -0.22417287528514862, 0.009530719369649887, -0.01654822751879692, -0.040646959096193314] skip-layers: [11, 10, 8, 4, 9]
step:5550/5550 val_loss:2.917571 train_time:1412560ms step_avg:254.52ms x-lambda: 0.8236949443817139 lambdas: [-0.08721575140953064, -0.2243674099445343, 0.009520018473267555, -0.01671561412513256, -0.04097339138388634] skip-layers: [11, 10, 8, 4, 9]

## 8000-add-skip-multiple-5-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.16ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10]
step:125/5550 val_loss:4.267007 train_time:29809ms step_avg:238.47ms x-lambda: 1.0351482629776 lambdas: [0.02967890165746212, 0.034989289939403534, 0.03840268403291702, 0.04159391671419144, 0.05153714492917061] skip-layers: [14, 13, 12, 11, 10]
step:250/5550 val_loss:3.848898 train_time:58684ms step_avg:234.74ms x-lambda: 0.9885787963867188 lambdas: [0.0005830114241689444, 0.01749326102435589, 0.01835276372730732, 0.01860039494931698, 0.028399284929037094] skip-layers: [14, 13, 12, 11, 10]
step:375/5550 val_loss:3.676056 train_time:87966ms step_avg:234.58ms x-lambda: 0.9760763645172119 lambdas: [-0.0031976117752492428, 0.014779826626181602, 0.006200697273015976, -0.0021410230547189713, -0.029512561857700348] skip-layers: [14, 13, 12, 11, 10]
step:500/5550 val_loss:3.559346 train_time:117640ms step_avg:235.28ms x-lambda: 0.9722095727920532 lambdas: [-0.0084915766492486, 0.011339799501001835, -0.005619571544229984, -0.019118521362543106, -0.08771297335624695] skip-layers: [14, 13, 12, 11, 10]
step:625/5550 val_loss:3.482396 train_time:147540ms step_avg:236.06ms x-lambda: 0.9685003161430359 lambdas: [-0.010694880969822407, 0.01104297861456871, -0.012532554566860199, -0.02767772786319256, -0.1345689743757248] skip-layers: [14, 13, 12, 11, 10]
step:750/5550 val_loss:3.425673 train_time:178678ms step_avg:238.24ms x-lambda: 0.9630604386329651 lambdas: [-0.014058766886591911, 0.009550338611006737, -0.019718414172530174, -0.03364806994795799, -0.17278778553009033] skip-layers: [14, 13, 12, 11, 10]
step:875/5550 val_loss:3.383120 train_time:209031ms step_avg:238.89ms x-lambda: 0.9542880654335022 lambdas: [-0.017356570810079575, 0.008241408504545689, -0.025416480377316475, -0.03487401828169823, -0.20110726356506348] skip-layers: [14, 13, 12, 11, 10]
step:1000/5550 val_loss:3.349547 train_time:239623ms step_avg:239.62ms x-lambda: 0.9457637071609497 lambdas: [-0.022794492542743683, 0.0027523282915353775, -0.035363905131816864, -0.03862600401043892, -0.22786112129688263] skip-layers: [14, 13, 12, 11, 10]
step:1125/5550 val_loss:3.318200 train_time:270253ms step_avg:240.23ms x-lambda: 0.9370566606521606 lambdas: [-0.027389558032155037, -0.0006027306662872434, -0.04145725443959236, -0.03582796826958656, -0.24398201704025269] skip-layers: [14, 13, 12, 11, 10]
step:1250/5550 val_loss:3.291925 train_time:301026ms step_avg:240.82ms x-lambda: 0.9312837719917297 lambdas: [-0.029566466808319092, -0.0032520226668566465, -0.04607084020972252, -0.03184722736477852, -0.2552606165409088] skip-layers: [14, 13, 12, 11, 10]
step:1375/5550 val_loss:3.270998 train_time:331962ms step_avg:241.43ms x-lambda: 0.9225671887397766 lambdas: [-0.03364358842372894, -0.007298297714442015, -0.051365215331315994, -0.0273713618516922, -0.2643693685531616] skip-layers: [14, 13, 12, 11, 10]
step:1500/5550 val_loss:3.252994 train_time:362933ms step_avg:241.96ms x-lambda: 0.9184806942939758 lambdas: [-0.03473366051912308, -0.010441434569656849, -0.056339237838983536, -0.021325981244444847, -0.27068427205085754] skip-layers: [14, 13, 12, 11, 10]
step:1625/5550 val_loss:3.237583 train_time:393944ms step_avg:242.43ms x-lambda: 0.9091324210166931 lambdas: [-0.0392410084605217, -0.015363316982984543, -0.06221054494380951, -0.0161795224994421, -0.2768513858318329] skip-layers: [14, 13, 12, 11, 10]
step:1750/5550 val_loss:3.220275 train_time:426098ms step_avg:243.48ms x-lambda: 0.9022064805030823 lambdas: [-0.04338409751653671, -0.02064504101872444, -0.06828609853982925, -0.011615036986768246, -0.28023871779441833] skip-layers: [14, 13, 12, 11, 10]
step:1875/5550 val_loss:3.201339 train_time:457226ms step_avg:243.85ms x-lambda: 0.8954126834869385 lambdas: [-0.04674660414457321, -0.025338228791952133, -0.07371407002210617, -0.00695571256801486, -0.28313374519348145] skip-layers: [14, 13, 12, 11, 10]
step:2000/5550 val_loss:3.186818 train_time:493671ms step_avg:246.84ms x-lambda: 0.8912054896354675 lambdas: [-0.048971351236104965, -0.029684389010071754, -0.07797800004482269, -0.0019135491456836462, -0.2832329571247101] skip-layers: [14, 13, 12, 11, 10]
step:2125/5550 val_loss:3.171921 train_time:524980ms step_avg:247.05ms x-lambda: 0.8875744938850403 lambdas: [-0.05082244053483009, -0.03372674435377121, -0.08257092535495758, 0.0017148955957964063, -0.28597337007522583] skip-layers: [14, 13, 12, 11, 10]
step:2250/5550 val_loss:3.157114 train_time:558411ms step_avg:248.18ms x-lambda: 0.8851658701896667 lambdas: [-0.052322547882795334, -0.03718035668134689, -0.08590919524431229, 0.006497865077108145, -0.284990131855011] skip-layers: [14, 13, 12, 11, 10]
step:2375/5550 val_loss:3.146449 train_time:589746ms step_avg:248.31ms x-lambda: 0.8817335963249207 lambdas: [-0.05448554456233978, -0.04178125783801079, -0.09032783657312393, 0.009506570175290108, -0.284551203250885] skip-layers: [14, 13, 12, 11, 10]
step:2500/5550 val_loss:3.134165 train_time:621101ms step_avg:248.44ms x-lambda: 0.8810663819313049 lambdas: [-0.05455648899078369, -0.044442735612392426, -0.09275505691766739, 0.013972152024507523, -0.2837928831577301] skip-layers: [14, 13, 12, 11, 10]
step:2625/5550 val_loss:3.122926 train_time:652404ms step_avg:248.54ms x-lambda: 0.87735915184021 lambdas: [-0.05708484351634979, -0.048977330327034, -0.09623018652200699, 0.016212649643421173, -0.2839779555797577] skip-layers: [14, 13, 12, 11, 10]
step:2750/5550 val_loss:3.112138 train_time:684785ms step_avg:249.01ms x-lambda: 0.877478837966919 lambdas: [-0.056793585419654846, -0.05149396136403084, -0.09816327691078186, 0.018604841083288193, -0.28145164251327515] skip-layers: [14, 13, 12, 11, 10]
step:2875/5550 val_loss:3.102094 train_time:717223ms step_avg:249.47ms x-lambda: 0.8774897456169128 lambdas: [-0.05743318796157837, -0.0540260411798954, -0.10083483159542084, 0.022213930264115334, -0.2802579700946808] skip-layers: [14, 13, 12, 11, 10]
step:3000/5550 val_loss:3.091389 train_time:748583ms step_avg:249.53ms x-lambda: 0.8769102096557617 lambdas: [-0.05809175968170166, -0.056802429258823395, -0.10241569578647614, 0.02454635128378868, -0.2789858281612396] skip-layers: [14, 13, 12, 11, 10]
step:3125/5550 val_loss:3.080535 train_time:784212ms step_avg:250.95ms x-lambda: 0.8770371675491333 lambdas: [-0.058725882321596146, -0.059822894632816315, -0.10473691672086716, 0.026714226230978966, -0.28057387471199036] skip-layers: [14, 13, 12, 11, 10]
step:3250/5550 val_loss:3.069245 train_time:816586ms step_avg:251.26ms x-lambda: 0.878016471862793 lambdas: [-0.05872213840484619, -0.06252433359622955, -0.10581215471029282, 0.028660975396633148, -0.2786644399166107] skip-layers: [14, 13, 12, 11, 10]
step:3375/5550 val_loss:3.060200 train_time:847868ms step_avg:251.22ms x-lambda: 0.8796228170394897 lambdas: [-0.05907730385661125, -0.06531941145658493, -0.10798470675945282, 0.03080807998776436, -0.2798340320587158] skip-layers: [14, 13, 12, 11, 10]
step:3500/5550 val_loss:3.051822 train_time:882546ms step_avg:252.16ms x-lambda: 0.8800086379051208 lambdas: [-0.05961322784423828, -0.06812608987092972, -0.10985817760229111, 0.03198206424713135, -0.27756109833717346] skip-layers: [14, 13, 12, 11, 10]
step:3625/5550 val_loss:3.043392 train_time:913891ms step_avg:252.11ms x-lambda: 0.8819737434387207 lambdas: [-0.059098467230796814, -0.06969068199396133, -0.11106661707162857, 0.03326797112822533, -0.27702805399894714] skip-layers: [14, 13, 12, 11, 10]
step:3750/5550 val_loss:3.033573 train_time:945151ms step_avg:252.04ms x-lambda: 0.883466362953186 lambdas: [-0.0586862750351429, -0.07084071636199951, -0.11109397560358047, 0.034814734011888504, -0.2753180265426636] skip-layers: [14, 13, 12, 11, 10]
step:3875/5550 val_loss:3.024815 train_time:976545ms step_avg:252.01ms x-lambda: 0.8883339762687683 lambdas: [-0.057197388261556625, -0.07215475291013718, -0.11231069266796112, 0.036969009786844254, -0.27596792578697205] skip-layers: [14, 13, 12, 11, 10]
step:4000/5550 val_loss:3.015472 train_time:1007937ms step_avg:251.98ms x-lambda: 0.8904522061347961 lambdas: [-0.05841195955872536, -0.07462864369153976, -0.11282049119472504, 0.03833898901939392, -0.2765617072582245] skip-layers: [14, 13, 12, 11, 10]
step:4125/5550 val_loss:3.006151 train_time:1040481ms step_avg:252.24ms x-lambda: 0.8944650888442993 lambdas: [-0.05697283148765564, -0.07607623934745789, -0.11383261531591415, 0.03865256905555725, -0.2751343250274658] skip-layers: [14, 13, 12, 11, 10]
step:4250/5550 val_loss:2.997895 train_time:1072039ms step_avg:252.24ms x-lambda: 0.8980647921562195 lambdas: [-0.05665889382362366, -0.07726629078388214, -0.11371969431638718, 0.03986595943570137, -0.2759820222854614] skip-layers: [14, 13, 12, 11, 10]
step:4375/5550 val_loss:2.988514 train_time:1106718ms step_avg:252.96ms x-lambda: 0.9008013010025024 lambdas: [-0.05738913267850876, -0.07999526709318161, -0.11560550332069397, 0.04021802172064781, -0.2763397693634033] skip-layers: [14, 13, 12, 11, 10]
step:4500/5550 val_loss:2.980421 train_time:1141478ms step_avg:253.66ms x-lambda: 0.9060747623443604 lambdas: [-0.056998904794454575, -0.08143579214811325, -0.11623299866914749, 0.04117676615715027, -0.2761724293231964] skip-layers: [14, 13, 12, 11, 10]
step:4625/5550 val_loss:2.971204 train_time:1173279ms step_avg:253.68ms x-lambda: 0.9109209775924683 lambdas: [-0.05516998469829559, -0.08223491907119751, -0.116275854408741, 0.04215020686388016, -0.27703356742858887] skip-layers: [14, 13, 12, 11, 10]
step:4750/5550 val_loss:2.961684 train_time:1208530ms step_avg:254.43ms x-lambda: 0.9162807464599609 lambdas: [-0.05464775115251541, -0.08272967487573624, -0.11629631370306015, 0.04357071965932846, -0.2775309383869171] skip-layers: [14, 13, 12, 11, 10]
step:4875/5550 val_loss:2.952887 train_time:1240630ms step_avg:254.49ms x-lambda: 0.921108067035675 lambdas: [-0.05455400422215462, -0.08401955664157867, -0.11760631948709488, 0.04390581697225571, -0.27868497371673584] skip-layers: [14, 13, 12, 11, 10]
step:5000/5550 val_loss:2.944720 train_time:1272811ms step_avg:254.56ms x-lambda: 0.9275707006454468 lambdas: [-0.05382708087563515, -0.08527041226625443, -0.11814258247613907, 0.04536346718668938, -0.2788920998573303] skip-layers: [14, 13, 12, 11, 10]
step:5125/5550 val_loss:2.937161 train_time:1305153ms step_avg:254.66ms x-lambda: 0.9327629208564758 lambdas: [-0.053853731602430344, -0.08613133430480957, -0.11825963109731674, 0.046219293028116226, -0.2806597650051117] skip-layers: [14, 13, 12, 11, 10]
step:5250/5550 val_loss:2.929924 train_time:1339744ms step_avg:255.19ms x-lambda: 0.9373834729194641 lambdas: [-0.05370515584945679, -0.08718840777873993, -0.11866866052150726, 0.04676540940999985, -0.2806335687637329] skip-layers: [14, 13, 12, 11, 10]
step:5375/5550 val_loss:2.923557 train_time:1372399ms step_avg:255.33ms x-lambda: 0.9418490529060364 lambdas: [-0.053433675318956375, -0.08763094991445541, -0.11929310113191605, 0.04768677055835724, -0.28244709968566895] skip-layers: [14, 13, 12, 11, 10]
step:5500/5550 val_loss:2.918739 train_time:1405284ms step_avg:255.51ms x-lambda: 0.9448723196983337 lambdas: [-0.0527944453060627, -0.08805625140666962, -0.11946284770965576, 0.048138588666915894, -0.28257808089256287] skip-layers: [14, 13, 12, 11, 10]
step:5550/5550 val_loss:2.917552 train_time:1420708ms step_avg:255.98ms x-lambda: 0.9454688429832458 lambdas: [-0.052743684500455856, -0.08792446553707123, -0.11945199966430664, 0.04820401966571808, -0.2831731140613556] skip-layers: [14, 13, 12, 11, 10]

## 8000-add-skip-multiple-5-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4]
step:125/5550 val_loss:4.266359 train_time:28707ms step_avg:229.65ms x-lambda: 1.0716431140899658 lambdas: [0.09009110182523727, 0.01012747548520565, -0.010840578004717827, -0.028499167412519455, 0.10924974083900452] skip-layers: [0, 1, 2, 3, 4]
step:250/5550 val_loss:3.852451 train_time:57595ms step_avg:230.38ms x-lambda: 1.0347062349319458 lambdas: [0.08118316531181335, -0.03335466608405113, -0.06958852708339691, -0.12528084218502045, 0.15782828629016876] skip-layers: [0, 1, 2, 3, 4]
step:375/5550 val_loss:3.671538 train_time:86939ms step_avg:231.84ms x-lambda: 1.000925064086914 lambdas: [0.06671387702226639, -0.042372800409793854, -0.08627244085073471, -0.17717225849628448, 0.1544734388589859] skip-layers: [0, 1, 2, 3, 4]
step:500/5550 val_loss:3.555977 train_time:116675ms step_avg:233.35ms x-lambda: 0.9601941704750061 lambdas: [0.059685345739126205, -0.04105718433856964, -0.09095266461372375, -0.20115558803081512, 0.14906977117061615] skip-layers: [0, 1, 2, 3, 4]
step:625/5550 val_loss:3.479744 train_time:147488ms step_avg:235.98ms x-lambda: 0.9172921776771545 lambdas: [0.054088935256004333, -0.03613530099391937, -0.0905904471874237, -0.20907890796661377, 0.1435362845659256] skip-layers: [0, 1, 2, 3, 4]
step:750/5550 val_loss:3.426018 train_time:177695ms step_avg:236.93ms x-lambda: 0.8793219923973083 lambdas: [0.048736393451690674, -0.03317566215991974, -0.0906052365899086, -0.20938515663146973, 0.1349346935749054] skip-layers: [0, 1, 2, 3, 4]
step:875/5550 val_loss:3.380755 train_time:208887ms step_avg:238.73ms x-lambda: 0.8401959538459778 lambdas: [0.04424208775162697, -0.02849762514233589, -0.08690866082906723, -0.20219776034355164, 0.127222940325737] skip-layers: [0, 1, 2, 3, 4]
step:1000/5550 val_loss:3.348569 train_time:239453ms step_avg:239.45ms x-lambda: 0.8052945733070374 lambdas: [0.03875809907913208, -0.026589106768369675, -0.08495035022497177, -0.1928587406873703, 0.11495203524827957] skip-layers: [0, 1, 2, 3, 4]
step:1125/5550 val_loss:3.318797 train_time:270083ms step_avg:240.07ms x-lambda: 0.7747997045516968 lambdas: [0.03489234298467636, -0.02382577583193779, -0.08182654529809952, -0.18142357468605042, 0.10532888770103455] skip-layers: [0, 1, 2, 3, 4]
step:1250/5550 val_loss:3.292451 train_time:300869ms step_avg:240.70ms x-lambda: 0.7504344582557678 lambdas: [0.035412512719631195, -0.019715992733836174, -0.07633418589830399, -0.16732145845890045, 0.09914736449718475] skip-layers: [0, 1, 2, 3, 4]
step:1375/5550 val_loss:3.273298 train_time:331792ms step_avg:241.30ms x-lambda: 0.7237038016319275 lambdas: [0.031103061512112617, -0.020007401704788208, -0.07548976689577103, -0.15936538577079773, 0.08789688348770142] skip-layers: [0, 1, 2, 3, 4]
step:1500/5550 val_loss:3.253659 train_time:362727ms step_avg:241.82ms x-lambda: 0.7030941247940063 lambdas: [0.03010871820151806, -0.01773752272129059, -0.07352928072214127, -0.1496792882680893, 0.08212436735630035] skip-layers: [0, 1, 2, 3, 4]
step:1625/5550 val_loss:3.237250 train_time:393742ms step_avg:242.30ms x-lambda: 0.685385525226593 lambdas: [0.02899070642888546, -0.015559691935777664, -0.06910815834999084, -0.13877931237220764, 0.0771327093243599] skip-layers: [0, 1, 2, 3, 4]
step:1750/5550 val_loss:3.221732 train_time:425937ms step_avg:243.39ms x-lambda: 0.6672053337097168 lambdas: [0.0278555229306221, -0.01292736828327179, -0.06555002927780151, -0.12922611832618713, 0.07068294286727905] skip-layers: [0, 1, 2, 3, 4]
step:1875/5550 val_loss:3.205657 train_time:456989ms step_avg:243.73ms x-lambda: 0.6562239527702332 lambdas: [0.02801956795156002, -0.009733125567436218, -0.06230619549751282, -0.11956724524497986, 0.06660551577806473] skip-layers: [0, 1, 2, 3, 4]
step:2000/5550 val_loss:3.188539 train_time:488278ms step_avg:244.14ms x-lambda: 0.6410646438598633 lambdas: [0.026003029197454453, -0.010474812239408493, -0.061692386865615845, -0.11359260976314545, 0.061311572790145874] skip-layers: [0, 1, 2, 3, 4]
step:2125/5550 val_loss:3.173488 train_time:519633ms step_avg:244.53ms x-lambda: 0.6315270066261292 lambdas: [0.024186713621020317, -0.010656844824552536, -0.060749951750040054, -0.10929055511951447, 0.05632498487830162] skip-layers: [0, 1, 2, 3, 4]
step:2250/5550 val_loss:3.158962 train_time:550997ms step_avg:244.89ms x-lambda: 0.6251029968261719 lambdas: [0.02424200251698494, -0.010367709212005138, -0.059200216084718704, -0.10252413153648376, 0.05142431706190109] skip-layers: [0, 1, 2, 3, 4]
step:2375/5550 val_loss:3.148357 train_time:583432ms step_avg:245.66ms x-lambda: 0.6166045665740967 lambdas: [0.02231038734316826, -0.009848805144429207, -0.058536097407341, -0.09802117198705673, 0.04845589026808739] skip-layers: [0, 1, 2, 3, 4]
step:2500/5550 val_loss:3.136665 train_time:614732ms step_avg:245.89ms x-lambda: 0.6120810508728027 lambdas: [0.023391906172037125, -0.008271174505352974, -0.056081999093294144, -0.09516352415084839, 0.047786690294742584] skip-layers: [0, 1, 2, 3, 4]
step:2625/5550 val_loss:3.125758 train_time:647139ms step_avg:246.53ms x-lambda: 0.6097191572189331 lambdas: [0.02307962253689766, -0.007591817993670702, -0.05468157306313515, -0.08934754878282547, 0.04480458050966263] skip-layers: [0, 1, 2, 3, 4]
step:2750/5550 val_loss:3.113808 train_time:679515ms step_avg:247.10ms x-lambda: 0.6045472025871277 lambdas: [0.021649960428476334, -0.006573349237442017, -0.05313500761985779, -0.0867592990398407, 0.0425272211432457] skip-layers: [0, 1, 2, 3, 4]
step:2875/5550 val_loss:3.104690 train_time:710767ms step_avg:247.22ms x-lambda: 0.601883590221405 lambdas: [0.02165098302066326, -0.007495948113501072, -0.051730986684560776, -0.0825667455792427, 0.03966641053557396] skip-layers: [0, 1, 2, 3, 4]
step:3000/5550 val_loss:3.093432 train_time:742099ms step_avg:247.37ms x-lambda: 0.5995044112205505 lambdas: [0.020212551578879356, -0.007171310018748045, -0.05163520202040672, -0.08096478879451752, 0.039270371198654175] skip-layers: [0, 1, 2, 3, 4]
step:3125/5550 val_loss:3.082559 train_time:773434ms step_avg:247.50ms x-lambda: 0.5985110998153687 lambdas: [0.02022840827703476, -0.006941649597138166, -0.05218920856714249, -0.08017916977405548, 0.036981210112571716] skip-layers: [0, 1, 2, 3, 4]
step:3250/5550 val_loss:3.071134 train_time:806853ms step_avg:248.26ms x-lambda: 0.5996459722518921 lambdas: [0.019811255857348442, -0.006060592830181122, -0.05071093887090683, -0.07657317072153091, 0.03612557798624039] skip-layers: [0, 1, 2, 3, 4]
step:3375/5550 val_loss:3.063146 train_time:840385ms step_avg:249.00ms x-lambda: 0.6000330448150635 lambdas: [0.018137488514184952, -0.0072921933606266975, -0.050937164574861526, -0.07666317373514175, 0.0342252179980278] skip-layers: [0, 1, 2, 3, 4]
step:3500/5550 val_loss:3.054856 train_time:871715ms step_avg:249.06ms x-lambda: 0.5994684100151062 lambdas: [0.017574097961187363, -0.007167653646320105, -0.05019426718354225, -0.07397115230560303, 0.0322008915245533] skip-layers: [0, 1, 2, 3, 4]
step:3625/5550 val_loss:3.045105 train_time:903018ms step_avg:249.11ms x-lambda: 0.6029112339019775 lambdas: [0.01917969435453415, -0.005874390713870525, -0.04858950898051262, -0.07236216962337494, 0.03185032308101654] skip-layers: [0, 1, 2, 3, 4]
step:3750/5550 val_loss:3.035398 train_time:935328ms step_avg:249.42ms x-lambda: 0.6030475497245789 lambdas: [0.019367065280675888, -0.006193808279931545, -0.04749143496155739, -0.07084184139966965, 0.031739648431539536] skip-layers: [0, 1, 2, 3, 4]
step:3875/5550 val_loss:3.026948 train_time:966692ms step_avg:249.47ms x-lambda: 0.6106550097465515 lambdas: [0.01888040080666542, -0.0043840366415679455, -0.04801182448863983, -0.0695212259888649, 0.03090282343327999] skip-layers: [0, 1, 2, 3, 4]
step:4000/5550 val_loss:3.017116 train_time:998046ms step_avg:249.51ms x-lambda: 0.6128948330879211 lambdas: [0.018392149358987808, -0.004230454098433256, -0.047096796333789825, -0.06738394498825073, 0.029562735930085182] skip-layers: [0, 1, 2, 3, 4]
step:4125/5550 val_loss:3.008227 train_time:1030566ms step_avg:249.83ms x-lambda: 0.618566632270813 lambdas: [0.01799563504755497, -0.00598424207419157, -0.0468788705766201, -0.06681462377309799, 0.02791106328368187] skip-layers: [0, 1, 2, 3, 4]
step:4250/5550 val_loss:2.999731 train_time:1062142ms step_avg:249.92ms x-lambda: 0.621198832988739 lambdas: [0.01734558492898941, -0.005465311463922262, -0.046239085495471954, -0.06480620056390762, 0.028002426028251648] skip-layers: [0, 1, 2, 3, 4]
step:4375/5550 val_loss:2.990796 train_time:1093801ms step_avg:250.01ms x-lambda: 0.6258368492126465 lambdas: [0.018795471638441086, -0.005489443428814411, -0.0467844158411026, -0.06499537825584412, 0.02749621495604515] skip-layers: [0, 1, 2, 3, 4]
step:4500/5550 val_loss:2.982722 train_time:1128705ms step_avg:250.82ms x-lambda: 0.6307133436203003 lambdas: [0.018159540370106697, -0.006362944841384888, -0.04542205110192299, -0.06448771804571152, 0.026415305212140083] skip-layers: [0, 1, 2, 3, 4]
step:4625/5550 val_loss:2.973111 train_time:1160520ms step_avg:250.92ms x-lambda: 0.6381708979606628 lambdas: [0.01682598516345024, -0.005825659725815058, -0.04482497274875641, -0.06374966353178024, 0.02579951100051403] skip-layers: [0, 1, 2, 3, 4]
step:4750/5550 val_loss:2.963859 train_time:1192493ms step_avg:251.05ms x-lambda: 0.6459779143333435 lambdas: [0.01843482255935669, -0.004034137818962336, -0.04617000371217728, -0.061606019735336304, 0.026381047442555428] skip-layers: [0, 1, 2, 3, 4]
step:4875/5550 val_loss:2.955067 train_time:1225801ms step_avg:251.45ms x-lambda: 0.6525369882583618 lambdas: [0.017874471843242645, -0.004554583225399256, -0.04530913755297661, -0.06241980567574501, 0.025366635993123055] skip-layers: [0, 1, 2, 3, 4]
step:5000/5550 val_loss:2.946796 train_time:1257968ms step_avg:251.59ms x-lambda: 0.6603971123695374 lambdas: [0.01703209988772869, -0.0048475079238414764, -0.045603685081005096, -0.061419807374477386, 0.02561994083225727] skip-layers: [0, 1, 2, 3, 4]
step:5125/5550 val_loss:2.939210 train_time:1291301ms step_avg:251.96ms x-lambda: 0.6683746576309204 lambdas: [0.017408542335033417, -0.00401889206841588, -0.04408535733819008, -0.060633789747953415, 0.025916002690792084] skip-layers: [0, 1, 2, 3, 4]
step:5250/5550 val_loss:2.932046 train_time:1323833ms step_avg:252.16ms x-lambda: 0.6759262084960938 lambdas: [0.016615519300103188, -0.004133994225412607, -0.04454676806926727, -0.059954509139060974, 0.024446459487080574] skip-layers: [0, 1, 2, 3, 4]
step:5375/5550 val_loss:2.925625 train_time:1356452ms step_avg:252.36ms x-lambda: 0.6852308511734009 lambdas: [0.01708206720650196, -0.0036054833326488733, -0.043896134942770004, -0.06046275794506073, 0.02430632710456848] skip-layers: [0, 1, 2, 3, 4]
step:5500/5550 val_loss:2.920841 train_time:1390374ms step_avg:252.80ms x-lambda: 0.6906929612159729 lambdas: [0.01708180643618107, -0.0049155093729496, -0.04465965926647186, -0.0597236268222332, 0.024615857750177383] skip-layers: [0, 1, 2, 3, 4]
step:5550/5550 val_loss:2.919676 train_time:1403618ms step_avg:252.90ms x-lambda: 0.6922534704208374 lambdas: [0.016765659675002098, -0.004489703103899956, -0.044509418308734894, -0.05972394347190857, 0.02477933280169964] skip-layers: [0, 1, 2, 3, 4]

## 8000-add-skip-multiple-5-method-random-0

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:0.54ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [2, 0, 6, 9, 11]
step:125/5550 val_loss:4.264972 train_time:28702ms step_avg:229.61ms x-lambda: 1.1062883138656616 lambdas: [0.032713163644075394, 0.0007948404527269304, 0.014429043978452682, 0.02280728705227375, 0.024583572521805763] skip-layers: [2, 0, 6, 9, 11]
step:250/5550 val_loss:3.857624 train_time:57588ms step_avg:230.35ms x-lambda: 1.081295371055603 lambdas: [-0.010670085437595844, -0.01407061330974102, -0.002301332075148821, -0.023523593321442604, -0.010447521694004536] skip-layers: [2, 0, 6, 9, 11]
step:375/5550 val_loss:3.679636 train_time:86939ms step_avg:231.84ms x-lambda: 1.010201334953308 lambdas: [-0.01766885258257389, -0.015824103727936745, -0.005507122725248337, -0.02942321076989174, -0.01865941658616066] skip-layers: [2, 0, 6, 9, 11]
step:500/5550 val_loss:3.565579 train_time:116727ms step_avg:233.45ms x-lambda: 0.9438551664352417 lambdas: [-0.021712303161621094, -0.01886739768087864, -0.010016660206019878, -0.029990706592798233, -0.02121572569012642] skip-layers: [2, 0, 6, 9, 11]
step:625/5550 val_loss:3.485600 train_time:146732ms step_avg:234.77ms x-lambda: 0.8890318870544434 lambdas: [-0.02015812136232853, -0.017853932455182076, -0.009372524917125702, -0.026485858485102654, -0.019270362332463264] skip-layers: [2, 0, 6, 9, 11]
step:750/5550 val_loss:3.433067 train_time:176965ms step_avg:235.95ms x-lambda: 0.8443785309791565 lambdas: [-0.02321602776646614, -0.020524268969893456, -0.01210416853427887, -0.028130104765295982, -0.019857265055179596] skip-layers: [2, 0, 6, 9, 11]
step:875/5550 val_loss:3.385612 train_time:207300ms step_avg:236.91ms x-lambda: 0.8017798662185669 lambdas: [-0.020565543323755264, -0.016938988119363785, -0.010949276387691498, -0.024113329127430916, -0.01724696159362793] skip-layers: [2, 0, 6, 9, 11]
step:1000/5550 val_loss:3.352427 train_time:237916ms step_avg:237.92ms x-lambda: 0.7640195488929749 lambdas: [-0.02078390121459961, -0.017350656911730766, -0.011698083020746708, -0.02480166405439377, -0.01736525259912014] skip-layers: [2, 0, 6, 9, 11]
step:1125/5550 val_loss:3.323412 train_time:271747ms step_avg:241.55ms x-lambda: 0.7314009070396423 lambdas: [-0.02045370824635029, -0.0167703814804554, -0.01065460778772831, -0.02363256737589836, -0.016797777265310287] skip-layers: [2, 0, 6, 9, 11]
step:1250/5550 val_loss:3.297509 train_time:303558ms step_avg:242.85ms x-lambda: 0.7093330025672913 lambdas: [-0.01745763048529625, -0.013455672189593315, -0.008516327477991581, -0.019874153658747673, -0.012948594056069851] skip-layers: [2, 0, 6, 9, 11]
step:1375/5550 val_loss:3.276552 train_time:334546ms step_avg:243.31ms x-lambda: 0.6851423382759094 lambdas: [-0.017405938357114792, -0.01360445935279131, -0.008421936072409153, -0.018504971638321877, -0.015132980421185493] skip-layers: [2, 0, 6, 9, 11]
step:1500/5550 val_loss:3.258252 train_time:365537ms step_avg:243.69ms x-lambda: 0.6637636423110962 lambdas: [-0.018413009122014046, -0.014804788865149021, -0.011578993871808052, -0.020252689719200134, -0.01463843509554863] skip-layers: [2, 0, 6, 9, 11]
step:1625/5550 val_loss:3.242897 train_time:399721ms step_avg:245.98ms x-lambda: 0.6479775309562683 lambdas: [-0.014611097052693367, -0.010798166505992413, -0.006444775499403477, -0.015507896430790424, -0.011200699023902416] skip-layers: [2, 0, 6, 9, 11]
step:1750/5550 val_loss:3.225507 train_time:430758ms step_avg:246.15ms x-lambda: 0.6283664703369141 lambdas: [-0.01613130047917366, -0.011619473807513714, -0.0074613275937736034, -0.017247145995497704, -0.012037626467645168] skip-layers: [2, 0, 6, 9, 11]
step:1875/5550 val_loss:3.208829 train_time:461862ms step_avg:246.33ms x-lambda: 0.6196785569190979 lambdas: [-0.013743238523602486, -0.009136982262134552, -0.006020088214427233, -0.014893747866153717, -0.009812912903726101] skip-layers: [2, 0, 6, 9, 11]
step:2000/5550 val_loss:3.191405 train_time:493212ms step_avg:246.61ms x-lambda: 0.6036357283592224 lambdas: [-0.014358065091073513, -0.010488850064575672, -0.007097138557583094, -0.01551947183907032, -0.009741513058543205] skip-layers: [2, 0, 6, 9, 11]
step:2125/5550 val_loss:3.176407 train_time:525565ms step_avg:247.32ms x-lambda: 0.5984143614768982 lambdas: [-0.014424639753997326, -0.01037032064050436, -0.006614364217966795, -0.01452531386166811, -0.010845404118299484] skip-layers: [2, 0, 6, 9, 11]
step:2250/5550 val_loss:3.163400 train_time:556893ms step_avg:247.51ms x-lambda: 0.59319669008255 lambdas: [-0.01293946523219347, -0.00950255524367094, -0.005673583596944809, -0.014199447818100452, -0.009884294122457504] skip-layers: [2, 0, 6, 9, 11]
step:2375/5550 val_loss:3.152248 train_time:589363ms step_avg:248.15ms x-lambda: 0.5843170285224915 lambdas: [-0.014089561067521572, -0.00981961376965046, -0.006901917513459921, -0.01475229486823082, -0.01107106264680624] skip-layers: [2, 0, 6, 9, 11]
step:2500/5550 val_loss:3.139323 train_time:620674ms step_avg:248.27ms x-lambda: 0.5819863677024841 lambdas: [-0.013131330721080303, -0.008358531631529331, -0.005553442053496838, -0.013259033672511578, -0.008641193620860577] skip-layers: [2, 0, 6, 9, 11]
step:2625/5550 val_loss:3.127602 train_time:651970ms step_avg:248.37ms x-lambda: 0.5777818560600281 lambdas: [-0.012415495701134205, -0.008521736599504948, -0.005665650591254234, -0.012846166267991066, -0.009045327082276344] skip-layers: [2, 0, 6, 9, 11]
step:2750/5550 val_loss:3.117542 train_time:683235ms step_avg:248.45ms x-lambda: 0.5731984376907349 lambdas: [-0.01225521694868803, -0.008150708861649036, -0.006393022835254669, -0.013278516009449959, -0.00902821309864521] skip-layers: [2, 0, 6, 9, 11]
step:2875/5550 val_loss:3.107426 train_time:715653ms step_avg:248.92ms x-lambda: 0.573314905166626 lambdas: [-0.012160110287368298, -0.00697451364248991, -0.005694126710295677, -0.012899473309516907, -0.008711547590792179] skip-layers: [2, 0, 6, 9, 11]
step:3000/5550 val_loss:3.096344 train_time:747008ms step_avg:249.00ms x-lambda: 0.5719721913337708 lambdas: [-0.012829702347517014, -0.008814176544547081, -0.005634763278067112, -0.01274621207267046, -0.009807477705180645] skip-layers: [2, 0, 6, 9, 11]
step:3125/5550 val_loss:3.085621 train_time:778338ms step_avg:249.07ms x-lambda: 0.5721142888069153 lambdas: [-0.012597372755408287, -0.007775596808642149, -0.005584673024713993, -0.013349838554859161, -0.008631379343569279] skip-layers: [2, 0, 6, 9, 11]
step:3250/5550 val_loss:3.074592 train_time:809607ms step_avg:249.11ms x-lambda: 0.5738024115562439 lambdas: [-0.011370470747351646, -0.0067253196612000465, -0.004059952683746815, -0.01192641444504261, -0.007706217467784882] skip-layers: [2, 0, 6, 9, 11]
step:3375/5550 val_loss:3.065444 train_time:845097ms step_avg:250.40ms x-lambda: 0.5748602747917175 lambdas: [-0.012269525788724422, -0.008113033138215542, -0.004974693525582552, -0.011621975339949131, -0.00925850123167038] skip-layers: [2, 0, 6, 9, 11]
step:3500/5550 val_loss:3.056530 train_time:876440ms step_avg:250.41ms x-lambda: 0.5745002627372742 lambdas: [-0.011738047935068607, -0.0066655417904257774, -0.005519090685993433, -0.012851892039179802, -0.009096963331103325] skip-layers: [2, 0, 6, 9, 11]
step:3625/5550 val_loss:3.047479 train_time:907770ms step_avg:250.42ms x-lambda: 0.5778920650482178 lambdas: [-0.01095976959913969, -0.007166367955505848, -0.004722275771200657, -0.011537628248333931, -0.008402026258409023] skip-layers: [2, 0, 6, 9, 11]
step:3750/5550 val_loss:3.038001 train_time:939082ms step_avg:250.42ms x-lambda: 0.5789778828620911 lambdas: [-0.010959370993077755, -0.005933978594839573, -0.004792860243469477, -0.011770053766667843, -0.008486378006637096] skip-layers: [2, 0, 6, 9, 11]
step:3875/5550 val_loss:3.029409 train_time:971472ms step_avg:250.70ms x-lambda: 0.5865461826324463 lambdas: [-0.010925520211458206, -0.005913917440921068, -0.004822119604796171, -0.011197916232049465, -0.007854324765503407] skip-layers: [2, 0, 6, 9, 11]
step:4000/5550 val_loss:3.019983 train_time:1002835ms step_avg:250.71ms x-lambda: 0.5870848894119263 lambdas: [-0.01065085269510746, -0.007453819736838341, -0.004959371872246265, -0.010528657585382462, -0.006704601924866438] skip-layers: [2, 0, 6, 9, 11]
step:4125/5550 val_loss:3.010851 train_time:1034246ms step_avg:250.73ms x-lambda: 0.5940848588943481 lambdas: [-0.010354269295930862, -0.005922421347349882, -0.0045139784924685955, -0.010142615996301174, -0.0071848551742732525] skip-layers: [2, 0, 6, 9, 11]
step:4250/5550 val_loss:3.002613 train_time:1066903ms step_avg:251.04ms x-lambda: 0.5980381965637207 lambdas: [-0.01030875276774168, -0.006914791185408831, -0.004041098058223724, -0.010546775534749031, -0.007380193565040827] skip-layers: [2, 0, 6, 9, 11]
step:4375/5550 val_loss:2.993435 train_time:1102644ms step_avg:252.03ms x-lambda: 0.602087140083313 lambdas: [-0.011171838268637657, -0.007317391689866781, -0.00518957432359457, -0.01066056452691555, -0.008346731774508953] skip-layers: [2, 0, 6, 9, 11]
step:4500/5550 val_loss:2.985184 train_time:1136285ms step_avg:252.51ms x-lambda: 0.6073107123374939 lambdas: [-0.009981559589505196, -0.006556110456585884, -0.005980733782052994, -0.010408343747258186, -0.007305930834263563] skip-layers: [2, 0, 6, 9, 11]
step:4625/5550 val_loss:2.975361 train_time:1168097ms step_avg:252.56ms x-lambda: 0.614804744720459 lambdas: [-0.009657597169280052, -0.006420559715479612, -0.004736797418445349, -0.010589134879410267, -0.0064369626343250275] skip-layers: [2, 0, 6, 9, 11]
step:4750/5550 val_loss:2.966155 train_time:1200102ms step_avg:252.65ms x-lambda: 0.6221831440925598 lambdas: [-0.0098639614880085, -0.006304985377937555, -0.0034199466463178396, -0.009366846643388271, -0.006787667516618967] skip-layers: [2, 0, 6, 9, 11]
step:4875/5550 val_loss:2.957540 train_time:1233420ms step_avg:253.01ms x-lambda: 0.6287859082221985 lambdas: [-0.009803460910916328, -0.0055574760772287846, -0.004594400990754366, -0.010176473297178745, -0.007023863028734922] skip-layers: [2, 0, 6, 9, 11]
step:5000/5550 val_loss:2.949232 train_time:1265638ms step_avg:253.13ms x-lambda: 0.6354553699493408 lambdas: [-0.01015479490160942, -0.006280763074755669, -0.004469935782253742, -0.009754191152751446, -0.0055134836584329605] skip-layers: [2, 0, 6, 9, 11]
step:5125/5550 val_loss:2.941547 train_time:1299170ms step_avg:253.50ms x-lambda: 0.6430919170379639 lambdas: [-0.008762256242334843, -0.0057485164143145084, -0.0037536323070526123, -0.009839754551649094, -0.006614771671593189] skip-layers: [2, 0, 6, 9, 11]
step:5250/5550 val_loss:2.934321 train_time:1332825ms step_avg:253.87ms x-lambda: 0.6499513983726501 lambdas: [-0.009191480465233326, -0.006124116480350494, -0.0041851806454360485, -0.009330329485237598, -0.006363355088979006] skip-layers: [2, 0, 6, 9, 11]
step:5375/5550 val_loss:2.927958 train_time:1365492ms step_avg:254.05ms x-lambda: 0.6581477522850037 lambdas: [-0.009307022206485271, -0.005421721376478672, -0.003850448876619339, -0.009792582131922245, -0.006341654807329178] skip-layers: [2, 0, 6, 9, 11]
step:5500/5550 val_loss:2.923174 train_time:1400665ms step_avg:254.67ms x-lambda: 0.6631251573562622 lambdas: [-0.00938550103455782, -0.006210018880665302, -0.0037670673336833715, -0.009409829042851925, -0.006862044334411621] skip-layers: [2, 0, 6, 9, 11]
step:5550/5550 val_loss:2.921976 train_time:1414849ms step_avg:254.93ms x-lambda: 0.6643219590187073 lambdas: [-0.009204220958054066, -0.006143846083432436, -0.004314027726650238, -0.009862263686954975, -0.006615606136620045] skip-layers: [2, 0, 6, 9, 11]

## 8000-add-skip-multiple-5-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.31ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6]
step:125/5550 val_loss:4.273887 train_time:28737ms step_avg:229.89ms x-lambda: 1.0473023653030396 lambdas: [0.030962251126766205, -0.0008124744053930044, 0.0496365986764431, 0.043458011001348495, 0.055350467562675476] skip-layers: [1, 2, 7, 14, 6]
step:250/5550 val_loss:3.847309 train_time:57644ms step_avg:230.58ms x-lambda: 1.0283631086349487 lambdas: [-0.020020226016640663, -0.07336009293794632, 0.04248370975255966, 0.035228319466114044, 0.040420908480882645] skip-layers: [1, 2, 7, 14, 6]
step:375/5550 val_loss:3.673322 train_time:86964ms step_avg:231.90ms x-lambda: 1.0051180124282837 lambdas: [-0.03535093739628792, -0.10453508049249649, 0.029162071645259857, 0.024544253945350647, 0.006485234946012497] skip-layers: [1, 2, 7, 14, 6]
step:500/5550 val_loss:3.557015 train_time:116698ms step_avg:233.40ms x-lambda: 0.9786846041679382 lambdas: [-0.04044458270072937, -0.12178236991167068, 0.023472627624869347, 0.004205386620014906, -0.01983758807182312] skip-layers: [1, 2, 7, 14, 6]
step:625/5550 val_loss:3.479813 train_time:147637ms step_avg:236.22ms x-lambda: 0.9542649388313293 lambdas: [-0.03690518066287041, -0.12708334624767303, 0.025148820132017136, -0.014357751235365868, -0.03218841925263405] skip-layers: [1, 2, 7, 14, 6]
step:750/5550 val_loss:3.425747 train_time:177882ms step_avg:237.18ms x-lambda: 0.9315881729125977 lambdas: [-0.03380503132939339, -0.12963387370109558, 0.02409268729388714, -0.033172477036714554, -0.040526773780584335] skip-layers: [1, 2, 7, 14, 6]
step:875/5550 val_loss:3.382963 train_time:208248ms step_avg:238.00ms x-lambda: 0.9073373079299927 lambdas: [-0.028887128457427025, -0.12712392210960388, 0.024294134229421616, -0.05143624171614647, -0.04340261593461037] skip-layers: [1, 2, 7, 14, 6]
step:1000/5550 val_loss:3.347429 train_time:238870ms step_avg:238.87ms x-lambda: 0.8871376514434814 lambdas: [-0.024844447150826454, -0.12188179790973663, 0.023148084059357643, -0.0672193169593811, -0.04587985575199127] skip-layers: [1, 2, 7, 14, 6]
step:1125/5550 val_loss:3.318543 train_time:269533ms step_avg:239.58ms x-lambda: 0.8667035102844238 lambdas: [-0.025186801329255104, -0.11931406706571579, 0.02039140649139881, -0.08528811484575272, -0.047728992998600006] skip-layers: [1, 2, 7, 14, 6]
step:1250/5550 val_loss:3.295414 train_time:301375ms step_avg:241.10ms x-lambda: 0.8547999262809753 lambdas: [-0.019784636795520782, -0.11132436990737915, 0.02216748706996441, -0.09543191641569138, -0.04577680304646492] skip-layers: [1, 2, 7, 14, 6]
step:1375/5550 val_loss:3.272302 train_time:332358ms step_avg:241.71ms x-lambda: 0.8375431895256042 lambdas: [-0.019355259835720062, -0.10764281451702118, 0.019386447966098785, -0.10787571221590042, -0.04684792831540108] skip-layers: [1, 2, 7, 14, 6]
step:1500/5550 val_loss:3.253510 train_time:363287ms step_avg:242.19ms x-lambda: 0.8247436285018921 lambdas: [-0.01796228066086769, -0.10366751253604889, 0.017794763669371605, -0.11817135661840439, -0.04703819751739502] skip-layers: [1, 2, 7, 14, 6]
step:1625/5550 val_loss:3.237272 train_time:394363ms step_avg:242.68ms x-lambda: 0.810928463935852 lambdas: [-0.01633519120514393, -0.0985635295510292, 0.016717951744794846, -0.12735241651535034, -0.046416811645030975] skip-layers: [1, 2, 7, 14, 6]
step:1750/5550 val_loss:3.221029 train_time:425396ms step_avg:243.08ms x-lambda: 0.7983564138412476 lambdas: [-0.015352830290794373, -0.09407230466604233, 0.018581338226795197, -0.1362740844488144, -0.04509644955396652] skip-layers: [1, 2, 7, 14, 6]
step:1875/5550 val_loss:3.205858 train_time:456443ms step_avg:243.44ms x-lambda: 0.7943155169487 lambdas: [-0.01208901684731245, -0.0877893716096878, 0.0191327054053545, -0.13994307816028595, -0.041861847043037415] skip-layers: [1, 2, 7, 14, 6]
step:2000/5550 val_loss:3.189128 train_time:488832ms step_avg:244.42ms x-lambda: 0.7856512069702148 lambdas: [-0.011567970737814903, -0.08532703667879105, 0.016809482127428055, -0.14899969100952148, -0.041583351790905] skip-layers: [1, 2, 7, 14, 6]
step:2125/5550 val_loss:3.173748 train_time:520177ms step_avg:244.79ms x-lambda: 0.7814272046089172 lambdas: [-0.011724707670509815, -0.08406422287225723, 0.015123668126761913, -0.15558069944381714, -0.04246952384710312] skip-layers: [1, 2, 7, 14, 6]
step:2250/5550 val_loss:3.159848 train_time:552635ms step_avg:245.62ms x-lambda: 0.7774702310562134 lambdas: [-0.011432136408984661, -0.08051211386919022, 0.014307230710983276, -0.16171279549598694, -0.04093707725405693] skip-layers: [1, 2, 7, 14, 6]
step:2375/5550 val_loss:3.148576 train_time:585033ms step_avg:246.33ms x-lambda: 0.773772656917572 lambdas: [-0.011560477316379547, -0.07761462032794952, 0.013527385890483856, -0.16648045182228088, -0.04061354696750641] skip-layers: [1, 2, 7, 14, 6]
step:2500/5550 val_loss:3.136883 train_time:620421ms step_avg:248.17ms x-lambda: 0.7729101181030273 lambdas: [-0.009173093363642693, -0.07563041895627975, 0.013482572510838509, -0.17174959182739258, -0.03960275650024414] skip-layers: [1, 2, 7, 14, 6]
step:2625/5550 val_loss:3.124684 train_time:651770ms step_avg:248.29ms x-lambda: 0.7714426517486572 lambdas: [-0.009043420664966106, -0.07353813201189041, 0.013371236622333527, -0.17525149881839752, -0.03940388187766075] skip-layers: [1, 2, 7, 14, 6]
step:2750/5550 val_loss:3.113462 train_time:684113ms step_avg:248.77ms x-lambda: 0.7715415954589844 lambdas: [-0.008273022249341011, -0.0713224709033966, 0.013309324160218239, -0.17920705676078796, -0.03730093315243721] skip-layers: [1, 2, 7, 14, 6]
step:2875/5550 val_loss:3.104746 train_time:715438ms step_avg:248.85ms x-lambda: 0.771446943283081 lambdas: [-0.008621317334473133, -0.06945327669382095, 0.012224952690303326, -0.1845713108778, -0.037974778562784195] skip-layers: [1, 2, 7, 14, 6]
step:3000/5550 val_loss:3.094264 train_time:746822ms step_avg:248.94ms x-lambda: 0.7726693153381348 lambdas: [-0.01019112765789032, -0.06949078291654587, 0.010451633483171463, -0.18929815292358398, -0.03797274827957153] skip-layers: [1, 2, 7, 14, 6]
step:3125/5550 val_loss:3.082763 train_time:778165ms step_avg:249.01ms x-lambda: 0.774285614490509 lambdas: [-0.0085322055965662, -0.06848561763763428, 0.010659109801054, -0.19394847750663757, -0.03769445791840553] skip-layers: [1, 2, 7, 14, 6]
step:3250/5550 val_loss:3.071655 train_time:809479ms step_avg:249.07ms x-lambda: 0.7794243693351746 lambdas: [-0.007008255459368229, -0.06626541912555695, 0.011797559447586536, -0.19642280042171478, -0.03595319390296936] skip-layers: [1, 2, 7, 14, 6]
step:3375/5550 val_loss:3.062804 train_time:840789ms step_avg:249.12ms x-lambda: 0.7819719314575195 lambdas: [-0.008050232194364071, -0.06709150224924088, 0.010735796764492989, -0.20089974999427795, -0.0355168953537941] skip-layers: [1, 2, 7, 14, 6]
step:3500/5550 val_loss:3.053857 train_time:874282ms step_avg:249.79ms x-lambda: 0.7849656939506531 lambdas: [-0.008336344733834267, -0.065762460231781, 0.00909197237342596, -0.2056356966495514, -0.03683949261903763] skip-layers: [1, 2, 7, 14, 6]
step:3625/5550 val_loss:3.045556 train_time:907535ms step_avg:250.35ms x-lambda: 0.7909975647926331 lambdas: [-0.007897540926933289, -0.06446796655654907, 0.009542597457766533, -0.2093801200389862, -0.03558110445737839] skip-layers: [1, 2, 7, 14, 6]
step:3750/5550 val_loss:3.035605 train_time:938836ms step_avg:250.36ms x-lambda: 0.7939558029174805 lambdas: [-0.007023411802947521, -0.06374796479940414, 0.00936566386371851, -0.21457481384277344, -0.03391729295253754] skip-layers: [1, 2, 7, 14, 6]
step:3875/5550 val_loss:3.026922 train_time:970217ms step_avg:250.38ms x-lambda: 0.8036817908287048 lambdas: [-0.005975274369120598, -0.062458619475364685, 0.00909574143588543, -0.21686804294586182, -0.03431496024131775] skip-layers: [1, 2, 7, 14, 6]
step:4000/5550 val_loss:3.017124 train_time:1001581ms step_avg:250.40ms x-lambda: 0.8105324506759644 lambdas: [-0.007309264037758112, -0.06228528171777725, 0.008667374029755592, -0.2228691428899765, -0.03443939611315727] skip-layers: [1, 2, 7, 14, 6]
step:4125/5550 val_loss:3.007896 train_time:1032986ms step_avg:250.42ms x-lambda: 0.8175109624862671 lambdas: [-0.005731746554374695, -0.062178779393434525, 0.008503691293299198, -0.22726167738437653, -0.033334214240312576] skip-layers: [1, 2, 7, 14, 6]
step:4250/5550 val_loss:2.999885 train_time:1065598ms step_avg:250.73ms x-lambda: 0.8247652053833008 lambdas: [-0.006039968691766262, -0.06050177663564682, 0.008480296470224857, -0.23139336705207825, -0.03393852338194847] skip-layers: [1, 2, 7, 14, 6]
step:4375/5550 val_loss:2.990782 train_time:1097226ms step_avg:250.79ms x-lambda: 0.8318057656288147 lambdas: [-0.0070327045395970345, -0.061484258621931076, 0.007182470988482237, -0.2369321584701538, -0.034280914813280106] skip-layers: [1, 2, 7, 14, 6]
step:4500/5550 val_loss:2.982608 train_time:1128964ms step_avg:250.88ms x-lambda: 0.8406510949134827 lambdas: [-0.005980355199426413, -0.05976566672325134, 0.007076991256326437, -0.2407611906528473, -0.033122241497039795] skip-layers: [1, 2, 7, 14, 6]
step:4625/5550 val_loss:2.973392 train_time:1160802ms step_avg:250.98ms x-lambda: 0.8496694564819336 lambdas: [-0.00587905989959836, -0.06076265871524811, 0.006412825547158718, -0.24348768591880798, -0.03385975584387779] skip-layers: [1, 2, 7, 14, 6]
step:4750/5550 val_loss:2.964116 train_time:1192801ms step_avg:251.12ms x-lambda: 0.8582648634910583 lambdas: [-0.004741381853818893, -0.05957656726241112, 0.0073947906494140625, -0.24780604243278503, -0.03196079283952713] skip-layers: [1, 2, 7, 14, 6]
step:4875/5550 val_loss:2.955197 train_time:1225977ms step_avg:251.48ms x-lambda: 0.8672154545783997 lambdas: [-0.006229929625988007, -0.05754127353429794, 0.005377073306590319, -0.25154849886894226, -0.03210088983178139] skip-layers: [1, 2, 7, 14, 6]
step:5000/5550 val_loss:2.946906 train_time:1261486ms step_avg:252.30ms x-lambda: 0.8764925003051758 lambdas: [-0.005748499650508165, -0.058480050414800644, 0.005693560466170311, -0.25482481718063354, -0.03254401683807373] skip-layers: [1, 2, 7, 14, 6]
step:5125/5550 val_loss:2.939489 train_time:1293851ms step_avg:252.46ms x-lambda: 0.8844574093818665 lambdas: [-0.005809936672449112, -0.058420658111572266, 0.0062799532897770405, -0.2570831775665283, -0.03151644393801689] skip-layers: [1, 2, 7, 14, 6]
step:5250/5550 val_loss:2.932122 train_time:1326419ms step_avg:252.65ms x-lambda: 0.8918430805206299 lambdas: [-0.006045799236744642, -0.05796772986650467, 0.0053195045329630375, -0.260267972946167, -0.030936339870095253] skip-layers: [1, 2, 7, 14, 6]
step:5375/5550 val_loss:2.925663 train_time:1359101ms step_avg:252.86ms x-lambda: 0.8996778130531311 lambdas: [-0.005384922958910465, -0.05799168720841408, 0.00477984081953764, -0.26214247941970825, -0.03054828755557537] skip-layers: [1, 2, 7, 14, 6]
step:5500/5550 val_loss:2.920901 train_time:1392062ms step_avg:253.10ms x-lambda: 0.9049546718597412 lambdas: [-0.005818936973810196, -0.058020368218421936, 0.0045293839648365974, -0.2629895508289337, -0.03060663305222988] skip-layers: [1, 2, 7, 14, 6]
step:5550/5550 val_loss:2.919703 train_time:1405327ms step_avg:253.21ms x-lambda: 0.9058361649513245 lambdas: [-0.005730424076318741, -0.058165278285741806, 0.0040799775160849094, -0.26325786113739014, -0.030755024403333664] skip-layers: [1, 2, 7, 14, 6]

## 8000-add-skip-multiple-6-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3]
step:125/5550 val_loss:4.250829 train_time:28736ms step_avg:229.89ms x-lambda: 1.033126950263977 lambdas: [0.03819969668984413, 0.04900536313652992, 0.03544677421450615, 0.0804249569773674, 0.03713918477296829, -0.04298895224928856] skip-layers: [11, 10, 8, 4, 9, 3]
step:250/5550 val_loss:3.860744 train_time:57614ms step_avg:230.46ms x-lambda: 0.9757651686668396 lambdas: [0.02618071436882019, 0.046886149793863297, 0.0006421408616006374, 0.13489103317260742, -0.008850290440022945, -0.16947518289089203] skip-layers: [11, 10, 8, 4, 9, 3]
step:375/5550 val_loss:3.679593 train_time:86896ms step_avg:231.72ms x-lambda: 0.9624905586242676 lambdas: [0.020817432552576065, 0.02853975258767605, -0.016831884160637856, 0.14759384095668793, -0.0580226331949234, -0.236970454454422] skip-layers: [11, 10, 8, 4, 9, 3]
step:500/5550 val_loss:3.564747 train_time:117621ms step_avg:235.24ms x-lambda: 0.9545560479164124 lambdas: [0.013712515123188496, 0.0061554331332445145, -0.014410052448511124, 0.14980106055736542, -0.09346187114715576, -0.2635490298271179] skip-layers: [11, 10, 8, 4, 9, 3]
step:625/5550 val_loss:3.485771 train_time:147592ms step_avg:236.15ms x-lambda: 0.9382944107055664 lambdas: [0.0013899418991059065, -0.019389191642403603, -0.007536175660789013, 0.146335631608963, -0.12098310142755508, -0.27632397413253784] skip-layers: [11, 10, 8, 4, 9, 3]
step:750/5550 val_loss:3.431468 train_time:177833ms step_avg:237.11ms x-lambda: 0.9270724058151245 lambdas: [-0.010149621404707432, -0.040728285908699036, 0.0016813463298603892, 0.14199383556842804, -0.13418133556842804, -0.2758336663246155] skip-layers: [11, 10, 8, 4, 9, 3]
step:875/5550 val_loss:3.384563 train_time:208172ms step_avg:237.91ms x-lambda: 0.9108914732933044 lambdas: [-0.022101234644651413, -0.05963193625211716, 0.008845847100019455, 0.1373964101076126, -0.13986742496490479, -0.26748543977737427] skip-layers: [11, 10, 8, 4, 9, 3]
step:1000/5550 val_loss:3.348961 train_time:239884ms step_avg:239.88ms x-lambda: 0.894720196723938 lambdas: [-0.0346849262714386, -0.07786599546670914, 0.014791171066462994, 0.1305447369813919, -0.14086389541625977, -0.2558666169643402] skip-layers: [11, 10, 8, 4, 9, 3]
step:1125/5550 val_loss:3.318858 train_time:271717ms step_avg:241.53ms x-lambda: 0.8786095976829529 lambdas: [-0.04690496623516083, -0.09416499733924866, 0.01673963852226734, 0.12271043658256531, -0.13683049380779266, -0.24348682165145874] skip-layers: [11, 10, 8, 4, 9, 3]
step:1250/5550 val_loss:3.293252 train_time:303678ms step_avg:242.94ms x-lambda: 0.8628689050674438 lambdas: [-0.057834379374980927, -0.10768142342567444, 0.020647702738642693, 0.115216463804245, -0.13089878857135773, -0.2304420918226242] skip-layers: [11, 10, 8, 4, 9, 3]
step:1375/5550 val_loss:3.272823 train_time:334646ms step_avg:243.38ms x-lambda: 0.8488704562187195 lambdas: [-0.0667530819773674, -0.11955834180116653, 0.01990850456058979, 0.10995503515005112, -0.12613646686077118, -0.21545492112636566] skip-layers: [11, 10, 8, 4, 9, 3]
step:1500/5550 val_loss:3.252784 train_time:365605ms step_avg:243.74ms x-lambda: 0.8361387252807617 lambdas: [-0.07301764190196991, -0.1291835606098175, 0.0230154637247324, 0.10395447909832001, -0.11909140646457672, -0.20409102737903595] skip-layers: [11, 10, 8, 4, 9, 3]
step:1625/5550 val_loss:3.238015 train_time:396627ms step_avg:244.08ms x-lambda: 0.8219616413116455 lambdas: [-0.08001041412353516, -0.1382140964269638, 0.02491849474608898, 0.09870708733797073, -0.11212849617004395, -0.18992266058921814] skip-layers: [11, 10, 8, 4, 9, 3]
step:1750/5550 val_loss:3.221107 train_time:428607ms step_avg:244.92ms x-lambda: 0.8078513741493225 lambdas: [-0.08675751835107803, -0.1449088156223297, 0.024975012987852097, 0.09062905609607697, -0.10599441826343536, -0.17919033765792847] skip-layers: [11, 10, 8, 4, 9, 3]
step:1875/5550 val_loss:3.203571 train_time:460675ms step_avg:245.69ms x-lambda: 0.7968382239341736 lambdas: [-0.09115913510322571, -0.15108540654182434, 0.02492745779454708, 0.08557707816362381, -0.10190698504447937, -0.1672622561454773] skip-layers: [11, 10, 8, 4, 9, 3]
step:2000/5550 val_loss:3.187862 train_time:494227ms step_avg:247.11ms x-lambda: 0.7870451807975769 lambdas: [-0.09457649290561676, -0.15381193161010742, 0.023852523416280746, 0.08124484866857529, -0.09614567458629608, -0.15671426057815552] skip-layers: [11, 10, 8, 4, 9, 3]
step:2125/5550 val_loss:3.173388 train_time:525558ms step_avg:247.32ms x-lambda: 0.7795859575271606 lambdas: [-0.0982980877161026, -0.15800803899765015, 0.02498144470155239, 0.07686584442853928, -0.09311781078577042, -0.14953045547008514] skip-layers: [11, 10, 8, 4, 9, 3]
step:2250/5550 val_loss:3.159215 train_time:556877ms step_avg:247.50ms x-lambda: 0.7727643251419067 lambdas: [-0.10089657455682755, -0.1602666676044464, 0.02410561963915825, 0.07183488458395004, -0.08961571753025055, -0.14274033904075623] skip-layers: [11, 10, 8, 4, 9, 3]
step:2375/5550 val_loss:3.147516 train_time:588231ms step_avg:247.68ms x-lambda: 0.7658964991569519 lambdas: [-0.10193537175655365, -0.1603744775056839, 0.02522198297083378, 0.069487564265728, -0.08636797219514847, -0.1352665275335312] skip-layers: [11, 10, 8, 4, 9, 3]
step:2500/5550 val_loss:3.136149 train_time:619550ms step_avg:247.82ms x-lambda: 0.7591705322265625 lambdas: [-0.1030658408999443, -0.1613641083240509, 0.022994594648480415, 0.06597673892974854, -0.08382351696491241, -0.13020820915699005] skip-layers: [11, 10, 8, 4, 9, 3]
step:2625/5550 val_loss:3.124444 train_time:653117ms step_avg:248.81ms x-lambda: 0.7518823742866516 lambdas: [-0.10484522581100464, -0.16414985060691833, 0.023135365918278694, 0.06218438223004341, -0.08270768076181412, -0.12536033987998962] skip-layers: [11, 10, 8, 4, 9, 3]
step:2750/5550 val_loss:3.113977 train_time:686497ms step_avg:249.64ms x-lambda: 0.7503790855407715 lambdas: [-0.10487526655197144, -0.1630622148513794, 0.02384776435792446, 0.06262116134166718, -0.07848019897937775, -0.11913435906171799] skip-layers: [11, 10, 8, 4, 9, 3]
step:2875/5550 val_loss:3.104599 train_time:717813ms step_avg:249.67ms x-lambda: 0.745829164981842 lambdas: [-0.10652687400579453, -0.1656046211719513, 0.02444726973772049, 0.058723434805870056, -0.07734911888837814, -0.11488443613052368] skip-layers: [11, 10, 8, 4, 9, 3]
step:3000/5550 val_loss:3.093602 train_time:750331ms step_avg:250.11ms x-lambda: 0.7440170645713806 lambdas: [-0.1055973470211029, -0.1651158630847931, 0.023597214370965958, 0.05765770003199577, -0.07461726665496826, -0.10973405838012695] skip-layers: [11, 10, 8, 4, 9, 3]
step:3125/5550 val_loss:3.082599 train_time:781685ms step_avg:250.14ms x-lambda: 0.7412658333778381 lambdas: [-0.10731856524944305, -0.16810563206672668, 0.022099696099758148, 0.053024206310510635, -0.07527090609073639, -0.1081172302365303] skip-layers: [11, 10, 8, 4, 9, 3]
step:3250/5550 val_loss:3.070750 train_time:813014ms step_avg:250.16ms x-lambda: 0.7406312227249146 lambdas: [-0.10655996948480606, -0.16631528735160828, 0.0230974443256855, 0.052909545600414276, -0.07406152039766312, -0.10474743694067001] skip-layers: [11, 10, 8, 4, 9, 3]
step:3375/5550 val_loss:3.062563 train_time:844338ms step_avg:250.17ms x-lambda: 0.7390940189361572 lambdas: [-0.10830347239971161, -0.1674804389476776, 0.022591492161154747, 0.05197535827755928, -0.07197771221399307, -0.10459573566913605] skip-layers: [11, 10, 8, 4, 9, 3]
step:3500/5550 val_loss:3.053574 train_time:875720ms step_avg:250.21ms x-lambda: 0.73776775598526 lambdas: [-0.1084805279970169, -0.16844940185546875, 0.021997658535838127, 0.04894278943538666, -0.07212697714567184, -0.10036294907331467] skip-layers: [11, 10, 8, 4, 9, 3]
step:3625/5550 val_loss:3.044627 train_time:907057ms step_avg:250.22ms x-lambda: 0.7383222579956055 lambdas: [-0.10743487626314163, -0.1678636223077774, 0.0220131017267704, 0.04730495065450668, -0.0680336058139801, -0.09847962856292725] skip-layers: [11, 10, 8, 4, 9, 3]
step:3750/5550 val_loss:3.034946 train_time:938391ms step_avg:250.24ms x-lambda: 0.7387073040008545 lambdas: [-0.10828607529401779, -0.16809627413749695, 0.023196563124656677, 0.047955457121133804, -0.06884946674108505, -0.0954349935054779] skip-layers: [11, 10, 8, 4, 9, 3]
step:3875/5550 val_loss:3.026143 train_time:969829ms step_avg:250.28ms x-lambda: 0.7431182265281677 lambdas: [-0.10781698673963547, -0.1689077466726303, 0.022229252383112907, 0.047117676585912704, -0.06791741400957108, -0.09294477105140686] skip-layers: [11, 10, 8, 4, 9, 3]
step:4000/5550 val_loss:3.016793 train_time:1002224ms step_avg:250.56ms x-lambda: 0.7444038987159729 lambdas: [-0.10765934735536575, -0.17005452513694763, 0.020518217235803604, 0.04556834697723389, -0.06688177585601807, -0.09190715104341507] skip-layers: [11, 10, 8, 4, 9, 3]
step:4125/5550 val_loss:3.007374 train_time:1034796ms step_avg:250.86ms x-lambda: 0.7465099692344666 lambdas: [-0.10802856832742691, -0.16919772326946259, 0.021946020424365997, 0.04425128549337387, -0.06621621549129486, -0.08959931135177612] skip-layers: [11, 10, 8, 4, 9, 3]
step:4250/5550 val_loss:2.999111 train_time:1066430ms step_avg:250.92ms x-lambda: 0.7510916590690613 lambdas: [-0.10787405073642731, -0.16950936615467072, 0.02178601361811161, 0.0447593554854393, -0.0664108470082283, -0.08894486725330353] skip-layers: [11, 10, 8, 4, 9, 3]
step:4375/5550 val_loss:2.989999 train_time:1098094ms step_avg:250.99ms x-lambda: 0.7520858645439148 lambdas: [-0.10949066281318665, -0.1718755066394806, 0.02132784202694893, 0.04264761880040169, -0.06683360040187836, -0.08866073191165924] skip-layers: [11, 10, 8, 4, 9, 3]
step:4500/5550 val_loss:2.981740 train_time:1129825ms step_avg:251.07ms x-lambda: 0.7564176321029663 lambdas: [-0.10881040245294571, -0.17200186848640442, 0.020505085587501526, 0.04180882126092911, -0.0664115771651268, -0.08634205907583237] skip-layers: [11, 10, 8, 4, 9, 3]
step:4625/5550 val_loss:2.972130 train_time:1161666ms step_avg:251.17ms x-lambda: 0.7630911469459534 lambdas: [-0.10833214968442917, -0.17074543237686157, 0.020100226625800133, 0.040673431009054184, -0.06603579968214035, -0.08599641174077988] skip-layers: [11, 10, 8, 4, 9, 3]
step:4750/5550 val_loss:2.962896 train_time:1193692ms step_avg:251.30ms x-lambda: 0.7673286199569702 lambdas: [-0.10771283507347107, -0.17162862420082092, 0.02063809521496296, 0.04163328558206558, -0.06636146456003189, -0.08379790186882019] skip-layers: [11, 10, 8, 4, 9, 3]
step:4875/5550 val_loss:2.954164 train_time:1225838ms step_avg:251.45ms x-lambda: 0.7720044851303101 lambdas: [-0.10774392634630203, -0.17312198877334595, 0.02013307623565197, 0.04094201326370239, -0.06569333374500275, -0.08310582488775253] skip-layers: [11, 10, 8, 4, 9, 3]
step:5000/5550 val_loss:2.946024 train_time:1260129ms step_avg:252.03ms x-lambda: 0.7786096334457397 lambdas: [-0.10868832468986511, -0.17443716526031494, 0.019127367064356804, 0.040737029165029526, -0.06487441062927246, -0.0831439346075058] skip-layers: [11, 10, 8, 4, 9, 3]
step:5125/5550 val_loss:2.938316 train_time:1292483ms step_avg:252.19ms x-lambda: 0.7826417088508606 lambdas: [-0.10804334282875061, -0.1752168983221054, 0.020326415076851845, 0.040363650768995285, -0.06560693681240082, -0.08192456513643265] skip-layers: [11, 10, 8, 4, 9, 3]
step:5250/5550 val_loss:2.931140 train_time:1327240ms step_avg:252.81ms x-lambda: 0.7873597741127014 lambdas: [-0.1081460565328598, -0.17448332905769348, 0.019334983080625534, 0.038494259119033813, -0.06624019891023636, -0.08079879730939865] skip-layers: [11, 10, 8, 4, 9, 3]
step:5375/5550 val_loss:2.924685 train_time:1359891ms step_avg:253.00ms x-lambda: 0.7923223376274109 lambdas: [-0.10799723863601685, -0.17590194940567017, 0.01884997822344303, 0.03886942192912102, -0.06564079225063324, -0.08052408695220947] skip-layers: [11, 10, 8, 4, 9, 3]
step:5500/5550 val_loss:2.919945 train_time:1392807ms step_avg:253.24ms x-lambda: 0.7957211136817932 lambdas: [-0.10799549520015717, -0.17599202692508698, 0.01873166859149933, 0.039498258382081985, -0.06608309596776962, -0.08083710074424744] skip-layers: [11, 10, 8, 4, 9, 3]
step:5550/5550 val_loss:2.918792 train_time:1406067ms step_avg:253.35ms x-lambda: 0.796420693397522 lambdas: [-0.10792288184165955, -0.17630980908870697, 0.018295420333743095, 0.03944774344563484, -0.06624619662761688, -0.08062966167926788] skip-layers: [11, 10, 8, 4, 9, 3]

## 8000-add-skip-multiple-6-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.18ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5]
step:125/5550 val_loss:4.258719 train_time:29902ms step_avg:239.22ms x-lambda: 1.0544679164886475 lambdas: [0.07520365715026855, 0.011299456469714642, -0.021475326269865036, -0.04004351422190666, 0.09623576700687408, 0.0756116509437561] skip-layers: [0, 1, 2, 3, 4, 5]
step:250/5550 val_loss:3.847583 train_time:58842ms step_avg:235.37ms x-lambda: 1.0178141593933105 lambdas: [0.06434007734060287, -0.02382262423634529, -0.07581879198551178, -0.14015842974185944, 0.1335873156785965, 0.07042110711336136] skip-layers: [0, 1, 2, 3, 4, 5]
step:375/5550 val_loss:3.674549 train_time:88218ms step_avg:235.25ms x-lambda: 0.9856133460998535 lambdas: [0.052988987416028976, -0.028586644679307938, -0.08688871562480927, -0.18827448785305023, 0.1342364400625229, 0.045206621289253235] skip-layers: [0, 1, 2, 3, 4, 5]
step:500/5550 val_loss:3.559206 train_time:117985ms step_avg:235.97ms x-lambda: 0.9466524720191956 lambdas: [0.04767387732863426, -0.02516079694032669, -0.08720605075359344, -0.20857471227645874, 0.13618223369121552, 0.027991684153676033] skip-layers: [0, 1, 2, 3, 4, 5]
step:625/5550 val_loss:3.481535 train_time:147975ms step_avg:236.76ms x-lambda: 0.9006897211074829 lambdas: [0.040796831250190735, -0.02345873787999153, -0.08723147213459015, -0.21820084750652313, 0.13421781361103058, 0.013026082888245583] skip-layers: [0, 1, 2, 3, 4, 5]
step:750/5550 val_loss:3.428847 train_time:178236ms step_avg:237.65ms x-lambda: 0.8680847883224487 lambdas: [0.03781263157725334, -0.01885806955397129, -0.08354871720075607, -0.215293288230896, 0.1334814876317978, 0.0058123767375946045] skip-layers: [0, 1, 2, 3, 4, 5]
step:875/5550 val_loss:3.384390 train_time:208637ms step_avg:238.44ms x-lambda: 0.8317104578018188 lambdas: [0.035610757768154144, -0.014103460125625134, -0.07874730229377747, -0.20790743827819824, 0.13036873936653137, 0.0016909567639231682] skip-layers: [0, 1, 2, 3, 4, 5]
step:1000/5550 val_loss:3.348006 train_time:239277ms step_avg:239.28ms x-lambda: 0.7980313301086426 lambdas: [0.031387995928525925, -0.01297435350716114, -0.07685229927301407, -0.19991202652454376, 0.12112639844417572, -0.004567480646073818] skip-layers: [0, 1, 2, 3, 4, 5]
step:1125/5550 val_loss:3.320190 train_time:269946ms step_avg:239.95ms x-lambda: 0.7696607708930969 lambdas: [0.03026183694601059, -0.009939688257873058, -0.07235540449619293, -0.18648064136505127, 0.11558923125267029, -0.004885395988821983] skip-layers: [0, 1, 2, 3, 4, 5]
step:1250/5550 val_loss:3.295461 train_time:300766ms step_avg:240.61ms x-lambda: 0.7442359328269958 lambdas: [0.029175279662013054, -0.008552223443984985, -0.07019060105085373, -0.1765257865190506, 0.1070089042186737, -0.0059200674295425415] skip-layers: [0, 1, 2, 3, 4, 5]
step:1375/5550 val_loss:3.272658 train_time:335150ms step_avg:243.75ms x-lambda: 0.7174651026725769 lambdas: [0.026253607124090195, -0.007806331384927034, -0.06723207235336304, -0.16529780626296997, 0.09821511059999466, -0.008356711827218533] skip-layers: [0, 1, 2, 3, 4, 5]
step:1500/5550 val_loss:3.256058 train_time:367340ms step_avg:244.89ms x-lambda: 0.6991522312164307 lambdas: [0.023570386692881584, -0.008521154522895813, -0.06696764379739761, -0.1578773558139801, 0.09050127863883972, -0.010510261170566082] skip-layers: [0, 1, 2, 3, 4, 5]
step:1625/5550 val_loss:3.237230 train_time:398421ms step_avg:245.18ms x-lambda: 0.6794345378875732 lambdas: [0.02485269494354725, -0.007295516785234213, -0.06337501108646393, -0.146635964512825, 0.08585458993911743, -0.009394621476531029] skip-layers: [0, 1, 2, 3, 4, 5]
step:1750/5550 val_loss:3.223347 train_time:431551ms step_avg:246.60ms x-lambda: 0.6622810959815979 lambdas: [0.02323818765580654, -0.004492397420108318, -0.05935060605406761, -0.1363229751586914, 0.08178602159023285, -0.009007730521261692] skip-layers: [0, 1, 2, 3, 4, 5]
step:1875/5550 val_loss:3.204090 train_time:463794ms step_avg:247.36ms x-lambda: 0.6492777466773987 lambdas: [0.02118838019669056, -0.005436320323497057, -0.05908592417836189, -0.13040271401405334, 0.07497135549783707, -0.011048449203372002] skip-layers: [0, 1, 2, 3, 4, 5]
step:2000/5550 val_loss:3.188531 train_time:497201ms step_avg:248.60ms x-lambda: 0.6364184617996216 lambdas: [0.020730286836624146, -0.0033470888156443834, -0.056549157947301865, -0.12163034081459045, 0.07120389491319656, -0.009730988182127476] skip-layers: [0, 1, 2, 3, 4, 5]
step:2125/5550 val_loss:3.173970 train_time:529773ms step_avg:249.30ms x-lambda: 0.6296896934509277 lambdas: [0.019524255767464638, -0.003174230456352234, -0.05547468736767769, -0.11674001812934875, 0.06704361736774445, -0.010758426040410995] skip-layers: [0, 1, 2, 3, 4, 5]
step:2250/5550 val_loss:3.159744 train_time:561120ms step_avg:249.39ms x-lambda: 0.6208072304725647 lambdas: [0.019100811332464218, -0.0037269634194672108, -0.054094038903713226, -0.11011931300163269, 0.06351857632398605, -0.010927889496088028] skip-layers: [0, 1, 2, 3, 4, 5]
step:2375/5550 val_loss:3.148236 train_time:593581ms step_avg:249.93ms x-lambda: 0.6157909631729126 lambdas: [0.01921083778142929, -0.003129442920908332, -0.05152422934770584, -0.10369031131267548, 0.06070539355278015, -0.010613851249217987] skip-layers: [0, 1, 2, 3, 4, 5]
step:2500/5550 val_loss:3.137250 train_time:624953ms step_avg:249.98ms x-lambda: 0.608447790145874 lambdas: [0.019795365631580353, -0.001651240629144013, -0.05111294239759445, -0.09938115626573563, 0.05841594561934471, -0.010703688487410545] skip-layers: [0, 1, 2, 3, 4, 5]
step:2625/5550 val_loss:3.126100 train_time:656321ms step_avg:250.03ms x-lambda: 0.6063901782035828 lambdas: [0.019571779295802116, -0.002022789791226387, -0.04985639080405235, -0.09509875625371933, 0.0556558258831501, -0.010536662302911282] skip-layers: [0, 1, 2, 3, 4, 5]
step:2750/5550 val_loss:3.114638 train_time:689768ms step_avg:250.82ms x-lambda: 0.6023033857345581 lambdas: [0.017359307035803795, -0.0011199741857126355, -0.04875370115041733, -0.09277310222387314, 0.054394278675317764, -0.010357001796364784] skip-layers: [0, 1, 2, 3, 4, 5]
step:2875/5550 val_loss:3.105107 train_time:723169ms step_avg:251.54ms x-lambda: 0.5995983481407166 lambdas: [0.019252007827162743, -0.001255690585821867, -0.047915019094944, -0.0894615575671196, 0.051306646317243576, -0.011507431976497173] skip-layers: [0, 1, 2, 3, 4, 5]
step:3000/5550 val_loss:3.093924 train_time:755525ms step_avg:251.84ms x-lambda: 0.5995232462882996 lambdas: [0.017121020704507828, -0.002269984921440482, -0.04728947952389717, -0.08622564375400543, 0.04960937052965164, -0.011128743179142475] skip-layers: [0, 1, 2, 3, 4, 5]
step:3125/5550 val_loss:3.083539 train_time:786945ms step_avg:251.82ms x-lambda: 0.5962681174278259 lambdas: [0.01666252873837948, -0.0035111154429614544, -0.04802759736776352, -0.08617694675922394, 0.04735461622476578, -0.011881198734045029] skip-layers: [0, 1, 2, 3, 4, 5]
step:3250/5550 val_loss:3.071595 train_time:819401ms step_avg:252.12ms x-lambda: 0.5990428328514099 lambdas: [0.016394276171922684, -0.0014514961512759328, -0.0468427911400795, -0.08096636086702347, 0.04596400633454323, -0.010665744543075562] skip-layers: [0, 1, 2, 3, 4, 5]
step:3375/5550 val_loss:3.063235 train_time:850757ms step_avg:252.08ms x-lambda: 0.5988949537277222 lambdas: [0.01454857736825943, -0.0020776260644197464, -0.0472138449549675, -0.08163869380950928, 0.045207805931568146, -0.012269465252757072] skip-layers: [0, 1, 2, 3, 4, 5]
step:3500/5550 val_loss:3.053964 train_time:882136ms step_avg:252.04ms x-lambda: 0.599238932132721 lambdas: [0.015746450051665306, -0.001561923767440021, -0.04540302976965904, -0.07832834869623184, 0.04364412650465965, -0.01179205346852541] skip-layers: [0, 1, 2, 3, 4, 5]
step:3625/5550 val_loss:3.045453 train_time:914571ms step_avg:252.30ms x-lambda: 0.6032409071922302 lambdas: [0.0162761602550745, -0.000901660299859941, -0.04512635990977287, -0.07627461850643158, 0.044365886598825455, -0.01189380045980215] skip-layers: [0, 1, 2, 3, 4, 5]
step:3750/5550 val_loss:3.035735 train_time:947119ms step_avg:252.57ms x-lambda: 0.6027234196662903 lambdas: [0.017204467207193375, -0.001857380149886012, -0.044003602117300034, -0.073697030544281, 0.044307827949523926, -0.010719853453338146] skip-layers: [0, 1, 2, 3, 4, 5]
step:3875/5550 val_loss:3.026767 train_time:978571ms step_avg:252.53ms x-lambda: 0.6100325584411621 lambdas: [0.016283152624964714, -0.001754064578562975, -0.044099658727645874, -0.07375607639551163, 0.041902389377355576, -0.012300756759941578] skip-layers: [0, 1, 2, 3, 4, 5]
step:4000/5550 val_loss:3.017338 train_time:1009970ms step_avg:252.49ms x-lambda: 0.6144707798957825 lambdas: [0.01660999096930027, -0.0007008550455793738, -0.04228878393769264, -0.07207349687814713, 0.04135484620928764, -0.010850480757653713] skip-layers: [0, 1, 2, 3, 4, 5]
step:4125/5550 val_loss:3.008173 train_time:1044820ms step_avg:253.29ms x-lambda: 0.6189597249031067 lambdas: [0.016386352479457855, -0.0007941952208057046, -0.04418075829744339, -0.07045560330152512, 0.03933876007795334, -0.011393271386623383] skip-layers: [0, 1, 2, 3, 4, 5]
step:4250/5550 val_loss:2.999805 train_time:1079503ms step_avg:254.00ms x-lambda: 0.6229477524757385 lambdas: [0.015336957760155201, -0.0021551342215389013, -0.04262427240610123, -0.06879691034555435, 0.040177375078201294, -0.011234859935939312] skip-layers: [0, 1, 2, 3, 4, 5]
step:4375/5550 val_loss:2.990596 train_time:1111183ms step_avg:253.98ms x-lambda: 0.6272956728935242 lambdas: [0.015751736238598824, -0.002442479133605957, -0.04336179047822952, -0.06946518272161484, 0.038991108536720276, -0.012739043682813644] skip-layers: [0, 1, 2, 3, 4, 5]
step:4500/5550 val_loss:2.982280 train_time:1143829ms step_avg:254.18ms x-lambda: 0.634532630443573 lambdas: [0.015514892525970936, -0.001870626350864768, -0.04261685162782669, -0.0679519847035408, 0.038418594747781754, -0.01228057686239481] skip-layers: [0, 1, 2, 3, 4, 5]
step:4625/5550 val_loss:2.972938 train_time:1178833ms step_avg:254.88ms x-lambda: 0.6417983770370483 lambdas: [0.015303634107112885, -0.0019424828933551908, -0.041834231466054916, -0.06706196814775467, 0.03755267709493637, -0.01330077275633812] skip-layers: [0, 1, 2, 3, 4, 5]
step:4750/5550 val_loss:2.963687 train_time:1211876ms step_avg:255.13ms x-lambda: 0.6479466557502747 lambdas: [0.015909772366285324, -0.0003123011556454003, -0.04226363077759743, -0.06603848189115524, 0.03842509165406227, -0.011990776285529137] skip-layers: [0, 1, 2, 3, 4, 5]
step:4875/5550 val_loss:2.954700 train_time:1244037ms step_avg:255.19ms x-lambda: 0.6551976203918457 lambdas: [0.014490154571831226, -0.0010536650661379099, -0.0422808900475502, -0.06557174772024155, 0.038125935941934586, -0.012887044809758663] skip-layers: [0, 1, 2, 3, 4, 5]
step:5000/5550 val_loss:2.946549 train_time:1276289ms step_avg:255.26ms x-lambda: 0.6631085276603699 lambdas: [0.014232886955142021, -0.0018249998101964593, -0.04172659292817116, -0.06571323424577713, 0.03779338672757149, -0.01264901366084814] skip-layers: [0, 1, 2, 3, 4, 5]
step:5125/5550 val_loss:2.939085 train_time:1309495ms step_avg:255.51ms x-lambda: 0.6712216734886169 lambdas: [0.014956844970583916, -0.0007254958618432283, -0.040848951786756516, -0.06331824511289597, 0.03709490969777107, -0.012557180598378181] skip-layers: [0, 1, 2, 3, 4, 5]
step:5250/5550 val_loss:2.931956 train_time:1343171ms step_avg:255.84ms x-lambda: 0.6793973445892334 lambdas: [0.014415006153285503, -0.0015447938349097967, -0.04170873388648033, -0.06325002759695053, 0.03708993270993233, -0.012395900674164295] skip-layers: [0, 1, 2, 3, 4, 5]
step:5375/5550 val_loss:2.925385 train_time:1375917ms step_avg:255.98ms x-lambda: 0.6873171925544739 lambdas: [0.014862826094031334, -0.0014133010990917683, -0.04115946218371391, -0.06338510662317276, 0.03634290769696236, -0.013209622353315353] skip-layers: [0, 1, 2, 3, 4, 5]
step:5500/5550 val_loss:2.920556 train_time:1408881ms step_avg:256.16ms x-lambda: 0.6930859684944153 lambdas: [0.014286722987890244, -0.0007366929785348475, -0.04140741005539894, -0.06355103850364685, 0.03650927543640137, -0.01251260470598936] skip-layers: [0, 1, 2, 3, 4, 5]
step:5550/5550 val_loss:2.919378 train_time:1422147ms step_avg:256.24ms x-lambda: 0.6941905617713928 lambdas: [0.014512328431010246, -0.001000307034701109, -0.04167475551366806, -0.06325193494558334, 0.036438051611185074, -0.012904767878353596] skip-layers: [0, 1, 2, 3, 4, 5]

## 8000-add-skip-multiple-6-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [8, 5, 2, 12, 11, 7]
step:125/5550 val_loss:4.272930 train_time:29757ms step_avg:238.06ms x-lambda: 1.094300627708435 lambdas: [0.009712085127830505, -0.01805429346859455, -0.019294770434498787, 0.07861964404582977, 0.016954924911260605, 0.03282582387328148] skip-layers: [8, 5, 2, 12, 11, 7]
step:250/5550 val_loss:3.854186 train_time:58729ms step_avg:234.92ms x-lambda: 1.0630686283111572 lambdas: [-0.009941520169377327, -0.00695948489010334, -0.056623443961143494, 0.008126440457999706, -0.00020011013839393854, 0.010221341624855995] skip-layers: [8, 5, 2, 12, 11, 7]
step:375/5550 val_loss:3.678921 train_time:88064ms step_avg:234.84ms x-lambda: 1.0110512971878052 lambdas: [-0.013642393983900547, -0.0019211478065699339, -0.04963664337992668, -0.01785174012184143, -0.009018114767968655, -0.004255669191479683] skip-layers: [8, 5, 2, 12, 11, 7]
step:500/5550 val_loss:3.560470 train_time:117847ms step_avg:235.69ms x-lambda: 0.9621443748474121 lambdas: [-0.01797429658472538, -0.007983329705893993, -0.04778365418314934, -0.0332803837954998, -0.01595199480652809, -0.013445781543850899] skip-layers: [8, 5, 2, 12, 11, 7]
step:625/5550 val_loss:3.482316 train_time:147847ms step_avg:236.56ms x-lambda: 0.9153035283088684 lambdas: [-0.01814386248588562, -0.009727573953568935, -0.04187753051519394, -0.03561290726065636, -0.015594281256198883, -0.013593168929219246] skip-layers: [8, 5, 2, 12, 11, 7]
step:750/5550 val_loss:3.429989 train_time:178132ms step_avg:237.51ms x-lambda: 0.8694400787353516 lambdas: [-0.017123794183135033, -0.01160498894751072, -0.03819961100816727, -0.03430983051657677, -0.015126732178032398, -0.014204036444425583] skip-layers: [8, 5, 2, 12, 11, 7]
step:875/5550 val_loss:3.384372 train_time:210546ms step_avg:240.62ms x-lambda: 0.8251567482948303 lambdas: [-0.01702270656824112, -0.01182524673640728, -0.035167478024959564, -0.032575156539678574, -0.015371057204902172, -0.013535491190850735] skip-layers: [8, 5, 2, 12, 11, 7]
step:1000/5550 val_loss:3.349072 train_time:241201ms step_avg:241.20ms x-lambda: 0.7913911938667297 lambdas: [-0.01413806714117527, -0.009750306606292725, -0.02981720305979252, -0.030103184282779694, -0.01307303924113512, -0.012524724937975407] skip-layers: [8, 5, 2, 12, 11, 7]
step:1125/5550 val_loss:3.319848 train_time:271919ms step_avg:241.71ms x-lambda: 0.7602896094322205 lambdas: [-0.015277438797056675, -0.010795840062201023, -0.027612611651420593, -0.028125930577516556, -0.012657353654503822, -0.011089520528912544] skip-layers: [8, 5, 2, 12, 11, 7]
step:1250/5550 val_loss:3.294956 train_time:305057ms step_avg:244.05ms x-lambda: 0.7341574430465698 lambdas: [-0.013501960784196854, -0.008783940225839615, -0.024282433092594147, -0.0259360633790493, -0.011072428897023201, -0.009690748527646065] skip-layers: [8, 5, 2, 12, 11, 7]
step:1375/5550 val_loss:3.273375 train_time:336049ms step_avg:244.40ms x-lambda: 0.7098474502563477 lambdas: [-0.013081851415336132, -0.009747090749442577, -0.02296002395451069, -0.024313433095812798, -0.011559656821191311, -0.009858591482043266] skip-layers: [8, 5, 2, 12, 11, 7]
step:1500/5550 val_loss:3.256751 train_time:368105ms step_avg:245.40ms x-lambda: 0.6884443163871765 lambdas: [-0.014987833797931671, -0.011278349906206131, -0.02320508286356926, -0.0253825131803751, -0.012372837401926517, -0.011147079057991505] skip-layers: [8, 5, 2, 12, 11, 7]
step:1625/5550 val_loss:3.238516 train_time:399185ms step_avg:245.65ms x-lambda: 0.671080470085144 lambdas: [-0.011151662096381187, -0.007445833645761013, -0.01949976570904255, -0.022309182211756706, -0.010271682403981686, -0.008327968418598175] skip-layers: [8, 5, 2, 12, 11, 7]
step:1750/5550 val_loss:3.224246 train_time:430249ms step_avg:245.86ms x-lambda: 0.652800440788269 lambdas: [-0.012721400707960129, -0.009282024577260017, -0.019352583214640617, -0.02373635768890381, -0.011630671098828316, -0.010499303229153156] skip-layers: [8, 5, 2, 12, 11, 7]
step:1875/5550 val_loss:3.205731 train_time:464745ms step_avg:247.86ms x-lambda: 0.6423571109771729 lambdas: [-0.010898344218730927, -0.007144305855035782, -0.015757441520690918, -0.01890985108911991, -0.007997285574674606, -0.007527771405875683] skip-layers: [8, 5, 2, 12, 11, 7]
step:2000/5550 val_loss:3.189577 train_time:496117ms step_avg:248.06ms x-lambda: 0.6295129656791687 lambdas: [-0.009679976850748062, -0.006778151728212833, -0.01638474129140377, -0.018191881477832794, -0.00878671184182167, -0.006936573423445225] skip-layers: [8, 5, 2, 12, 11, 7]
step:2125/5550 val_loss:3.174750 train_time:530757ms step_avg:249.77ms x-lambda: 0.6199131011962891 lambdas: [-0.010929415933787823, -0.008265037089586258, -0.01613912545144558, -0.01950986683368683, -0.008603443391621113, -0.008114814758300781] skip-layers: [8, 5, 2, 12, 11, 7]
step:2250/5550 val_loss:3.160186 train_time:562107ms step_avg:249.83ms x-lambda: 0.6125844717025757 lambdas: [-0.01010081171989441, -0.007621404714882374, -0.015152025036513805, -0.018585069105029106, -0.008563264273107052, -0.00857638567686081] skip-layers: [8, 5, 2, 12, 11, 7]
step:2375/5550 val_loss:3.149300 train_time:593504ms step_avg:249.90ms x-lambda: 0.6083619594573975 lambdas: [-0.009557281620800495, -0.005973289720714092, -0.013252037577331066, -0.016943521797657013, -0.007255240809172392, -0.006829858757555485] skip-layers: [8, 5, 2, 12, 11, 7]
step:2500/5550 val_loss:3.136544 train_time:624905ms step_avg:249.96ms x-lambda: 0.6032947897911072 lambdas: [-0.009713171981275082, -0.006279573775827885, -0.012726735323667526, -0.017372025176882744, -0.007629784289747477, -0.006404094863682985] skip-layers: [8, 5, 2, 12, 11, 7]
step:2625/5550 val_loss:3.125393 train_time:657281ms step_avg:250.39ms x-lambda: 0.5997928380966187 lambdas: [-0.008674219250679016, -0.006442185025662184, -0.011525195091962814, -0.01618964970111847, -0.007591008674353361, -0.00707938801497221] skip-layers: [8, 5, 2, 12, 11, 7]
step:2750/5550 val_loss:3.114543 train_time:689814ms step_avg:250.84ms x-lambda: 0.5951456427574158 lambdas: [-0.009044921025633812, -0.007118476089090109, -0.012017972767353058, -0.015676595270633698, -0.007465003523975611, -0.007773899473249912] skip-layers: [8, 5, 2, 12, 11, 7]
step:2875/5550 val_loss:3.104955 train_time:721168ms step_avg:250.84ms x-lambda: 0.593695878982544 lambdas: [-0.008872448466718197, -0.006508390884846449, -0.011424330063164234, -0.01497261319309473, -0.006338906940072775, -0.007191597484052181] skip-layers: [8, 5, 2, 12, 11, 7]
step:3000/5550 val_loss:3.094144 train_time:753583ms step_avg:251.19ms x-lambda: 0.5947064161300659 lambdas: [-0.008991502225399017, -0.0048108468763530254, -0.011966235935688019, -0.014890133403241634, -0.00693892315030098, -0.005543493665754795] skip-layers: [8, 5, 2, 12, 11, 7]
step:3125/5550 val_loss:3.083104 train_time:785962ms step_avg:251.51ms x-lambda: 0.5910763144493103 lambdas: [-0.00837453082203865, -0.006683654617518187, -0.010521951131522655, -0.01518841739743948, -0.007857279852032661, -0.006759453099220991] skip-layers: [8, 5, 2, 12, 11, 7]
step:3250/5550 val_loss:3.071845 train_time:819355ms step_avg:252.11ms x-lambda: 0.5935603976249695 lambdas: [-0.008277330547571182, -0.0052568609826266766, -0.01057418156415224, -0.014812813140451908, -0.007442535366863012, -0.0062775686383247375] skip-layers: [8, 5, 2, 12, 11, 7]
step:3375/5550 val_loss:3.063809 train_time:850691ms step_avg:252.06ms x-lambda: 0.5923269391059875 lambdas: [-0.00834975391626358, -0.005963051691651344, -0.012723018415272236, -0.014319266192615032, -0.007669875398278236, -0.005321606062352657] skip-layers: [8, 5, 2, 12, 11, 7]
step:3500/5550 val_loss:3.054515 train_time:883150ms step_avg:252.33ms x-lambda: 0.5926254391670227 lambdas: [-0.009160928428173065, -0.006435112562030554, -0.010925468988716602, -0.014991634525358677, -0.00843935925513506, -0.007949532940983772] skip-layers: [8, 5, 2, 12, 11, 7]
step:3625/5550 val_loss:3.045155 train_time:914521ms step_avg:252.28ms x-lambda: 0.5966256856918335 lambdas: [-0.0075542256236076355, -0.005472699645906687, -0.010197213850915432, -0.014136203564703465, -0.0068310038186609745, -0.005536718759685755] skip-layers: [8, 5, 2, 12, 11, 7]
step:3750/5550 val_loss:3.036063 train_time:945877ms step_avg:252.23ms x-lambda: 0.5978828072547913 lambdas: [-0.008082459680736065, -0.005187028553336859, -0.009579614736139774, -0.014480742625892162, -0.006685723550617695, -0.00661119818687439] skip-layers: [8, 5, 2, 12, 11, 7]
step:3875/5550 val_loss:3.027287 train_time:977339ms step_avg:252.22ms x-lambda: 0.6054086685180664 lambdas: [-0.00818842276930809, -0.005485977046191692, -0.009722989052534103, -0.01371331699192524, -0.006847870536148548, -0.005372210405766964] skip-layers: [8, 5, 2, 12, 11, 7]
step:4000/5550 val_loss:3.017235 train_time:1008736ms step_avg:252.18ms x-lambda: 0.6086443662643433 lambdas: [-0.008323322981595993, -0.005141019821166992, -0.009778597392141819, -0.01277216523885727, -0.0069961994886398315, -0.0053843301720917225] skip-layers: [8, 5, 2, 12, 11, 7]
step:4125/5550 val_loss:3.008552 train_time:1040213ms step_avg:252.17ms x-lambda: 0.6123164892196655 lambdas: [-0.007646291516721249, -0.004071416798979044, -0.009361044503748417, -0.012137816287577152, -0.005762971471995115, -0.005981598049402237] skip-layers: [8, 5, 2, 12, 11, 7]
step:4250/5550 val_loss:2.999877 train_time:1071829ms step_avg:252.20ms x-lambda: 0.6172221899032593 lambdas: [-0.007239997386932373, -0.005321837961673737, -0.009851576760411263, -0.012813934125006199, -0.006074969656765461, -0.005573544185608625] skip-layers: [8, 5, 2, 12, 11, 7]
step:4375/5550 val_loss:2.991250 train_time:1104678ms step_avg:252.50ms x-lambda: 0.618969202041626 lambdas: [-0.007943425327539444, -0.005309759639203548, -0.010460938327014446, -0.014269322156906128, -0.0071302372962236404, -0.0062915184535086155] skip-layers: [8, 5, 2, 12, 11, 7]
step:4500/5550 val_loss:2.982638 train_time:1136405ms step_avg:252.53ms x-lambda: 0.62581866979599 lambdas: [-0.007053806446492672, -0.005210477393120527, -0.009145243093371391, -0.012117474339902401, -0.006801866460591555, -0.006707748863846064] skip-layers: [8, 5, 2, 12, 11, 7]
step:4625/5550 val_loss:2.973364 train_time:1169363ms step_avg:252.84ms x-lambda: 0.6347512602806091 lambdas: [-0.008582975715398788, -0.006422239355742931, -0.010154136456549168, -0.01274043321609497, -0.006437827832996845, -0.006013407837599516] skip-layers: [8, 5, 2, 12, 11, 7]
step:4750/5550 val_loss:2.964018 train_time:1203561ms step_avg:253.38ms x-lambda: 0.6399840712547302 lambdas: [-0.006946844048798084, -0.0044694021344184875, -0.007459759712219238, -0.01237424835562706, -0.004263509996235371, -0.0054160309955477715] skip-layers: [8, 5, 2, 12, 11, 7]
step:4875/5550 val_loss:2.955165 train_time:1236574ms step_avg:253.66ms x-lambda: 0.6472204327583313 lambdas: [-0.007858655415475368, -0.0045479475520551205, -0.008575566112995148, -0.011504734866321087, -0.005727964919060469, -0.005240510683506727] skip-layers: [8, 5, 2, 12, 11, 7]
step:5000/5550 val_loss:2.946985 train_time:1272176ms step_avg:254.44ms x-lambda: 0.6549294590950012 lambdas: [-0.007067549508064985, -0.004435280337929726, -0.008310665376484394, -0.01242705900222063, -0.006492427084594965, -0.006132054608315229] skip-layers: [8, 5, 2, 12, 11, 7]
step:5125/5550 val_loss:2.939206 train_time:1305743ms step_avg:254.78ms x-lambda: 0.6622960567474365 lambdas: [-0.00673421286046505, -0.005184101406484842, -0.007875884883105755, -0.012067338451743126, -0.006001909729093313, -0.005150054581463337] skip-layers: [8, 5, 2, 12, 11, 7]
step:5250/5550 val_loss:2.932095 train_time:1338326ms step_avg:254.92ms x-lambda: 0.6694579124450684 lambdas: [-0.0071677458472549915, -0.0048657795414328575, -0.008251413702964783, -0.011622212827205658, -0.005405812989920378, -0.005871743895113468] skip-layers: [8, 5, 2, 12, 11, 7]
step:5375/5550 val_loss:2.925655 train_time:1372219ms step_avg:255.30ms x-lambda: 0.6779379844665527 lambdas: [-0.007493474055081606, -0.004391348455101252, -0.007237114943563938, -0.012184282764792442, -0.006150792818516493, -0.005526290740817785] skip-layers: [8, 5, 2, 12, 11, 7]
step:5500/5550 val_loss:2.920841 train_time:1407286ms step_avg:255.87ms x-lambda: 0.6828557252883911 lambdas: [-0.007759396918118, -0.004754122346639633, -0.007594431284815073, -0.012246811762452126, -0.005576299969106913, -0.005725497845560312] skip-layers: [8, 5, 2, 12, 11, 7]
step:5550/5550 val_loss:2.919645 train_time:1420551ms step_avg:255.96ms x-lambda: 0.6840049028396606 lambdas: [-0.00722518702968955, -0.004761979915201664, -0.008234974928200245, -0.011924258433282375, -0.005739364307373762, -0.00594092532992363] skip-layers: [8, 5, 2, 12, 11, 7]

## 8000-add-skip-multiple-6-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5]
step:125/5550 val_loss:4.269403 train_time:28792ms step_avg:230.34ms x-lambda: 1.0415891408920288 lambdas: [0.03249349445104599, -0.01463531143963337, 0.0466734915971756, 0.037076130509376526, 0.04837318882346153, 0.060773782432079315] skip-layers: [1, 2, 7, 14, 6, 5]
step:250/5550 val_loss:3.854610 train_time:58934ms step_avg:235.74ms x-lambda: 1.0038065910339355 lambdas: [-0.012606058269739151, -0.10757119953632355, 0.038885585963726044, 0.025171294808387756, 0.02167556621134281, 0.06122355908155441] skip-layers: [1, 2, 7, 14, 6, 5]
step:375/5550 val_loss:3.672246 train_time:88375ms step_avg:235.67ms x-lambda: 0.9732498526573181 lambdas: [-0.020299702882766724, -0.14801210165023804, 0.029800986871123314, 0.023591173812747, -0.011311681009829044, 0.04192236810922623] skip-layers: [1, 2, 7, 14, 6, 5]
step:500/5550 val_loss:3.557246 train_time:118242ms step_avg:236.48ms x-lambda: 0.9476670622825623 lambdas: [-0.017605481669306755, -0.16867420077323914, 0.028114493936300278, 0.014113928191363811, -0.03276297077536583, 0.02915177121758461] skip-layers: [1, 2, 7, 14, 6, 5]
step:625/5550 val_loss:3.479514 train_time:148320ms step_avg:237.31ms x-lambda: 0.9197843074798584 lambdas: [-0.013477630913257599, -0.18263699114322662, 0.027174733579158783, -0.0019047318492084742, -0.04661594703793526, 0.021762918680906296] skip-layers: [1, 2, 7, 14, 6, 5]
step:750/5550 val_loss:3.427412 train_time:179599ms step_avg:239.47ms x-lambda: 0.8993679881095886 lambdas: [-0.007127986755222082, -0.1878795027732849, 0.027688778936862946, -0.01440154854208231, -0.051973797380924225, 0.019300410524010658] skip-layers: [1, 2, 7, 14, 6, 5]
step:875/5550 val_loss:3.381182 train_time:210036ms step_avg:240.04ms x-lambda: 0.8757450580596924 lambdas: [-0.0012553639244288206, -0.18679136037826538, 0.027075152844190598, -0.029317550361156464, -0.054318781942129135, 0.01707308739423752] skip-layers: [1, 2, 7, 14, 6, 5]
step:1000/5550 val_loss:3.346930 train_time:240704ms step_avg:240.70ms x-lambda: 0.8553991913795471 lambdas: [0.004729380831122398, -0.1833684891462326, 0.026368172839283943, -0.04274750128388405, -0.0546821728348732, 0.01694333925843239] skip-layers: [1, 2, 7, 14, 6, 5]
step:1125/5550 val_loss:3.317825 train_time:272264ms step_avg:242.01ms x-lambda: 0.8365466594696045 lambdas: [0.005690924823284149, -0.1798633337020874, 0.023699263110756874, -0.05688267573714256, -0.05676841363310814, 0.013773265294730663] skip-layers: [1, 2, 7, 14, 6, 5]
step:1250/5550 val_loss:3.294852 train_time:303095ms step_avg:242.48ms x-lambda: 0.8227558135986328 lambdas: [0.009440310299396515, -0.17298489809036255, 0.025814516469836235, -0.06689904630184174, -0.054308902472257614, 0.015147756785154343] skip-layers: [1, 2, 7, 14, 6, 5]
step:1375/5550 val_loss:3.273273 train_time:339305ms step_avg:246.77ms x-lambda: 0.8061983585357666 lambdas: [0.011330080218613148, -0.16590915620326996, 0.02217208966612816, -0.07740044593811035, -0.05526835098862648, 0.012337224557995796] skip-layers: [1, 2, 7, 14, 6, 5]
step:1500/5550 val_loss:3.255207 train_time:370302ms step_avg:246.87ms x-lambda: 0.7927370071411133 lambdas: [0.009524372406303883, -0.16201061010360718, 0.02002507634460926, -0.08784947544336319, -0.057579487562179565, 0.009010049514472485] skip-layers: [1, 2, 7, 14, 6, 5]
step:1625/5550 val_loss:3.236858 train_time:401391ms step_avg:247.01ms x-lambda: 0.781967282295227 lambdas: [0.012240896001458168, -0.15286748111248016, 0.022187614813447, -0.09417986869812012, -0.05332307517528534, 0.011044956743717194] skip-layers: [1, 2, 7, 14, 6, 5]
step:1750/5550 val_loss:3.220899 train_time:432469ms step_avg:247.13ms x-lambda: 0.7680599689483643 lambdas: [0.011720461770892143, -0.14836353063583374, 0.02017112262547016, -0.10483893752098083, -0.05322927236557007, 0.009438099339604378] skip-layers: [1, 2, 7, 14, 6, 5]
step:1875/5550 val_loss:3.204568 train_time:463594ms step_avg:247.25ms x-lambda: 0.7635996341705322 lambdas: [0.013193274848163128, -0.14135600626468658, 0.021778544411063194, -0.10889466851949692, -0.05073678120970726, 0.011398534290492535] skip-layers: [1, 2, 7, 14, 6, 5]
step:2000/5550 val_loss:3.188037 train_time:496103ms step_avg:248.05ms x-lambda: 0.7543957233428955 lambdas: [0.01302720420062542, -0.13603489100933075, 0.019172269850969315, -0.1176697239279747, -0.05023423582315445, 0.010349778458476067] skip-layers: [1, 2, 7, 14, 6, 5]
step:2125/5550 val_loss:3.173668 train_time:528576ms step_avg:248.74ms x-lambda: 0.750275731086731 lambdas: [0.012530959211289883, -0.13216672837734222, 0.01808706857264042, -0.12316662073135376, -0.04963649436831474, 0.009125069715082645] skip-layers: [1, 2, 7, 14, 6, 5]
step:2250/5550 val_loss:3.159450 train_time:559945ms step_avg:248.86ms x-lambda: 0.7464059591293335 lambdas: [0.012401429936289787, -0.1275145560503006, 0.017813241109251976, -0.12898658215999603, -0.049823105335235596, 0.00773194245994091] skip-layers: [1, 2, 7, 14, 6, 5]
step:2375/5550 val_loss:3.148345 train_time:591362ms step_avg:248.99ms x-lambda: 0.7427549362182617 lambdas: [0.012862504459917545, -0.12321962416172028, 0.017075615003705025, -0.13475589454174042, -0.047614455223083496, 0.007402168586850166] skip-layers: [1, 2, 7, 14, 6, 5]
step:2500/5550 val_loss:3.136763 train_time:622732ms step_avg:249.09ms x-lambda: 0.74275803565979 lambdas: [0.01377827674150467, -0.11937553435564041, 0.016469363123178482, -0.13818563520908356, -0.044890254735946655, 0.007214363664388657] skip-layers: [1, 2, 7, 14, 6, 5]
step:2625/5550 val_loss:3.125214 train_time:656410ms step_avg:250.06ms x-lambda: 0.7396869659423828 lambdas: [0.012548481114208698, -0.1168932169675827, 0.014757339842617512, -0.14346952736377716, -0.04655659943819046, 0.0077192834578454494] skip-layers: [1, 2, 7, 14, 6, 5]
step:2750/5550 val_loss:3.114544 train_time:687751ms step_avg:250.09ms x-lambda: 0.7404573559761047 lambdas: [0.013944774866104126, -0.11324696987867355, 0.016532685607671738, -0.146832674741745, -0.04314982891082764, 0.008405586704611778] skip-layers: [1, 2, 7, 14, 6, 5]
step:2875/5550 val_loss:3.104820 train_time:719088ms step_avg:250.12ms x-lambda: 0.7408413290977478 lambdas: [0.012802427634596825, -0.10908408463001251, 0.014414601027965546, -0.15104258060455322, -0.043476544320583344, 0.007576419971883297] skip-layers: [1, 2, 7, 14, 6, 5]
step:3000/5550 val_loss:3.094259 train_time:750492ms step_avg:250.16ms x-lambda: 0.7416697144508362 lambdas: [0.01162679959088564, -0.10773619264364243, 0.013889797963202, -0.1549263745546341, -0.04412307217717171, 0.006401730701327324] skip-layers: [1, 2, 7, 14, 6, 5]
step:3125/5550 val_loss:3.083464 train_time:781896ms step_avg:250.21ms x-lambda: 0.7422078251838684 lambdas: [0.012138952501118183, -0.10751096159219742, 0.012968039140105247, -0.15938003361225128, -0.04359173774719238, 0.005725666414946318] skip-layers: [1, 2, 7, 14, 6, 5]
step:3250/5550 val_loss:3.071770 train_time:813269ms step_avg:250.24ms x-lambda: 0.7471686005592346 lambdas: [0.011874605901539326, -0.10326974838972092, 0.013713189400732517, -0.1622486114501953, -0.04275095835328102, 0.006348905153572559] skip-layers: [1, 2, 7, 14, 6, 5]
step:3375/5550 val_loss:3.063560 train_time:844616ms step_avg:250.26ms x-lambda: 0.749325692653656 lambdas: [0.011533577926456928, -0.10239630937576294, 0.012412234209477901, -0.16618715226650238, -0.041685041040182114, 0.006236847024410963] skip-layers: [1, 2, 7, 14, 6, 5]
step:3500/5550 val_loss:3.054513 train_time:876023ms step_avg:250.29ms x-lambda: 0.7529223561286926 lambdas: [0.01132901106029749, -0.09980583190917969, 0.013884738087654114, -0.17000038921833038, -0.04230961576104164, 0.004506558179855347] skip-layers: [1, 2, 7, 14, 6, 5]
step:3625/5550 val_loss:3.045989 train_time:908516ms step_avg:250.63ms x-lambda: 0.7583140730857849 lambdas: [0.011532483622431755, -0.09896987676620483, 0.01163023617118597, -0.17339392006397247, -0.039906058460474014, 0.005407721735537052] skip-layers: [1, 2, 7, 14, 6, 5]
step:3750/5550 val_loss:3.036398 train_time:940934ms step_avg:250.92ms x-lambda: 0.7616140246391296 lambdas: [0.01243781577795744, -0.09699644893407822, 0.013149715960025787, -0.17718505859375, -0.0404965914785862, 0.0070282090455293655] skip-layers: [1, 2, 7, 14, 6, 5]
step:3875/5550 val_loss:3.027709 train_time:974410ms step_avg:251.46ms x-lambda: 0.7701255679130554 lambdas: [0.012043536640703678, -0.0945701152086258, 0.010978312231600285, -0.17849239706993103, -0.039597999304533005, 0.00593666173517704] skip-layers: [1, 2, 7, 14, 6, 5]
step:4000/5550 val_loss:3.018421 train_time:1005848ms step_avg:251.46ms x-lambda: 0.7759977579116821 lambdas: [0.012568246573209763, -0.09364650398492813, 0.01086642686277628, -0.18247774243354797, -0.03926079720258713, 0.006763719022274017] skip-layers: [1, 2, 7, 14, 6, 5]
step:4125/5550 val_loss:3.008801 train_time:1038353ms step_avg:251.72ms x-lambda: 0.7834020256996155 lambdas: [0.011379261501133442, -0.09230885654687881, 0.011696593835949898, -0.18673570454120636, -0.037909068167209625, 0.005693704355508089] skip-layers: [1, 2, 7, 14, 6, 5]
step:4250/5550 val_loss:3.000646 train_time:1070051ms step_avg:251.78ms x-lambda: 0.789953351020813 lambdas: [0.011525396257638931, -0.09209410101175308, 0.011622932739555836, -0.19047023355960846, -0.038836777210235596, 0.006369619630277157] skip-layers: [1, 2, 7, 14, 6, 5]
step:4375/5550 val_loss:2.991432 train_time:1102845ms step_avg:252.08ms x-lambda: 0.7958616614341736 lambdas: [0.011256463825702667, -0.09175766259431839, 0.010625668801367283, -0.19489341974258423, -0.03813652694225311, 0.0036953261587768793] skip-layers: [1, 2, 7, 14, 6, 5]
step:4500/5550 val_loss:2.983455 train_time:1136805ms step_avg:252.62ms x-lambda: 0.8044769167900085 lambdas: [0.01105589047074318, -0.09009630978107452, 0.010259074158966541, -0.1974998563528061, -0.038290251046419144, 0.004336511716246605] skip-layers: [1, 2, 7, 14, 6, 5]
step:4625/5550 val_loss:2.974281 train_time:1170817ms step_avg:253.15ms x-lambda: 0.81517094373703 lambdas: [0.0100283557549119, -0.08927154541015625, 0.008586704730987549, -0.20012639462947845, -0.039092741906642914, 0.003914802800863981] skip-layers: [1, 2, 7, 14, 6, 5]
step:4750/5550 val_loss:2.964973 train_time:1202875ms step_avg:253.24ms x-lambda: 0.822733461856842 lambdas: [0.01095402892678976, -0.08831683546304703, 0.010127915069460869, -0.20418024063110352, -0.03734653815627098, 0.005569417029619217] skip-layers: [1, 2, 7, 14, 6, 5]
step:4875/5550 val_loss:2.956056 train_time:1235012ms step_avg:253.34ms x-lambda: 0.8316723704338074 lambdas: [0.01176351960748434, -0.08745715022087097, 0.008692510426044464, -0.20749840140342712, -0.03700243681669235, 0.0038940708618611097] skip-layers: [1, 2, 7, 14, 6, 5]
step:5000/5550 val_loss:2.947851 train_time:1270503ms step_avg:254.10ms x-lambda: 0.8414795398712158 lambdas: [0.011130568571388721, -0.08733192086219788, 0.00838212389498949, -0.21033793687820435, -0.03666715696454048, 0.0040735346265137196] skip-layers: [1, 2, 7, 14, 6, 5]
step:5125/5550 val_loss:2.940290 train_time:1302911ms step_avg:254.23ms x-lambda: 0.8503218293190002 lambdas: [0.011321917176246643, -0.08617109060287476, 0.008397518657147884, -0.21261140704154968, -0.035780441015958786, 0.004596593324095011] skip-layers: [1, 2, 7, 14, 6, 5]
step:5250/5550 val_loss:2.932994 train_time:1335494ms step_avg:254.38ms x-lambda: 0.8579341769218445 lambdas: [0.010492578148841858, -0.08568961918354034, 0.008267655037343502, -0.21505047380924225, -0.03553036227822304, 0.003955410327762365] skip-layers: [1, 2, 7, 14, 6, 5]
step:5375/5550 val_loss:2.926558 train_time:1370329ms step_avg:254.94ms x-lambda: 0.8666825294494629 lambdas: [0.010831955820322037, -0.08508139103651047, 0.007976029068231583, -0.21586757898330688, -0.03574912250041962, 0.003798452904447913] skip-layers: [1, 2, 7, 14, 6, 5]
step:5500/5550 val_loss:2.921799 train_time:1406438ms step_avg:255.72ms x-lambda: 0.87163907289505 lambdas: [0.010338397696614265, -0.08544892817735672, 0.0075505138374865055, -0.21626663208007812, -0.03496617451310158, 0.0036332421004772186] skip-layers: [1, 2, 7, 14, 6, 5]
step:5550/5550 val_loss:2.920623 train_time:1421728ms step_avg:256.17ms x-lambda: 0.8728266954421997 lambdas: [0.010286189615726471, -0.08565317094326019, 0.006912713870406151, -0.21644003689289093, -0.03507797047495842, 0.003808412468060851] skip-layers: [1, 2, 7, 14, 6, 5]

## 8000-add-skip-multiple-10-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:125/5550 val_loss:4.267296 train_time:29322ms step_avg:234.58ms x-lambda: 1.020965576171875 lambdas: [0.03121498040854931, 0.029033422470092773, 0.013746995478868484, 0.06231051683425903, 0.014785128645598888, -0.04844820871949196, 0.022444892674684525, 0.07210730016231537, 0.02648506686091423, 0.03932494670152664] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:250/5550 val_loss:3.844740 train_time:58773ms step_avg:235.09ms x-lambda: 1.0122615098953247 lambdas: [0.04357915744185448, 0.011530266143381596, -0.027570519596338272, 0.0922001376748085, -0.04337940737605095, -0.16834184527397156, 0.03508283570408821, 0.036623597145080566, 0.03850433602929115, 0.03589708358049393] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:375/5550 val_loss:3.673337 train_time:88705ms step_avg:236.55ms x-lambda: 1.0100719928741455 lambdas: [0.048189613968133926, -0.024037552997469902, -0.03415708243846893, 0.0913504958152771, -0.08988959342241287, -0.21866706013679504, 0.045527756214141846, 0.022282807156443596, 0.044921450316905975, 0.025239309296011925] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:500/5550 val_loss:3.556687 train_time:118980ms step_avg:237.96ms x-lambda: 0.9994065761566162 lambdas: [0.046270567923784256, -0.05941959470510483, -0.025841590017080307, 0.08911735564470291, -0.11770345270633698, -0.23744913935661316, 0.04289940372109413, 0.01713689975440502, 0.041477836668491364, 0.020934127271175385] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:625/5550 val_loss:3.479829 train_time:149403ms step_avg:239.04ms x-lambda: 0.9804675579071045 lambdas: [0.044061657041311264, -0.09215735644102097, -0.013901736587285995, 0.08791528642177582, -0.12999412417411804, -0.24026840925216675, 0.036728765815496445, 0.014324591495096684, 0.036264218389987946, 0.02024361863732338] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:750/5550 val_loss:3.428190 train_time:180153ms step_avg:240.20ms x-lambda: 0.9624309539794922 lambdas: [0.041400037705898285, -0.1217234805226326, -0.006239405833184719, 0.08302009105682373, -0.13030070066452026, -0.23597055673599243, 0.028858836740255356, 0.011237704195082188, 0.02960960939526558, 0.017978033050894737] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:875/5550 val_loss:3.381061 train_time:210984ms step_avg:241.12ms x-lambda: 0.9416521191596985 lambdas: [0.03864303231239319, -0.14713045954704285, -0.0010779276490211487, 0.07961615175008774, -0.12334603816270828, -0.22383636236190796, 0.019058533012866974, 0.009455656632781029, 0.022130215540528297, 0.017339106649160385] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1000/5550 val_loss:3.345998 train_time:242115ms step_avg:242.12ms x-lambda: 0.9219791889190674 lambdas: [0.037908948957920074, -0.16955766081809998, 0.0017665247432887554, 0.07601729035377502, -0.11380169540643692, -0.20680202543735504, 0.010228706523776054, 0.01095686387270689, 0.016586491838097572, 0.01690528355538845] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1125/5550 val_loss:3.317388 train_time:273284ms step_avg:242.92ms x-lambda: 0.9046022295951843 lambdas: [0.03855830803513527, -0.18971459567546844, 0.002824498573318124, 0.06990842521190643, -0.10478252917528152, -0.1923806369304657, 0.0016379915177822113, 0.008885861374437809, 0.010783765465021133, 0.014487781561911106] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1250/5550 val_loss:3.291337 train_time:304615ms step_avg:243.69ms x-lambda: 0.8883954286575317 lambdas: [0.0384388342499733, -0.20511473715305328, 0.005415612831711769, 0.06495793163776398, -0.09516739845275879, -0.1802549511194229, -0.0067906626500189304, 0.007251053117215633, 0.005995203275233507, 0.014667076990008354] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1375/5550 val_loss:3.272113 train_time:336119ms step_avg:244.45ms x-lambda: 0.8712728023529053 lambdas: [0.03825223445892334, -0.21922039985656738, 0.003922286909073591, 0.05911532789468765, -0.08750662207603455, -0.1678592413663864, -0.016048027202486992, 0.005221718922257423, 0.001084140851162374, 0.011834567412734032] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1500/5550 val_loss:3.252046 train_time:367597ms step_avg:245.06ms x-lambda: 0.8584972620010376 lambdas: [0.040511976927518845, -0.23020443320274353, 0.006220133975148201, 0.05498170852661133, -0.08024682104587555, -0.1579492837190628, -0.022833939641714096, 0.005266976077109575, -0.0019519167253747582, 0.010950724594295025] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1625/5550 val_loss:3.236984 train_time:399122ms step_avg:245.61ms x-lambda: 0.8464899659156799 lambdas: [0.04373416304588318, -0.23699304461479187, 0.007220148574560881, 0.053795475512742996, -0.07256713509559631, -0.1466953009366989, -0.02840787172317505, 0.007314461283385754, -0.0034901336766779423, 0.012605161406099796] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1750/5550 val_loss:3.220697 train_time:430626ms step_avg:246.07ms x-lambda: 0.8331701159477234 lambdas: [0.04508443549275398, -0.24357762932777405, 0.007526986300945282, 0.04825122281908989, -0.06760184466838837, -0.13649576902389526, -0.03675498440861702, 0.005879062227904797, -0.007460942491889, 0.011617675423622131] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:1875/5550 val_loss:3.203040 train_time:462190ms step_avg:246.50ms x-lambda: 0.8235230445861816 lambdas: [0.049424704164266586, -0.2475489228963852, 0.009155597537755966, 0.04627075046300888, -0.06210522726178169, -0.12809871137142181, -0.04162798076868057, 0.00649270648136735, -0.007853057235479355, 0.01237125787883997] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2000/5550 val_loss:3.190407 train_time:493921ms step_avg:246.96ms x-lambda: 0.8151236772537231 lambdas: [0.0527912899851799, -0.25000250339508057, 0.009761154651641846, 0.04436284303665161, -0.05710370093584061, -0.12033900618553162, -0.04737139120697975, 0.006895127240568399, -0.009551916271448135, 0.012178984470665455] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2125/5550 val_loss:3.173058 train_time:525726ms step_avg:247.40ms x-lambda: 0.8061152100563049 lambdas: [0.053661007434129715, -0.25568950176239014, 0.007941429503262043, 0.04104629158973694, -0.05612962320446968, -0.11591385304927826, -0.05305517464876175, 0.004885786212980747, -0.01219548936933279, 0.011804288253188133] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2250/5550 val_loss:3.158520 train_time:557511ms step_avg:247.78ms x-lambda: 0.7992111444473267 lambdas: [0.055734485387802124, -0.25702372193336487, 0.007735003717243671, 0.03732366859912872, -0.05297527089715004, -0.11078725010156631, -0.05894860997796059, 0.005500861443579197, -0.014279651455581188, 0.008389845490455627] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2375/5550 val_loss:3.147079 train_time:589346ms step_avg:248.15ms x-lambda: 0.7934311032295227 lambdas: [0.057880546897649765, -0.25852853059768677, 0.00807815883308649, 0.035455748438835144, -0.05053992196917534, -0.10491355508565903, -0.06271710991859436, 0.005126954521983862, -0.015026884153485298, 0.008966362103819847] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2500/5550 val_loss:3.137374 train_time:621104ms step_avg:248.44ms x-lambda: 0.7894777059555054 lambdas: [0.06266294419765472, -0.25722214579582214, 0.008635789155960083, 0.03593559190630913, -0.04643253982067108, -0.0998743548989296, -0.06534254550933838, 0.006280602887272835, -0.014045623131096363, 0.010385100729763508] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2625/5550 val_loss:3.124368 train_time:652873ms step_avg:248.71ms x-lambda: 0.7824059724807739 lambdas: [0.062264230102300644, -0.26035410165786743, 0.008018044754862785, 0.031586311757564545, -0.0471813790500164, -0.09736494719982147, -0.07030650973320007, 0.004525092430412769, -0.017449071630835533, 0.007813719101250172] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2750/5550 val_loss:3.113349 train_time:684628ms step_avg:248.96ms x-lambda: 0.7804096937179565 lambdas: [0.06355036050081253, -0.2584784924983978, 0.007807579357177019, 0.0319693461060524, -0.04394412040710449, -0.09403692185878754, -0.07246477156877518, 0.00541352853178978, -0.017958085983991623, 0.009618655778467655] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:2875/5550 val_loss:3.104791 train_time:716425ms step_avg:249.19ms x-lambda: 0.7779107093811035 lambdas: [0.06637737154960632, -0.258626252412796, 0.008210927248001099, 0.03100687824189663, -0.04258649796247482, -0.08870011568069458, -0.07503464818000793, 0.005524299573153257, -0.017959583550691605, 0.00916021317243576] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3000/5550 val_loss:3.093301 train_time:748229ms step_avg:249.41ms x-lambda: 0.7765477895736694 lambdas: [0.06753029674291611, -0.25922030210494995, 0.0077516911551356316, 0.030201464891433716, -0.04162132740020752, -0.08734815567731857, -0.07734473049640656, 0.005465189926326275, -0.018810519948601723, 0.008384992368519306] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3125/5550 val_loss:3.082122 train_time:780076ms step_avg:249.62ms x-lambda: 0.7743475437164307 lambdas: [0.06731196492910385, -0.2606964111328125, 0.006674258038401604, 0.028162643313407898, -0.04193151369690895, -0.08611482381820679, -0.08187215030193329, 0.004957160912454128, -0.021239671856164932, 0.007715691812336445] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3250/5550 val_loss:3.070934 train_time:811875ms step_avg:249.81ms x-lambda: 0.7743762135505676 lambdas: [0.06853415817022324, -0.2602854073047638, 0.005160925444215536, 0.02671149931848049, -0.04125501587986946, -0.08398067206144333, -0.08370216190814972, 0.004126712679862976, -0.020306063815951347, 0.007449358701705933] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3375/5550 val_loss:3.062382 train_time:843659ms step_avg:249.97ms x-lambda: 0.7739409804344177 lambdas: [0.06961879879236221, -0.2610074579715729, 0.007209147326648235, 0.027938557788729668, -0.039078887552022934, -0.08359888195991516, -0.08565962314605713, 0.003805548185482621, -0.021790217608213425, 0.007105677388608456] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3500/5550 val_loss:3.053844 train_time:875530ms step_avg:250.15ms x-lambda: 0.773320734500885 lambdas: [0.06983545422554016, -0.2603336572647095, 0.006552320439368486, 0.024660857394337654, -0.039653051644563675, -0.08000494539737701, -0.0882866382598877, 0.004080999176949263, -0.022076163440942764, 0.005662558134645224] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3625/5550 val_loss:3.044843 train_time:907366ms step_avg:250.31ms x-lambda: 0.7751767635345459 lambdas: [0.07205180823802948, -0.25931715965270996, 0.006076265126466751, 0.025528892874717712, -0.036874301731586456, -0.07897236943244934, -0.08822958171367645, 0.003361045615747571, -0.021789222955703735, 0.0064298533834517] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3750/5550 val_loss:3.035326 train_time:939137ms step_avg:250.44ms x-lambda: 0.7746706008911133 lambdas: [0.07208649069070816, -0.2594369351863861, 0.006561286747455597, 0.023612871766090393, -0.037004366517066956, -0.0765238106250763, -0.09061254560947418, 0.00438364502042532, -0.022442197427153587, 0.007517031393945217] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:3875/5550 val_loss:3.026104 train_time:971047ms step_avg:250.59ms x-lambda: 0.7801199555397034 lambdas: [0.07458631694316864, -0.25982990860939026, 0.0064016771502792835, 0.02459951862692833, -0.03631626069545746, -0.07464002072811127, -0.0909949541091919, 0.004059774335473776, -0.021860908716917038, 0.005906993523240089] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4000/5550 val_loss:3.017190 train_time:1002950ms step_avg:250.74ms x-lambda: 0.7822375297546387 lambdas: [0.07655573636293411, -0.2598322331905365, 0.005669102072715759, 0.02370474487543106, -0.03621813654899597, -0.0736490786075592, -0.09271098673343658, 0.004829493351280689, -0.022308098152279854, 0.006785504054278135] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4125/5550 val_loss:3.007779 train_time:1034892ms step_avg:250.88ms x-lambda: 0.7853130102157593 lambdas: [0.07639691233634949, -0.2598666548728943, 0.006182915065437555, 0.024173211306333542, -0.034988563507795334, -0.07374060153961182, -0.09452751278877258, 0.00444202683866024, -0.023026905953884125, 0.006245703902095556] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4250/5550 val_loss:2.999290 train_time:1067040ms step_avg:251.07ms x-lambda: 0.7890943884849548 lambdas: [0.07774891704320908, -0.2610187530517578, 0.006005192641168833, 0.023988528177142143, -0.035156603902578354, -0.07170247286558151, -0.09488283097743988, 0.004054049961268902, -0.022823771461844444, 0.005902179051190615] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4375/5550 val_loss:2.990524 train_time:1099150ms step_avg:251.23ms x-lambda: 0.7913617491722107 lambdas: [0.07829321175813675, -0.26177868247032166, 0.00547632435336709, 0.021471291780471802, -0.03600705787539482, -0.0719497799873352, -0.09703513979911804, 0.003557757241651416, -0.024104058742523193, 0.005261952988803387] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4500/5550 val_loss:2.982208 train_time:1131322ms step_avg:251.40ms x-lambda: 0.7962256669998169 lambdas: [0.07905907928943634, -0.26304569840431213, 0.006061376538127661, 0.021539993584156036, -0.035593051463365555, -0.07019919157028198, -0.09768186509609222, 0.004156435839831829, -0.02364044450223446, 0.005578095093369484] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4625/5550 val_loss:2.972608 train_time:1163639ms step_avg:251.60ms x-lambda: 0.8022724986076355 lambdas: [0.08052576333284378, -0.26347866654396057, 0.004154270980507135, 0.020966097712516785, -0.034418102353811264, -0.06933730840682983, -0.0977865681052208, 0.0030481419526040554, -0.024179404601454735, 0.005170821212232113] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4750/5550 val_loss:2.963456 train_time:1196038ms step_avg:251.80ms x-lambda: 0.8077949285507202 lambdas: [0.08293633162975311, -0.2633611857891083, 0.00572553277015686, 0.021919293329119682, -0.03492424264550209, -0.0689472109079361, -0.09814492613077164, 0.0048125931061804295, -0.02386176958680153, 0.005595602560788393] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:4875/5550 val_loss:2.954616 train_time:1228612ms step_avg:252.02ms x-lambda: 0.8131651282310486 lambdas: [0.08389295637607574, -0.26461878418922424, 0.004168128129094839, 0.021971754729747772, -0.03470364958047867, -0.06766294687986374, -0.10002732276916504, 0.004037073347717524, -0.02398359216749668, 0.005195494741201401] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5000/5550 val_loss:2.946285 train_time:1261284ms step_avg:252.26ms x-lambda: 0.8193370699882507 lambdas: [0.08493480831384659, -0.2649284899234772, 0.004782528150826693, 0.0210407841950655, -0.034875012934207916, -0.06707373261451721, -0.10104203969240189, 0.0038919481448829174, -0.024076029658317566, 0.004871628247201443] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5125/5550 val_loss:2.938941 train_time:1294099ms step_avg:252.51ms x-lambda: 0.8249940872192383 lambdas: [0.08695206046104431, -0.2661189138889313, 0.004873492754995823, 0.02079038694500923, -0.03497513756155968, -0.06644873321056366, -0.10150638222694397, 0.0038870754651725292, -0.024748582392930984, 0.005024597514420748] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5250/5550 val_loss:2.931736 train_time:1327120ms step_avg:252.78ms x-lambda: 0.8303956389427185 lambdas: [0.08772370219230652, -0.2656768560409546, 0.005075936671346426, 0.020991923287510872, -0.03471996635198593, -0.06563380360603333, -0.10228589177131653, 0.003682204755023122, -0.025045808404684067, 0.004850420169532299] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5375/5550 val_loss:2.925300 train_time:1360225ms step_avg:253.07ms x-lambda: 0.835860550403595 lambdas: [0.08918321132659912, -0.2682403028011322, 0.004140007775276899, 0.020216399803757668, -0.03550209850072861, -0.06543270498514175, -0.10289023816585541, 0.004404081963002682, -0.025531940162181854, 0.0050002168864011765] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5500/5550 val_loss:2.920517 train_time:1393613ms step_avg:253.38ms x-lambda: 0.839505672454834 lambdas: [0.0898018553853035, -0.2688104510307312, 0.0034283017739653587, 0.02037057653069496, -0.03481631726026535, -0.06516379863023758, -0.10356924682855606, 0.003848158521577716, -0.025913668796420097, 0.004701828584074974] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]
step:5550/5550 val_loss:2.919347 train_time:1407048ms step_avg:253.52ms x-lambda: 0.8404720425605774 lambdas: [0.08999430388212204, -0.2691645324230194, 0.004239567555487156, 0.020630089566111565, -0.03535068407654762, -0.06508255004882812, -0.10341370105743408, 0.0038720129523426294, -0.02586241625249386, 0.004339832812547684] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5]



## 8000-add-skip-multiple-10-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:125/5550 val_loss:4.258919 train_time:29316ms step_avg:234.53ms x-lambda: 1.0192440748214722 lambdas: [0.014475448057055473, 0.01797979697585106, 0.02158266119658947, 0.024189934134483337, 0.031104380264878273, 0.017413515597581863, 0.019859543070197105, 0.02066316083073616, 0.022851867601275444, 0.03774961829185486] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:250/5550 val_loss:3.852298 train_time:58798ms step_avg:235.19ms x-lambda: 0.9968896508216858 lambdas: [0.007039361167699099, 0.01848340779542923, 0.019980065524578094, 0.020740114152431488, 0.021151993423700333, -0.0373486690223217, -0.008722060360014439, 0.021991834044456482, -0.0047448789700865746, 0.035586122423410416] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:375/5550 val_loss:3.675513 train_time:88755ms step_avg:236.68ms x-lambda: 0.9899230003356934 lambdas: [0.009467950090765953, 0.02511112205684185, 0.019733276218175888, 0.015700511634349823, -0.01732436940073967, -0.0875387191772461, -0.017476923763751984, 0.03122844360768795, -0.030347058549523354, 0.014243699610233307] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:500/5550 val_loss:3.558621 train_time:119078ms step_avg:238.16ms x-lambda: 0.9806395769119263 lambdas: [0.0027235192246735096, 0.023929575458168983, 0.013695809990167618, 0.009180812165141106, -0.057786744087934494, -0.11898207664489746, -0.015012781135737896, 0.040695078670978546, -0.04203229397535324, -0.0010764066828414798] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:625/5550 val_loss:3.483248 train_time:149627ms step_avg:239.40ms x-lambda: 0.9725425839424133 lambdas: [-0.0029061543755233288, 0.023808414116501808, 0.009213488548994064, 0.007515384815633297, -0.09278910607099533, -0.13369378447532654, -0.005326937884092331, 0.04883093014359474, -0.041637975722551346, -0.006034857593476772] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:750/5550 val_loss:3.427079 train_time:180432ms step_avg:240.58ms x-lambda: 0.9603464007377625 lambdas: [-0.012689000926911831, 0.01942729949951172, 0.001269138534553349, 0.0047634863294661045, -0.12486118823289871, -0.13877448439598083, 0.0007079809438437223, 0.049452655017375946, -0.04116513952612877, -0.010349373333156109] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:875/5550 val_loss:3.382884 train_time:211353ms step_avg:241.55ms x-lambda: 0.9469320774078369 lambdas: [-0.022398291155695915, 0.014517337083816528, -0.006778153590857983, 0.003172678407281637, -0.15366680920124054, -0.1368095874786377, 0.006060197949409485, 0.04890470206737518, -0.03927268087863922, -0.012968473136425018] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1000/5550 val_loss:3.346104 train_time:242484ms step_avg:242.48ms x-lambda: 0.9383221864700317 lambdas: [-0.027992095798254013, 0.01277097500860691, -0.010787689127027988, 0.0062899598851799965, -0.1764075756072998, -0.13029219210147858, 0.00879573356360197, 0.04768593609333038, -0.035410404205322266, -0.012192221358418465] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1125/5550 val_loss:3.317476 train_time:273661ms step_avg:243.25ms x-lambda: 0.9269651174545288 lambdas: [-0.03734946623444557, 0.00773425679653883, -0.017779899761080742, 0.007437839638441801, -0.19946976006031036, -0.12267082184553146, 0.010174313560128212, 0.045167431235313416, -0.03422445058822632, -0.013918280601501465] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1250/5550 val_loss:3.291162 train_time:304966ms step_avg:243.97ms x-lambda: 0.9206528067588806 lambdas: [-0.04202772304415703, 0.005630089435726404, -0.02197880856692791, 0.011232394725084305, -0.21684685349464417, -0.1140979677438736, 0.011548584327101707, 0.044409509748220444, -0.031131427735090256, -0.012225172482430935] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1375/5550 val_loss:3.270744 train_time:336455ms step_avg:244.69ms x-lambda: 0.9111316204071045 lambdas: [-0.04819093272089958, 0.0016748650232329965, -0.02700912207365036, 0.014900888316333294, -0.23154546320438385, -0.10653246939182281, 0.013800964690744877, 0.04180023819208145, -0.029761003330349922, -0.012978085316717625] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1500/5550 val_loss:3.250105 train_time:367907ms step_avg:245.27ms x-lambda: 0.9043259620666504 lambdas: [-0.05381429195404053, -0.0020963558927178383, -0.03165416046977043, 0.019292764365673065, -0.2441100925207138, -0.10039456188678741, 0.014277173206210136, 0.040861789137125015, -0.02841290831565857, -0.01270008273422718] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1625/5550 val_loss:3.236102 train_time:399464ms step_avg:245.82ms x-lambda: 0.8981563448905945 lambdas: [-0.059168774634599686, -0.004832325037568808, -0.03559868410229683, 0.02537747658789158, -0.2541840970516205, -0.09247582405805588, 0.015803137794137, 0.03997233882546425, -0.02647438645362854, -0.010124142281711102] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1750/5550 val_loss:3.219543 train_time:430968ms step_avg:246.27ms x-lambda: 0.8900901079177856 lambdas: [-0.06512670964002609, -0.009677025489509106, -0.0408671610057354, 0.02905789017677307, -0.2623778283596039, -0.08618282526731491, 0.016125988215208054, 0.03900817409157753, -0.02524435892701149, -0.010285682044923306] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:1875/5550 val_loss:3.201893 train_time:462544ms step_avg:246.69ms x-lambda: 0.8859963417053223 lambdas: [-0.06807544082403183, -0.012335999868810177, -0.0441829152405262, 0.03412821888923645, -0.2689377963542938, -0.08237484097480774, 0.015926167368888855, 0.03821909800171852, -0.02403453178703785, -0.010313562117516994] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2000/5550 val_loss:3.185910 train_time:494319ms step_avg:247.16ms x-lambda: 0.8800761103630066 lambdas: [-0.07339198887348175, -0.01607576385140419, -0.047844041138887405, 0.03932151570916176, -0.27373403310775757, -0.07805852591991425, 0.014884636737406254, 0.035636674612760544, -0.02312593348324299, -0.011163344606757164] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2125/5550 val_loss:3.171334 train_time:526129ms step_avg:247.59ms x-lambda: 0.8762896060943604 lambdas: [-0.07771919667720795, -0.019535528495907784, -0.05187060683965683, 0.04305876046419144, -0.2782142460346222, -0.07480808347463608, 0.014764081686735153, 0.03406647965312004, -0.023774102330207825, -0.011013166978955269] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2250/5550 val_loss:3.156955 train_time:557949ms step_avg:247.98ms x-lambda: 0.8739217519760132 lambdas: [-0.08043330162763596, -0.021980956196784973, -0.05460396409034729, 0.04740665853023529, -0.28148311376571655, -0.0710001215338707, 0.015267285518348217, 0.03423600271344185, -0.022702841088175774, -0.011171761900186539] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2375/5550 val_loss:3.145148 train_time:589789ms step_avg:248.33ms x-lambda: 0.8716344833374023 lambdas: [-0.08215433359146118, -0.02364274673163891, -0.056599389761686325, 0.051215846091508865, -0.2820984721183777, -0.06793638318777084, 0.014710884541273117, 0.03250008821487427, -0.020914193242788315, -0.010116782039403915] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2500/5550 val_loss:3.134458 train_time:621562ms step_avg:248.62ms x-lambda: 0.869653046131134 lambdas: [-0.08538118004798889, -0.026126399636268616, -0.05940880626440048, 0.05444249138236046, -0.2843186855316162, -0.06517749279737473, 0.014788400381803513, 0.031065354123711586, -0.02068452164530754, -0.009717956185340881] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2625/5550 val_loss:3.122229 train_time:653336ms step_avg:248.89ms x-lambda: 0.8664411902427673 lambdas: [-0.08857692033052444, -0.028962479904294014, -0.062227390706539154, 0.05689350143074989, -0.2859502136707306, -0.06269014626741409, 0.01363888755440712, 0.02964286133646965, -0.0208844356238842, -0.011181613430380821] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2750/5550 val_loss:3.111986 train_time:685119ms step_avg:249.13ms x-lambda: 0.8654359579086304 lambdas: [-0.09120767563581467, -0.0322117954492569, -0.06512565910816193, 0.0591844879090786, -0.2873406708240509, -0.06127253919839859, 0.01384291984140873, 0.029088981449604034, -0.020028144121170044, -0.010802395641803741] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:2875/5550 val_loss:3.102756 train_time:716942ms step_avg:249.37ms x-lambda: 0.8664510250091553 lambdas: [-0.09169776737689972, -0.03220159187912941, -0.0653332993388176, 0.06410276889801025, -0.28626391291618347, -0.05805386230349541, 0.015246249735355377, 0.030124200507998466, -0.017982013523578644, -0.009157927706837654] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3000/5550 val_loss:3.091096 train_time:748752ms step_avg:249.58ms x-lambda: 0.8660269379615784 lambdas: [-0.0939466804265976, -0.03469162434339523, -0.06720200181007385, 0.06544511020183563, -0.28790655732154846, -0.05836295709013939, 0.014694008976221085, 0.028140949085354805, -0.018786560744047165, -0.01069748867303133] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3125/5550 val_loss:3.080064 train_time:780605ms step_avg:249.79ms x-lambda: 0.8663419485092163 lambdas: [-0.09546253085136414, -0.03575112670660019, -0.06874258816242218, 0.0674968883395195, -0.28852489590644836, -0.05692121013998985, 0.01257132738828659, 0.028241457417607307, -0.017269322648644447, -0.009010862559080124] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3250/5550 val_loss:3.069206 train_time:812426ms step_avg:249.98ms x-lambda: 0.8670861124992371 lambdas: [-0.09708750247955322, -0.03766900673508644, -0.07036222517490387, 0.06959855556488037, -0.2874719500541687, -0.05618922784924507, 0.0130291897803545, 0.027226239442825317, -0.018090959638357162, -0.009840118698775768] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3375/5550 val_loss:3.060501 train_time:844234ms step_avg:250.14ms x-lambda: 0.8685818314552307 lambdas: [-0.09771911799907684, -0.03834656625986099, -0.07110223174095154, 0.07055072486400604, -0.289121150970459, -0.05306043103337288, 0.013393346220254898, 0.02668108604848385, -0.017302121967077255, -0.009462490677833557] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3500/5550 val_loss:3.051980 train_time:876069ms step_avg:250.31ms x-lambda: 0.8691907525062561 lambdas: [-0.09918002784252167, -0.04060188680887222, -0.07331370562314987, 0.07170552015304565, -0.28844013810157776, -0.05487946793437004, 0.01327531784772873, 0.026540370658040047, -0.017812389880418777, -0.009741570800542831] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3625/5550 val_loss:3.043031 train_time:907877ms step_avg:250.45ms x-lambda: 0.8718017935752869 lambdas: [-0.09926547110080719, -0.04026143252849579, -0.0729033350944519, 0.0748177021741867, -0.28824126720428467, -0.05237586051225662, 0.01354699581861496, 0.025190498679876328, -0.016727659851312637, -0.00986469816416502] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3750/5550 val_loss:3.033234 train_time:939684ms step_avg:250.58ms x-lambda: 0.8733785152435303 lambdas: [-0.10064902901649475, -0.04215412959456444, -0.07427392154932022, 0.07470035552978516, -0.28907710313796997, -0.0515255443751812, 0.012849569320678711, 0.025454290211200714, -0.0169400442391634, -0.00976548157632351] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:3875/5550 val_loss:3.024986 train_time:971578ms step_avg:250.73ms x-lambda: 0.8782946467399597 lambdas: [-0.09916781634092331, -0.04176019877195358, -0.07404737174510956, 0.07675731182098389, -0.2892039120197296, -0.05078117921948433, 0.012948737479746342, 0.025045985355973244, -0.01618337072432041, -0.00927602220326662] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4000/5550 val_loss:3.015126 train_time:1003429ms step_avg:250.86ms x-lambda: 0.8804182410240173 lambdas: [-0.10117638856172562, -0.04382643103599548, -0.07560378313064575, 0.0782879963517189, -0.2900286018848419, -0.05151233822107315, 0.013785050250589848, 0.023494942113757133, -0.015859020873904228, -0.009666508994996548] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4125/5550 val_loss:3.005754 train_time:1035336ms step_avg:250.99ms x-lambda: 0.8845916986465454 lambdas: [-0.1016659215092659, -0.04478701576590538, -0.07571136951446533, 0.07906772941350937, -0.2899596095085144, -0.04912934452295303, 0.01308059599250555, 0.025535110384225845, -0.015649734064936638, -0.010008307173848152] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4250/5550 val_loss:2.997958 train_time:1067433ms step_avg:251.16ms x-lambda: 0.8890888690948486 lambdas: [-0.10112409293651581, -0.0449686124920845, -0.07596712559461594, 0.08111819624900818, -0.29042136669158936, -0.04894663393497467, 0.013650214299559593, 0.025591576471924782, -0.015302634797990322, -0.008968953974545002] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4375/5550 val_loss:2.988357 train_time:1099581ms step_avg:251.33ms x-lambda: 0.8917179703712463 lambdas: [-0.10290848463773727, -0.04680950567126274, -0.07819098979234695, 0.08104784786701202, -0.291919082403183, -0.04985128343105316, 0.012946686707437038, 0.02312278561294079, -0.015417058952152729, -0.009823919273912907] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4500/5550 val_loss:2.980468 train_time:1131741ms step_avg:251.50ms x-lambda: 0.8958532214164734 lambdas: [-0.10332910716533661, -0.04749076068401337, -0.07832358032464981, 0.08220133930444717, -0.2924961745738983, -0.04857761040329933, 0.01243158895522356, 0.023305023089051247, -0.015211628749966621, -0.01035348605364561] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4625/5550 val_loss:2.970792 train_time:1164054ms step_avg:251.69ms x-lambda: 0.9022710919380188 lambdas: [-0.10264307260513306, -0.04772496968507767, -0.07791505008935928, 0.08343172073364258, -0.2929847836494446, -0.048971954733133316, 0.012926353141665459, 0.02269159071147442, -0.015229801647365093, -0.009859699755907059] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4750/5550 val_loss:2.961895 train_time:1196456ms step_avg:251.89ms x-lambda: 0.9080595374107361 lambdas: [-0.10188751667737961, -0.04777338355779648, -0.07858453691005707, 0.085471011698246, -0.2935120165348053, -0.04904231056571007, 0.012706929817795753, 0.023817745968699455, -0.014937114901840687, -0.009607107378542423] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:4875/5550 val_loss:2.952831 train_time:1229075ms step_avg:252.12ms x-lambda: 0.9129392504692078 lambdas: [-0.1021982803940773, -0.04819731414318085, -0.0790875107049942, 0.08653020858764648, -0.2954121530056, -0.04860728979110718, 0.011649549938738346, 0.02233201637864113, -0.014552171342074871, -0.011030982248485088] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5000/5550 val_loss:2.944799 train_time:1261773ms step_avg:252.35ms x-lambda: 0.9188705682754517 lambdas: [-0.10260538756847382, -0.04899299517273903, -0.07908011227846146, 0.08845221996307373, -0.29622015357017517, -0.04749802127480507, 0.011717334389686584, 0.021917739883065224, -0.014354702085256577, -0.009968917816877365] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5125/5550 val_loss:2.937110 train_time:1294599ms step_avg:252.60ms x-lambda: 0.9243384599685669 lambdas: [-0.10284866392612457, -0.04960966110229492, -0.07986888289451599, 0.08903943747282028, -0.29732441902160645, -0.04856131970882416, 0.012539300136268139, 0.023216409608721733, -0.014822687953710556, -0.01011928915977478] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5250/5550 val_loss:2.929879 train_time:1327646ms step_avg:252.88ms x-lambda: 0.9288365840911865 lambdas: [-0.10331444442272186, -0.04977552965283394, -0.07985501736402512, 0.09029006958007812, -0.29759448766708374, -0.04784504696726799, 0.011355889961123466, 0.022110896185040474, -0.013899356126785278, -0.00997986551374197] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5375/5550 val_loss:2.923406 train_time:1360774ms step_avg:253.17ms x-lambda: 0.934360921382904 lambdas: [-0.10283113270998001, -0.04966622591018677, -0.07999870181083679, 0.09169705957174301, -0.29917407035827637, -0.048856351524591446, 0.010939576663076878, 0.022135594859719276, -0.014087021350860596, -0.009715850464999676] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5500/5550 val_loss:2.918559 train_time:1394222ms step_avg:253.49ms x-lambda: 0.9371211528778076 lambdas: [-0.10296173393726349, -0.05018030107021332, -0.08017373085021973, 0.09238783270120621, -0.30033934116363525, -0.0487247109413147, 0.011416951194405556, 0.021581094712018967, -0.014161660335958004, -0.010354033671319485] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]
step:5550/5550 val_loss:2.917396 train_time:1407666ms step_avg:253.63ms x-lambda: 0.9376956820487976 lambdas: [-0.1030377671122551, -0.05035768076777458, -0.08042041957378387, 0.09250088781118393, -0.3006490170955658, -0.0485733225941658, 0.011040322482585907, 0.021423185244202614, -0.013715438544750214, -0.010074164718389511] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5]



## 8000-add-skip-multiple-10-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.14ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:125/5550 val_loss:4.268038 train_time:29318ms step_avg:234.54ms x-lambda: 1.0264924764633179 lambdas: [0.08114387094974518, 0.003982992842793465, -0.0342409573495388, -0.054794568568468094, 0.07318270951509476, 0.050031062215566635, 0.032281242311000824, 0.027026062831282616, 0.02173425257205963, 0.025987431406974792] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:250/5550 val_loss:3.846369 train_time:58758ms step_avg:235.03ms x-lambda: 1.0122874975204468 lambdas: [0.07996075600385666, -0.030069749802350998, -0.08829394727945328, -0.144714817404747, 0.12529106438159943, 0.06252245604991913, 0.01690749265253544, 0.036823540925979614, -0.014406890608370304, -0.02230832166969776] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:375/5550 val_loss:3.672945 train_time:88689ms step_avg:236.50ms x-lambda: 1.006547451019287 lambdas: [0.06919040530920029, -0.03695828467607498, -0.10186974704265594, -0.18954090774059296, 0.13150274753570557, 0.04995644837617874, -0.0049389866180717945, 0.043864212930202484, -0.030041784048080444, -0.07254830002784729] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:500/5550 val_loss:3.559389 train_time:118966ms step_avg:237.93ms x-lambda: 0.984849750995636 lambdas: [0.061140019446611404, -0.03563794866204262, -0.10533711314201355, -0.21150636672973633, 0.12961609661579132, 0.04013315588235855, -0.019095446914434433, 0.04997674375772476, -0.03381405770778656, -0.11161181330680847] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:625/5550 val_loss:3.480270 train_time:149461ms step_avg:239.14ms x-lambda: 0.9575179815292358 lambdas: [0.05456490442156792, -0.03241619095206261, -0.10507144033908844, -0.2188173085451126, 0.125480055809021, 0.034294553101062775, -0.025434397161006927, 0.05336283519864082, -0.0303109809756279, -0.1408456265926361] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:750/5550 val_loss:3.427828 train_time:180210ms step_avg:240.28ms x-lambda: 0.930121660232544 lambdas: [0.05133791267871857, -0.027513213455677032, -0.10224844515323639, -0.21458274126052856, 0.11879191547632217, 0.030971253290772438, -0.026478677988052368, 0.05568290501832962, -0.022965973243117332, -0.15743419528007507] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:875/5550 val_loss:3.380786 train_time:211061ms step_avg:241.21ms x-lambda: 0.8951135277748108 lambdas: [0.04628106579184532, -0.024226153269410133, -0.09815802425146103, -0.20662693679332733, 0.10978935658931732, 0.02845042571425438, -0.027180392295122147, 0.05495432764291763, -0.020686142146587372, -0.16955488920211792] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1000/5550 val_loss:3.346266 train_time:242183ms step_avg:242.18ms x-lambda: 0.866269588470459 lambdas: [0.04378880560398102, -0.020488884299993515, -0.09400760382413864, -0.1942019909620285, 0.09919244050979614, 0.026036880910396576, -0.02652573399245739, 0.05476991459727287, -0.01792200654745102, -0.1762562096118927] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1125/5550 val_loss:3.317866 train_time:273368ms step_avg:242.99ms x-lambda: 0.8357967734336853 lambdas: [0.038322944194078445, -0.019566895440220833, -0.09249565005302429, -0.18315333127975464, 0.08806725591421127, 0.0220035407692194, -0.02690332569181919, 0.05017365515232086, -0.016326896846294403, -0.18173405528068542] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1250/5550 val_loss:3.293088 train_time:304657ms step_avg:243.73ms x-lambda: 0.8115832805633545 lambdas: [0.037608202546834946, -0.016128312796354294, -0.08746806532144547, -0.16917631030082703, 0.08014457672834396, 0.022030942142009735, -0.025132905691862106, 0.049649983644485474, -0.013555617071688175, -0.1812494546175003] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1375/5550 val_loss:3.271739 train_time:336141ms step_avg:244.47ms x-lambda: 0.7837458848953247 lambdas: [0.03302299231290817, -0.01551835983991623, -0.08523162454366684, -0.15707586705684662, 0.0709884986281395, 0.01962430216372013, -0.025699330493807793, 0.04695942997932434, -0.012935581617057323, -0.1830918788909912] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1500/5550 val_loss:3.250771 train_time:367596ms step_avg:245.06ms x-lambda: 0.7643486261367798 lambdas: [0.03249688073992729, -0.013277806341648102, -0.08079279959201813, -0.14618811011314392, 0.06329178810119629, 0.018368324264883995, -0.024706706404685974, 0.04672013595700264, -0.009748279117047787, -0.18143032491207123] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1625/5550 val_loss:3.235292 train_time:399117ms step_avg:245.61ms x-lambda: 0.7412237524986267 lambdas: [0.03183384984731674, -0.012988857924938202, -0.08114393800497055, -0.1368938684463501, 0.057287801057100296, 0.017447246238589287, -0.02333184704184532, 0.04532073810696602, -0.009411095641553402, -0.18067097663879395] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1750/5550 val_loss:3.220711 train_time:430605ms step_avg:246.06ms x-lambda: 0.7202450037002563 lambdas: [0.028541438281536102, -0.012334044091403484, -0.07713392376899719, -0.12820252776145935, 0.050897758454084396, 0.016615774482488632, -0.02462683990597725, 0.042598117142915726, -0.009405730292201042, -0.18070007860660553] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:1875/5550 val_loss:3.206459 train_time:462166ms step_avg:246.49ms x-lambda: 0.707813024520874 lambdas: [0.03019069880247116, -0.008834349922835827, -0.07177655398845673, -0.11684225499629974, 0.047942668199539185, 0.0182102769613266, -0.021385224536061287, 0.04502110928297043, -0.004915147088468075, -0.17483855783939362] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2000/5550 val_loss:3.187047 train_time:493898ms step_avg:246.95ms x-lambda: 0.6881967186927795 lambdas: [0.02637730911374092, -0.010021989233791828, -0.07150260359048843, -0.11177965998649597, 0.041736774146556854, 0.015833642333745956, -0.021459605544805527, 0.0416264645755291, -0.006853078026324511, -0.17569655179977417] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2125/5550 val_loss:3.173198 train_time:525689ms step_avg:247.38ms x-lambda: 0.6794151663780212 lambdas: [0.02576569654047489, -0.009230208583176136, -0.0693422481417656, -0.10667335987091064, 0.03828160837292671, 0.014466369524598122, -0.02216593362390995, 0.039360370486974716, -0.005775745026767254, -0.1741490662097931] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2250/5550 val_loss:3.159041 train_time:557500ms step_avg:247.78ms x-lambda: 0.6680561304092407 lambdas: [0.024138471111655235, -0.008593926206231117, -0.0681828036904335, -0.10121263563632965, 0.03347024694085121, 0.012728415429592133, -0.021193169057369232, 0.03743033483624458, -0.0059375278651714325, -0.17196553945541382] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2375/5550 val_loss:3.147835 train_time:589319ms step_avg:248.13ms x-lambda: 0.6593428254127502 lambdas: [0.02370953932404518, -0.008387385867536068, -0.0661952942609787, -0.09647753089666367, 0.03237633779644966, 0.012132578529417515, -0.020879095420241356, 0.03802773728966713, -0.005726586561650038, -0.16891515254974365] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2500/5550 val_loss:3.136276 train_time:621077ms step_avg:248.43ms x-lambda: 0.6528121829032898 lambdas: [0.024767320603132248, -0.006611795164644718, -0.06375415623188019, -0.09054238349199295, 0.0318664088845253, 0.013984783552587032, -0.019136345013976097, 0.03709808737039566, -0.005423719063401222, -0.16632790863513947] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2625/5550 val_loss:3.124745 train_time:652821ms step_avg:248.69ms x-lambda: 0.6463038325309753 lambdas: [0.022979741916060448, -0.005760107189416885, -0.06207418814301491, -0.0847972184419632, 0.02895841933786869, 0.012691139243543148, -0.019469421356916428, 0.03719909116625786, -0.0034231645986437798, -0.1648849993944168] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2750/5550 val_loss:3.113880 train_time:684588ms step_avg:248.94ms x-lambda: 0.6405022740364075 lambdas: [0.02175719663500786, -0.007069738581776619, -0.06230372190475464, -0.084139883518219, 0.026218585669994354, 0.010822959244251251, -0.01839076168835163, 0.03482590243220329, -0.005194582976400852, -0.16359999775886536] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:2875/5550 val_loss:3.104107 train_time:716399ms step_avg:249.18ms x-lambda: 0.6370733380317688 lambdas: [0.02129090577363968, -0.006472409702837467, -0.060717061161994934, -0.08170271664857864, 0.024607745930552483, 0.011543183587491512, -0.018656350672245026, 0.03493599593639374, -0.004174279049038887, -0.1618463397026062] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3000/5550 val_loss:3.093960 train_time:748183ms step_avg:249.39ms x-lambda: 0.63458251953125 lambdas: [0.021286308765411377, -0.005215326324105263, -0.05843552574515343, -0.07630130648612976, 0.024990828707814217, 0.012805050238966942, -0.017795436084270477, 0.03596540912985802, -0.002532638143748045, -0.15903104841709137] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3125/5550 val_loss:3.083064 train_time:780038ms step_avg:249.61ms x-lambda: 0.6320196986198425 lambdas: [0.020818285644054413, -0.005680188070982695, -0.05912306532263756, -0.07758597284555435, 0.022335611283779144, 0.011151673272252083, -0.019062336534261703, 0.03345569223165512, -0.004462713375687599, -0.15856090188026428] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3250/5550 val_loss:3.071046 train_time:811835ms step_avg:249.80ms x-lambda: 0.63262540102005 lambdas: [0.020190875977277756, -0.00670534186065197, -0.05821414664387703, -0.07202668488025665, 0.022014431655406952, 0.01194666139781475, -0.017995696514844894, 0.033806100487709045, -0.00325149018317461, -0.15675896406173706] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3375/5550 val_loss:3.062907 train_time:843617ms step_avg:249.96ms x-lambda: 0.6289957165718079 lambdas: [0.019322799518704414, -0.005840024445205927, -0.058420341461896896, -0.07288166135549545, 0.0198675449937582, 0.010125111788511276, -0.018222017213702202, 0.031866300851106644, -0.0035483110696077347, -0.15511387586593628] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3500/5550 val_loss:3.054251 train_time:875421ms step_avg:250.12ms x-lambda: 0.6286183595657349 lambdas: [0.019537096843123436, -0.007412411272525787, -0.05737259238958359, -0.06986597180366516, 0.018419131636619568, 0.009379511699080467, -0.01858658716082573, 0.03038734942674637, -0.005144757218658924, -0.1560678780078888] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3625/5550 val_loss:3.045416 train_time:907221ms step_avg:250.27ms x-lambda: 0.6307241320610046 lambdas: [0.01923001930117607, -0.005264436826109886, -0.05638914555311203, -0.06996732950210571, 0.019613653421401978, 0.008795571513473988, -0.016634471714496613, 0.0321599580347538, -0.002350025810301304, -0.15227074921131134] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3750/5550 val_loss:3.035346 train_time:939012ms step_avg:250.40ms x-lambda: 0.6289162635803223 lambdas: [0.01946168765425682, -0.005709534510970116, -0.05495701730251312, -0.0666017010807991, 0.018294040113687515, 0.009959172457456589, -0.01734110154211521, 0.03244052454829216, -0.0026555329095572233, -0.15291205048561096] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:3875/5550 val_loss:3.026548 train_time:970883ms step_avg:250.55ms x-lambda: 0.6354650855064392 lambdas: [0.019904404878616333, -0.00527691375464201, -0.054281093180179596, -0.06498333066701889, 0.019140472635626793, 0.0088726207613945, -0.015113284811377525, 0.03174145519733429, -0.0029504443518817425, -0.1514788120985031] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4000/5550 val_loss:3.017097 train_time:1002724ms step_avg:250.68ms x-lambda: 0.6375707387924194 lambdas: [0.019256355240941048, -0.0054631782695651054, -0.05400710552930832, -0.06404825299978256, 0.01725827530026436, 0.009794235229492188, -0.015652932226657867, 0.030520956963300705, -0.0028001924511045218, -0.15088927745819092] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4125/5550 val_loss:3.008009 train_time:1034612ms step_avg:250.82ms x-lambda: 0.6399384140968323 lambdas: [0.019436558708548546, -0.004920398350805044, -0.05386710166931152, -0.06339992582798004, 0.016922784969210625, 0.009515898302197456, -0.015073338523507118, 0.03164226561784744, -0.0026571289636194706, -0.1494019478559494] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4250/5550 val_loss:2.999799 train_time:1066694ms step_avg:250.99ms x-lambda: 0.644420325756073 lambdas: [0.019180964678525925, -0.004524633754044771, -0.05345025658607483, -0.061788637191057205, 0.017956212162971497, 0.009733478538691998, -0.01551985926926136, 0.03126528114080429, -0.0013368083164095879, -0.15020181238651276] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4375/5550 val_loss:2.990659 train_time:1098816ms step_avg:251.16ms x-lambda: 0.6464570164680481 lambdas: [0.0172625370323658, -0.004957804922014475, -0.05380810424685478, -0.06158718839287758, 0.016277018934488297, 0.007835657335817814, -0.015528548508882523, 0.029937047511339188, -0.003221334656700492, -0.1514139026403427] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4500/5550 val_loss:2.982356 train_time:1130988ms step_avg:251.33ms x-lambda: 0.6512867212295532 lambdas: [0.018134722486138344, -0.005678865592926741, -0.05362372472882271, -0.060807399451732635, 0.015496078878641129, 0.007741587236523628, -0.015850646421313286, 0.029965119436383247, -0.0031476037111133337, -0.15152643620967865] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4625/5550 val_loss:2.972886 train_time:1163301ms step_avg:251.52ms x-lambda: 0.6578534841537476 lambdas: [0.01827993430197239, -0.004947875626385212, -0.05336912348866463, -0.05989920347929001, 0.01585291139781475, 0.008274545893073082, -0.015589695423841476, 0.028794873505830765, -0.0019309513736516237, -0.1492062360048294] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4750/5550 val_loss:2.963899 train_time:1195701ms step_avg:251.73ms x-lambda: 0.6636937856674194 lambdas: [0.018677379935979843, -0.003670354373753071, -0.05252360180020332, -0.05934525653719902, 0.016621991991996765, 0.008738034404814243, -0.015040167607367039, 0.03014463186264038, -0.002076774602755904, -0.1501910537481308] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:4875/5550 val_loss:2.954977 train_time:1228299ms step_avg:251.96ms x-lambda: 0.6692801713943481 lambdas: [0.017920445650815964, -0.004671410657465458, -0.05210907384753227, -0.058723174035549164, 0.016209546476602554, 0.006861387751996517, -0.01547801960259676, 0.028715599328279495, -0.002597620477899909, -0.15022587776184082] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5000/5550 val_loss:2.946841 train_time:1260995ms step_avg:252.20ms x-lambda: 0.6756936311721802 lambdas: [0.017937680706381798, -0.004354272969067097, -0.05152333155274391, -0.05720384046435356, 0.015885869041085243, 0.007901027798652649, -0.015627529472112656, 0.02828085981309414, -0.0024049996864050627, -0.15075264871120453] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5125/5550 val_loss:2.939201 train_time:1293808ms step_avg:252.45ms x-lambda: 0.6822381019592285 lambdas: [0.017871703952550888, -0.004202269017696381, -0.05075998976826668, -0.05689173564314842, 0.015474488027393818, 0.007874050177633762, -0.014250345528125763, 0.02895888313651085, -0.002177388407289982, -0.15182660520076752] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5250/5550 val_loss:2.932019 train_time:1326842ms step_avg:252.73ms x-lambda: 0.6877890229225159 lambdas: [0.01773405447602272, -0.004233867861330509, -0.051472198218107224, -0.056120485067367554, 0.014882387593388557, 0.007280142977833748, -0.013736460357904434, 0.027861593291163445, -0.001701527158729732, -0.15127737820148468] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5375/5550 val_loss:2.925615 train_time:1359973ms step_avg:253.02ms x-lambda: 0.6939113736152649 lambdas: [0.01803818717598915, -0.003763413056731224, -0.05139867588877678, -0.056364983320236206, 0.014943977817893028, 0.007738803513348103, -0.014264436438679695, 0.027997080236673355, -0.001970200100913644, -0.15179410576820374] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5500/5550 val_loss:2.920881 train_time:1393382ms step_avg:253.34ms x-lambda: 0.6979771256446838 lambdas: [0.01719813421368599, -0.004554971121251583, -0.051211338490247726, -0.0559321753680706, 0.015132402069866657, 0.006745550781488419, -0.013760129921138287, 0.026904115453362465, -0.0026783542707562447, -0.15164494514465332] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
step:5550/5550 val_loss:2.919693 train_time:1406824ms step_avg:253.48ms x-lambda: 0.6989520192146301 lambdas: [0.017335452139377594, -0.00441993772983551, -0.05128132551908493, -0.05615488439798355, 0.015148643404245377, 0.007124654017388821, -0.013836248777806759, 0.026894351467490196, -0.0025943501386791468, -0.15168635547161102] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]



## 8000-add-skip-multiple-10-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.26ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:125/5550 val_loss:4.266254 train_time:29372ms step_avg:234.98ms x-lambda: 1.0530403852462769 lambdas: [0.0445014126598835, 0.0034505375660955906, 0.017031490802764893, 0.013078453950583935, 0.02102343551814556, 0.009960692375898361, 0.008801961317658424, 0.016787799075245857, 0.009260343387722969, 0.057385995984077454] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:250/5550 val_loss:3.861741 train_time:58937ms step_avg:235.75ms x-lambda: 1.0841798782348633 lambdas: [0.007452395744621754, -0.03235302492976189, -0.00010553631000220776, -0.005609042011201382, 0.01100972294807434, -0.013229811564087868, 0.001540105789899826, -0.028072284534573555, -0.007264754734933376, 0.016845133155584335] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:375/5550 val_loss:3.682753 train_time:88891ms step_avg:237.04ms x-lambda: 1.0852620601654053 lambdas: [-0.016200009733438492, -0.04086890071630478, -0.013641253113746643, -0.018108367919921875, -0.0010291463695466518, -0.018969837576150894, -0.006089733447879553, -0.04339767247438431, -0.01501488033682108, -0.013298958539962769] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:500/5550 val_loss:3.559938 train_time:119208ms step_avg:238.42ms x-lambda: 1.0571610927581787 lambdas: [-0.024868275970220566, -0.04460880905389786, -0.020791837945580482, -0.02303561381995678, -0.008773802779614925, -0.023193351924419403, -0.011731176637113094, -0.04661943018436432, -0.019661571830511093, -0.026763271540403366] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:625/5550 val_loss:3.483077 train_time:149711ms step_avg:239.54ms x-lambda: 1.018848180770874 lambdas: [-0.02595955692231655, -0.04336673021316528, -0.022636959329247475, -0.02493804506957531, -0.012315845116972923, -0.022776704281568527, -0.01641896367073059, -0.04663735628128052, -0.019960135221481323, -0.03055552765727043] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:750/5550 val_loss:3.428919 train_time:180520ms step_avg:240.69ms x-lambda: 0.9774010181427002 lambdas: [-0.026639996096491814, -0.04228486865758896, -0.025397861376404762, -0.023543210700154305, -0.014717338606715202, -0.023190511390566826, -0.019157078117132187, -0.044794321060180664, -0.019956666976213455, -0.03157041221857071] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:875/5550 val_loss:3.382568 train_time:211431ms step_avg:241.64ms x-lambda: 0.9311240911483765 lambdas: [-0.026020079851150513, -0.04001446068286896, -0.025020042434334755, -0.024876093491911888, -0.01588919572532177, -0.023378435522317886, -0.01979256048798561, -0.041509103029966354, -0.020451806485652924, -0.031197400763630867] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1000/5550 val_loss:3.347980 train_time:242629ms step_avg:242.63ms x-lambda: 0.8918663859367371 lambdas: [-0.02316427230834961, -0.036083973944187164, -0.02285519801080227, -0.022203953936696053, -0.015242687426507473, -0.020760701969265938, -0.018506215885281563, -0.03737850859761238, -0.017756875604391098, -0.0287637896835804] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1125/5550 val_loss:3.320748 train_time:273844ms step_avg:243.42ms x-lambda: 0.8524508476257324 lambdas: [-0.023531850427389145, -0.03573266416788101, -0.024571962654590607, -0.023156775161623955, -0.016161862760782242, -0.0220039039850235, -0.01944804936647415, -0.036944638937711716, -0.02019745297729969, -0.02946268767118454] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1250/5550 val_loss:3.292244 train_time:305191ms step_avg:244.15ms x-lambda: 0.8198102116584778 lambdas: [-0.020972751080989838, -0.03238781914114952, -0.02165813557803631, -0.021032627671957016, -0.015293034724891186, -0.01943061873316765, -0.017505649477243423, -0.03270166367292404, -0.017927946522831917, -0.02580178529024124] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1375/5550 val_loss:3.272214 train_time:336737ms step_avg:244.90ms x-lambda: 0.7886757254600525 lambdas: [-0.01887638494372368, -0.030820386484265327, -0.020414991304278374, -0.019734090194106102, -0.013554153963923454, -0.019837941974401474, -0.016444893553853035, -0.031807661056518555, -0.017778445035219193, -0.02538180537521839] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1500/5550 val_loss:3.255604 train_time:368241ms step_avg:245.49ms x-lambda: 0.763684093952179 lambdas: [-0.01981331780552864, -0.030259039252996445, -0.018931418657302856, -0.019719859585165977, -0.014489244669675827, -0.01974382810294628, -0.0164476428180933, -0.03043534979224205, -0.016321741044521332, -0.02385939285159111] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1625/5550 val_loss:3.239580 train_time:399811ms step_avg:246.04ms x-lambda: 0.7395200133323669 lambdas: [-0.016902944073081017, -0.028215639293193817, -0.017831919714808464, -0.018090087920427322, -0.01274463813751936, -0.01673785410821438, -0.014051706530153751, -0.027828359976410866, -0.014687423594295979, -0.021819207817316055] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1750/5550 val_loss:3.221373 train_time:431381ms step_avg:246.50ms x-lambda: 0.7168369293212891 lambdas: [-0.016214974224567413, -0.02613052725791931, -0.017170825973153114, -0.01696116290986538, -0.011762768030166626, -0.015417094342410564, -0.012808939442038536, -0.026621172204613686, -0.013515491038560867, -0.0206092968583107] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:1875/5550 val_loss:3.203071 train_time:463000ms step_avg:246.93ms x-lambda: 0.7010380029678345 lambdas: [-0.015214504674077034, -0.02459738403558731, -0.016759390011429787, -0.016309663653373718, -0.011566066183149815, -0.015258094295859337, -0.014120644889771938, -0.024396248161792755, -0.013832055032253265, -0.01980077102780342] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2000/5550 val_loss:3.188925 train_time:494800ms step_avg:247.40ms x-lambda: 0.6834726929664612 lambdas: [-0.015320316888391972, -0.024304665625095367, -0.015570173040032387, -0.013940989971160889, -0.01154871191829443, -0.014293931424617767, -0.013090871274471283, -0.022705135866999626, -0.011338946409523487, -0.019345710054039955] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2125/5550 val_loss:3.173780 train_time:526617ms step_avg:247.82ms x-lambda: 0.6730743050575256 lambdas: [-0.014912769198417664, -0.022792572155594826, -0.014896109700202942, -0.01486524660140276, -0.01075058989226818, -0.014722391963005066, -0.012988383881747723, -0.022704577073454857, -0.012539452873170376, -0.018338898196816444] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2250/5550 val_loss:3.159705 train_time:558460ms step_avg:248.20ms x-lambda: 0.6625578999519348 lambdas: [-0.013473695144057274, -0.021909654140472412, -0.014729947783052921, -0.015199598856270313, -0.011177594773471355, -0.01406916044652462, -0.013391191139817238, -0.021843798458576202, -0.011576497927308083, -0.018213264644145966] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2375/5550 val_loss:3.149397 train_time:590309ms step_avg:248.55ms x-lambda: 0.6558646559715271 lambdas: [-0.012368633411824703, -0.020258959382772446, -0.012411195784807205, -0.012156199663877487, -0.008955429308116436, -0.012611161917448044, -0.011352885514497757, -0.019615311175584793, -0.01041937805712223, -0.01682855561375618] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2500/5550 val_loss:3.135991 train_time:622116ms step_avg:248.85ms x-lambda: 0.6465991139411926 lambdas: [-0.013461949303746223, -0.020202334970235825, -0.01338956505060196, -0.0137025760486722, -0.008786937221884727, -0.012713932432234287, -0.011171985417604446, -0.019685745239257812, -0.010418190620839596, -0.01691143773496151] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2625/5550 val_loss:3.124753 train_time:653929ms step_avg:249.12ms x-lambda: 0.6421444416046143 lambdas: [-0.011972899548709393, -0.01899622566998005, -0.011528328992426395, -0.011872763745486736, -0.010000120848417282, -0.011647509410977364, -0.009941913187503815, -0.018779965117573738, -0.010236223228275776, -0.014256173744797707] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2750/5550 val_loss:3.113990 train_time:685742ms step_avg:249.36ms x-lambda: 0.6363760828971863 lambdas: [-0.01178514864295721, -0.019418863579630852, -0.012686311267316341, -0.011946449056267738, -0.009872030466794968, -0.01196055393666029, -0.01103296596556902, -0.019185269251465797, -0.011288934387266636, -0.015313918702304363] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:2875/5550 val_loss:3.104503 train_time:717579ms step_avg:249.59ms x-lambda: 0.6333808302879333 lambdas: [-0.010315267369151115, -0.017455248162150383, -0.01130681112408638, -0.011932166293263435, -0.009305717423558235, -0.010881181806325912, -0.009319955483078957, -0.01789875701069832, -0.010489760898053646, -0.014413599856197834] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3000/5550 val_loss:3.093050 train_time:749405ms step_avg:249.80ms x-lambda: 0.6307319402694702 lambdas: [-0.011514130979776382, -0.01889513060450554, -0.011662382632493973, -0.012321040965616703, -0.009316589683294296, -0.011302444152534008, -0.010995796881616116, -0.017520315945148468, -0.009438843466341496, -0.014210221357643604] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3125/5550 val_loss:3.082435 train_time:781273ms step_avg:250.01ms x-lambda: 0.6280609369277954 lambdas: [-0.011505022644996643, -0.019653648138046265, -0.012559409253299236, -0.011727619916200638, -0.010133238509297371, -0.010763632133603096, -0.010033206082880497, -0.018304232507944107, -0.010374041274189949, -0.014992717653512955] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3250/5550 val_loss:3.070987 train_time:813099ms step_avg:250.18ms x-lambda: 0.6278167963027954 lambdas: [-0.011487854644656181, -0.018352163955569267, -0.012136382050812244, -0.011420412920415401, -0.009150461293756962, -0.011234871111810207, -0.00977807305753231, -0.016748623922467232, -0.009939032606780529, -0.014235424809157848] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3375/5550 val_loss:3.062523 train_time:844935ms step_avg:250.35ms x-lambda: 0.6277403831481934 lambdas: [-0.01097080484032631, -0.018735909834504128, -0.01257403939962387, -0.011259225197136402, -0.00901791825890541, -0.010300971567630768, -0.009839029051363468, -0.01716824434697628, -0.009655737318098545, -0.014699714258313179] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3500/5550 val_loss:3.053640 train_time:876798ms step_avg:250.51ms x-lambda: 0.6268295645713806 lambdas: [-0.011964166536927223, -0.017691534012556076, -0.011763375252485275, -0.012268172577023506, -0.009552127681672573, -0.010767576284706593, -0.009640772826969624, -0.017239399254322052, -0.009574931114912033, -0.013364228419959545] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3625/5550 val_loss:3.045055 train_time:908613ms step_avg:250.65ms x-lambda: 0.6293405294418335 lambdas: [-0.010400115512311459, -0.017941497266292572, -0.009610508568584919, -0.010137403383851051, -0.007595484610646963, -0.011203301139175892, -0.009303483180701733, -0.01644938252866268, -0.008217696100473404, -0.013418572023510933] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3750/5550 val_loss:3.035462 train_time:940443ms step_avg:250.78ms x-lambda: 0.6288462281227112 lambdas: [-0.010833201929926872, -0.0167806725949049, -0.010602772235870361, -0.010430125519633293, -0.008229994215071201, -0.010049466043710709, -0.009167196229100227, -0.015139305964112282, -0.00903999898582697, -0.01297158282250166] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:3875/5550 val_loss:3.026534 train_time:972362ms step_avg:250.93ms x-lambda: 0.6357458233833313 lambdas: [-0.010357721708714962, -0.016903676092624664, -0.009906161576509476, -0.011066334322094917, -0.007945924997329712, -0.009804080240428448, -0.009204786270856857, -0.016608716920018196, -0.009232381358742714, -0.012617887929081917] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4000/5550 val_loss:3.017331 train_time:1004217ms step_avg:251.05ms x-lambda: 0.6375323534011841 lambdas: [-0.010274000465869904, -0.017080850899219513, -0.010612087324261665, -0.010432093404233456, -0.00858895294368267, -0.009906599298119545, -0.008704813197255135, -0.016374696046113968, -0.009781592525541782, -0.01257014274597168] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4125/5550 val_loss:3.007910 train_time:1036132ms step_avg:251.18ms x-lambda: 0.6405017375946045 lambdas: [-0.009081595577299595, -0.015643227845430374, -0.009765858761966228, -0.01008563581854105, -0.00846339575946331, -0.010451797395944595, -0.009111110121011734, -0.0152093805372715, -0.008424951694905758, -0.012664275243878365] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4250/5550 val_loss:2.999420 train_time:1068269ms step_avg:251.36ms x-lambda: 0.6458157896995544 lambdas: [-0.00978206004947424, -0.017706703394651413, -0.009911407716572285, -0.010305513627827168, -0.007437019608914852, -0.0103608388453722, -0.008235127665102482, -0.015861017629504204, -0.008034208789467812, -0.012976417317986488] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4375/5550 val_loss:2.990459 train_time:1100425ms step_avg:251.53ms x-lambda: 0.6486232280731201 lambdas: [-0.010353997349739075, -0.01601523347198963, -0.010239595547318459, -0.010287684388458729, -0.008459891192615032, -0.010828058235347271, -0.0088192755356431, -0.01563457027077675, -0.008684850297868252, -0.013424739241600037] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4500/5550 val_loss:2.982347 train_time:1132652ms step_avg:251.70ms x-lambda: 0.6540797352790833 lambdas: [-0.010799949057400227, -0.016587236896157265, -0.009937994182109833, -0.009362510405480862, -0.007979942485690117, -0.0100021380931139, -0.008263403549790382, -0.015559952706098557, -0.008810646831989288, -0.01318616233766079] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4625/5550 val_loss:2.972968 train_time:1165006ms step_avg:251.89ms x-lambda: 0.6616079807281494 lambdas: [-0.00944497436285019, -0.01764000952243805, -0.009960555471479893, -0.009813687764108181, -0.007279832847416401, -0.01054044347256422, -0.008395505137741566, -0.01622833125293255, -0.00915854424238205, -0.012881917878985405] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4750/5550 val_loss:2.963712 train_time:1197446ms step_avg:252.09ms x-lambda: 0.667471706867218 lambdas: [-0.008562321774661541, -0.014984041452407837, -0.009419343434274197, -0.01036165002733469, -0.007763630244880915, -0.009783588349819183, -0.00789575558155775, -0.015050908550620079, -0.008099214173853397, -0.012170074507594109] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:4875/5550 val_loss:2.954899 train_time:1230054ms step_avg:252.32ms x-lambda: 0.6739971041679382 lambdas: [-0.009837184101343155, -0.015715807676315308, -0.009084612131118774, -0.009788697585463524, -0.008655265904963017, -0.01034922618418932, -0.00898108258843422, -0.01553423423320055, -0.008192972280085087, -0.01244067121297121] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5000/5550 val_loss:2.946828 train_time:1262763ms step_avg:252.55ms x-lambda: 0.681202232837677 lambdas: [-0.009579402394592762, -0.016146963462233543, -0.01004084013402462, -0.008991453796625137, -0.007751575671136379, -0.009235593490302563, -0.007564398925751448, -0.014960949309170246, -0.008749954402446747, -0.011182237416505814] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5125/5550 val_loss:2.939019 train_time:1295606ms step_avg:252.80ms x-lambda: 0.6882541179656982 lambdas: [-0.009050252847373486, -0.014940395019948483, -0.009197409264743328, -0.009767594747245312, -0.007241991814225912, -0.009110680781304836, -0.007696513086557388, -0.015194681473076344, -0.00814595352858305, -0.01136227510869503] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5250/5550 val_loss:2.931722 train_time:1328689ms step_avg:253.08ms x-lambda: 0.6949196457862854 lambdas: [-0.008784216828644276, -0.014843319542706013, -0.009097878821194172, -0.010262612253427505, -0.007429671939462423, -0.009531598538160324, -0.007933931425213814, -0.01400816347450018, -0.007345179095864296, -0.011815221980214119] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5375/5550 val_loss:2.925395 train_time:1361831ms step_avg:253.36ms x-lambda: 0.7023986577987671 lambdas: [-0.00963079184293747, -0.014543347992002964, -0.00900652538985014, -0.009718158282339573, -0.007242627441883087, -0.009341193363070488, -0.007959946990013123, -0.014305809512734413, -0.00760598573833704, -0.01125309057533741] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5500/5550 val_loss:2.920550 train_time:1395275ms step_avg:253.69ms x-lambda: 0.7084074020385742 lambdas: [-0.0093779806047678, -0.014761839993298054, -0.009569291025400162, -0.009310564026236534, -0.007599779404699802, -0.010105074383318424, -0.007918931543827057, -0.015070333145558834, -0.007705389056354761, -0.01137594599276781] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]
step:5550/5550 val_loss:2.919363 train_time:1408708ms step_avg:253.82ms x-lambda: 0.7099339365959167 lambdas: [-0.009432231076061726, -0.015048474073410034, -0.009342389181256294, -0.009582556784152985, -0.007666341960430145, -0.009828583337366581, -0.008054504171013832, -0.01448200922459364, -0.007974871434271336, -0.011653441935777664] skip-layers: [12, 2, 0, 14, 5, 4, 1, 13, 10, 9]



## 8000-add-skip-multiple-10-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:1.21ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:125/5550 val_loss:4.258632 train_time:29340ms step_avg:234.72ms x-lambda: 1.0315905809402466 lambdas: [0.002444110345095396, -0.023699067533016205, 0.030072931200265884, 0.02474023401737213, 0.03302625194191933, 0.05196526274085045, 0.033681295812129974, 0.07161969691514969, 0.030898382887244225, -0.0385279655456543] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:250/5550 val_loss:3.847554 train_time:58809ms step_avg:235.24ms x-lambda: 1.000010371208191 lambdas: [-0.034660276025533676, -0.07164658606052399, 0.02100815623998642, 0.013154511339962482, 0.008184298872947693, 0.06318620592355728, 0.03762326389551163, 0.07009480148553848, 0.03363185003399849, -0.1116747185587883] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:375/5550 val_loss:3.670304 train_time:88714ms step_avg:236.57ms x-lambda: 0.965959370136261 lambdas: [-0.04528101906180382, -0.08614597469568253, 0.011315448209643364, 0.0041445167735219, -0.021141069009900093, 0.05658436194062233, 0.02832416631281376, 0.0618266798555851, 0.029911190271377563, -0.14260901510715485] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:500/5550 val_loss:3.554990 train_time:119013ms step_avg:238.03ms x-lambda: 0.9477624297142029 lambdas: [-0.04476609453558922, -0.08816774934530258, 0.010600734502077103, -0.0064605604857206345, -0.038825057446956635, 0.054325494915246964, 0.013952882960438728, 0.05762815475463867, 0.021495530381798744, -0.14985518157482147] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:625/5550 val_loss:3.477337 train_time:149545ms step_avg:239.27ms x-lambda: 0.9283632040023804 lambdas: [-0.044515930116176605, -0.09107373654842377, 0.00989171490073204, -0.020751649513840675, -0.05175497755408287, 0.05113636702299118, -0.005694685969501734, 0.05068816989660263, 0.008090768940746784, -0.148338183760643] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:750/5550 val_loss:3.424664 train_time:180315ms step_avg:240.42ms x-lambda: 0.9180233478546143 lambdas: [-0.040982551872730255, -0.08972547948360443, 0.011638433672487736, -0.030325356870889664, -0.05597373843193054, 0.049225814640522, -0.022617151960730553, 0.04771512746810913, -0.0018377858214080334, -0.14013953506946564] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:875/5550 val_loss:3.378761 train_time:211171ms step_avg:241.34ms x-lambda: 0.9077959656715393 lambdas: [-0.03770951181650162, -0.0879971981048584, 0.010841004550457, -0.039383020251989365, -0.05749973654747009, 0.0483684316277504, -0.0407952219247818, 0.044468846172094345, -0.012671741656959057, -0.1291259378194809] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1000/5550 val_loss:3.343683 train_time:242342ms step_avg:242.34ms x-lambda: 0.8970781564712524 lambdas: [-0.03399459645152092, -0.08598167449235916, 0.010831286199390888, -0.047568242996931076, -0.05755789205431938, 0.04498754069209099, -0.05701819434762001, 0.04206181690096855, -0.022685294970870018, -0.11750166118144989] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1125/5550 val_loss:3.315979 train_time:273547ms step_avg:243.15ms x-lambda: 0.888996422290802 lambdas: [-0.03217356279492378, -0.08479689061641693, 0.010063707828521729, -0.05455098673701286, -0.05793605372309685, 0.04136331379413605, -0.07239440083503723, 0.03709853067994118, -0.03240010887384415, -0.10950605571269989] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1250/5550 val_loss:3.294588 train_time:304859ms step_avg:243.89ms x-lambda: 0.8867217898368835 lambdas: [-0.027595670893788338, -0.08055579662322998, 0.011829383671283722, -0.0563313364982605, -0.055604707449674606, 0.041012607514858246, -0.08299760520458221, 0.038294728845357895, -0.03778254613280296, -0.09859637916088104] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1375/5550 val_loss:3.270606 train_time:336377ms step_avg:244.64ms x-lambda: 0.8775672912597656 lambdas: [-0.027649899944663048, -0.08147141337394714, 0.007868209853768349, -0.06360094249248505, -0.0570683516561985, 0.03672242909669876, -0.0976625382900238, 0.03274701535701752, -0.04869631677865982, -0.09395407885313034] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1500/5550 val_loss:3.249046 train_time:367852ms step_avg:245.23ms x-lambda: 0.8750693202018738 lambdas: [-0.024983320385217667, -0.07853058725595474, 0.010055205784738064, -0.06572960317134857, -0.0535501204431057, 0.03471558168530464, -0.10757001489400864, 0.03157823532819748, -0.05495305359363556, -0.08614718914031982] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1625/5550 val_loss:3.234264 train_time:399412ms step_avg:245.79ms x-lambda: 0.8705686330795288 lambdas: [-0.022632792592048645, -0.07690925151109695, 0.009194018319249153, -0.06882829964160919, -0.052572667598724365, 0.03305050730705261, -0.11774536222219467, 0.03048229031264782, -0.062253329902887344, -0.08038707077503204] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1750/5550 val_loss:3.219711 train_time:430937ms step_avg:246.25ms x-lambda: 0.8670615553855896 lambdas: [-0.02140071429312229, -0.07337430864572525, 0.010606471449136734, -0.07248548418283463, -0.0498315803706646, 0.03244759887456894, -0.12723681330680847, 0.029591647908091545, -0.0698930025100708, -0.07453697174787521] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:1875/5550 val_loss:3.201340 train_time:462521ms step_avg:246.68ms x-lambda: 0.8661966919898987 lambdas: [-0.02070685848593712, -0.07219047844409943, 0.009248390793800354, -0.07469544559717178, -0.04978121444582939, 0.03041919134557247, -0.13487285375595093, 0.02791980654001236, -0.07623788714408875, -0.07053082436323166] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2000/5550 val_loss:3.186657 train_time:494309ms step_avg:247.15ms x-lambda: 0.865756630897522 lambdas: [-0.01855769008398056, -0.06887029856443405, 0.008595244958996773, -0.07597629725933075, -0.046132441610097885, 0.029112353920936584, -0.14095740020275116, 0.026989685371518135, -0.08302716910839081, -0.0652984082698822] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2125/5550 val_loss:3.171571 train_time:526139ms step_avg:247.59ms x-lambda: 0.8668825030326843 lambdas: [-0.01674715057015419, -0.06695126742124557, 0.007875600829720497, -0.07728096097707748, -0.04584599658846855, 0.028666993603110313, -0.14694857597351074, 0.0255084540694952, -0.08954881131649017, -0.06218194216489792] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2250/5550 val_loss:3.157650 train_time:557985ms step_avg:247.99ms x-lambda: 0.8681519031524658 lambdas: [-0.01704411767423153, -0.065725177526474, 0.007105709053575993, -0.07888144254684448, -0.04563327133655548, 0.02671283297240734, -0.15247121453285217, 0.02493046410381794, -0.09619705379009247, -0.05968157947063446] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2375/5550 val_loss:3.146820 train_time:589846ms step_avg:248.36ms x-lambda: 0.8683645725250244 lambdas: [-0.01680188626050949, -0.06407525390386581, 0.006225614342838526, -0.08040492981672287, -0.04488333687186241, 0.024783950299024582, -0.15749305486679077, 0.023254642263054848, -0.10309796035289764, -0.05701488256454468] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2500/5550 val_loss:3.134991 train_time:621647ms step_avg:248.66ms x-lambda: 0.8709557056427002 lambdas: [-0.015117774717509747, -0.06291989982128143, 0.004928811453282833, -0.08033780008554459, -0.04385234788060188, 0.025069214403629303, -0.1602027267217636, 0.023524455726146698, -0.10850603133440018, -0.05469494313001633] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2625/5550 val_loss:3.124164 train_time:653473ms step_avg:248.94ms x-lambda: 0.8712265491485596 lambdas: [-0.015286710113286972, -0.06136075034737587, 0.005161748733371496, -0.08154294639825821, -0.042688991874456406, 0.023062512278556824, -0.16434794664382935, 0.021816447377204895, -0.11512934416532516, -0.051627255976200104] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2750/5550 val_loss:3.112890 train_time:685272ms step_avg:249.19ms x-lambda: 0.8762627840042114 lambdas: [-0.012271695770323277, -0.05897917225956917, 0.006641862913966179, -0.07994398474693298, -0.03901667147874832, 0.024181663990020752, -0.16583505272865295, 0.023112380877137184, -0.1189902126789093, -0.0482322983443737] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:2875/5550 val_loss:3.103423 train_time:717117ms step_avg:249.43ms x-lambda: 0.8784391283988953 lambdas: [-0.01255302969366312, -0.05681093782186508, 0.005308161955326796, -0.08052399009466171, -0.038396600633859634, 0.023591365665197372, -0.16755540668964386, 0.022929159924387932, -0.12451495975255966, -0.04754991829395294] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3000/5550 val_loss:3.092302 train_time:748947ms step_avg:249.65ms x-lambda: 0.8821191191673279 lambdas: [-0.014133187010884285, -0.05707605928182602, 0.004880858585238457, -0.08123084157705307, -0.03897441551089287, 0.021154535934329033, -0.16990278661251068, 0.02000471204519272, -0.1301182210445404, -0.047030720859766006] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3125/5550 val_loss:3.082029 train_time:780847ms step_avg:249.87ms x-lambda: 0.8835880756378174 lambdas: [-0.012971747666597366, -0.05808937922120094, 0.003943068906664848, -0.08354412019252777, -0.03927801549434662, 0.020467229187488556, -0.17243215441703796, 0.01964625157415867, -0.13645362854003906, -0.04567129909992218] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3250/5550 val_loss:3.070275 train_time:812688ms step_avg:250.06ms x-lambda: 0.8882970809936523 lambdas: [-0.01225439552217722, -0.05680243670940399, 0.003483738051727414, -0.08313234150409698, -0.037755370140075684, 0.021055947989225388, -0.17332613468170166, 0.020486649125814438, -0.1401827186346054, -0.043998293578624725] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3375/5550 val_loss:3.062298 train_time:844520ms step_avg:250.23ms x-lambda: 0.8923276662826538 lambdas: [-0.013162098824977875, -0.055305276066064835, 0.0032351664267480373, -0.08281893283128738, -0.03670933470129967, 0.020445866510272026, -0.1755755990743637, 0.019209716469049454, -0.14522746205329895, -0.043347667902708054] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3500/5550 val_loss:3.053225 train_time:876365ms step_avg:250.39ms x-lambda: 0.8958950638771057 lambdas: [-0.011687596328556538, -0.05427749454975128, 0.0034598475322127342, -0.08369828760623932, -0.0374058298766613, 0.01933959126472473, -0.17737095057964325, 0.019331591203808784, -0.1493951678276062, -0.041335977613925934] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3625/5550 val_loss:3.043852 train_time:908183ms step_avg:250.53ms x-lambda: 0.9018278121948242 lambdas: [-0.011423005722463131, -0.053043171763420105, 0.004103712737560272, -0.08237966895103455, -0.03630664199590683, 0.01870298944413662, -0.1768682450056076, 0.01974903978407383, -0.15311171114444733, -0.04133632779121399] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3750/5550 val_loss:3.034359 train_time:940014ms step_avg:250.67ms x-lambda: 0.9062947034835815 lambdas: [-0.010668376460671425, -0.05192665383219719, 0.003316042711958289, -0.08243696391582489, -0.03548479452729225, 0.01977040246129036, -0.17768535017967224, 0.02009548246860504, -0.15710240602493286, -0.03911284729838371] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:3875/5550 val_loss:3.026079 train_time:971923ms step_avg:250.82ms x-lambda: 0.9129186272621155 lambdas: [-0.011264667846262455, -0.05086100846529007, 0.0036154617555439472, -0.0805673599243164, -0.035511136054992676, 0.018656160682439804, -0.17894630134105682, 0.019045433029532433, -0.16074271500110626, -0.039945509284734726] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4000/5550 val_loss:3.016245 train_time:1003796ms step_avg:250.95ms x-lambda: 0.9183921813964844 lambdas: [-0.01095152460038662, -0.05023803934454918, 0.0028861842583864927, -0.08131437748670578, -0.0349811352789402, 0.01814354956150055, -0.1791839450597763, 0.019121332094073296, -0.16445571184158325, -0.038163721561431885] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4125/5550 val_loss:3.007192 train_time:1035709ms step_avg:251.08ms x-lambda: 0.9243103265762329 lambdas: [-0.0111217200756073, -0.05096524953842163, 0.0026921755634248257, -0.08136021345853806, -0.03320454806089401, 0.01757677085697651, -0.18185505270957947, 0.019784875214099884, -0.1690937727689743, -0.038536060601472855] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4250/5550 val_loss:2.998928 train_time:1067840ms step_avg:251.26ms x-lambda: 0.930655300617218 lambdas: [-0.009844143874943256, -0.049254342913627625, 0.002435619942843914, -0.08017109334468842, -0.03335089981555939, 0.019024306908249855, -0.18181611597537994, 0.018262309953570366, -0.1713157296180725, -0.03723044693470001] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4375/5550 val_loss:2.989891 train_time:1100007ms step_avg:251.43ms x-lambda: 0.935851514339447 lambdas: [-0.010396997444331646, -0.050692930817604065, 0.0022500662598758936, -0.08186884224414825, -0.032933395355939865, 0.017428351566195488, -0.18441526591777802, 0.018376868218183517, -0.17612485587596893, -0.037528231739997864] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4500/5550 val_loss:2.981463 train_time:1132211ms step_avg:251.60ms x-lambda: 0.9429643154144287 lambdas: [-0.009839000180363655, -0.05002830922603607, 0.002377406693994999, -0.08148093521595001, -0.03329390287399292, 0.01754128374159336, -0.18437738716602325, 0.01835058629512787, -0.17962853610515594, -0.03726070746779442] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4625/5550 val_loss:2.971967 train_time:1164568ms step_avg:251.80ms x-lambda: 0.9509384036064148 lambdas: [-0.00952249113470316, -0.048168059438467026, 0.0008721002377569675, -0.07985223829746246, -0.03193753957748413, 0.01713230460882187, -0.1841384619474411, 0.018753455951809883, -0.18178699910640717, -0.03551199287176132] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4750/5550 val_loss:2.962784 train_time:1196996ms step_avg:252.00ms x-lambda: 0.9573146104812622 lambdas: [-0.008277013897895813, -0.04760558903217316, 0.0019079952035099268, -0.08025134354829788, -0.03153344243764877, 0.016897372901439667, -0.18481960892677307, 0.01923033408820629, -0.18395209312438965, -0.035218823701143265] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:4875/5550 val_loss:2.953747 train_time:1229577ms step_avg:252.22ms x-lambda: 0.9638922810554504 lambdas: [-0.008390138857066631, -0.04857783764600754, 0.0008084478322416544, -0.07998901605606079, -0.031571049243211746, 0.015378615818917751, -0.18571831285953522, 0.018695728853344917, -0.1868317723274231, -0.0358157642185688] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5000/5550 val_loss:2.945594 train_time:1262285ms step_avg:252.46ms x-lambda: 0.971086323261261 lambdas: [-0.009297390468418598, -0.048298802226781845, 0.0006678454810753465, -0.0797705203294754, -0.03222096711397171, 0.016569841653108597, -0.18613046407699585, 0.018605511635541916, -0.18844252824783325, -0.03513349965214729] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5125/5550 val_loss:2.938030 train_time:1295133ms step_avg:252.71ms x-lambda: 0.9762704372406006 lambdas: [-0.007710025645792484, -0.04736391827464104, 0.0007462332723662257, -0.0800691694021225, -0.031042376533150673, 0.015646997839212418, -0.18712244927883148, 0.01821226254105568, -0.19112814962863922, -0.0335109569132328] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5250/5550 val_loss:2.930765 train_time:1328194ms step_avg:252.99ms x-lambda: 0.9820489287376404 lambdas: [-0.008126547560095787, -0.047193970531225204, 0.0013210955075919628, -0.07969243079423904, -0.029696742072701454, 0.015415199100971222, -0.18746159970760345, 0.017766254022717476, -0.19287040829658508, -0.033627040684223175] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5375/5550 val_loss:2.924330 train_time:1361358ms step_avg:253.28ms x-lambda: 0.9876697659492493 lambdas: [-0.00811771396547556, -0.04788545146584511, 2.682824560906738e-05, -0.07924361526966095, -0.030497735366225243, 0.01616436243057251, -0.18772253394126892, 0.018354831263422966, -0.19336609542369843, -0.03401876986026764] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5500/5550 val_loss:2.919576 train_time:1394801ms step_avg:253.60ms x-lambda: 0.9905522465705872 lambdas: [-0.008527377620339394, -0.047166891396045685, -4.766422716784291e-05, -0.07912296801805496, -0.0295676551759243, 0.015252364799380302, -0.18826524913311005, 0.01751781813800335, -0.19406796991825104, -0.03383231163024902] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]
step:5550/5550 val_loss:2.918391 train_time:1408238ms step_avg:253.74ms x-lambda: 0.9913191795349121 lambdas: [-0.008037618361413479, -0.047548044472932816, -0.0004054770979564637, -0.07900714874267578, -0.029841391369700432, 0.015360353514552116, -0.18854817748069763, 0.017861472442746162, -0.19437836110591888, -0.03355634957551956] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3]



## 8000-add-skip-multiple-11-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:125/5550 val_loss:4.256218 train_time:29345ms step_avg:234.76ms x-lambda: 1.0205624103546143 lambdas: [0.023010892793536186, 0.031175626441836357, 0.01799219474196434, 0.05873797833919525, 0.0166401918977499, -0.05633817985653877, 0.017222469672560692, 0.0664970725774765, 0.020246902480721474, 0.04127119854092598, 0.02449866384267807] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:250/5550 val_loss:3.847475 train_time:58832ms step_avg:235.33ms x-lambda: 1.0014362335205078 lambdas: [0.01608848199248314, 0.018105128780007362, -0.009223486296832561, 0.08901339769363403, -0.03902124613523483, -0.16533814370632172, 0.021836979314684868, 0.042206164449453354, 0.01975262351334095, 0.04841988533735275, 0.009180469438433647] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:375/5550 val_loss:3.672942 train_time:88787ms step_avg:236.76ms x-lambda: 0.9972254633903503 lambdas: [0.004299420863389969, -0.015040676109492779, -0.011094649322330952, 0.08895514160394669, -0.09194432944059372, -0.21371150016784668, 0.0291728712618351, 0.030199594795703888, 0.01701343059539795, 0.044841960072517395, 0.0010903255315497518] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:500/5550 val_loss:3.556348 train_time:119076ms step_avg:238.15ms x-lambda: 0.9923182725906372 lambdas: [-0.012811422348022461, -0.04927106946706772, -0.004162736237049103, 0.08301080763339996, -0.1282455325126648, -0.23520517349243164, 0.024752266705036163, 0.02372472546994686, 0.005822526291012764, 0.040140699595212936, -0.001551159773953259] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:625/5550 val_loss:3.477945 train_time:149590ms step_avg:239.34ms x-lambda: 0.9888577461242676 lambdas: [-0.024993471801280975, -0.07584892213344574, 0.007985835894942284, 0.08047313243150711, -0.14512623846530914, -0.2377282828092575, 0.02176901325583458, 0.02150801569223404, -0.003075709566473961, 0.03853989019989967, 0.003732762299478054] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:750/5550 val_loss:3.426998 train_time:180416ms step_avg:240.55ms x-lambda: 0.9851954579353333 lambdas: [-0.03773205354809761, -0.09824161231517792, 0.015246058814227581, 0.0771792009472847, -0.1502644568681717, -0.23269276320934296, 0.015650445595383644, 0.019169578328728676, -0.013706722296774387, 0.034863196313381195, 0.00666642002761364] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:875/5550 val_loss:3.379734 train_time:211352ms step_avg:241.55ms x-lambda: 0.973271906375885 lambdas: [-0.05132264271378517, -0.1181742399930954, 0.016934463754296303, 0.07199189811944962, -0.15049205720424652, -0.22436955571174622, 0.006078720558434725, 0.014660689048469067, -0.02701239474117756, 0.030864300206303596, 0.00614611292257905] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1000/5550 val_loss:3.345018 train_time:242510ms step_avg:242.51ms x-lambda: 0.965700626373291 lambdas: [-0.06146702542901039, -0.13337527215480804, 0.018162740394473076, 0.0677742213010788, -0.1454755663871765, -0.20984649658203125, -0.0019642235711216927, 0.014142332598567009, -0.03783576935529709, 0.02754402533173561, 0.00621173856779933] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1125/5550 val_loss:3.316675 train_time:273677ms step_avg:243.27ms x-lambda: 0.9583278894424438 lambdas: [-0.06983787566423416, -0.14608436822891235, 0.01972053200006485, 0.061595648527145386, -0.137172669172287, -0.1964237540960312, -0.010368035174906254, 0.012340459041297436, -0.04804123565554619, 0.024962080642580986, 0.006717517040669918] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1250/5550 val_loss:3.292261 train_time:304992ms step_avg:243.99ms x-lambda: 0.9546172022819519 lambdas: [-0.07346533983945847, -0.15155765414237976, 0.02266411855816841, 0.059876106679439545, -0.12655551731586456, -0.1815531849861145, -0.015877127647399902, 0.012999366037547588, -0.05472388118505478, 0.025344720110297203, 0.008599501103162766] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1375/5550 val_loss:3.269640 train_time:336499ms step_avg:244.73ms x-lambda: 0.9446321129798889 lambdas: [-0.07982637733221054, -0.1603698581457138, 0.02117905206978321, 0.054053373634815216, -0.12241870164871216, -0.16983699798583984, -0.025541914626955986, 0.010979771614074707, -0.06491442024707794, 0.021410413086414337, 0.004884161986410618] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1500/5550 val_loss:3.254841 train_time:367956ms step_avg:245.30ms x-lambda: 0.9384030699729919 lambdas: [-0.08451458066701889, -0.16683700680732727, 0.020142927765846252, 0.049374282360076904, -0.11696833372116089, -0.1612316370010376, -0.03345421329140663, 0.008141064085066319, -0.07327044010162354, 0.018831565976142883, 0.004340473096817732] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1625/5550 val_loss:3.235224 train_time:399502ms step_avg:245.85ms x-lambda: 0.9335801601409912 lambdas: [-0.08537210524082184, -0.1681579351425171, 0.02278427965939045, 0.04863844811916351, -0.10876112431287766, -0.1486893743276596, -0.03920618072152138, 0.010552438907325268, -0.0784129723906517, 0.021516185253858566, 0.008018363267183304] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1750/5550 val_loss:3.219622 train_time:431011ms step_avg:246.29ms x-lambda: 0.9262823462486267 lambdas: [-0.08833801001310349, -0.16993361711502075, 0.021790267899632454, 0.04413508623838425, -0.10366689413785934, -0.1403760462999344, -0.047892261296510696, 0.009331575594842434, -0.08548987656831741, 0.018861988559365273, 0.0061622001230716705] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:1875/5550 val_loss:3.202323 train_time:462592ms step_avg:246.72ms x-lambda: 0.9225435256958008 lambdas: [-0.08792020380496979, -0.16973620653152466, 0.022799041122198105, 0.041734226047992706, -0.097246453166008, -0.1312466710805893, -0.05315135419368744, 0.009905197657644749, -0.08925614506006241, 0.019396677613258362, 0.00552467443048954] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2000/5550 val_loss:3.186280 train_time:494370ms step_avg:247.18ms x-lambda: 0.9164749979972839 lambdas: [-0.08948859572410583, -0.1701091080904007, 0.020721908658742905, 0.03879604488611221, -0.09273874759674072, -0.12375267595052719, -0.06170979514718056, 0.009029276669025421, -0.09576676785945892, 0.017728473991155624, 0.005501234903931618] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2125/5550 val_loss:3.171564 train_time:526212ms step_avg:247.63ms x-lambda: 0.913285493850708 lambdas: [-0.08946819603443146, -0.1711927354335785, 0.02065962925553322, 0.03626943752169609, -0.09084681421518326, -0.11722638458013535, -0.06771072000265121, 0.008504386059939861, -0.09981602430343628, 0.017531653866171837, 0.003748662304133177] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2250/5550 val_loss:3.157423 train_time:558041ms step_avg:248.02ms x-lambda: 0.9107003211975098 lambdas: [-0.08742355555295944, -0.17044693231582642, 0.019751720130443573, 0.03519231826066971, -0.08762574195861816, -0.11159546673297882, -0.07353105396032333, 0.008869859389960766, -0.1031377911567688, 0.01600446179509163, 0.004674267955124378] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2375/5550 val_loss:3.146244 train_time:589899ms step_avg:248.38ms x-lambda: 0.9077484607696533 lambdas: [-0.08716925233602524, -0.17100165784358978, 0.019704576581716537, 0.03287608176469803, -0.08330728113651276, -0.10683971643447876, -0.07978630065917969, 0.00841878168284893, -0.10719093680381775, 0.014774670824408531, 0.004020174965262413] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2500/5550 val_loss:3.134849 train_time:621683ms step_avg:248.67ms x-lambda: 0.9056206345558167 lambdas: [-0.0864795669913292, -0.1701732873916626, 0.018826516345143318, 0.03141333907842636, -0.08219364285469055, -0.10305754840373993, -0.08553080260753632, 0.00833985023200512, -0.11072517186403275, 0.01478044968098402, 0.004434598609805107] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2625/5550 val_loss:3.123305 train_time:653490ms step_avg:248.95ms x-lambda: 0.9033967852592468 lambdas: [-0.08546703308820724, -0.1704927235841751, 0.017049724236130714, 0.029344411566853523, -0.07929132133722305, -0.0987882912158966, -0.09067220240831375, 0.00672812107950449, -0.11392901092767715, 0.012943974696099758, 0.0032115282956510782] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2750/5550 val_loss:3.112042 train_time:685273ms step_avg:249.19ms x-lambda: 0.9022367596626282 lambdas: [-0.08395780622959137, -0.1678684651851654, 0.01859801635146141, 0.03018469735980034, -0.0756644532084465, -0.0933615192770958, -0.09518105536699295, 0.00842879619449377, -0.1149347573518753, 0.015264284797012806, 0.004831997212022543] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:2875/5550 val_loss:3.102304 train_time:717089ms step_avg:249.42ms x-lambda: 0.9022989869117737 lambdas: [-0.08134429156780243, -0.16772781312465668, 0.018626781180500984, 0.027874818071722984, -0.07382585108280182, -0.09077425301074982, -0.09944846481084824, 0.007558468729257584, -0.11667311936616898, 0.013545777648687363, 0.003442613407969475] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3000/5550 val_loss:3.092676 train_time:748924ms step_avg:249.64ms x-lambda: 0.9034237861633301 lambdas: [-0.07996353507041931, -0.16564972698688507, 0.02000471018254757, 0.02899753488600254, -0.07173055410385132, -0.08624815195798874, -0.10223088413476944, 0.007034857291728258, -0.11737139523029327, 0.015024474821984768, 0.005117664113640785] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3125/5550 val_loss:3.080469 train_time:780809ms step_avg:249.86ms x-lambda: 0.9019820094108582 lambdas: [-0.07996337115764618, -0.16718429327011108, 0.01790279895067215, 0.02629300206899643, -0.07114557176828384, -0.0867641419172287, -0.10751040279865265, 0.007728006225079298, -0.12041344493627548, 0.012986540794372559, 0.004850435070693493] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3250/5550 val_loss:3.069352 train_time:812626ms step_avg:250.04ms x-lambda: 0.9044601917266846 lambdas: [-0.0795196145772934, -0.16738677024841309, 0.017241938039660454, 0.025019504129886627, -0.06849559396505356, -0.08305678516626358, -0.11040114611387253, 0.006507533602416515, -0.12168151140213013, 0.012659662403166294, 0.004342634230852127] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3375/5550 val_loss:3.060982 train_time:844451ms step_avg:250.21ms x-lambda: 0.9057254791259766 lambdas: [-0.07837897539138794, -0.16706892848014832, 0.01745939627289772, 0.023454926908016205, -0.06799084693193436, -0.08226002007722855, -0.11374495923519135, 0.00646220101043582, -0.12330586463212967, 0.011410395614802837, 0.0028911828994750977] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3500/5550 val_loss:3.051342 train_time:876290ms step_avg:250.37ms x-lambda: 0.9075302481651306 lambdas: [-0.07815694063901901, -0.16518591344356537, 0.016906460747122765, 0.022463982924818993, -0.06625940650701523, -0.0799301415681839, -0.11733527481555939, 0.006257901433855295, -0.12427360564470291, 0.012479579076170921, 0.002206866629421711] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3625/5550 val_loss:3.042836 train_time:908111ms step_avg:250.51ms x-lambda: 0.9102904200553894 lambdas: [-0.07676815241575241, -0.16464893519878387, 0.0175776407122612, 0.022237369790673256, -0.0647917240858078, -0.07846491783857346, -0.12021401524543762, 0.005784356500953436, -0.12527748942375183, 0.010390465147793293, 0.0030354366172105074] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3750/5550 val_loss:3.033708 train_time:939948ms step_avg:250.65ms x-lambda: 0.9110364317893982 lambdas: [-0.07773222774267197, -0.16553661227226257, 0.015128941275179386, 0.02198304794728756, -0.06487799435853958, -0.07654304057359695, -0.12402849644422531, 0.005520511884242296, -0.1264011263847351, 0.012047439813613892, 0.0018989709205925465] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:3875/5550 val_loss:3.024691 train_time:971836ms step_avg:250.80ms x-lambda: 0.916167140007019 lambdas: [-0.07476211339235306, -0.1655377298593521, 0.015950951725244522, 0.022491566836833954, -0.06308095157146454, -0.07469150424003601, -0.12541253864765167, 0.005671140272170305, -0.12620292603969574, 0.010667967610061169, 0.0020979736000299454] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4000/5550 val_loss:3.015105 train_time:1003705ms step_avg:250.93ms x-lambda: 0.9193599820137024 lambdas: [-0.07494628429412842, -0.16386811435222626, 0.016516901552677155, 0.02142403833568096, -0.06257379800081253, -0.0727086067199707, -0.12827393412590027, 0.006463332567363977, -0.12781332433223724, 0.010198058560490608, 0.0028605530969798565] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4125/5550 val_loss:3.006237 train_time:1035603ms step_avg:251.06ms x-lambda: 0.9238013625144958 lambdas: [-0.07408306747674942, -0.1637113243341446, 0.01790311187505722, 0.020772775635123253, -0.06069263815879822, -0.07176052778959274, -0.1303165853023529, 0.006661125924438238, -0.12863488495349884, 0.010569322854280472, 0.0028096865862607956] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4250/5550 val_loss:2.998141 train_time:1067705ms step_avg:251.22ms x-lambda: 0.9290457367897034 lambdas: [-0.07371969521045685, -0.1650809943675995, 0.01692514307796955, 0.021095965057611465, -0.06147358566522598, -0.07104209810495377, -0.13189688324928284, 0.006547112483531237, -0.12936004996299744, 0.010914087295532227, 0.0024203439243137836] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4375/5550 val_loss:2.988671 train_time:1099874ms step_avg:251.40ms x-lambda: 0.9324889779090881 lambdas: [-0.07322071492671967, -0.16501595079898834, 0.016949348151683807, 0.021007850766181946, -0.062264446169137955, -0.07056594640016556, -0.13600283861160278, 0.006203383207321167, -0.13109706342220306, 0.010246285237371922, 0.0026115041691809893] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4500/5550 val_loss:2.980621 train_time:1132055ms step_avg:251.57ms x-lambda: 0.9370237588882446 lambdas: [-0.07262644916772842, -0.1649259626865387, 0.01651870831847191, 0.019563324749469757, -0.06040302291512489, -0.0696643814444542, -0.13890619575977325, 0.0058282045647501945, -0.1326829046010971, 0.009267851710319519, 0.0023698038421571255] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4625/5550 val_loss:2.971353 train_time:1164436ms step_avg:251.77ms x-lambda: 0.9434686303138733 lambdas: [-0.07159597426652908, -0.1651352494955063, 0.014499488286674023, 0.01993439719080925, -0.0611104741692543, -0.06852792948484421, -0.1392291635274887, 0.005527873989194632, -0.1326552778482437, 0.009152678772807121, 0.00122983125038445] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4750/5550 val_loss:2.962027 train_time:1196917ms step_avg:251.98ms x-lambda: 0.9495325088500977 lambdas: [-0.07090715318918228, -0.16545279324054718, 0.015183967538177967, 0.02084655687212944, -0.06022072583436966, -0.06764905154705048, -0.14078064262866974, 0.007365715224295855, -0.13282108306884766, 0.010734652169048786, 0.0018001270946115255] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:4875/5550 val_loss:2.953098 train_time:1229523ms step_avg:252.21ms x-lambda: 0.9548550248146057 lambdas: [-0.07000643014907837, -0.16733145713806152, 0.015328770503401756, 0.020180007442831993, -0.05911657586693764, -0.06575668603181839, -0.1424877792596817, 0.006271056830883026, -0.13378770649433136, 0.008762355893850327, 0.0017401899676769972] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5000/5550 val_loss:2.944931 train_time:1262234ms step_avg:252.45ms x-lambda: 0.9609547853469849 lambdas: [-0.06926139444112778, -0.1681661158800125, 0.014769352972507477, 0.020506873726844788, -0.05967830866575241, -0.06614338606595993, -0.14410044252872467, 0.005822549574077129, -0.13530750572681427, 0.00949860829859972, 0.0024067487102001905] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5125/5550 val_loss:2.937246 train_time:1295061ms step_avg:252.69ms x-lambda: 0.9662583470344543 lambdas: [-0.06885190308094025, -0.1695014238357544, 0.014654458500444889, 0.019469281658530235, -0.06001812592148781, -0.06595533341169357, -0.14566197991371155, 0.005812619812786579, -0.13621634244918823, 0.00901393499225378, 0.0018837000243365765] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5250/5550 val_loss:2.930132 train_time:1328111ms step_avg:252.97ms x-lambda: 0.9712681174278259 lambdas: [-0.06775255501270294, -0.16919182240962982, 0.014207522384822369, 0.0203974861651659, -0.05871407687664032, -0.0649525597691536, -0.1465703845024109, 0.005505494307726622, -0.13695338368415833, 0.009525935165584087, 0.002594343153759837] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5375/5550 val_loss:2.923662 train_time:1361265ms step_avg:253.26ms x-lambda: 0.9760192632675171 lambdas: [-0.06750614941120148, -0.16975004971027374, 0.01397599559277296, 0.019476206973195076, -0.05913963168859482, -0.06523539125919342, -0.1471313238143921, 0.006176432594656944, -0.1376446783542633, 0.009054848924279213, 0.001845923950895667] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5500/5550 val_loss:2.918841 train_time:1394697ms step_avg:253.58ms x-lambda: 0.9784969687461853 lambdas: [-0.06684987992048264, -0.17015279829502106, 0.014035781845450401, 0.020155562087893486, -0.05896884202957153, -0.06549925357103348, -0.1479908525943756, 0.005949690937995911, -0.1381906121969223, 0.008188813924789429, 0.0015783598646521568] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]
step:5550/5550 val_loss:2.917622 train_time:1408141ms step_avg:253.72ms x-lambda: 0.9793316721916199 lambdas: [-0.06639531254768372, -0.17043571174144745, 0.013972149230539799, 0.02026810497045517, -0.05926577001810074, -0.06553944200277328, -0.14786948263645172, 0.005725601688027382, -0.1379563957452774, 0.008116725832223892, 0.001952406601049006] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6]



## 8000-add-skip-multiple-11-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.16ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:125/5550 val_loss:4.254170 train_time:29347ms step_avg:234.77ms x-lambda: 1.0170232057571411 lambdas: [0.010675311088562012, 0.014968084171414375, 0.017268864437937737, 0.019171644002199173, 0.030481070280075073, 0.01829267293214798, 0.018908511847257614, 0.01882697455585003, 0.02280966192483902, 0.03715284541249275, 0.05634318292140961] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:250/5550 val_loss:3.854376 train_time:58758ms step_avg:235.03ms x-lambda: 0.9812921285629272 lambdas: [-0.0006634693127125502, 0.008388444781303406, 0.0074548376724123955, 0.003867183346301317, 0.019465206190943718, -0.03060612641274929, -0.00729919970035553, 0.019349049776792526, -0.002831489546224475, 0.03184939920902252, 0.07470906525850296] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:375/5550 val_loss:3.676888 train_time:88739ms step_avg:236.64ms x-lambda: 0.9751697182655334 lambdas: [0.007391416467726231, 0.014371439814567566, 0.007118800655007362, -0.005180355627089739, -0.01217919122427702, -0.08158525079488754, -0.012786957435309887, 0.025645894929766655, -0.023738591000437737, 0.014549003913998604, 0.05009777098894119] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:500/5550 val_loss:3.560941 train_time:119097ms step_avg:238.19ms x-lambda: 0.9688495993614197 lambdas: [0.006400783080607653, 0.012159067206084728, 0.0018789834575727582, -0.01415492407977581, -0.045259732753038406, -0.11872036010026932, -0.009289262816309929, 0.030666369944810867, -0.03342823311686516, 0.004880013410001993, 0.023501969873905182] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:625/5550 val_loss:3.482268 train_time:149732ms step_avg:239.57ms x-lambda: 0.9649810791015625 lambdas: [0.004472853150218725, 0.008337619714438915, -0.003192854579538107, -0.02055044285953045, -0.072512686252594, -0.14199432730674744, -0.001330787898041308, 0.03496161848306656, -0.03361158445477486, 0.0038381079211831093, 0.003148656105622649] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:750/5550 val_loss:3.428591 train_time:180663ms step_avg:240.88ms x-lambda: 0.9595931768417358 lambdas: [0.002290889387950301, 0.003825336927548051, -0.008125084452331066, -0.023638533428311348, -0.09375859051942825, -0.1532537192106247, 0.005594888236373663, 0.035777345299720764, -0.03060532920062542, 0.005096734501421452, -0.010835285298526287] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:875/5550 val_loss:3.383458 train_time:211610ms step_avg:241.84ms x-lambda: 0.9485186338424683 lambdas: [-0.0027465582825243473, -0.0038374578580260277, -0.01547167170792818, -0.026872994378209114, -0.11222093552350998, -0.15925978124141693, 0.01188565045595169, 0.03539152070879936, -0.028543943539261818, 0.0047574336640536785, -0.022213643416762352] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1000/5550 val_loss:3.347075 train_time:242831ms step_avg:242.83ms x-lambda: 0.9406927227973938 lambdas: [-0.0054458025842905045, -0.009451758116483688, -0.020652292296290398, -0.027561228722333908, -0.1260661631822586, -0.1594092696905136, 0.01460213027894497, 0.03398137167096138, -0.025799911469221115, 0.006899247877299786, -0.026327311992645264] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1125/5550 val_loss:3.317121 train_time:274109ms step_avg:243.65ms x-lambda: 0.931300699710846 lambdas: [-0.010263388976454735, -0.01703946851193905, -0.026764705777168274, -0.027026550844311714, -0.13973389565944672, -0.15614262223243713, 0.01731513999402523, 0.032440658658742905, -0.024754177778959274, 0.007434009574353695, -0.029730940237641335] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1250/5550 val_loss:3.294062 train_time:305452ms step_avg:244.36ms x-lambda: 0.9252891540527344 lambdas: [-0.011729983612895012, -0.021801810711622238, -0.03039497137069702, -0.025019655004143715, -0.14934615790843964, -0.15119609236717224, 0.020537683740258217, 0.031392697244882584, -0.02210371382534504, 0.009258699603378773, -0.029371654614806175] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1375/5550 val_loss:3.272727 train_time:336985ms step_avg:245.08ms x-lambda: 0.913506031036377 lambdas: [-0.017673365771770477, -0.03125229477882385, -0.037759196013212204, -0.025616372004151344, -0.16086450219154358, -0.14709077775478363, 0.018929705023765564, 0.028099922463297844, -0.02352233976125717, 0.006708810105919838, -0.03175101801753044] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1500/5550 val_loss:3.252652 train_time:368490ms step_avg:245.66ms x-lambda: 0.9088906049728394 lambdas: [-0.018055126070976257, -0.03617017716169357, -0.04024834930896759, -0.02105988748371601, -0.16785851120948792, -0.1399233639240265, 0.02155412919819355, 0.02933400124311447, -0.02001097984611988, 0.00844093132764101, -0.03020617924630642] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1625/5550 val_loss:3.236790 train_time:400050ms step_avg:246.18ms x-lambda: 0.8992733955383301 lambdas: [-0.021937323734164238, -0.04375065118074417, -0.04497504606842995, -0.018210534006357193, -0.17572547495365143, -0.13483445346355438, 0.022187724709510803, 0.027108993381261826, -0.01915518194437027, 0.007937947288155556, -0.02965049259364605] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1750/5550 val_loss:3.221798 train_time:431591ms step_avg:246.62ms x-lambda: 0.8915456533432007 lambdas: [-0.02515728399157524, -0.050730813294649124, -0.04914473369717598, -0.015519633889198303, -0.1810414046049118, -0.12869533896446228, 0.02197371795773506, 0.02724556252360344, -0.01982378587126732, 0.008184760808944702, -0.028864383697509766] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:1875/5550 val_loss:3.202746 train_time:463215ms step_avg:247.05ms x-lambda: 0.8857598304748535 lambdas: [-0.026397384703159332, -0.05568579584360123, -0.05165780708193779, -0.010502568446099758, -0.1862320899963379, -0.12314236164093018, 0.022332413122057915, 0.0258320365101099, -0.01864052377641201, 0.007398934103548527, -0.028073934838175774] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2000/5550 val_loss:3.187519 train_time:495038ms step_avg:247.52ms x-lambda: 0.8786661624908447 lambdas: [-0.02868199348449707, -0.062452420592308044, -0.055489372462034225, -0.007926974445581436, -0.190372034907341, -0.11953166127204895, 0.02193274348974228, 0.0234245415776968, -0.01779414899647236, 0.008104362525045872, -0.027579668909311295] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2125/5550 val_loss:3.173063 train_time:526857ms step_avg:247.93ms x-lambda: 0.8751327991485596 lambdas: [-0.029348954558372498, -0.0669342502951622, -0.05708622559905052, -0.003388469573110342, -0.1940336525440216, -0.11532337963581085, 0.023270828649401665, 0.023994075134396553, -0.016539979726076126, 0.0076637486927211285, -0.026030104607343674] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2250/5550 val_loss:3.158606 train_time:558762ms step_avg:248.34ms x-lambda: 0.870618999004364 lambdas: [-0.030605390667915344, -0.07286068797111511, -0.05967925861477852, -0.00042997649870812893, -0.19639651477336884, -0.11124613881111145, 0.022937797009944916, 0.02299630269408226, -0.017954282462596893, 0.007065935991704464, -0.026440780609846115] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2375/5550 val_loss:3.148333 train_time:590675ms step_avg:248.71ms x-lambda: 0.8682970404624939 lambdas: [-0.02986874058842659, -0.07631651312112808, -0.06022491678595543, 0.004795180633664131, -0.19585920870304108, -0.10623550415039062, 0.02292504906654358, 0.02302008494734764, -0.015643034130334854, 0.008229320868849754, -0.024503560736775398] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2500/5550 val_loss:3.136831 train_time:622553ms step_avg:249.02ms x-lambda: 0.8655867576599121 lambdas: [-0.02992350421845913, -0.08034738898277283, -0.0622098445892334, 0.007728207856416702, -0.19883310794830322, -0.10351100564002991, 0.023159082978963852, 0.02298823371529579, -0.015468627214431763, 0.008486155420541763, -0.023819787427783012] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2625/5550 val_loss:3.124881 train_time:654429ms step_avg:249.31ms x-lambda: 0.8602220416069031 lambdas: [-0.03202933445572853, -0.08743246644735336, -0.06646201759576797, 0.0070449127815663815, -0.20191030204296112, -0.10281152278184891, 0.01932404935359955, 0.0196838341653347, -0.016931576654314995, 0.005878497380763292, -0.024498997256159782] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2750/5550 val_loss:3.112471 train_time:686236ms step_avg:249.54ms x-lambda: 0.8596015572547913 lambdas: [-0.031190967187285423, -0.0905224084854126, -0.06637845933437347, 0.011109009385108948, -0.20043832063674927, -0.09767387807369232, 0.021749665960669518, 0.02055422216653824, -0.01395830325782299, 0.007308324798941612, -0.023702291771769524] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:2875/5550 val_loss:3.104083 train_time:718088ms step_avg:249.77ms x-lambda: 0.8585906624794006 lambdas: [-0.03075944073498249, -0.09375963360071182, -0.06692007929086685, 0.014057422988116741, -0.20183336734771729, -0.09495846927165985, 0.021624011918902397, 0.020510055124759674, -0.013210040517151356, 0.007104838266968727, -0.022352775558829308] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3000/5550 val_loss:3.094626 train_time:749912ms step_avg:249.97ms x-lambda: 0.8576623201370239 lambdas: [-0.02937098778784275, -0.09606534242630005, -0.06683782488107681, 0.01745889149606228, -0.20123116672039032, -0.0920368880033493, 0.02220170944929123, 0.020916493609547615, -0.012982654385268688, 0.0078115034848451614, -0.020641589537262917] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3125/5550 val_loss:3.081724 train_time:781798ms step_avg:250.18ms x-lambda: 0.8551331162452698 lambdas: [-0.03123181127011776, -0.10123661160469055, -0.06982941180467606, 0.017908217385411263, -0.20436625182628632, -0.09194614738225937, 0.02116096392273903, 0.018741395324468613, -0.014201291836798191, 0.005999601911753416, -0.023839889094233513] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3250/5550 val_loss:3.070040 train_time:813711ms step_avg:250.37ms x-lambda: 0.8558651804924011 lambdas: [-0.030042530968785286, -0.10343694686889648, -0.0699295923113823, 0.02014605700969696, -0.2033184915781021, -0.09186204522848129, 0.020169328898191452, 0.019049014896154404, -0.015082312747836113, 0.007299093063920736, -0.022219307720661163] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3375/5550 val_loss:3.062027 train_time:845598ms step_avg:250.55ms x-lambda: 0.855571448802948 lambdas: [-0.029630044475197792, -0.10596855729818344, -0.07064151018857956, 0.022950636222958565, -0.20442897081375122, -0.08902249485254288, 0.02133183740079403, 0.017986707389354706, -0.01362785417586565, 0.006326615344733, -0.02174464613199234] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3500/5550 val_loss:3.054490 train_time:877520ms step_avg:250.72ms x-lambda: 0.8554635643959045 lambdas: [-0.03000083938241005, -0.1110309287905693, -0.07299795001745224, 0.02220248058438301, -0.20502109825611115, -0.0883004292845726, 0.018586231395602226, 0.017147336155176163, -0.015424251556396484, 0.003231142181903124, -0.023597100749611855] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3625/5550 val_loss:3.044134 train_time:909396ms step_avg:250.87ms x-lambda: 0.8583893775939941 lambdas: [-0.02736065909266472, -0.1118302047252655, -0.07155881077051163, 0.02498958259820938, -0.20471283793449402, -0.08564133197069168, 0.02149103209376335, 0.016739055514335632, -0.013969767838716507, 0.005390702281147242, -0.022257590666413307] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3750/5550 val_loss:3.034567 train_time:941283ms step_avg:251.01ms x-lambda: 0.8580794334411621 lambdas: [-0.027509255334734917, -0.11519988626241684, -0.0731533020734787, 0.025966491550207138, -0.20440037548542023, -0.08493897318840027, 0.020654037594795227, 0.016877779737114906, -0.013594508171081543, 0.006821895018219948, -0.021917123347520828] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:3875/5550 val_loss:3.025513 train_time:973303ms step_avg:251.17ms x-lambda: 0.8620806336402893 lambdas: [-0.02541010081768036, -0.11689943820238113, -0.07270412147045135, 0.027711722999811172, -0.20556308329105377, -0.08333572745323181, 0.02053598314523697, 0.01684749685227871, -0.012888635508716106, 0.005441197659820318, -0.020540064200758934] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4000/5550 val_loss:3.016164 train_time:1005210ms step_avg:251.30ms x-lambda: 0.8655288219451904 lambdas: [-0.02432183176279068, -0.11883838474750519, -0.07301254570484161, 0.028523677960038185, -0.2056712508201599, -0.08251045644283295, 0.020811868831515312, 0.015468101017177105, -0.012931877747178078, 0.005179768428206444, -0.020851874724030495] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4125/5550 val_loss:3.006968 train_time:1037128ms step_avg:251.42ms x-lambda: 0.8671296834945679 lambdas: [-0.023596573621034622, -0.12207994610071182, -0.07414538413286209, 0.029009057208895683, -0.20585523545742035, -0.08119391649961472, 0.019931258633732796, 0.017541714012622833, -0.012877333909273148, 0.004700544290244579, -0.020408062264323235] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4250/5550 val_loss:2.998837 train_time:1069309ms step_avg:251.60ms x-lambda: 0.8713628053665161 lambdas: [-0.020990503951907158, -0.12295538932085037, -0.07355579733848572, 0.030884234234690666, -0.20673565566539764, -0.08013034611940384, 0.020762974396348, 0.017345724627375603, -0.011594841256737709, 0.005234547425061464, -0.020103931427001953] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4375/5550 val_loss:2.989685 train_time:1101528ms step_avg:251.78ms x-lambda: 0.8741645216941833 lambdas: [-0.021501965820789337, -0.1268204003572464, -0.07530928403139114, 0.030945681035518646, -0.20747900009155273, -0.08103051781654358, 0.01982903853058815, 0.015589416958391666, -0.01296682097017765, 0.005415302235633135, -0.020208464935421944] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4500/5550 val_loss:2.981283 train_time:1133754ms step_avg:251.95ms x-lambda: 0.8771999478340149 lambdas: [-0.020601581782102585, -0.12900108098983765, -0.07524038851261139, 0.03242361545562744, -0.20809634029865265, -0.08031486719846725, 0.018935834988951683, 0.015457822009921074, -0.012425968423485756, 0.005111195147037506, -0.021197093650698662] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4625/5550 val_loss:2.971742 train_time:1166150ms step_avg:252.14ms x-lambda: 0.8825541138648987 lambdas: [-0.018855605274438858, -0.1294805407524109, -0.07427317649126053, 0.03405710309743881, -0.2079177349805832, -0.07944607734680176, 0.019746161997318268, 0.015130961313843727, -0.012154961004853249, 0.0052606104873120785, -0.02067963033914566] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4750/5550 val_loss:2.962803 train_time:1198646ms step_avg:252.35ms x-lambda: 0.8870826363563538 lambdas: [-0.01777864433825016, -0.13100607693195343, -0.0746760368347168, 0.03544389456510544, -0.20889031887054443, -0.07876090705394745, 0.019779233261942863, 0.016414154320955276, -0.012381167151033878, 0.005898239556699991, -0.020336413756012917] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:4875/5550 val_loss:2.953867 train_time:1231319ms step_avg:252.58ms x-lambda: 0.8915960192680359 lambdas: [-0.016767675057053566, -0.13242851197719574, -0.07496912777423859, 0.03597614914178848, -0.21036207675933838, -0.07881248742341995, 0.019391454756259918, 0.015402170829474926, -0.012404044158756733, 0.0049493988044559956, -0.019256489351391792] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5000/5550 val_loss:2.945807 train_time:1264108ms step_avg:252.82ms x-lambda: 0.8976583480834961 lambdas: [-0.015968015417456627, -0.13385263085365295, -0.07541600614786148, 0.03764868155121803, -0.21102850139141083, -0.07906386256217957, 0.019127225503325462, 0.014649155549705029, -0.011350637301802635, 0.004894718993455172, -0.01897292770445347] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5125/5550 val_loss:2.938059 train_time:1297014ms step_avg:253.08ms x-lambda: 0.9021555781364441 lambdas: [-0.01522933691740036, -0.1349165141582489, -0.0758104994893074, 0.03812751919031143, -0.21247130632400513, -0.07929646968841553, 0.019414175301790237, 0.015366768464446068, -0.012619937770068645, 0.004845397546887398, -0.01988210529088974] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5250/5550 val_loss:2.930950 train_time:1330112ms step_avg:253.35ms x-lambda: 0.9068536758422852 lambdas: [-0.014577217400074005, -0.1359400898218155, -0.07690539211034775, 0.03919257968664169, -0.21197175979614258, -0.0779278352856636, 0.018887531012296677, 0.015581827610731125, -0.011160122230648994, 0.005048156250268221, -0.019690025597810745] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5375/5550 val_loss:2.924435 train_time:1363359ms step_avg:253.65ms x-lambda: 0.9119608402252197 lambdas: [-0.013610339723527431, -0.13689014315605164, -0.07674137502908707, 0.04015016183257103, -0.21369889378547668, -0.07887383550405502, 0.018883921205997467, 0.01459032204002142, -0.011475933715701103, 0.004510949831455946, -0.01930350996553898] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5500/5550 val_loss:2.919584 train_time:1396786ms step_avg:253.96ms x-lambda: 0.9146134853363037 lambdas: [-0.013315857388079166, -0.13756941258907318, -0.07694902271032333, 0.04118282347917557, -0.21425852179527283, -0.07890298217535019, 0.018295839428901672, 0.014295091852545738, -0.011513694189488888, 0.0040225316770374775, -0.019146621227264404] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]
step:5550/5550 val_loss:2.918418 train_time:1410217ms step_avg:254.09ms x-lambda: 0.9153122901916504 lambdas: [-0.0133891012519598, -0.13783574104309082, -0.07723213732242584, 0.041381899267435074, -0.21439751982688904, -0.0790591835975647, 0.01872512698173523, 0.014102176763117313, -0.011286504566669464, 0.004064465872943401, -0.019131813198328018] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4]



## 8000-add-skip-multiple-11-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:125/5550 val_loss:4.256192 train_time:29346ms step_avg:234.77ms x-lambda: 1.0248761177062988 lambdas: [0.07377437502145767, 0.008396927267313004, -0.03787877410650253, -0.054379016160964966, 0.06462039053440094, 0.04358842596411705, 0.028568865731358528, 0.023962708190083504, 0.025185788050293922, 0.02678748033940792, 0.03844842314720154] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:250/5550 val_loss:3.854604 train_time:58806ms step_avg:235.22ms x-lambda: 1.019468903541565 lambdas: [0.06796111911535263, -0.01672501489520073, -0.0951540544629097, -0.14868971705436707, 0.11870324611663818, 0.05554191768169403, 0.010994008742272854, 0.025976916775107384, -0.009260584600269794, -0.016375234350562096, 0.042118582874536514] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:375/5550 val_loss:3.681596 train_time:88770ms step_avg:236.72ms x-lambda: 1.0360400676727295 lambdas: [0.05810505151748657, -0.017451869323849678, -0.10708089917898178, -0.1982530951499939, 0.13117730617523193, 0.04701308533549309, -0.009487040340900421, 0.034865058958530426, -0.02345096506178379, -0.06518741697072983, 0.023489102721214294] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:500/5550 val_loss:3.561514 train_time:119093ms step_avg:238.19ms x-lambda: 1.0312368869781494 lambdas: [0.04883977398276329, -0.014503702521324158, -0.10964207351207733, -0.22477692365646362, 0.13182182610034943, 0.036224134266376495, -0.022400634363293648, 0.039613403379917145, -0.025795964524149895, -0.10378304868936539, -0.0039042611606419086] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:625/5550 val_loss:3.483006 train_time:149611ms step_avg:239.38ms x-lambda: 1.0205161571502686 lambdas: [0.04395994544029236, -0.009150819852948189, -0.1066628023982048, -0.232251837849617, 0.13375619053840637, 0.03202829509973526, -0.02390098199248314, 0.04576842114329338, -0.018591083586215973, -0.12619005143642426, -0.029012739658355713] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:750/5550 val_loss:3.429791 train_time:180448ms step_avg:240.60ms x-lambda: 1.0033286809921265 lambdas: [0.03811895102262497, -0.007147335913032293, -0.10689006745815277, -0.23174794018268585, 0.13079676032066345, 0.026334717869758606, -0.025077058002352715, 0.045673269778490067, -0.013647296465933323, -0.1413288116455078, -0.05419708043336868] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:875/5550 val_loss:3.384438 train_time:211373ms step_avg:241.57ms x-lambda: 0.9771072268486023 lambdas: [0.03518405184149742, -0.004039006307721138, -0.1036573275923729, -0.22242584824562073, 0.1278059035539627, 0.021423112601041794, -0.02340041473507881, 0.045231692492961884, -0.009116340428590775, -0.14576148986816406, -0.07652067393064499] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1000/5550 val_loss:3.348482 train_time:242593ms step_avg:242.59ms x-lambda: 0.950481116771698 lambdas: [0.03181464597582817, -0.0031893395353108644, -0.10161062330007553, -0.21112710237503052, 0.12148318439722061, 0.01806374080479145, -0.022911058738827705, 0.04330136999487877, -0.006430468987673521, -0.14641554653644562, -0.0973922535777092] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1125/5550 val_loss:3.320468 train_time:273856ms step_avg:243.43ms x-lambda: 0.9264268279075623 lambdas: [0.02719266153872013, -0.003738564904779196, -0.10006239265203476, -0.19731886684894562, 0.11498402804136276, 0.014500181190669537, -0.022219065576791763, 0.04073372855782509, -0.005258781835436821, -0.1441517174243927, -0.11526033282279968] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1250/5550 val_loss:3.294661 train_time:305232ms step_avg:244.19ms x-lambda: 0.904881477355957 lambdas: [0.026608068495988846, -0.0013760613510385156, -0.09753124415874481, -0.18438683450222015, 0.1096685454249382, 0.01434923242777586, -0.019566023722290993, 0.03925573453307152, -0.0025394782423973083, -0.137445867061615, -0.12867744266986847] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1375/5550 val_loss:3.273821 train_time:336815ms step_avg:244.96ms x-lambda: 0.8820647597312927 lambdas: [0.024333981797099113, -0.0003797424433287233, -0.09484072029590607, -0.17120783030986786, 0.1028469055891037, 0.011847088113427162, -0.019921554252505302, 0.03880190849304199, -0.0011495895450934768, -0.13199608027935028, -0.1420002281665802] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1500/5550 val_loss:3.254248 train_time:368377ms step_avg:245.58ms x-lambda: 0.8621191382408142 lambdas: [0.021825488656759262, -0.0001512562157586217, -0.09379273653030396, -0.1606108844280243, 0.09687702357769012, 0.010422857478260994, -0.019325723871588707, 0.03587346524000168, -0.0009239547653123736, -0.12600991129875183, -0.15366721153259277] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1625/5550 val_loss:3.239335 train_time:399986ms step_avg:246.15ms x-lambda: 0.8437368273735046 lambdas: [0.023561224341392517, 0.0013134432956576347, -0.09003347158432007, -0.1476563662290573, 0.09342582523822784, 0.011459967121481895, -0.01614530012011528, 0.03737858682870865, 0.002644512802362442, -0.11873191595077515, -0.16151197254657745] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1750/5550 val_loss:3.224689 train_time:431578ms step_avg:246.62ms x-lambda: 0.8240248560905457 lambdas: [0.021344242617487907, 0.0016315883258357644, -0.0886017233133316, -0.1364900767803192, 0.08733385056257248, 0.010441276244819164, -0.017021017149090767, 0.03531217575073242, 0.0025070905685424805, -0.11278577893972397, -0.16809391975402832] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:1875/5550 val_loss:3.205383 train_time:463259ms step_avg:247.07ms x-lambda: 0.8093584179878235 lambdas: [0.020633509382605553, 0.0019744383171200752, -0.08626657724380493, -0.1268693506717682, 0.0832216814160347, 0.009268200024962425, -0.014957936480641365, 0.03537613898515701, 0.0034301176201552153, -0.10756464302539825, -0.17408184707164764] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2000/5550 val_loss:3.190557 train_time:495136ms step_avg:247.57ms x-lambda: 0.7931114435195923 lambdas: [0.0199571643024683, 0.0017668635118752718, -0.0847923755645752, -0.11886287480592728, 0.077952541410923, 0.008637693710625172, -0.014840444549918175, 0.033617451786994934, 0.0029946686699986458, -0.10304585099220276, -0.17913956940174103] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2125/5550 val_loss:3.174546 train_time:527063ms step_avg:248.03ms x-lambda: 0.7823673486709595 lambdas: [0.019039517268538475, 0.0013402423355728388, -0.08353890478610992, -0.11390099674463272, 0.07415199279785156, 0.007519002538174391, -0.01598137430846691, 0.03157849982380867, 0.002899077022448182, -0.1015816479921341, -0.1833156943321228] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2250/5550 val_loss:3.159864 train_time:558923ms step_avg:248.41ms x-lambda: 0.7727535963058472 lambdas: [0.01708720065653324, 0.0017742007039487362, -0.08263126760721207, -0.10730868577957153, 0.06944920867681503, 0.006394504569470882, -0.015394185669720173, 0.03093889355659485, 0.0021514336112886667, -0.09698034822940826, -0.18548274040222168] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2375/5550 val_loss:3.148758 train_time:590849ms step_avg:248.78ms x-lambda: 0.7623893618583679 lambdas: [0.018130958080291748, 0.0008059612009674311, -0.08100371062755585, -0.10203840583562851, 0.06578283756971359, 0.004945134278386831, -0.0151801947504282, 0.029377680271863937, 0.00259592873044312, -0.09472483396530151, -0.18665654957294464] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2500/5550 val_loss:3.137672 train_time:622705ms step_avg:249.08ms x-lambda: 0.7556917667388916 lambdas: [0.018261626362800598, 0.003562805475667119, -0.07786550372838974, -0.0968373492360115, 0.0660676509141922, 0.007121110334992409, -0.012960482388734818, 0.02909724786877632, 0.003590804059058428, -0.09074920415878296, -0.18642833828926086] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2625/5550 val_loss:3.125527 train_time:654544ms step_avg:249.35ms x-lambda: 0.7485918402671814 lambdas: [0.01599208079278469, 0.001981505425646901, -0.0768226757645607, -0.09294293820858002, 0.06142568588256836, 0.005356708541512489, -0.013483615592122078, 0.02860710583627224, 0.0031523334328085184, -0.08998584747314453, -0.1870710402727127] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2750/5550 val_loss:3.114830 train_time:686391ms step_avg:249.60ms x-lambda: 0.7428280115127563 lambdas: [0.015891866758465767, 0.0019458835013210773, -0.07620424032211304, -0.0891028419137001, 0.060529254376888275, 0.005630980245769024, -0.013454164378345013, 0.028024276718497276, 0.002190901432186365, -0.08731076121330261, -0.18750031292438507] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:2875/5550 val_loss:3.104877 train_time:718278ms step_avg:249.84ms x-lambda: 0.736743688583374 lambdas: [0.015482179820537567, 0.0027967237401753664, -0.07576137781143188, -0.08542492985725403, 0.05715271830558777, 0.004795760381966829, -0.012470515444874763, 0.0267840176820755, 0.0030284372624009848, -0.0844467282295227, -0.1883588433265686] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3000/5550 val_loss:3.094330 train_time:750161ms step_avg:250.05ms x-lambda: 0.7336605787277222 lambdas: [0.014634549617767334, 0.001961410278454423, -0.07270757108926773, -0.08151369541883469, 0.05621219426393509, 0.005495082121342421, -0.011844414286315441, 0.02666177786886692, 0.00278577976860106, -0.08339779824018478, -0.18793299794197083] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3125/5550 val_loss:3.084051 train_time:782089ms step_avg:250.27ms x-lambda: 0.7297637462615967 lambdas: [0.01436313334852457, -0.00019882991909980774, -0.07395807653665543, -0.08049359917640686, 0.05263867229223251, 0.004081066232174635, -0.013617102056741714, 0.025494471192359924, 0.0010923235677182674, -0.08355195820331573, -0.18892672657966614] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3250/5550 val_loss:3.071460 train_time:813959ms step_avg:250.45ms x-lambda: 0.7300836443901062 lambdas: [0.013634179718792439, 0.002516460372135043, -0.07205324620008469, -0.07641366869211197, 0.05222490429878235, 0.004404147155582905, -0.01297398004680872, 0.025878623127937317, 0.0028851148672401905, -0.08063051849603653, -0.1876668930053711] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3375/5550 val_loss:3.063174 train_time:845818ms step_avg:250.61ms x-lambda: 0.727719783782959 lambdas: [0.01307853776961565, 0.001110268640331924, -0.0715891644358635, -0.07584740221500397, 0.05065477639436722, 0.002769787795841694, -0.012195172719657421, 0.02464798279106617, 0.002562344539910555, -0.08041039109230042, -0.1890663355588913] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3500/5550 val_loss:3.054710 train_time:877730ms step_avg:250.78ms x-lambda: 0.7266842722892761 lambdas: [0.013513576239347458, 0.0014233647380024195, -0.07056915014982224, -0.07353602349758148, 0.04883487895131111, 0.0029590146150439978, -0.012913738377392292, 0.024458982050418854, 0.002566826529800892, -0.07876010239124298, -0.1884666532278061] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3625/5550 val_loss:3.045405 train_time:909598ms step_avg:250.92ms x-lambda: 0.7266587615013123 lambdas: [0.013209215365350246, 0.0012307551223784685, -0.06964763253927231, -0.0711105614900589, 0.048328377306461334, 0.003496202640235424, -0.012144907377660275, 0.024275319650769234, 0.0039161876775324345, -0.0773414671421051, -0.1870836764574051] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3750/5550 val_loss:3.036239 train_time:941502ms step_avg:251.07ms x-lambda: 0.7261747121810913 lambdas: [0.013214481063187122, 0.0019056966993957758, -0.06911195069551468, -0.07010561227798462, 0.04731029272079468, 0.003967141266912222, -0.012438160367310047, 0.024739695712924004, 0.0031945735681802034, -0.07659818977117538, -0.18759676814079285] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:3875/5550 val_loss:3.027049 train_time:973465ms step_avg:251.22ms x-lambda: 0.7306632995605469 lambdas: [0.013296837918460369, 0.00225388677790761, -0.06794067472219467, -0.06770846992731094, 0.047382500022649765, 0.0020622825250029564, -0.011668630875647068, 0.023903217166662216, 0.0025387483183294535, -0.0754140168428421, -0.1878589540719986] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4000/5550 val_loss:3.017645 train_time:1005412ms step_avg:251.35ms x-lambda: 0.7310263514518738 lambdas: [0.012379863299429417, 0.0019216065993532538, -0.06845123320817947, -0.06667967140674591, 0.04536879062652588, 0.0032017300836741924, -0.011248171329498291, 0.023594364523887634, 0.002666302490979433, -0.07478535920381546, -0.188224196434021] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4125/5550 val_loss:3.008383 train_time:1037397ms step_avg:251.49ms x-lambda: 0.7335139513015747 lambdas: [0.013284826651215553, 0.0013711671344935894, -0.06719119101762772, -0.06450856477022171, 0.04459493234753609, 0.0020172481890767813, -0.010628126561641693, 0.02326219156384468, 0.003193560056388378, -0.07333438843488693, -0.18757084012031555] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4250/5550 val_loss:2.999972 train_time:1069580ms step_avg:251.67ms x-lambda: 0.7370167374610901 lambdas: [0.012533452361822128, 0.001236014999449253, -0.06707055866718292, -0.06484906375408173, 0.04549599066376686, 0.003266537794843316, -0.011209337040781975, 0.023231128230690956, 0.0032459786161780357, -0.07387815415859222, -0.18850943446159363] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4375/5550 val_loss:2.990833 train_time:1101734ms step_avg:251.82ms x-lambda: 0.7394219636917114 lambdas: [0.012862599454820156, 0.0009628352709114552, -0.06673335283994675, -0.06380464136600494, 0.04451131448149681, 0.002464248100295663, -0.010545038618147373, 0.022193007171154022, 0.0017730600666254759, -0.07450708746910095, -0.1885591447353363] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4500/5550 val_loss:2.982716 train_time:1133995ms step_avg:252.00ms x-lambda: 0.7435930967330933 lambdas: [0.012118975631892681, 0.0020507650915533304, -0.06564531475305557, -0.06322670727968216, 0.042288608849048615, 0.0026212548837065697, -0.011124967597424984, 0.022308874875307083, 0.002856111153960228, -0.07325167953968048, -0.1893976628780365] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4625/5550 val_loss:2.973312 train_time:1166340ms step_avg:252.18ms x-lambda: 0.7499914765357971 lambdas: [0.011989160440862179, 0.0013231488410383463, -0.06465380638837814, -0.061980996280908585, 0.04246804118156433, 0.002063218504190445, -0.009868515655398369, 0.02118212915956974, 0.002484619151800871, -0.07328875362873077, -0.18934819102287292] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4750/5550 val_loss:2.964002 train_time:1198771ms step_avg:252.37ms x-lambda: 0.7555212378501892 lambdas: [0.013596701435744762, 0.0033300556242465973, -0.06431198865175247, -0.06095754727721214, 0.042752210050821304, 0.0026348913088440895, -0.010052296333014965, 0.02198290452361107, 0.002243978204205632, -0.07267816364765167, -0.18943002820014954] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:4875/5550 val_loss:2.955370 train_time:1231403ms step_avg:252.60ms x-lambda: 0.76103675365448 lambdas: [0.012452838011085987, 0.001576587208546698, -0.06418772041797638, -0.05884981527924538, 0.04213828593492508, 0.0021013421937823296, -0.011572442017495632, 0.02117244154214859, 0.002321473555639386, -0.07380536943674088, -0.18909230828285217] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5000/5550 val_loss:2.947059 train_time:1264135ms step_avg:252.83ms x-lambda: 0.7675715088844299 lambdas: [0.013002716936171055, 0.0017901036189869046, -0.06426306068897247, -0.05943275988101959, 0.042160823941230774, 0.0015425102319568396, -0.010443908162415028, 0.02153550647199154, 0.002099901670590043, -0.07341186702251434, -0.1893591433763504] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5125/5550 val_loss:2.939303 train_time:1296983ms step_avg:253.07ms x-lambda: 0.7733297944068909 lambdas: [0.012707165442407131, 0.0017106642480939627, -0.06370434910058975, -0.05882685258984566, 0.0428754985332489, 0.0019305773312225938, -0.009812827222049236, 0.021613458171486855, 0.0015613751020282507, -0.0729459673166275, -0.19102105498313904] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5250/5550 val_loss:2.932104 train_time:1330013ms step_avg:253.34ms x-lambda: 0.7781863212585449 lambdas: [0.012741368263959885, 0.0022638067603111267, -0.06361164152622223, -0.05711381137371063, 0.04114393889904022, 0.0016909734113141894, -0.009328894317150116, 0.021399561315774918, 0.0018739447696134448, -0.07205024361610413, -0.19077183306217194] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5375/5550 val_loss:2.925703 train_time:1363164ms step_avg:253.61ms x-lambda: 0.7853191494941711 lambdas: [0.012993691489100456, 0.0025230771861970425, -0.0637114942073822, -0.05864240974187851, 0.0421791598200798, 0.0019526120740920305, -0.00997762382030487, 0.020310118794441223, 0.0018783335108309984, -0.07316901534795761, -0.19068431854248047] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5500/5550 val_loss:2.920838 train_time:1396616ms step_avg:253.93ms x-lambda: 0.7884299159049988 lambdas: [0.01208342146128416, 0.0016368287615478039, -0.06400344520807266, -0.05797484144568443, 0.041627611964941025, 0.001523199025541544, -0.009229360148310661, 0.02022532746195793, 0.001584526733495295, -0.07294407486915588, -0.19093462824821472] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
step:5550/5550 val_loss:2.919669 train_time:1410063ms step_avg:254.07ms x-lambda: 0.7895288467407227 lambdas: [0.011837580241262913, 0.0018353733466938138, -0.06425610184669495, -0.05767086520791054, 0.041841860860586166, 0.0011599913705140352, -0.009385413490235806, 0.020029570907354355, 0.001445890637114644, -0.07299351692199707, -0.19122099876403809] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]



## 8000-add-skip-multiple-11-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.12ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:125/5550 val_loss:4.262252 train_time:29346ms step_avg:234.77ms x-lambda: 1.0415682792663574 lambdas: [0.025305384770035744, 0.015048292465507984, 0.011103118769824505, 0.016329053789377213, 0.028546001762151718, 0.02847096137702465, 0.014723055064678192, 0.020527159795165062, 0.0253924373537302, 0.0383099801838398, -0.006843780633062124] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:250/5550 val_loss:3.847152 train_time:58835ms step_avg:235.34ms x-lambda: 1.0588784217834473 lambdas: [0.010916822589933872, -0.000270057818852365, -0.016103185713291168, -0.004994461312890053, 0.012365788221359253, -0.0003970393445342779, 0.002419120632112026, 0.002161334967240691, 0.014944331720471382, -0.003046299796551466, -0.017654841765761375] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:375/5550 val_loss:3.674143 train_time:88800ms step_avg:236.80ms x-lambda: 1.0668631792068481 lambdas: [-0.00716782733798027, -0.007599669508635998, -0.02084730565547943, -0.018062297254800797, -0.007565670181065798, -0.017659321427345276, -0.010363573208451271, -0.006191630382090807, -0.006059244740754366, -0.022788485512137413, -0.014128989540040493] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:500/5550 val_loss:3.557496 train_time:119112ms step_avg:238.22ms x-lambda: 1.0510892868041992 lambdas: [-0.01930926740169525, -0.017421996220946312, -0.021596504375338554, -0.027470426633954048, -0.023288525640964508, -0.02578461915254593, -0.017527829855680466, -0.013270625844597816, -0.023034855723381042, -0.031052978709340096, -0.0148875517770648] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:625/5550 val_loss:3.481992 train_time:149635ms step_avg:239.42ms x-lambda: 1.0245797634124756 lambdas: [-0.023031583055853844, -0.019639281556010246, -0.016851872205734253, -0.029837748035788536, -0.027986783534288406, -0.027832644060254097, -0.01699073053896427, -0.011450208723545074, -0.027882695198059082, -0.030329063534736633, -0.014778916724026203] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:750/5550 val_loss:3.426736 train_time:180499ms step_avg:240.67ms x-lambda: 0.987216055393219 lambdas: [-0.025532349944114685, -0.022449681535363197, -0.01826140284538269, -0.03231148421764374, -0.030903752893209457, -0.029458755627274513, -0.01874574087560177, -0.013549717143177986, -0.029268687590956688, -0.030666623264551163, -0.017062555998563766] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:875/5550 val_loss:3.381407 train_time:211455ms step_avg:241.66ms x-lambda: 0.9466705918312073 lambdas: [-0.026146572083234787, -0.021952645853161812, -0.016374612227082253, -0.03025536984205246, -0.02917042188346386, -0.028559017926454544, -0.01754642091691494, -0.013136240653693676, -0.03049946203827858, -0.028180662542581558, -0.01709485799074173] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1000/5550 val_loss:3.348184 train_time:242672ms step_avg:242.67ms x-lambda: 0.9074699878692627 lambdas: [-0.024587729945778847, -0.020797280594706535, -0.016045214608311653, -0.0278958547860384, -0.028885910287499428, -0.027275249361991882, -0.01586558297276497, -0.01220918633043766, -0.029428424313664436, -0.02625168301165104, -0.015484997071325779] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1125/5550 val_loss:3.317595 train_time:273939ms step_avg:243.50ms x-lambda: 0.8694356679916382 lambdas: [-0.025683647021651268, -0.022129986435174942, -0.015950316563248634, -0.028374597430229187, -0.028408892452716827, -0.028959032148122787, -0.015879608690738678, -0.013898095116019249, -0.029200822114944458, -0.025840571150183678, -0.01754651591181755] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1250/5550 val_loss:3.294500 train_time:305341ms step_avg:244.27ms x-lambda: 0.8382530808448792 lambdas: [-0.02349027991294861, -0.018677370622754097, -0.013649336993694305, -0.02501443773508072, -0.025094669312238693, -0.025429775938391685, -0.012802042067050934, -0.011539402417838573, -0.02630522847175598, -0.0216671135276556, -0.015032111667096615] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1375/5550 val_loss:3.270796 train_time:336901ms step_avg:245.02ms x-lambda: 0.8048098683357239 lambdas: [-0.023860687389969826, -0.019035983830690384, -0.015572897158563137, -0.024771541357040405, -0.0251493938267231, -0.02680894173681736, -0.012817311100661755, -0.013646534644067287, -0.02614157646894455, -0.021995382383465767, -0.016504229977726936] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1500/5550 val_loss:3.256132 train_time:368463ms step_avg:245.64ms x-lambda: 0.7792528867721558 lambdas: [-0.024991394951939583, -0.020402800291776657, -0.016977887600660324, -0.02659338153898716, -0.025379806756973267, -0.027582082897424698, -0.0151586988940835, -0.014516713097691536, -0.027036812156438828, -0.02252296358346939, -0.017854778096079826] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1625/5550 val_loss:3.236249 train_time:400059ms step_avg:246.19ms x-lambda: 0.7546242475509644 lambdas: [-0.021414242684841156, -0.0172407329082489, -0.014514986425638199, -0.023310288786888123, -0.022757800295948982, -0.024186382070183754, -0.012399433180689812, -0.011556618846952915, -0.024135150015354156, -0.020987816154956818, -0.015146211721003056] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1750/5550 val_loss:3.220453 train_time:431639ms step_avg:246.65ms x-lambda: 0.7340623736381531 lambdas: [-0.02090134471654892, -0.016099246218800545, -0.013849777169525623, -0.022149065509438515, -0.021418051794171333, -0.02236437238752842, -0.011519595980644226, -0.011445919051766396, -0.023081058636307716, -0.01840832084417343, -0.01426774449646473] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:1875/5550 val_loss:3.202786 train_time:463320ms step_avg:247.10ms x-lambda: 0.7174789309501648 lambdas: [-0.01944904960691929, -0.016881613060832024, -0.012579401023685932, -0.021386468783020973, -0.01908496767282486, -0.021357940509915352, -0.011159130372107029, -0.010252760723233223, -0.021696792915463448, -0.018452012911438942, -0.012745932675898075] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2000/5550 val_loss:3.187062 train_time:495156ms step_avg:247.58ms x-lambda: 0.7008915543556213 lambdas: [-0.02044776640832424, -0.014924154616892338, -0.01238427683711052, -0.01981346309185028, -0.020403921604156494, -0.020823566243052483, -0.010226411744952202, -0.01136596780270338, -0.01913735270500183, -0.017528166994452477, -0.013230646029114723] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2125/5550 val_loss:3.172899 train_time:527058ms step_avg:248.03ms x-lambda: 0.6918877363204956 lambdas: [-0.018796341493725777, -0.015120984986424446, -0.011910788714885712, -0.01842454820871353, -0.018977556377649307, -0.02032696083188057, -0.009770938195288181, -0.009473354555666447, -0.01972404681146145, -0.0169367752969265, -0.011766265146434307] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2250/5550 val_loss:3.159103 train_time:558938ms step_avg:248.42ms x-lambda: 0.6784520149230957 lambdas: [-0.019279660657048225, -0.01609802432358265, -0.012288657017052174, -0.01908894069492817, -0.01938805542886257, -0.019931910559535027, -0.009884406812489033, -0.010213233530521393, -0.019676409661769867, -0.017272455617785454, -0.013118477538228035] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2375/5550 val_loss:3.147753 train_time:590841ms step_avg:248.78ms x-lambda: 0.6706172823905945 lambdas: [-0.017281370237469673, -0.015193687751889229, -0.011659976094961166, -0.019045649096369743, -0.018449893221259117, -0.019980493932962418, -0.010145054198801517, -0.01146465539932251, -0.01992645487189293, -0.016427114605903625, -0.012750471942126751] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2500/5550 val_loss:3.135393 train_time:622693ms step_avg:249.08ms x-lambda: 0.6629899144172668 lambdas: [-0.018434422090649605, -0.014360438100993633, -0.01178564690053463, -0.018020406365394592, -0.016558758914470673, -0.018123498186469078, -0.0091552147641778, -0.008360292762517929, -0.018528535962104797, -0.01500149816274643, -0.011964325793087482] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2625/5550 val_loss:3.125280 train_time:654547ms step_avg:249.35ms x-lambda: 0.658967137336731 lambdas: [-0.015817174687981606, -0.01266741193830967, -0.009124807082116604, -0.016685672104358673, -0.01496108341962099, -0.017687896266579628, -0.006959563586860895, -0.008360935375094414, -0.01659095659852028, -0.014780406840145588, -0.010467776097357273] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2750/5550 val_loss:3.112684 train_time:686392ms step_avg:249.60ms x-lambda: 0.6526809334754944 lambdas: [-0.015720417723059654, -0.013256813399493694, -0.010802199132740498, -0.016728600487113, -0.015118498355150223, -0.01681649312376976, -0.008069837465882301, -0.009004801511764526, -0.016352452337741852, -0.015041977167129517, -0.011545034125447273] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:2875/5550 val_loss:3.103484 train_time:718294ms step_avg:249.84ms x-lambda: 0.6485556364059448 lambdas: [-0.016197003424167633, -0.012982705608010292, -0.009483898058533669, -0.015953296795487404, -0.015049963258206844, -0.018053948879241943, -0.008125262334942818, -0.008286645635962486, -0.015477685257792473, -0.013855688273906708, -0.011696207337081432] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3000/5550 val_loss:3.092794 train_time:750181ms step_avg:250.06ms x-lambda: 0.6469197869300842 lambdas: [-0.016446026042103767, -0.011701326817274094, -0.010204341262578964, -0.016141459345817566, -0.014455296099185944, -0.016019372269511223, -0.008721605874598026, -0.00982560683041811, -0.01624961569905281, -0.013929135166108608, -0.01033057738095522] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3125/5550 val_loss:3.081739 train_time:782108ms step_avg:250.27ms x-lambda: 0.6441270112991333 lambdas: [-0.016708195209503174, -0.012900521978735924, -0.010189585387706757, -0.01769947074353695, -0.01572597585618496, -0.018009310588240623, -0.0089707737788558, -0.008145672269165516, -0.016569441184401512, -0.014369293116033077, -0.01175873726606369] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3250/5550 val_loss:3.070596 train_time:813997ms step_avg:250.46ms x-lambda: 0.6439509987831116 lambdas: [-0.015336495824158192, -0.012479433789849281, -0.010209049098193645, -0.016330229118466377, -0.0147097734734416, -0.015607981942594051, -0.00821729190647602, -0.009023596532642841, -0.016365934163331985, -0.014610670506954193, -0.010307992808520794] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3375/5550 val_loss:3.063093 train_time:845850ms step_avg:250.62ms x-lambda: 0.6425992846488953 lambdas: [-0.017216265201568604, -0.012453312054276466, -0.010043288581073284, -0.01636749692261219, -0.014940804801881313, -0.0168001726269722, -0.009970058687031269, -0.008374328725039959, -0.01715177670121193, -0.01338398177176714, -0.010658099316060543] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3500/5550 val_loss:3.053697 train_time:877699ms step_avg:250.77ms x-lambda: 0.6418970227241516 lambdas: [-0.016294999048113823, -0.01295856386423111, -0.010723533108830452, -0.016514066606760025, -0.015054856427013874, -0.016501490026712418, -0.009057431481778622, -0.009119311347603798, -0.015313321724534035, -0.014197513461112976, -0.011123339645564556] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3625/5550 val_loss:3.044112 train_time:909532ms step_avg:250.91ms x-lambda: 0.6448052525520325 lambdas: [-0.015602233819663525, -0.012031478807330132, -0.010036487132310867, -0.01487570907920599, -0.013784512877464294, -0.015331081114709377, -0.007655475288629532, -0.008538338355720043, -0.0155764976516366, -0.013579166494309902, -0.010211394168436527] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3750/5550 val_loss:3.034815 train_time:941373ms step_avg:251.03ms x-lambda: 0.6439778208732605 lambdas: [-0.0150172533467412, -0.011639341711997986, -0.009227483533322811, -0.015028937719762325, -0.013299788348376751, -0.01447664201259613, -0.008675017394125462, -0.008331876248121262, -0.01401203591376543, -0.012514205649495125, -0.010269689373672009] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:3875/5550 val_loss:3.025915 train_time:973282ms step_avg:251.17ms x-lambda: 0.6490186452865601 lambdas: [-0.014629815705120564, -0.010938123799860477, -0.009175688028335571, -0.014525700360536575, -0.012391073629260063, -0.015062259510159492, -0.007456006947904825, -0.008496119640767574, -0.014880041591823101, -0.01238651480525732, -0.01009402982890606] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4000/5550 val_loss:3.016477 train_time:1005149ms step_avg:251.29ms x-lambda: 0.6521292328834534 lambdas: [-0.014793756417930126, -0.01120055466890335, -0.010019547306001186, -0.014539646916091442, -0.012642589397728443, -0.01624460332095623, -0.007309188134968281, -0.008560220710933208, -0.014449343085289001, -0.013115317560732365, -0.00930290948599577] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4125/5550 val_loss:3.007262 train_time:1037139ms step_avg:251.43ms x-lambda: 0.6566351056098938 lambdas: [-0.013358965516090393, -0.011873316019773483, -0.009100593626499176, -0.014393738470971584, -0.0117518100887537, -0.014384117908775806, -0.006762627512216568, -0.007190324366092682, -0.012846918776631355, -0.012157628312706947, -0.00936218909919262] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4250/5550 val_loss:2.998778 train_time:1069316ms step_avg:251.60ms x-lambda: 0.6609727740287781 lambdas: [-0.014588712714612484, -0.01061497163027525, -0.00910856481641531, -0.014806711114943027, -0.012130610644817352, -0.013764041475951672, -0.008094937540590763, -0.0073164161294698715, -0.015310028567910194, -0.011002806946635246, -0.009770951233804226] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4375/5550 val_loss:2.989822 train_time:1101467ms step_avg:251.76ms x-lambda: 0.6640914678573608 lambdas: [-0.015235371887683868, -0.01165606640279293, -0.009958994574844837, -0.014444543048739433, -0.013906757347285748, -0.015461299568414688, -0.007905086502432823, -0.008647164329886436, -0.014610085636377335, -0.013255437836050987, -0.010546989738941193] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4500/5550 val_loss:2.981202 train_time:1133660ms step_avg:251.92ms x-lambda: 0.6688006520271301 lambdas: [-0.01457273866981268, -0.011215932667255402, -0.008538754656910896, -0.014980063773691654, -0.011910890229046345, -0.014122828841209412, -0.007591539528220892, -0.008711225353181362, -0.014541116543114185, -0.01182814035564661, -0.009343083947896957] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4625/5550 val_loss:2.972061 train_time:1165978ms step_avg:252.10ms x-lambda: 0.6770504713058472 lambdas: [-0.016860755160450935, -0.01316050998866558, -0.011052573099732399, -0.014089330099523067, -0.011393901892006397, -0.016099410131573677, -0.006926786154508591, -0.01032648142427206, -0.012469199486076832, -0.011285555548965931, -0.008501231670379639] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4750/5550 val_loss:2.962595 train_time:1198376ms step_avg:252.29ms x-lambda: 0.682403564453125 lambdas: [-0.012516941875219345, -0.011676019057631493, -0.008426748216152191, -0.014242127537727356, -0.011554463766515255, -0.013521825894713402, -0.007079295348376036, -0.007172936573624611, -0.013383234851062298, -0.011792922392487526, -0.009860672987997532] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:4875/5550 val_loss:2.953618 train_time:1230991ms step_avg:252.51ms x-lambda: 0.6885574460029602 lambdas: [-0.013579525984823704, -0.010405064560472965, -0.00963831227272749, -0.014535154215991497, -0.012054724618792534, -0.0149297583848238, -0.007719848304986954, -0.007835831493139267, -0.013739926740527153, -0.01136094518005848, -0.010162747465074062] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5000/5550 val_loss:2.945455 train_time:1263685ms step_avg:252.74ms x-lambda: 0.6955462694168091 lambdas: [-0.013752683065831661, -0.01100879069417715, -0.009294265881180763, -0.013430162332952023, -0.011516625061631203, -0.013713043183088303, -0.0075195906683802605, -0.00780911510810256, -0.01273330394178629, -0.011686401441693306, -0.00885088462382555] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5125/5550 val_loss:2.937941 train_time:1296560ms step_avg:252.99ms x-lambda: 0.7038677334785461 lambdas: [-0.014403204433619976, -0.011333037167787552, -0.008160832338035107, -0.013819782063364983, -0.01077262219041586, -0.013651272282004356, -0.007486126851290464, -0.007599879056215286, -0.013259741477668285, -0.012497279793024063, -0.009011832065880299] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5250/5550 val_loss:2.930617 train_time:1329624ms step_avg:253.26ms x-lambda: 0.7105942964553833 lambdas: [-0.013703126460313797, -0.010622086003422737, -0.008398497477173805, -0.013918519020080566, -0.011641520075500011, -0.014132032170891762, -0.007153563667088747, -0.00792408362030983, -0.012285786680877209, -0.011863192543387413, -0.008918603882193565] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5375/5550 val_loss:2.924132 train_time:1362795ms step_avg:253.54ms x-lambda: 0.71858811378479 lambdas: [-0.014153427444398403, -0.011550172232091427, -0.008200802840292454, -0.013816744089126587, -0.011344444006681442, -0.013612831942737103, -0.007393410429358482, -0.0076394337229430676, -0.01327899657189846, -0.012138708494603634, -0.009450110606849194] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5500/5550 val_loss:2.919359 train_time:1396221ms step_avg:253.86ms x-lambda: 0.7233070731163025 lambdas: [-0.014284471049904823, -0.011386201716959476, -0.008929986506700516, -0.013678513467311859, -0.011264720931649208, -0.014033414423465729, -0.007419903296977282, -0.007779485546052456, -0.013357599265873432, -0.01182349119335413, -0.008866543881595135] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]
step:5550/5550 val_loss:2.918197 train_time:1409677ms step_avg:254.00ms x-lambda: 0.7246854305267334 lambdas: [-0.014209669083356857, -0.011057259514927864, -0.00860888697206974, -0.01371501199901104, -0.01170883234590292, -0.014458422549068928, -0.00730679277330637, -0.008191668428480625, -0.013017741031944752, -0.011765248142182827, -0.008973431773483753] skip-layers: [13, 7, 1, 6, 2, 9, 8, 5, 12, 4, 11]



## 8000-add-skip-multiple-11-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:1ms step_avg:0.78ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:125/5550 val_loss:4.262336 train_time:29323ms step_avg:234.59ms x-lambda: 1.0297404527664185 lambdas: [0.015615765936672688, -0.03577964007854462, 0.02711915411055088, 0.021118879318237305, 0.03116087056696415, 0.046884845942258835, 0.030385857447981834, 0.07659454643726349, 0.027140842750668526, -0.05394239351153374, 0.027807891368865967] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:250/5550 val_loss:3.850936 train_time:58813ms step_avg:235.25ms x-lambda: 1.01718008518219 lambdas: [-0.009003998711705208, -0.09773080796003342, 0.02474893257021904, 0.012746457941830158, 0.020266802981495857, 0.06914257258176804, 0.03918091207742691, 0.07193827629089355, 0.0340481735765934, -0.13384053111076355, -0.030222151428461075] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:375/5550 val_loss:3.679164 train_time:88805ms step_avg:236.81ms x-lambda: 1.0139437913894653 lambdas: [-0.009152136743068695, -0.11489954590797424, 0.03034830465912819, 0.01392655074596405, 0.0016722050495445728, 0.06788843125104904, 0.0392533503472805, 0.06423795223236084, 0.04069628566503525, -0.16744719445705414, -0.10038871318101883] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:500/5550 val_loss:3.562680 train_time:119085ms step_avg:238.17ms x-lambda: 1.009944200515747 lambdas: [-0.006661349907517433, -0.12182775884866714, 0.03615158796310425, 0.006999882869422436, -0.013144890777766705, 0.05773596465587616, 0.030039452016353607, 0.053562089800834656, 0.03726857900619507, -0.18372420966625214, -0.15304437279701233] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:625/5550 val_loss:3.482028 train_time:149614ms step_avg:239.38ms x-lambda: 1.0041778087615967 lambdas: [-0.0024411266203969717, -0.12393215298652649, 0.042412638664245605, -0.0009813400683924556, -0.017506320029497147, 0.05111737549304962, 0.01982869952917099, 0.046832576394081116, 0.031362924724817276, -0.18429553508758545, -0.18519294261932373] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:750/5550 val_loss:3.432022 train_time:180452ms step_avg:240.60ms x-lambda: 0.9965118169784546 lambdas: [7.465004455298185e-05, -0.12565797567367554, 0.044994451105594635, -0.010499544441699982, -0.021513808518648148, 0.044128671288490295, 0.008776914328336716, 0.041053954511880875, 0.02299698442220688, -0.1773870587348938, -0.20355236530303955] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:875/5550 val_loss:3.384372 train_time:211369ms step_avg:241.56ms x-lambda: 0.9851003289222717 lambdas: [0.004005223512649536, -0.12439446151256561, 0.047206487506628036, -0.020733101293444633, -0.02104591764509678, 0.038553494960069656, -0.0035842973738908768, 0.03598519787192345, 0.013431484811007977, -0.16498498618602753, -0.21106639504432678] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1000/5550 val_loss:3.348358 train_time:242554ms step_avg:242.55ms x-lambda: 0.9760189652442932 lambdas: [0.0077786678448319435, -0.12041536718606949, 0.04703821986913681, -0.029267530888319016, -0.019672660157084465, 0.034254979342222214, -0.014545546844601631, 0.034928083419799805, 0.0052847955375909805, -0.14921411871910095, -0.21311768889427185] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1125/5550 val_loss:3.320181 train_time:273785ms step_avg:243.36ms x-lambda: 0.9652703404426575 lambdas: [0.0068743121810257435, -0.11996340751647949, 0.04478054866194725, -0.040280744433403015, -0.0204056017100811, 0.028386736288666725, -0.026635902002453804, 0.029878193512558937, -0.005188412964344025, -0.13794323801994324, -0.21403539180755615] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1250/5550 val_loss:3.292865 train_time:305158ms step_avg:244.13ms x-lambda: 0.956606924533844 lambdas: [0.007885168306529522, -0.11674385517835617, 0.04477895051240921, -0.04828817769885063, -0.020220911130309105, 0.025645442306995392, -0.036058127880096436, 0.028588445857167244, -0.013675629161298275, -0.12558741867542267, -0.2101983278989792] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1375/5550 val_loss:3.273879 train_time:336642ms step_avg:244.83ms x-lambda: 0.9462294578552246 lambdas: [0.006644582375884056, -0.11498502641916275, 0.0418040007352829, -0.057574108242988586, -0.020665425807237625, 0.021034130826592445, -0.04674893617630005, 0.024898597970604897, -0.022834977135062218, -0.11600425839424133, -0.20838327705860138] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1500/5550 val_loss:3.254844 train_time:368151ms step_avg:245.43ms x-lambda: 0.9415777921676636 lambdas: [0.008750399574637413, -0.10988049954175949, 0.04287448525428772, -0.06209288537502289, -0.019799452275037766, 0.02067202515900135, -0.05303385108709335, 0.025058668106794357, -0.028361311182379723, -0.10495960712432861, -0.20209208130836487] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1625/5550 val_loss:3.238511 train_time:399732ms step_avg:245.99ms x-lambda: 0.9327252507209778 lambdas: [0.009500185027718544, -0.10642236471176147, 0.042360253632068634, -0.06940756738185883, -0.01937660574913025, 0.019398070871829987, -0.06096090376377106, 0.02376657910645008, -0.0359552763402462, -0.09778355807065964, -0.1987105906009674] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1750/5550 val_loss:3.223492 train_time:431261ms step_avg:246.43ms x-lambda: 0.925761878490448 lambdas: [0.009418737143278122, -0.10228180885314941, 0.041531067341566086, -0.07514362037181854, -0.0170929916203022, 0.01819666288793087, -0.06814228743314743, 0.022998139262199402, -0.042554549872875214, -0.08869127929210663, -0.1917780339717865] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:1875/5550 val_loss:3.205266 train_time:462817ms step_avg:246.84ms x-lambda: 0.9197006225585938 lambdas: [0.00825357623398304, -0.10095220804214478, 0.040241364389657974, -0.08019256591796875, -0.018185913562774658, 0.014873971231281757, -0.0743856281042099, 0.02104276791214943, -0.048377491533756256, -0.08528304845094681, -0.1902385801076889] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2000/5550 val_loss:3.188839 train_time:494651ms step_avg:247.33ms x-lambda: 0.9132660031318665 lambdas: [0.008687322027981281, -0.09620040655136108, 0.03849504142999649, -0.08571132272481918, -0.01730409264564514, 0.012650584802031517, -0.07904241979122162, 0.01969502866268158, -0.053166549652814865, -0.07861687988042831, -0.18431399762630463] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2125/5550 val_loss:3.175288 train_time:526533ms step_avg:247.78ms x-lambda: 0.9093340039253235 lambdas: [0.008854799903929234, -0.09398820996284485, 0.03707849979400635, -0.08974312990903854, -0.01670125499367714, 0.013010436668992043, -0.08359532058238983, 0.018881231546401978, -0.05799020081758499, -0.07483594119548798, -0.1814986765384674] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2250/5550 val_loss:3.160497 train_time:558386ms step_avg:248.17ms x-lambda: 0.9068924784660339 lambdas: [0.007634015753865242, -0.09104330837726593, 0.036966197192668915, -0.0934615433216095, -0.017012588679790497, 0.01059824600815773, -0.08745875954627991, 0.01781526580452919, -0.06224929913878441, -0.0702558383345604, -0.17693164944648743] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2375/5550 val_loss:3.148335 train_time:590275ms step_avg:248.54ms x-lambda: 0.9045614004135132 lambdas: [0.008805733174085617, -0.08767836540937424, 0.035777442157268524, -0.09509889036417007, -0.01533224992454052, 0.011209847405552864, -0.08998190611600876, 0.01762589067220688, -0.06456125527620316, -0.0652632787823677, -0.17273089289665222] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2500/5550 val_loss:3.136811 train_time:622035ms step_avg:248.81ms x-lambda: 0.9011642336845398 lambdas: [0.00849674828350544, -0.08593229204416275, 0.034431345760822296, -0.0987323671579361, -0.0165108609944582, 0.009357323870062828, -0.09263257682323456, 0.017711739987134933, -0.06877879053354263, -0.0631791427731514, -0.16887244582176208] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2625/5550 val_loss:3.125630 train_time:653794ms step_avg:249.06ms x-lambda: 0.8982926607131958 lambdas: [0.00745621882379055, -0.0839943215250969, 0.0340164490044117, -0.10116096585988998, -0.016073554754257202, 0.008534683845937252, -0.09493118524551392, 0.01639004610478878, -0.07159284502267838, -0.06015017628669739, -0.16731467843055725] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2750/5550 val_loss:3.114153 train_time:685579ms step_avg:249.30ms x-lambda: 0.8979986906051636 lambdas: [0.008325465954840183, -0.08083312958478928, 0.03477026894688606, -0.10194732248783112, -0.014057302847504616, 0.00994290504604578, -0.096700020134449, 0.016877535730600357, -0.07446788251399994, -0.05696936324238777, -0.16269342601299286] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:2875/5550 val_loss:3.104808 train_time:717469ms step_avg:249.55ms x-lambda: 0.8966295123100281 lambdas: [0.00859234482049942, -0.07875090837478638, 0.03284015133976936, -0.10444708913564682, -0.01378665491938591, 0.007961229421198368, -0.09785677492618561, 0.0161299891769886, -0.07709165662527084, -0.055024199187755585, -0.16000954806804657] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3000/5550 val_loss:3.093517 train_time:749325ms step_avg:249.78ms x-lambda: 0.8965243101119995 lambdas: [0.008127701468765736, -0.07625972479581833, 0.033666640520095825, -0.10588482767343521, -0.013331581838428974, 0.009366130456328392, -0.09918514639139175, 0.01575811579823494, -0.07890021800994873, -0.05353430286049843, -0.1582527756690979] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3125/5550 val_loss:3.082632 train_time:781231ms step_avg:249.99ms x-lambda: 0.8951483964920044 lambdas: [0.008549217134714127, -0.07592558860778809, 0.032704271376132965, -0.10854155570268631, -0.013172018341720104, 0.008387250825762749, -0.10058395564556122, 0.01544063538312912, -0.08138036727905273, -0.05315859243273735, -0.15746624767780304] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3250/5550 val_loss:3.071133 train_time:813056ms step_avg:250.17ms x-lambda: 0.8969398736953735 lambdas: [0.008207408711314201, -0.07411663979291916, 0.032325275242328644, -0.10809220373630524, -0.013584407977759838, 0.0077094403095543385, -0.10132822394371033, 0.015435054898262024, -0.08290332555770874, -0.05062273144721985, -0.15367993712425232] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3375/5550 val_loss:3.063317 train_time:844863ms step_avg:250.33ms x-lambda: 0.8980573415756226 lambdas: [0.0077619850635528564, -0.07314586639404297, 0.03233317658305168, -0.10941901803016663, -0.013449580408632755, 0.007249019108712673, -0.10318154096603394, 0.015071750618517399, -0.08512169867753983, -0.04959483444690704, -0.15257810056209564] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3500/5550 val_loss:3.054703 train_time:876684ms step_avg:250.48ms x-lambda: 0.8985039591789246 lambdas: [0.007062501274049282, -0.07328466325998306, 0.030438384041190147, -0.11108826100826263, -0.013376476243138313, 0.00594700314104557, -0.10446517914533615, 0.014141088351607323, -0.08777020871639252, -0.04826906695961952, -0.15127985179424286] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3625/5550 val_loss:3.045563 train_time:908502ms step_avg:250.62ms x-lambda: 0.9008821249008179 lambdas: [0.00679174717515707, -0.06979655474424362, 0.030510233715176582, -0.11157791316509247, -0.012467985972762108, 0.006300862412899733, -0.1052788719534874, 0.01383850909769535, -0.08882661163806915, -0.04672432690858841, -0.148629829287529] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3750/5550 val_loss:3.035890 train_time:940303ms step_avg:250.75ms x-lambda: 0.9025624990463257 lambdas: [0.007600976619869471, -0.0695684552192688, 0.030590223148465157, -0.11245354264974594, -0.012594186700880527, 0.006212926469743252, -0.10576429218053818, 0.01480039581656456, -0.09032868593931198, -0.04518265277147293, -0.14783823490142822] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:3875/5550 val_loss:3.026801 train_time:972190ms step_avg:250.89ms x-lambda: 0.9075709581375122 lambdas: [0.007879442535340786, -0.06722842901945114, 0.03023081086575985, -0.11146781593561172, -0.013052581809461117, 0.0058196657337248325, -0.10572262108325958, 0.013535050675272942, -0.09049854427576065, -0.04278005659580231, -0.1473030000925064] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4000/5550 val_loss:3.017174 train_time:1004057ms step_avg:251.01ms x-lambda: 0.9108946323394775 lambdas: [0.007064769044518471, -0.06811629980802536, 0.028754636645317078, -0.11247874796390533, -0.013357182964682579, 0.005853007081896067, -0.10609894245862961, 0.014751691371202469, -0.09233511984348297, -0.043453630059957504, -0.14598165452480316] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4125/5550 val_loss:3.008077 train_time:1035971ms step_avg:251.14ms x-lambda: 0.9138886332511902 lambdas: [0.00609959801658988, -0.06626032292842865, 0.0302862748503685, -0.11363736540079117, -0.011337113566696644, 0.004403006751090288, -0.10745135694742203, 0.014876834116876125, -0.09380337595939636, -0.043277330696582794, -0.14482790231704712] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4250/5550 val_loss:2.999859 train_time:1068097ms step_avg:251.32ms x-lambda: 0.9187880158424377 lambdas: [0.006647743750363588, -0.06550750881433487, 0.02956286258995533, -0.11271079629659653, -0.01165307778865099, 0.005904798861593008, -0.10723557323217392, 0.013162676244974136, -0.09413477033376694, -0.0422101765871048, -0.14546965062618256] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4375/5550 val_loss:2.991107 train_time:1100309ms step_avg:251.50ms x-lambda: 0.9224218130111694 lambdas: [0.006875830236822367, -0.06481358408927917, 0.02844046615064144, -0.11381429433822632, -0.011453421786427498, 0.00511898472905159, -0.10890650749206543, 0.012929130345582962, -0.0964682549238205, -0.041266217827796936, -0.14626987278461456] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4500/5550 val_loss:2.982713 train_time:1132511ms step_avg:251.67ms x-lambda: 0.9261084794998169 lambdas: [0.006145678460597992, -0.06430300325155258, 0.02837454527616501, -0.11485237628221512, -0.012370063923299313, 0.005013186018913984, -0.10934761166572571, 0.013245202600955963, -0.09686312824487686, -0.041718754917383194, -0.14466138184070587] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4625/5550 val_loss:2.972931 train_time:1164853ms step_avg:251.86ms x-lambda: 0.9324361681938171 lambdas: [0.006193309091031551, -0.06311633437871933, 0.027913250029087067, -0.11385107040405273, -0.011894247494637966, 0.004497087560594082, -0.1094110831618309, 0.013063314370810986, -0.09746287018060684, -0.039985448122024536, -0.1443844735622406] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4750/5550 val_loss:2.963699 train_time:1197352ms step_avg:252.07ms x-lambda: 0.9377016425132751 lambdas: [0.0076960232108831406, -0.062301136553287506, 0.028765294700860977, -0.11382891982793808, -0.011439402587711811, 0.005956235341727734, -0.1092841699719429, 0.01379495020955801, -0.09775454550981522, -0.03942638263106346, -0.14392095804214478] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:4875/5550 val_loss:2.954916 train_time:1229970ms step_avg:252.30ms x-lambda: 0.9429706335067749 lambdas: [0.006476882379502058, -0.06291569024324417, 0.027686232700943947, -0.11395445466041565, -0.011118745431303978, 0.003939897753298283, -0.10996580868959427, 0.013989368453621864, -0.09863334149122238, -0.03834123909473419, -0.14405639469623566] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5000/5550 val_loss:2.946811 train_time:1262747ms step_avg:252.55ms x-lambda: 0.9494314193725586 lambdas: [0.006473653018474579, -0.06123729795217514, 0.027058321982622147, -0.1136905625462532, -0.011569133959710598, 0.004231889732182026, -0.10992573946714401, 0.01264264713972807, -0.0992494747042656, -0.039006032049655914, -0.1449800282716751] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5125/5550 val_loss:2.939053 train_time:1295662ms step_avg:252.81ms x-lambda: 0.9548705220222473 lambdas: [0.006737079005688429, -0.06068005785346031, 0.027049440890550613, -0.11373631656169891, -0.011916851624846458, 0.004899871535599232, -0.11076148599386215, 0.0126485675573349, -0.10000612586736679, -0.03806593641638756, -0.14550337195396423] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5250/5550 val_loss:2.932114 train_time:1328762ms step_avg:253.10ms x-lambda: 0.9599809646606445 lambdas: [0.006766132079064846, -0.06077520549297333, 0.027396922931075096, -0.11321595311164856, -0.011074993759393692, 0.004475695546716452, -0.1104050725698471, 0.012233497574925423, -0.09998268634080887, -0.03709303215146065, -0.144958034157753] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5375/5550 val_loss:2.925630 train_time:1361951ms step_avg:253.39ms x-lambda: 0.9648099541664124 lambdas: [0.00660041393712163, -0.060777951031923294, 0.02701355144381523, -0.11312129348516464, -0.011260570026934147, 0.004184558987617493, -0.11078300327062607, 0.013100747019052505, -0.10024839639663696, -0.03759695217013359, -0.14608027040958405] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5500/5550 val_loss:2.920773 train_time:1395431ms step_avg:253.71ms x-lambda: 0.9684950113296509 lambdas: [0.006624931003898382, -0.0607418417930603, 0.02637491002678871, -0.1126394271850586, -0.011011704802513123, 0.003742585191503167, -0.11125284433364868, 0.012428255751729012, -0.10036451369524002, -0.037432711571455, -0.14592847228050232] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]
step:5550/5550 val_loss:2.919610 train_time:1408883ms step_avg:253.85ms x-lambda: 0.9690229892730713 lambdas: [0.0065420251339674, -0.060768019407987595, 0.025914454832673073, -0.11278098076581955, -0.011013874784111977, 0.004052308388054371, -0.11120663583278656, 0.01244392804801464, -0.10044503957033157, -0.03723554313182831, -0.14631862938404083] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9]



## 8000-add-skip-multiple-12-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:125/5550 val_loss:4.257670 train_time:29422ms step_avg:235.38ms x-lambda: 1.0163391828536987 lambdas: [0.02125997468829155, 0.027485938742756844, 0.01284877210855484, 0.05699915438890457, 0.01450088806450367, -0.05732777342200279, 0.01589958183467388, 0.07115880399942398, 0.018425635993480682, 0.03712955489754677, 0.022178061306476593, 0.00937563180923462] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:250/5550 val_loss:3.849716 train_time:58976ms step_avg:235.90ms x-lambda: 0.9849235415458679 lambdas: [0.021402308717370033, 0.01978779211640358, -0.024083225056529045, 0.09515037387609482, -0.03597921505570412, -0.17592401802539825, 0.022387560456991196, 0.04439820721745491, 0.022537341341376305, 0.04583719000220299, 0.006964758969843388, -0.006149329245090485] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:375/5550 val_loss:3.676141 train_time:88917ms step_avg:237.11ms x-lambda: 0.9764144420623779 lambdas: [0.018260831013321877, -0.006850612349808216, -0.035699762403964996, 0.09889613837003708, -0.08529552817344666, -0.23210690915584564, 0.03438363969326019, 0.03499506413936615, 0.026308394968509674, 0.042472612112760544, -0.0029249312356114388, -0.003001699224114418] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:500/5550 val_loss:3.559300 train_time:119195ms step_avg:238.39ms x-lambda: 0.967764139175415 lambdas: [0.00907634012401104, -0.03877447172999382, -0.032736994326114655, 0.09472507983446121, -0.12355274707078934, -0.2563517689704895, 0.03324967622756958, 0.030164919793605804, 0.0203518308699131, 0.037608999758958817, -0.006519943010061979, -0.00808788649737835] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:625/5550 val_loss:3.480712 train_time:149776ms step_avg:239.64ms x-lambda: 0.9651444554328918 lambdas: [0.0022024870850145817, -0.06741394102573395, -0.02020188421010971, 0.0904322937130928, -0.14620964229106903, -0.26068630814552307, 0.029491590335965157, 0.02526143193244934, 0.013018331490457058, 0.03485548868775368, -0.0030028573237359524, -0.012938760221004486] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:750/5550 val_loss:3.428065 train_time:180659ms step_avg:240.88ms x-lambda: 0.9627023935317993 lambdas: [-0.004523856565356255, -0.09300359338521957, -0.009503167122602463, 0.08417679369449615, -0.1577032059431076, -0.25533175468444824, 0.023121371865272522, 0.021905703470110893, 0.0036276113241910934, 0.03095931187272072, 0.00018107297364622355, -0.018437273800373077] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:875/5550 val_loss:3.383049 train_time:211647ms step_avg:241.88ms x-lambda: 0.959307849407196 lambdas: [-0.008084245026111603, -0.11312442272901535, -0.002013922668993473, 0.07941248267889023, -0.159593403339386, -0.241084486246109, 0.0169444028288126, 0.021727180108428, -0.004766327328979969, 0.02862333506345749, 0.004777050577104092, -0.024200236424803734] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1000/5550 val_loss:3.347293 train_time:242894ms step_avg:242.89ms x-lambda: 0.9544855952262878 lambdas: [-0.012007965706288815, -0.13133949041366577, 0.0041899005882442, 0.07347400486469269, -0.1565229892730713, -0.22492042183876038, 0.00837714597582817, 0.02017354965209961, -0.01483627688139677, 0.026370901614427567, 0.006533380597829819, -0.030861394479870796] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1125/5550 val_loss:3.317820 train_time:274148ms step_avg:243.69ms x-lambda: 0.9484412670135498 lambdas: [-0.013937195762991905, -0.14750270545482635, 0.007607975509017706, 0.06621821224689484, -0.1498205065727234, -0.21004417538642883, -0.0012432999210432172, 0.0171136986464262, -0.02442692220211029, 0.023089973255991936, 0.00767188984900713, -0.03895822912454605] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1250/5550 val_loss:3.294308 train_time:305531ms step_avg:244.42ms x-lambda: 0.9461525082588196 lambdas: [-0.013247699476778507, -0.15972907841205597, 0.010016875341534615, 0.06172361597418785, -0.1424262970685959, -0.19490379095077515, -0.007791388779878616, 0.017216632142663002, -0.031463269144296646, 0.022371307015419006, 0.006579962093383074, -0.042973048985004425] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1375/5550 val_loss:3.272687 train_time:337084ms step_avg:245.15ms x-lambda: 0.9388293027877808 lambdas: [-0.013468142598867416, -0.17234328389167786, 0.010006574913859367, 0.05552783980965614, -0.138275146484375, -0.18205121159553528, -0.017013663426041603, 0.013582094572484493, -0.041101839393377304, 0.019605793058872223, 0.005408364813774824, -0.0511629618704319] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1500/5550 val_loss:3.253828 train_time:368612ms step_avg:245.74ms x-lambda: 0.9352452158927917 lambdas: [-0.010793527588248253, -0.18186651170253754, 0.012802361510694027, 0.05169036239385605, -0.12994331121444702, -0.17055746912956238, -0.02408529631793499, 0.013443337753415108, -0.04738011956214905, 0.01887151040136814, 0.006665057968348265, -0.056006982922554016] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1625/5550 val_loss:3.237711 train_time:400211ms step_avg:246.28ms x-lambda: 0.9305139183998108 lambdas: [-0.008249440230429173, -0.18987320363521576, 0.01355459913611412, 0.04934598132967949, -0.124130479991436, -0.15947365760803223, -0.03253733739256859, 0.01263882964849472, -0.05469449982047081, 0.017654776573181152, 0.0069592054933309555, -0.06274085491895676] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1750/5550 val_loss:3.221872 train_time:431789ms step_avg:246.74ms x-lambda: 0.9268441200256348 lambdas: [-0.004907195921987295, -0.1967678666114807, 0.015459832735359669, 0.04468951001763344, -0.11703425645828247, -0.14727385342121124, -0.03944997489452362, 0.01231631450355053, -0.05964551866054535, 0.0166157353669405, 0.007767202332615852, -0.06800888478755951] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:1875/5550 val_loss:3.203304 train_time:463404ms step_avg:247.15ms x-lambda: 0.925259530544281 lambdas: [0.0006824544398114085, -0.20055349171161652, 0.017419377341866493, 0.04284939169883728, -0.11189734935760498, -0.13907340168952942, -0.044420547783374786, 0.012317909859120846, -0.06310801208019257, 0.015756214037537575, 0.0076186638325452805, -0.07148884981870651] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2000/5550 val_loss:3.188741 train_time:495249ms step_avg:247.62ms x-lambda: 0.921673059463501 lambdas: [0.004377089440822601, -0.20413510501384735, 0.016895830631256104, 0.03963490203022957, -0.10764751583337784, -0.12925748527050018, -0.05128178372979164, 0.011618337593972683, -0.06793427467346191, 0.014711533673107624, 0.0066862283274531364, -0.07725787162780762] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2125/5550 val_loss:3.174773 train_time:527123ms step_avg:248.06ms x-lambda: 0.9210032820701599 lambdas: [0.008471830748021603, -0.20826731622219086, 0.01689484901726246, 0.038506120443344116, -0.10321405529975891, -0.12321053445339203, -0.05684325844049454, 0.012015173211693764, -0.07144712656736374, 0.015412609092891216, 0.007132925093173981, -0.08103402704000473] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2250/5550 val_loss:3.159739 train_time:558989ms step_avg:248.44ms x-lambda: 0.9197641015052795 lambdas: [0.012517993338406086, -0.20971660315990448, 0.016513610258698463, 0.03454946354031563, -0.10107851028442383, -0.11820406466722488, -0.06253791600465775, 0.010000406764447689, -0.07578813284635544, 0.012956506572663784, 0.005138080101460218, -0.08566869050264359] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2375/5550 val_loss:3.148547 train_time:590879ms step_avg:248.79ms x-lambda: 0.9188181757926941 lambdas: [0.01593465358018875, -0.21096935868263245, 0.015628058463335037, 0.03367142751812935, -0.09662984311580658, -0.11214554309844971, -0.06721436977386475, 0.00998066645115614, -0.07875338941812515, 0.013600789941847324, 0.005947167985141277, -0.08928606659173965] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2500/5550 val_loss:3.137262 train_time:622711ms step_avg:249.08ms x-lambda: 0.9184608459472656 lambdas: [0.01881721056997776, -0.212511345744133, 0.015669051557779312, 0.03282728046178818, -0.09421409666538239, -0.1071007028222084, -0.07122641801834106, 0.011384580284357071, -0.08101064711809158, 0.012828943319618702, 0.005626286845654249, -0.09232378751039505] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2625/5550 val_loss:3.125428 train_time:654560ms step_avg:249.36ms x-lambda: 0.9169966578483582 lambdas: [0.02200590819120407, -0.2143690437078476, 0.015540014952421188, 0.030386822298169136, -0.09084734320640564, -0.10353538393974304, -0.07649029791355133, 0.009119800291955471, -0.08420252054929733, 0.01195596344769001, 0.004919932223856449, -0.0966433435678482] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2750/5550 val_loss:3.114636 train_time:686406ms step_avg:249.60ms x-lambda: 0.9195772409439087 lambdas: [0.024561308324337006, -0.2138678878545761, 0.01796560548245907, 0.03089255653321743, -0.08859837800264359, -0.09926829487085342, -0.07884261757135391, 0.009945432655513287, -0.08548397570848465, 0.012942416593432426, 0.006457124371081591, -0.09864354133605957] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:2875/5550 val_loss:3.106650 train_time:718287ms step_avg:249.84ms x-lambda: 0.9207214117050171 lambdas: [0.028479069471359253, -0.2147028148174286, 0.017470482736825943, 0.029923025518655777, -0.08565474301576614, -0.09511718899011612, -0.08151336759328842, 0.009672349318861961, -0.08586856722831726, 0.013368806801736355, 0.006511560641229153, -0.10093559324741364] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3000/5550 val_loss:3.094207 train_time:750144ms step_avg:250.05ms x-lambda: 0.9208147525787354 lambdas: [0.029145553708076477, -0.2158307284116745, 0.015698831528425217, 0.028305180370807648, -0.08570777624845505, -0.09414929896593094, -0.08610212057828903, 0.007769996300339699, -0.08916060626506805, 0.011975058354437351, 0.005969054531306028, -0.10419902950525284] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3125/5550 val_loss:3.083808 train_time:782059ms step_avg:250.26ms x-lambda: 0.9207934141159058 lambdas: [0.03142530471086502, -0.21790722012519836, 0.016151146963238716, 0.02606465481221676, -0.08418259769678116, -0.09113259613513947, -0.08974486589431763, 0.00831633247435093, -0.09103385359048843, 0.01003718189895153, 0.004610096104443073, -0.10815450549125671] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3250/5550 val_loss:3.071927 train_time:813938ms step_avg:250.44ms x-lambda: 0.9248602390289307 lambdas: [0.034617938101291656, -0.21787455677986145, 0.016096606850624084, 0.026141025125980377, -0.08215119689702988, -0.08793500810861588, -0.09066737443208694, 0.007730644196271896, -0.09011569619178772, 0.011362328194081783, 0.005406457930803299, -0.10917460173368454] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3375/5550 val_loss:3.063012 train_time:845795ms step_avg:250.61ms x-lambda: 0.926177442073822 lambdas: [0.035622287541627884, -0.21765181422233582, 0.016285231336951256, 0.02573304809629917, -0.08039442449808121, -0.0872453898191452, -0.09410372376441956, 0.007383822463452816, -0.0925101712346077, 0.009783416986465454, 0.005187404807657003, -0.11163304001092911] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3500/5550 val_loss:3.055434 train_time:877715ms step_avg:250.78ms x-lambda: 0.9280434846878052 lambdas: [0.03730848431587219, -0.21879751980304718, 0.015209205448627472, 0.022972550243139267, -0.08017118275165558, -0.08554574847221375, -0.0973934754729271, 0.006750496570020914, -0.09357251971960068, 0.00814676471054554, 0.00427903700619936, -0.11458959430456161] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3625/5550 val_loss:3.046262 train_time:909592ms step_avg:250.92ms x-lambda: 0.9316591024398804 lambdas: [0.03923622518777847, -0.21778492629528046, 0.015592681244015694, 0.023693429306149483, -0.0764119029045105, -0.08346503227949142, -0.09863139688968658, 0.006863742135465145, -0.09378913044929504, 0.008430056273937225, 0.00473824143409729, -0.11529456079006195] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3750/5550 val_loss:3.036298 train_time:941464ms step_avg:251.06ms x-lambda: 0.9343898892402649 lambdas: [0.04058415815234184, -0.2181796431541443, 0.015599668957293034, 0.02388407289981842, -0.07587273418903351, -0.08147359639406204, -0.10100799798965454, 0.007258162833750248, -0.094447061419487, 0.009786688722670078, 0.0036067464388906956, -0.11764800548553467] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:3875/5550 val_loss:3.027639 train_time:973410ms step_avg:251.20ms x-lambda: 0.9402164816856384 lambdas: [0.04266958311200142, -0.2195972055196762, 0.016240671277046204, 0.02233625017106533, -0.0752820149064064, -0.0798431932926178, -0.10138405859470367, 0.007272128947079182, -0.09451735019683838, 0.00925453845411539, 0.004280940163880587, -0.11729127168655396] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4000/5550 val_loss:3.017982 train_time:1005334ms step_avg:251.33ms x-lambda: 0.9443910717964172 lambdas: [0.04455650970339775, -0.21926957368850708, 0.015811476856470108, 0.02327842265367508, -0.07529523223638535, -0.07724661380052567, -0.10328944772481918, 0.007613233756273985, -0.09490121155977249, 0.009507021866738796, 0.003713031765073538, -0.11980096250772476] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4125/5550 val_loss:3.008799 train_time:1037309ms step_avg:251.47ms x-lambda: 0.9490921497344971 lambdas: [0.046111080795526505, -0.21924790740013123, 0.01590529829263687, 0.022324971854686737, -0.07403004914522171, -0.07641389220952988, -0.10585283488035202, 0.007415568921715021, -0.09547504037618637, 0.008574089035391808, 0.0046291411854326725, -0.12187979370355606] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4250/5550 val_loss:3.000865 train_time:1069456ms step_avg:251.64ms x-lambda: 0.9546502828598022 lambdas: [0.0474504791200161, -0.22050316631793976, 0.01694457232952118, 0.022439448162913322, -0.0741984024643898, -0.07494933158159256, -0.10673444718122482, 0.006407612469047308, -0.09547466784715652, 0.009084726683795452, 0.0047663296572864056, -0.1218506470322609] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4375/5550 val_loss:2.991430 train_time:1101650ms step_avg:251.81ms x-lambda: 0.9576270580291748 lambdas: [0.04712679982185364, -0.22143061459064484, 0.015299270860850811, 0.021375207230448723, -0.07256516814231873, -0.07524509727954865, -0.10961499810218811, 0.007050031796097755, -0.09781341999769211, 0.007915187627077103, 0.003915730398148298, -0.12465737015008926] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4500/5550 val_loss:2.983507 train_time:1133882ms step_avg:251.97ms x-lambda: 0.9633532762527466 lambdas: [0.04784359782934189, -0.22290672361850739, 0.014652520418167114, 0.020020591095089912, -0.0725570023059845, -0.07405493408441544, -0.11064863204956055, 0.007118650246411562, -0.09812993556261063, 0.007735700346529484, 0.003926437813788652, -0.12593825161457062] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4625/5550 val_loss:2.974032 train_time:1166319ms step_avg:252.18ms x-lambda: 0.9700381755828857 lambdas: [0.0491575188934803, -0.22221195697784424, 0.0145798334851861, 0.019518382847309113, -0.07262630015611649, -0.07341423630714417, -0.11083999276161194, 0.004956709686666727, -0.09813780337572098, 0.00829505454748869, 0.0036690940614789724, -0.12549073994159698] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4750/5550 val_loss:2.964893 train_time:1198811ms step_avg:252.38ms x-lambda: 0.9756390452384949 lambdas: [0.05079417675733566, -0.22315213084220886, 0.016207410022616386, 0.0211095679551363, -0.07294376194477081, -0.07226153463125229, -0.11166006326675415, 0.0066592153161764145, -0.09808380156755447, 0.00796880666166544, 0.0037616740446537733, -0.1268862634897232] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:4875/5550 val_loss:2.955982 train_time:1231487ms step_avg:252.61ms x-lambda: 0.9815120100975037 lambdas: [0.05181397870182991, -0.2249704897403717, 0.014348584227263927, 0.020896194502711296, -0.0716501995921135, -0.071761354804039, -0.1129830926656723, 0.007307001389563084, -0.09880291670560837, 0.007699852343648672, 0.0026227484922856092, -0.12831367552280426] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5000/5550 val_loss:2.947983 train_time:1264256ms step_avg:252.85ms x-lambda: 0.9881414771080017 lambdas: [0.05305766314268112, -0.2245384305715561, 0.015618226490914822, 0.021115299314260483, -0.07310065627098083, -0.07098755985498428, -0.11382758617401123, 0.006229782942682505, -0.09887903928756714, 0.007114299573004246, 0.0030498511623591185, -0.12829221785068512] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5125/5550 val_loss:2.940308 train_time:1297135ms step_avg:253.10ms x-lambda: 0.9931566119194031 lambdas: [0.05429175868630409, -0.226571723818779, 0.014782197773456573, 0.020778324455022812, -0.07233212888240814, -0.06968141347169876, -0.1152002289891243, 0.005992035381495953, -0.09925594180822372, 0.007391723804175854, 0.0035353428684175014, -0.12913285195827484] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5250/5550 val_loss:2.933235 train_time:1330213ms step_avg:253.37ms x-lambda: 0.9979367852210999 lambdas: [0.05494632199406624, -0.2267369031906128, 0.014371699653565884, 0.019678059965372086, -0.07122599333524704, -0.06819810718297958, -0.11600066721439362, 0.005961679387837648, -0.0998426079750061, 0.007577519863843918, 0.0036057927645742893, -0.13012054562568665] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5375/5550 val_loss:2.926748 train_time:1363408ms step_avg:253.66ms x-lambda: 1.0028022527694702 lambdas: [0.05622304603457451, -0.22791053354740143, 0.013955255039036274, 0.020172785967588425, -0.07222484052181244, -0.06826110184192657, -0.11635328829288483, 0.0065774028189480305, -0.09996499866247177, 0.007686534896492958, 0.0035335614811629057, -0.130488783121109] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5500/5550 val_loss:2.921955 train_time:1396891ms step_avg:253.98ms x-lambda: 1.0058448314666748 lambdas: [0.056517064571380615, -0.22829370200634003, 0.013651647605001926, 0.020114092156291008, -0.07184649258852005, -0.06838885694742203, -0.11667978018522263, 0.005861862562596798, -0.1006709560751915, 0.006919174455106258, 0.003561253659427166, -0.13067485392093658] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]
step:5550/5550 val_loss:2.920758 train_time:1410350ms step_avg:254.12ms x-lambda: 1.00690758228302 lambdas: [0.05669208988547325, -0.22857694327831268, 0.013197321444749832, 0.02067919261753559, -0.07197727262973785, -0.0686865821480751, -0.11648446321487427, 0.005919379182159901, -0.10062449425458908, 0.006772212218493223, 0.003455278929322958, -0.13055697083473206] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14]



## 8000-add-skip-multiple-12-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.31ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:125/5550 val_loss:4.250444 train_time:29419ms step_avg:235.35ms x-lambda: 1.021181344985962 lambdas: [0.015039030462503433, 0.019245631992816925, 0.021717721596360207, 0.02492859959602356, 0.030515214428305626, 0.017852632328867912, 0.018337737768888474, 0.01958330161869526, 0.02185193821787834, 0.03908124193549156, 0.05969581753015518, -0.051179420202970505] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:250/5550 val_loss:3.851568 train_time:58998ms step_avg:235.99ms x-lambda: 0.9987061619758606 lambdas: [0.008402762934565544, 0.017540229484438896, 0.01930912397801876, 0.021144984290003777, 0.02048182114958763, -0.03256085515022278, -0.010151666589081287, 0.020006243139505386, -9.757513180375099e-05, 0.045092012733221054, 0.0931224673986435, -0.1589670032262802] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:375/5550 val_loss:3.678460 train_time:89072ms step_avg:237.52ms x-lambda: 0.9913740754127502 lambdas: [0.013574990443885326, 0.020299401134252548, 0.018076438456773758, 0.01722731441259384, -0.006712453439831734, -0.08559665083885193, -0.01832388900220394, 0.027709927409887314, -0.01910599321126938, 0.03813699260354042, 0.09636536240577698, -0.21239154040813446] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:500/5550 val_loss:3.560771 train_time:119508ms step_avg:239.02ms x-lambda: 0.9899175763130188 lambdas: [0.014225664548575878, 0.01843998022377491, 0.014413920231163502, 0.013807221315801144, -0.03357239067554474, -0.12310950458049774, -0.011586756445467472, 0.03680962696671486, -0.025768937543034554, 0.03475559130311012, 0.09695730358362198, -0.23355764150619507] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:625/5550 val_loss:3.481942 train_time:150156ms step_avg:240.25ms x-lambda: 0.9823894500732422 lambdas: [0.00880295317620039, 0.010076590813696384, 0.004885011352598667, 0.007644351571798325, -0.059406641870737076, -0.14830125868320465, -0.00260249525308609, 0.038689058274030685, -0.029835324734449387, 0.029409019276499748, 0.09486015886068344, -0.2417958825826645] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:750/5550 val_loss:3.428154 train_time:181129ms step_avg:241.51ms x-lambda: 0.9770721197128296 lambdas: [0.0045107509940862656, 0.002359315287321806, -0.003392427694052458, 0.004554114770144224, -0.07805185765028, -0.15868613123893738, 0.006357688456773758, 0.03940621018409729, -0.02863061986863613, 0.026255879551172256, 0.09368856251239777, -0.2383231520652771] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:875/5550 val_loss:3.383797 train_time:212204ms step_avg:242.52ms x-lambda: 0.9680619835853577 lambdas: [-0.0014775772579014301, -0.00763542577624321, -0.013472453691065311, 0.00029175341478548944, -0.0957658663392067, -0.16348357498645782, 0.011758347041904926, 0.037332624197006226, -0.026339758187532425, 0.02322443760931492, 0.08974381536245346, -0.22965769469738007] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1000/5550 val_loss:3.348441 train_time:243539ms step_avg:243.54ms x-lambda: 0.9616403579711914 lambdas: [-0.0060258181765675545, -0.016309374943375587, -0.022177644073963165, -0.0013406419893726707, -0.10950855910778046, -0.1612900346517563, 0.016650129109621048, 0.036913808435201645, -0.02349192090332508, 0.021184811368584633, 0.08653727918863297, -0.21583905816078186] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1125/5550 val_loss:3.318628 train_time:274852ms step_avg:244.31ms x-lambda: 0.9535646438598633 lambdas: [-0.012208053842186928, -0.026831312105059624, -0.031366169452667236, -0.0028109990525990725, -0.12335007637739182, -0.1589544266462326, 0.019976427778601646, 0.032909028232097626, -0.022405341267585754, 0.017310980707406998, 0.08012856543064117, -0.20435857772827148] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1250/5550 val_loss:3.293294 train_time:306291ms step_avg:245.03ms x-lambda: 0.9474015235900879 lambdas: [-0.016085438430309296, -0.034850604832172394, -0.038641829043626785, -0.0019631595350801945, -0.1338103860616684, -0.15377183258533478, 0.021846644580364227, 0.0322025865316391, -0.02072570100426674, 0.01629321649670601, 0.07616118341684341, -0.19003985822200775] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1375/5550 val_loss:3.273183 train_time:337912ms step_avg:245.75ms x-lambda: 0.9391536712646484 lambdas: [-0.021228836849331856, -0.04430307447910309, -0.04705177620053291, -0.0017343586077913642, -0.14289890229701996, -0.14831827580928802, 0.020602118223905563, 0.029675044119358063, -0.020071830600500107, 0.013621068559587002, 0.06948471069335938, -0.17787328362464905] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1500/5550 val_loss:3.256053 train_time:369521ms step_avg:246.35ms x-lambda: 0.9336256980895996 lambdas: [-0.025022050365805626, -0.05236956477165222, -0.05367609113454819, 0.0005325403762981296, -0.1504850834608078, -0.14233243465423584, 0.02260868437588215, 0.027754638344049454, -0.01909685507416725, 0.012567109428346157, 0.06417493522167206, -0.16690878570079803] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1625/5550 val_loss:3.237751 train_time:401183ms step_avg:246.88ms x-lambda: 0.9283525943756104 lambdas: [-0.028593383729457855, -0.05944504961371422, -0.05929470807313919, 0.003974191378802061, -0.15586397051811218, -0.1372443437576294, 0.024026701226830482, 0.02838638424873352, -0.016953304409980774, 0.01326780952513218, 0.06067444756627083, -0.15645729005336761] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1750/5550 val_loss:3.222299 train_time:432811ms step_avg:247.32ms x-lambda: 0.9217482209205627 lambdas: [-0.03285955265164375, -0.06680230796337128, -0.06425747275352478, 0.007257531397044659, -0.15935812890529633, -0.13062390685081482, 0.025662781670689583, 0.028426285833120346, -0.015191026963293552, 0.011930955573916435, 0.0569765567779541, -0.14494411647319794] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:1875/5550 val_loss:3.204053 train_time:464501ms step_avg:247.73ms x-lambda: 0.9170121550559998 lambdas: [-0.03634769469499588, -0.07377373427152634, -0.0696275606751442, 0.01007907185703516, -0.16538093984127045, -0.12745057046413422, 0.025110792368650436, 0.02522227168083191, -0.016080379486083984, 0.009782707318663597, 0.0506204217672348, -0.1376994401216507] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2000/5550 val_loss:3.190017 train_time:496393ms step_avg:248.20ms x-lambda: 0.9125238656997681 lambdas: [-0.03849364072084427, -0.07986654341220856, -0.07308229058980942, 0.014210890978574753, -0.16675114631652832, -0.1208399087190628, 0.026472073048353195, 0.02502535842359066, -0.012918602675199509, 0.011579301208257675, 0.04856602102518082, -0.12870076298713684] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2125/5550 val_loss:3.173952 train_time:528320ms step_avg:248.62ms x-lambda: 0.9088218808174133 lambdas: [-0.041251130402088165, -0.08601226657629013, -0.07727004587650299, 0.01627766713500023, -0.16956765949726105, -0.12026814371347427, 0.023811351507902145, 0.023906659334897995, -0.014049963094294071, 0.009627491235733032, 0.044681109488010406, -0.1229134127497673] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2250/5550 val_loss:3.159947 train_time:560256ms step_avg:249.00ms x-lambda: 0.9070454835891724 lambdas: [-0.04336630925536156, -0.09145233780145645, -0.08084768056869507, 0.02032741904258728, -0.17054343223571777, -0.11560571193695068, 0.02627638168632984, 0.023171454668045044, -0.013503502123057842, 0.009146859869360924, 0.042412616312503815, -0.11601670831441879] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2375/5550 val_loss:3.148717 train_time:592184ms step_avg:249.34ms x-lambda: 0.9051042795181274 lambdas: [-0.04405894875526428, -0.09609299898147583, -0.08334875851869583, 0.022987017408013344, -0.17147637903690338, -0.11197216063737869, 0.025630971416831017, 0.02080700173974037, -0.01311514526605606, 0.008987282402813435, 0.039148323237895966, -0.11017660796642303] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2500/5550 val_loss:3.136837 train_time:624079ms step_avg:249.63ms x-lambda: 0.9032096266746521 lambdas: [-0.04573649913072586, -0.09992268681526184, -0.08605099469423294, 0.026103882119059563, -0.1729411780834198, -0.11003798246383667, 0.024054182693362236, 0.021219413727521896, -0.012552767992019653, 0.009682325646281242, 0.038370583206415176, -0.10585034638643265] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2625/5550 val_loss:3.124671 train_time:655973ms step_avg:249.89ms x-lambda: 0.9008000493049622 lambdas: [-0.047699324786663055, -0.10499255359172821, -0.08829879015684128, 0.028353668749332428, -0.17358553409576416, -0.10749471187591553, 0.0249598678201437, 0.01983507163822651, -0.012135142460465431, 0.008513541892170906, 0.035799406468868256, -0.10189744085073471] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2750/5550 val_loss:3.113873 train_time:687845ms step_avg:250.13ms x-lambda: 0.899933934211731 lambdas: [-0.04904944449663162, -0.10974439233541489, -0.09073150902986526, 0.029506102204322815, -0.17361009120941162, -0.10640956461429596, 0.024489648640155792, 0.019419554620981216, -0.011193772777915001, 0.008532553911209106, 0.0340510793030262, -0.09890187531709671] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:2875/5550 val_loss:3.105439 train_time:719766ms step_avg:250.35ms x-lambda: 0.9011484980583191 lambdas: [-0.04867959022521973, -0.11207009851932526, -0.09129372239112854, 0.03284899517893791, -0.17321087419986725, -0.10281331837177277, 0.026044871658086777, 0.01950175128877163, -0.010412447154521942, 0.008754144422709942, 0.034015119075775146, -0.09280763566493988] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3000/5550 val_loss:3.094048 train_time:751703ms step_avg:250.57ms x-lambda: 0.9009810090065002 lambdas: [-0.0493726022541523, -0.11550097912549973, -0.09272251278162003, 0.03472239524126053, -0.17317253351211548, -0.10028497874736786, 0.024472368881106377, 0.018532799556851387, -0.010537274181842804, 0.008234155364334583, 0.03190571442246437, -0.09111373126506805] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3125/5550 val_loss:3.083654 train_time:783682ms step_avg:250.78ms x-lambda: 0.8991279602050781 lambdas: [-0.052144717425107956, -0.1210012286901474, -0.09526841342449188, 0.034188929945230484, -0.17603030800819397, -0.09993942081928253, 0.023360470309853554, 0.01745438016951084, -0.01175003033131361, 0.007049709092825651, 0.029148824512958527, -0.08990004658699036] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3250/5550 val_loss:3.070822 train_time:815598ms step_avg:250.95ms x-lambda: 0.9022532105445862 lambdas: [-0.0511498861014843, -0.12291014194488525, -0.09464795142412186, 0.037173692137002945, -0.175541952252388, -0.09843453019857407, 0.025067100301384926, 0.017526304349303246, -0.01001075841486454, 0.007174997124820948, 0.029678314924240112, -0.08633437752723694] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3375/5550 val_loss:3.062535 train_time:847499ms step_avg:251.11ms x-lambda: 0.9032968282699585 lambdas: [-0.05157896876335144, -0.125551238656044, -0.0953521728515625, 0.038931768387556076, -0.1770819127559662, -0.09717974066734314, 0.02448541298508644, 0.01702410914003849, -0.010005248710513115, 0.0062569216825068, 0.028043746948242188, -0.0862400010228157] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3500/5550 val_loss:3.054449 train_time:879444ms step_avg:251.27ms x-lambda: 0.9034647345542908 lambdas: [-0.05254478380084038, -0.1289360672235489, -0.09749764204025269, 0.038709938526153564, -0.1764562577009201, -0.09610364586114883, 0.023669015616178513, 0.01619383506476879, -0.011242486536502838, 0.005386163480579853, 0.025989152491092682, -0.0830286517739296] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3625/5550 val_loss:3.045288 train_time:911369ms step_avg:251.41ms x-lambda: 0.9069784879684448 lambdas: [-0.05142415314912796, -0.1301518827676773, -0.09730017185211182, 0.040939029306173325, -0.17464104294776917, -0.09279052168130875, 0.02431807667016983, 0.016842417418956757, -0.009664749726653099, 0.006442999467253685, 0.02714035101234913, -0.08055619895458221] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3750/5550 val_loss:3.035537 train_time:943310ms step_avg:251.55ms x-lambda: 0.9079363942146301 lambdas: [-0.052600182592868805, -0.13351576030254364, -0.09865816682577133, 0.04073328152298927, -0.1760704070329666, -0.09426568448543549, 0.02380411885678768, 0.016587309539318085, -0.010192803107202053, 0.00630923081189394, 0.025587180629372597, -0.0786442831158638] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:3875/5550 val_loss:3.026559 train_time:975294ms step_avg:251.69ms x-lambda: 0.9124199748039246 lambdas: [-0.05077839642763138, -0.13430975377559662, -0.09804438054561615, 0.04327606409788132, -0.1772223562002182, -0.09205004572868347, 0.02356952428817749, 0.015291821211576462, -0.00966313760727644, 0.006240320857614279, 0.025875423103570938, -0.07673002779483795] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4000/5550 val_loss:3.017170 train_time:1007265ms step_avg:251.82ms x-lambda: 0.9155066013336182 lambdas: [-0.05132007598876953, -0.13650619983673096, -0.09928738325834274, 0.044468846172094345, -0.17717760801315308, -0.09220259636640549, 0.02400106191635132, 0.015367204323410988, -0.00962370727211237, 0.006730387452989817, 0.024774901568889618, -0.07703495025634766] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4125/5550 val_loss:3.007991 train_time:1039277ms step_avg:251.95ms x-lambda: 0.9192166924476624 lambdas: [-0.050953883677721024, -0.13869015872478485, -0.09990179538726807, 0.04551123082637787, -0.17711462080478668, -0.0904572606086731, 0.02477318048477173, 0.015455641783773899, -0.009126928634941578, 0.005880775395780802, 0.024191007018089294, -0.07498747110366821] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4250/5550 val_loss:2.999761 train_time:1071473ms step_avg:252.11ms x-lambda: 0.9232879281044006 lambdas: [-0.05063781142234802, -0.14019426703453064, -0.0997554361820221, 0.04575164243578911, -0.17741759121418, -0.09056472033262253, 0.02419612556695938, 0.016111299395561218, -0.009265472181141376, 0.006273854989558458, 0.024013256654143333, -0.07380688190460205] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4375/5550 val_loss:2.990563 train_time:1103731ms step_avg:252.28ms x-lambda: 0.9260969758033752 lambdas: [-0.05158652737736702, -0.1432698369026184, -0.10078499466180801, 0.046742331236600876, -0.17855453491210938, -0.09166985750198364, 0.02278376743197441, 0.014800423756241798, -0.008921802043914795, 0.004642141051590443, 0.022203342989087105, -0.07486442476511002] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4500/5550 val_loss:2.982427 train_time:1136005ms step_avg:252.45ms x-lambda: 0.9306886196136475 lambdas: [-0.05096936598420143, -0.14480441808700562, -0.10147227346897125, 0.04585498198866844, -0.17975817620754242, -0.09075865894556046, 0.02324596978724003, 0.01446558628231287, -0.008732116781175137, 0.005587789695709944, 0.022755902260541916, -0.07231047004461288] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4625/5550 val_loss:2.972903 train_time:1168452ms step_avg:252.64ms x-lambda: 0.9357476234436035 lambdas: [-0.05006653070449829, -0.14570540189743042, -0.10126587003469467, 0.04791610687971115, -0.17958609759807587, -0.08933073282241821, 0.02263326570391655, 0.014089046977460384, -0.00946498941630125, 0.0049520921893417835, 0.021898170933127403, -0.07101093977689743] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4750/5550 val_loss:2.963681 train_time:1200963ms step_avg:252.83ms x-lambda: 0.9414522647857666 lambdas: [-0.04920986667275429, -0.14655087888240814, -0.1007307767868042, 0.04928572103381157, -0.1793975681066513, -0.08993355929851532, 0.02287825010716915, 0.015331512317061424, -0.008209846913814545, 0.005445763003081083, 0.023175960406661034, -0.07011649012565613] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:4875/5550 val_loss:2.954895 train_time:1233679ms step_avg:253.06ms x-lambda: 0.9465060234069824 lambdas: [-0.0491170771420002, -0.14802466332912445, -0.1004248782992363, 0.05028066411614418, -0.18088984489440918, -0.0898798480629921, 0.022934235632419586, 0.01346895843744278, -0.008551476523280144, 0.004647314548492432, 0.022352345287799835, -0.06904258579015732] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5000/5550 val_loss:2.946540 train_time:1266494ms step_avg:253.30ms x-lambda: 0.9526806473731995 lambdas: [-0.048415862023830414, -0.14904530346393585, -0.1006736308336258, 0.051602594554424286, -0.1810210794210434, -0.08885517716407776, 0.022033534944057465, 0.01399841159582138, -0.008674358949065208, 0.004938853904604912, 0.022395163774490356, -0.06868815422058105] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5125/5550 val_loss:2.939021 train_time:1299455ms step_avg:253.55ms x-lambda: 0.9578347206115723 lambdas: [-0.04816551133990288, -0.15061061084270477, -0.1018945574760437, 0.052136629819869995, -0.18282495439052582, -0.0895540788769722, 0.022312024608254433, 0.014512118883430958, -0.008242725394666195, 0.005324519705027342, 0.02212153561413288, -0.06830037385225296] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5250/5550 val_loss:2.931841 train_time:1332590ms step_avg:253.83ms x-lambda: 0.962715208530426 lambdas: [-0.04753734916448593, -0.15120576322078705, -0.1019938737154007, 0.05290468782186508, -0.18266703188419342, -0.08862490952014923, 0.02177792228758335, 0.013477209955453873, -0.00725579122081399, 0.005093592219054699, 0.02173091471195221, -0.06761328876018524] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5375/5550 val_loss:2.925402 train_time:1365860ms step_avg:254.11ms x-lambda: 0.9681764245033264 lambdas: [-0.04723707586526871, -0.15181219577789307, -0.10201071202754974, 0.05409976840019226, -0.18381640315055847, -0.08942048251628876, 0.02156928740441799, 0.013458358123898506, -0.008344839327037334, 0.004714353010058403, 0.021968217566609383, -0.06794477254152298] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5500/5550 val_loss:2.920594 train_time:1399382ms step_avg:254.43ms x-lambda: 0.9709522724151611 lambdas: [-0.04737980663776398, -0.1528998166322708, -0.10230951011180878, 0.05449695885181427, -0.1849445402622223, -0.08891210705041885, 0.021631529554724693, 0.012537635862827301, -0.00776320043951273, 0.0038223869632929564, 0.021925101056694984, -0.06792009621858597] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]
step:5550/5550 val_loss:2.919441 train_time:1412848ms step_avg:254.57ms x-lambda: 0.9718378782272339 lambdas: [-0.04728902503848076, -0.15307894349098206, -0.10223440825939178, 0.05486311763525009, -0.18473409116268158, -0.08913303166627884, 0.021212197840213776, 0.012735364958643913, -0.007626699283719063, 0.0036533898673951626, 0.021921491250395775, -0.06777574121952057] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3]



## 8000-add-skip-multiple-12-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.18ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:125/5550 val_loss:4.264897 train_time:29396ms step_avg:235.16ms x-lambda: 1.0208368301391602 lambdas: [0.0781518816947937, 0.002718554111197591, -0.033331070095300674, -0.045036811381578445, 0.058598652482032776, 0.04111161455512047, 0.02492016926407814, 0.020629746839404106, 0.017440905794501305, 0.017814669758081436, 0.03130092844367027, 0.02920428477227688] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:250/5550 val_loss:3.854398 train_time:58978ms step_avg:235.91ms x-lambda: 0.993825376033783 lambdas: [0.07346723228693008, -0.03261328488588333, -0.09673752635717392, -0.1257271021604538, 0.10210543870925903, 0.05227253586053848, 0.009535173885524273, 0.028579190373420715, -0.014268042519688606, -0.03505006432533264, 0.020125888288021088, 0.04039664566516876] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:375/5550 val_loss:3.675574 train_time:88984ms step_avg:237.29ms x-lambda: 0.9930470585823059 lambdas: [0.06654748320579529, -0.03595137596130371, -0.11763325333595276, -0.16646015644073486, 0.11014183610677719, 0.0442417748272419, -0.009663608856499195, 0.03533850237727165, -0.02045113407075405, -0.08517273515462875, -0.0117063969373703, 0.047049082815647125] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:500/5550 val_loss:3.557972 train_time:119249ms step_avg:238.50ms x-lambda: 0.9954388737678528 lambdas: [0.06124985218048096, -0.03005203977227211, -0.12471246719360352, -0.18428045511245728, 0.11060718446969986, 0.03698872774839401, -0.01918265037238598, 0.043644681572914124, -0.012904990464448929, -0.1188235729932785, -0.046062834560871124, 0.04777631536126137] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:625/5550 val_loss:3.478860 train_time:149721ms step_avg:239.55ms x-lambda: 0.9853363633155823 lambdas: [0.05237995833158493, -0.02546253241598606, -0.13090312480926514, -0.19043374061584473, 0.10529423505067825, 0.029961325228214264, -0.02460544928908348, 0.044108908623456955, -0.005566081497818232, -0.14095665514469147, -0.08191444724798203, 0.04316987842321396] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:750/5550 val_loss:3.425478 train_time:180526ms step_avg:240.70ms x-lambda: 0.9751339554786682 lambdas: [0.0470486544072628, -0.01968466117978096, -0.13281172513961792, -0.18374763429164886, 0.10006768256425858, 0.026049168780446053, -0.02388586662709713, 0.0446278378367424, 0.0016347765922546387, -0.14840418100357056, -0.110013447701931, 0.04048023745417595] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:875/5550 val_loss:3.381538 train_time:211418ms step_avg:241.62ms x-lambda: 0.9530279636383057 lambdas: [0.042260877788066864, -0.015578048303723335, -0.13399703800678253, -0.17511442303657532, 0.0933198481798172, 0.02206404320895672, -0.021874062716960907, 0.04476131498813629, 0.00667151901870966, -0.1500081568956375, -0.13532641530036926, 0.034989356994628906] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1000/5550 val_loss:3.345557 train_time:242598ms step_avg:242.60ms x-lambda: 0.9341099262237549 lambdas: [0.03851471468806267, -0.01148027554154396, -0.13250412046909332, -0.159497931599617, 0.08477165549993515, 0.019441766664385796, -0.020894376561045647, 0.04119599983096123, 0.009140865877270699, -0.1465049386024475, -0.15752242505550385, 0.03226702660322189] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1125/5550 val_loss:3.316771 train_time:273818ms step_avg:243.39ms x-lambda: 0.9140545725822449 lambdas: [0.03480079025030136, -0.008661137893795967, -0.13197751343250275, -0.14491374790668488, 0.07639895379543304, 0.017286516726017, -0.019409310072660446, 0.03885873034596443, 0.010584782809019089, -0.13982073962688446, -0.17616945505142212, 0.030825471505522728] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1250/5550 val_loss:3.290963 train_time:305181ms step_avg:244.14ms x-lambda: 0.8936848640441895 lambdas: [0.03236733004450798, -0.008142299018800259, -0.13128484785556793, -0.13369207084178925, 0.07011757045984268, 0.015702975913882256, -0.018928220495581627, 0.03598742187023163, 0.012033568695187569, -0.13385702669620514, -0.19081954658031464, 0.029764335602521896] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1375/5550 val_loss:3.272302 train_time:336711ms step_avg:244.88ms x-lambda: 0.8700956702232361 lambdas: [0.028708262369036674, -0.007361015770584345, -0.129287451505661, -0.12160950899124146, 0.06427831947803497, 0.012886548414826393, -0.018620211631059647, 0.03345959633588791, 0.01133864838629961, -0.12936271727085114, -0.20505568385124207, 0.02864730916917324] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1500/5550 val_loss:3.251096 train_time:368195ms step_avg:245.46ms x-lambda: 0.854429304599762 lambdas: [0.028592636808753014, -0.003915905021131039, -0.12519747018814087, -0.11192034184932709, 0.059405867010354996, 0.013850974850356579, -0.01590411737561226, 0.033653851598501205, 0.014220202341675758, -0.1216328963637352, -0.2128984034061432, 0.032425206154584885] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1625/5550 val_loss:3.237217 train_time:399794ms step_avg:246.03ms x-lambda: 0.8347513675689697 lambdas: [0.027426373213529587, -0.0027317791245877743, -0.12186183780431747, -0.10245446860790253, 0.05582988262176514, 0.01279916986823082, -0.014696899801492691, 0.03223905339837074, 0.01487316470593214, -0.11588826030492783, -0.22203834354877472, 0.03383505716919899] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1750/5550 val_loss:3.221067 train_time:431350ms step_avg:246.49ms x-lambda: 0.8139536380767822 lambdas: [0.025751778855919838, -0.0023178118281066418, -0.11992906779050827, -0.09427392482757568, 0.050802599638700485, 0.012055138126015663, -0.015111377462744713, 0.03142200782895088, 0.014994286000728607, -0.11005689948797226, -0.2285982370376587, 0.03467133641242981] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:1875/5550 val_loss:3.202320 train_time:462950ms step_avg:246.91ms x-lambda: 0.7981072664260864 lambdas: [0.024151455610990524, -0.003285949118435383, -0.117392897605896, -0.0890951156616211, 0.045212168246507645, 0.009996957145631313, -0.015782935544848442, 0.03078591078519821, 0.013909040950238705, -0.10701068490743637, -0.2346324771642685, 0.03630585968494415] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2000/5550 val_loss:3.189179 train_time:494746ms step_avg:247.37ms x-lambda: 0.7833550572395325 lambdas: [0.023403225466609, -9.604264050722122e-06, -0.11157100647687912, -0.0818386822938919, 0.044696465134620667, 0.012319907546043396, -0.012394418008625507, 0.029903071001172066, 0.016479013487696648, -0.1011212021112442, -0.23623786866664886, 0.04105913266539574] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2125/5550 val_loss:3.171879 train_time:526612ms step_avg:247.82ms x-lambda: 0.7697469592094421 lambdas: [0.022699739784002304, -0.0015522224130108953, -0.11164159327745438, -0.07869483530521393, 0.04142853990197182, 0.010084068402647972, -0.01455009076744318, 0.026988646015524864, 0.01371681410819292, -0.10004791617393494, -0.23979809880256653, 0.0419045016169548] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2250/5550 val_loss:3.158210 train_time:558490ms step_avg:248.22ms x-lambda: 0.758389413356781 lambdas: [0.02029103972017765, -0.0022697006352245808, -0.10747849196195602, -0.07493121922016144, 0.0376422293484211, 0.00765048386529088, -0.013672726228833199, 0.026532288640737534, 0.013053209520876408, -0.09821690618991852, -0.24183426797389984, 0.04340540990233421] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2375/5550 val_loss:3.146432 train_time:590369ms step_avg:248.58ms x-lambda: 0.7491896748542786 lambdas: [0.02070900984108448, -0.0023291087709367275, -0.10511615872383118, -0.06984122842550278, 0.03581519052386284, 0.007180939428508282, -0.0131254643201828, 0.024921508505940437, 0.01388084702193737, -0.09335853159427643, -0.2434234321117401, 0.04542354494333267] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2500/5550 val_loss:3.134685 train_time:622202ms step_avg:248.88ms x-lambda: 0.7399536371231079 lambdas: [0.02085910551249981, -0.0006122636841610074, -0.10135965049266815, -0.0673566460609436, 0.03530089929699898, 0.008060557767748833, -0.013317256234586239, 0.024812687188386917, 0.01338953711092472, -0.09130973368883133, -0.24359950423240662, 0.046462830156087875] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2625/5550 val_loss:3.123908 train_time:654051ms step_avg:249.16ms x-lambda: 0.7309160232543945 lambdas: [0.019461369141936302, -0.0006114023854024708, -0.09997344017028809, -0.06373743712902069, 0.03305865451693535, 0.00858214870095253, -0.01222823653370142, 0.022797642275691032, 0.013693086802959442, -0.08980486541986465, -0.24476824700832367, 0.04824719950556755] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2750/5550 val_loss:3.112368 train_time:685851ms step_avg:249.40ms x-lambda: 0.7236928939819336 lambdas: [0.018684227019548416, -0.00135273567866534, -0.09842218458652496, -0.06333384662866592, 0.03120269626379013, 0.007344363257288933, -0.011652463115751743, 0.02307310327887535, 0.013371143490076065, -0.08822930604219437, -0.24482542276382446, 0.049114782363176346] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:2875/5550 val_loss:3.103500 train_time:717694ms step_avg:249.63ms x-lambda: 0.7201293110847473 lambdas: [0.019302310422062874, -0.0006194533780217171, -0.09462611377239227, -0.05833011120557785, 0.03222646191716194, 0.007984356954693794, -0.01029451284557581, 0.023796159774065018, 0.013495711609721184, -0.08508077263832092, -0.24465599656105042, 0.05199217051267624] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3000/5550 val_loss:3.091870 train_time:749546ms step_avg:249.85ms x-lambda: 0.7148703336715698 lambdas: [0.017720550298690796, -0.0012902163434773684, -0.0942569226026535, -0.05692256614565849, 0.02977149747312069, 0.007527858484536409, -0.010393882170319557, 0.02223893254995346, 0.012369039468467236, -0.08302715420722961, -0.2444019913673401, 0.05179254338145256] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3125/5550 val_loss:3.081230 train_time:781465ms step_avg:250.07ms x-lambda: 0.7117658853530884 lambdas: [0.017903408035635948, -0.0015484667383134365, -0.09396827220916748, -0.05565602704882622, 0.02847321517765522, 0.00751192681491375, -0.011750513687729836, 0.02127719484269619, 0.012782619334757328, -0.0837429016828537, -0.24600926041603088, 0.05239439755678177] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3250/5550 val_loss:3.069927 train_time:813360ms step_avg:250.26ms x-lambda: 0.7105587124824524 lambdas: [0.017884304746985435, 0.00014292245032265782, -0.09042657166719437, -0.05314569175243378, 0.027309386059641838, 0.006809441838413477, -0.010409384965896606, 0.02163008786737919, 0.012645076029002666, -0.08177337795495987, -0.24393698573112488, 0.054854270070791245] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3375/5550 val_loss:3.060943 train_time:845208ms step_avg:250.43ms x-lambda: 0.7083661556243896 lambdas: [0.017042655497789383, -0.00030216711456887424, -0.08928936719894409, -0.052137840539216995, 0.026810744777321815, 0.005639319773763418, -0.011044795624911785, 0.020105643197894096, 0.013296028599143028, -0.08069851994514465, -0.2455713450908661, 0.05453521013259888] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3500/5550 val_loss:3.053655 train_time:877083ms step_avg:250.60ms x-lambda: 0.7053239941596985 lambdas: [0.015967706218361855, -0.0013363135512918234, -0.08854366838932037, -0.05150953307747841, 0.02508990280330181, 0.00453153345733881, -0.011910125613212585, 0.01972760632634163, 0.012057635933160782, -0.07995662838220596, -0.24560467898845673, 0.05409121885895729] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3625/5550 val_loss:3.043929 train_time:908945ms step_avg:250.74ms x-lambda: 0.706760585308075 lambdas: [0.015883566811680794, -0.0004958832287229598, -0.08790972083806992, -0.049849946051836014, 0.025619493797421455, 0.004882502369582653, -0.010083758272230625, 0.019200431182980537, 0.013944882899522781, -0.07830705493688583, -0.24494652450084686, 0.05677727237343788] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3750/5550 val_loss:3.034019 train_time:940810ms step_avg:250.88ms x-lambda: 0.7044847011566162 lambdas: [0.01649032160639763, -0.0008701665792614222, -0.08590222150087357, -0.0486748181283474, 0.02457265928387642, 0.006838170811533928, -0.010415992699563503, 0.019411906599998474, 0.012457028962671757, -0.0761881023645401, -0.24473489820957184, 0.05647279694676399] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:3875/5550 val_loss:3.025609 train_time:972741ms step_avg:251.03ms x-lambda: 0.710308849811554 lambdas: [0.0165872760117054, -0.0001467802212573588, -0.08392643928527832, -0.04753614962100983, 0.024034010246396065, 0.0063228425569832325, -0.009863268584012985, 0.020278604701161385, 0.013291585259139538, -0.07649194449186325, -0.2446066290140152, 0.05807892605662346] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4000/5550 val_loss:3.015664 train_time:1004637ms step_avg:251.16ms x-lambda: 0.711143434047699 lambdas: [0.016589771956205368, -3.4883152693510056e-05, -0.08344528824090958, -0.0471191480755806, 0.023462830111384392, 0.005418095272034407, -0.00956339668482542, 0.018367458134889603, 0.013150728307664394, -0.07679934054613113, -0.24532537162303925, 0.05840858817100525] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4125/5550 val_loss:3.006504 train_time:1036604ms step_avg:251.30ms x-lambda: 0.7139313220977783 lambdas: [0.016112124547362328, -0.00030117452843114734, -0.082973912358284, -0.04517079144716263, 0.023140564560890198, 0.004856584593653679, -0.009191651828587055, 0.019563399255275726, 0.013159225694835186, -0.07495377957820892, -0.24473172426223755, 0.05931238830089569] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4250/5550 val_loss:2.998451 train_time:1068738ms step_avg:251.47ms x-lambda: 0.7165015339851379 lambdas: [0.015099108219146729, -0.0006236416520550847, -0.08125931769609451, -0.04538142308592796, 0.02357354760169983, 0.0057280296459794044, -0.007871962152421474, 0.01982744410634041, 0.013153993524610996, -0.07421822845935822, -0.24483975768089294, 0.06000608578324318] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4375/5550 val_loss:2.989219 train_time:1100892ms step_avg:251.63ms x-lambda: 0.7186375260353088 lambdas: [0.015847671777009964, -0.0008182519813999534, -0.0821247473359108, -0.045646607875823975, 0.02308204025030136, 0.00548962689936161, -0.00803480576723814, 0.017589759081602097, 0.012475941330194473, -0.07436446845531464, -0.24666878581047058, 0.05915629491209984] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4500/5550 val_loss:2.981145 train_time:1133104ms step_avg:251.80ms x-lambda: 0.7236685156822205 lambdas: [0.015114163979887962, -0.0004100783262401819, -0.08101360499858856, -0.04461558163166046, 0.02129937708377838, 0.0045938934199512005, -0.00945340283215046, 0.0183314960449934, 0.011828715912997723, -0.07359769940376282, -0.24734880030155182, 0.059737298637628555] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4625/5550 val_loss:2.971545 train_time:1165472ms step_avg:251.99ms x-lambda: 0.729393720626831 lambdas: [0.014118318445980549, 0.0003445034089963883, -0.07968863099813461, -0.04384216293692589, 0.022132690995931625, 0.0044187093153595924, -0.008617023006081581, 0.018044983968138695, 0.012821916490793228, -0.07329206168651581, -0.24691568315029144, 0.06050756946206093] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4750/5550 val_loss:2.962524 train_time:1197929ms step_avg:252.20ms x-lambda: 0.7352622747421265 lambdas: [0.016265179961919785, 0.0008166895713657141, -0.07914270460605621, -0.04350437968969345, 0.02148590236902237, 0.005749910604208708, -0.009264660999178886, 0.019356219097971916, 0.012160984799265862, -0.07410455495119095, -0.2470097839832306, 0.06152265518903732] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:4875/5550 val_loss:2.953500 train_time:1230563ms step_avg:252.42ms x-lambda: 0.7398831248283386 lambdas: [0.015051059424877167, 0.0007276458782143891, -0.0780324786901474, -0.04320473596453667, 0.02121378853917122, 0.0051615177653729916, -0.008939756080508232, 0.01749204844236374, 0.011741535738110542, -0.07320340722799301, -0.24851197004318237, 0.0617787130177021] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5000/5550 val_loss:2.945689 train_time:1263291ms step_avg:252.66ms x-lambda: 0.7465217709541321 lambdas: [0.01483198069036007, 0.001041223993524909, -0.078072190284729, -0.04171288013458252, 0.0211471077054739, 0.0043822661973536015, -0.009134232066571712, 0.01747194305062294, 0.011421747505664825, -0.07368956506252289, -0.2492513209581375, 0.0622531957924366] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5125/5550 val_loss:2.937950 train_time:1296171ms step_avg:252.91ms x-lambda: 0.7525384426116943 lambdas: [0.015016418881714344, 0.00034009048249572515, -0.07751038670539856, -0.041052039712667465, 0.021257098764181137, 0.004990074317902327, -0.009632745757699013, 0.017865590751171112, 0.012100040912628174, -0.07288447767496109, -0.25140663981437683, 0.0632554367184639] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5250/5550 val_loss:2.930673 train_time:1329255ms step_avg:253.19ms x-lambda: 0.7573505640029907 lambdas: [0.014657175168395042, 0.0006499022711068392, -0.07775113731622696, -0.039942916482686996, 0.020909182727336884, 0.003436014521867037, -0.0074764941819012165, 0.017301611602306366, 0.011261185631155968, -0.07367313653230667, -0.25071385502815247, 0.06388299912214279] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5375/5550 val_loss:2.924241 train_time:1362449ms step_avg:253.48ms x-lambda: 0.7635093331336975 lambdas: [0.015092132613062859, 6.699519872199744e-05, -0.0774153545498848, -0.04014989361166954, 0.02153993956744671, 0.004342182073742151, -0.008713208138942719, 0.01695823110640049, 0.011149246245622635, -0.07331252098083496, -0.2516493499279022, 0.064211905002594] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5500/5550 val_loss:2.919476 train_time:1395913ms step_avg:253.80ms x-lambda: 0.7670972943305969 lambdas: [0.014490647241473198, -0.00011583330342546105, -0.07703445851802826, -0.04091399908065796, 0.021165946498513222, 0.0034325227607041597, -0.008207971230149269, 0.016531730070710182, 0.010585031472146511, -0.07339281588792801, -0.25254565477371216, 0.06444093585014343] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
step:5550/5550 val_loss:2.918282 train_time:1409373ms step_avg:253.94ms x-lambda: 0.7682225704193115 lambdas: [0.014319498091936111, 0.0001627299061510712, -0.07713811099529266, -0.04046451300382614, 0.021294312551617622, 0.003518252167850733, -0.007846128195524216, 0.016427120193839073, 0.010830270126461983, -0.07363034784793854, -0.25273260474205017, 0.06482144445180893] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]



## 8000-add-skip-multiple-12-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.21ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:125/5550 val_loss:4.258174 train_time:30117ms step_avg:240.93ms x-lambda: 1.0517148971557617 lambdas: [0.01841561868786812, 0.039066825062036514, 0.019915178418159485, -0.0013496519532054663, 0.045409977436065674, 0.019741492345929146, 0.00868647638708353, 0.025065941736102104, 0.01729065738618374, 0.010651479475200176, -0.0006090190727263689, 0.0024220235645771027] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:250/5550 val_loss:3.849191 train_time:60343ms step_avg:241.37ms x-lambda: 1.0975075960159302 lambdas: [-0.0014055613428354263, 0.019747046753764153, -0.004813253879547119, -0.005220841150730848, 0.019996633753180504, -0.00423826090991497, -0.012607418932020664, 0.002434257883578539, 0.0009471429511904716, -0.017270028591156006, -0.019435524940490723, -0.005228834226727486] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:375/5550 val_loss:3.671889 train_time:91085ms step_avg:242.89ms x-lambda: 1.1105983257293701 lambdas: [-0.017863048240542412, -0.008893517777323723, -0.021453343331813812, -0.005955277010798454, -0.007885472849011421, -0.017363054677844048, -0.01914643682539463, -0.018494604155421257, -0.01008620671927929, -0.026547592133283615, -0.024864045903086662, -0.012525631114840508] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:500/5550 val_loss:3.557173 train_time:122062ms step_avg:244.12ms x-lambda: 1.0939310789108276 lambdas: [-0.023192014545202255, -0.020517297089099884, -0.027547677978873253, -0.007294746581465006, -0.020390821620821953, -0.025351153686642647, -0.024706164374947548, -0.026023738086223602, -0.01538829691708088, -0.03083505481481552, -0.028783131390810013, -0.017969468608498573] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:625/5550 val_loss:3.480755 train_time:153272ms step_avg:245.24ms x-lambda: 1.0598232746124268 lambdas: [-0.027162760496139526, -0.02337670885026455, -0.028711551800370216, -0.00640312023460865, -0.023821385577321053, -0.02793959528207779, -0.028442634269595146, -0.029696406796574593, -0.017367713153362274, -0.03525495156645775, -0.031190156936645508, -0.022201992571353912] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:750/5550 val_loss:3.426450 train_time:184909ms step_avg:246.55ms x-lambda: 1.0205504894256592 lambdas: [-0.027910690754652023, -0.026269493624567986, -0.030776413157582283, -0.009613335132598877, -0.025494543835520744, -0.028109103441238403, -0.03042753040790558, -0.030591214075684547, -0.019007427617907524, -0.036643076688051224, -0.02973918244242668, -0.024938471615314484] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:875/5550 val_loss:3.381719 train_time:216664ms step_avg:247.62ms x-lambda: 0.9726166725158691 lambdas: [-0.02756236121058464, -0.026554200798273087, -0.030084244906902313, -0.009448543190956116, -0.025137953460216522, -0.02834269031882286, -0.0322493240237236, -0.02980765514075756, -0.019097015261650085, -0.03628384321928024, -0.030494431033730507, -0.0247577466070652] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1000/5550 val_loss:3.346303 train_time:248566ms step_avg:248.57ms x-lambda: 0.9319359064102173 lambdas: [-0.023926911875605583, -0.024212436750531197, -0.026612741872668266, -0.008939610794186592, -0.024022985249757767, -0.025695743039250374, -0.02905302681028843, -0.02836190164089203, -0.017891738563776016, -0.03309019282460213, -0.026333751156926155, -0.02293064258992672] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1125/5550 val_loss:3.318319 train_time:280512ms step_avg:249.34ms x-lambda: 0.8905961513519287 lambdas: [-0.025852998718619347, -0.025394927710294724, -0.0261142048984766, -0.010453867726027966, -0.02485479600727558, -0.02648327127099037, -0.029437946155667305, -0.02846594713628292, -0.019559163600206375, -0.03357546031475067, -0.027613284066319466, -0.024515558034181595] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1250/5550 val_loss:3.291415 train_time:312552ms step_avg:250.04ms x-lambda: 0.8548438549041748 lambdas: [-0.022186225280165672, -0.023312708362936974, -0.022711556404829025, -0.008272862061858177, -0.022087056189775467, -0.02400144375860691, -0.026859721168875694, -0.024762410670518875, -0.017557790502905846, -0.029839204624295235, -0.024684838950634003, -0.021320872008800507] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1375/5550 val_loss:3.270948 train_time:344869ms step_avg:250.81ms x-lambda: 0.8210378885269165 lambdas: [-0.021693579852581024, -0.023001141846179962, -0.021311135962605476, -0.008373604156076908, -0.02080170437693596, -0.02371508628129959, -0.02692924253642559, -0.023154888302087784, -0.017479265108704567, -0.030837928876280785, -0.02270928956568241, -0.021457966417074203] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1500/5550 val_loss:3.253789 train_time:377150ms step_avg:251.43ms x-lambda: 0.7930854558944702 lambdas: [-0.020788567140698433, -0.023481836542487144, -0.021852729842066765, -0.008522172458469868, -0.02023223042488098, -0.022399693727493286, -0.027127183973789215, -0.0228889137506485, -0.017403366044163704, -0.028905585408210754, -0.022222265601158142, -0.02060386911034584] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1625/5550 val_loss:3.235893 train_time:409580ms step_avg:252.05ms x-lambda: 0.7668260335922241 lambdas: [-0.01959630474448204, -0.020510653033852577, -0.019359685480594635, -0.006819410715252161, -0.019166579470038414, -0.020389782264828682, -0.02345552295446396, -0.02117125876247883, -0.01593942940235138, -0.02681746706366539, -0.019474035128951073, -0.01831977814435959] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1750/5550 val_loss:3.220573 train_time:441877ms step_avg:252.50ms x-lambda: 0.7435416579246521 lambdas: [-0.019897090271115303, -0.020475959405303, -0.019061049446463585, -0.006514240056276321, -0.01723363623023033, -0.020098377019166946, -0.023526806384325027, -0.020567886531352997, -0.014270013198256493, -0.025936372578144073, -0.019265148788690567, -0.01746782660484314] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:1875/5550 val_loss:3.205585 train_time:474227ms step_avg:252.92ms x-lambda: 0.7267407774925232 lambdas: [-0.015181982889771461, -0.016904989257454872, -0.015985533595085144, -0.005558807402849197, -0.015574668534100056, -0.01763070933520794, -0.020535655319690704, -0.017463501542806625, -0.012549546547234058, -0.023289106786251068, -0.016323260962963104, -0.015674080699682236] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2000/5550 val_loss:3.187264 train_time:506756ms step_avg:253.38ms x-lambda: 0.706368088722229 lambdas: [-0.016760341823101044, -0.019589995965361595, -0.01680827885866165, -0.007755656260997057, -0.016809510067105293, -0.018171003088355064, -0.020717468112707138, -0.019332313910126686, -0.01548202708363533, -0.02419092133641243, -0.017339395359158516, -0.016444800421595573] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2125/5550 val_loss:3.171844 train_time:539231ms step_avg:253.76ms x-lambda: 0.6947754621505737 lambdas: [-0.016356782987713814, -0.017457859590649605, -0.01577416993677616, -0.006748115178197622, -0.01581660658121109, -0.017658110707998276, -0.02196577936410904, -0.018113650381565094, -0.013929951004683971, -0.023179924115538597, -0.016802795231342316, -0.015996426343917847] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2250/5550 val_loss:3.158277 train_time:571770ms step_avg:254.12ms x-lambda: 0.6821509599685669 lambdas: [-0.015541428700089455, -0.01798909902572632, -0.015463516116142273, -0.0076050120405852795, -0.016867998987436295, -0.017564725130796432, -0.02096928097307682, -0.017694924026727676, -0.014014306478202343, -0.022928452119231224, -0.015560916624963284, -0.01603003405034542] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2375/5550 val_loss:3.146986 train_time:604188ms step_avg:254.40ms x-lambda: 0.6724713444709778 lambdas: [-0.015313775278627872, -0.016992561519145966, -0.015672387555241585, -0.006470191292464733, -0.016024183481931686, -0.016765136271715164, -0.020212147384881973, -0.015785466879606247, -0.013198168016970158, -0.020786287263035774, -0.015032694675028324, -0.0154911819845438] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2500/5550 val_loss:3.137039 train_time:636649ms step_avg:254.66ms x-lambda: 0.6660770773887634 lambdas: [-0.012649092823266983, -0.015580646693706512, -0.013413604348897934, -0.005369828548282385, -0.013631773181259632, -0.015184355899691582, -0.01847534067928791, -0.01383827906101942, -0.012200361117720604, -0.01965962164103985, -0.013327863067388535, -0.013924489729106426] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2625/5550 val_loss:3.123806 train_time:669103ms step_avg:254.90ms x-lambda: 0.6570873260498047 lambdas: [-0.014651317149400711, -0.016891328617930412, -0.014951001852750778, -0.006058825179934502, -0.01554455328732729, -0.017229584977030754, -0.019583282992243767, -0.016688037663698196, -0.012765800580382347, -0.021183663979172707, -0.014806057326495647, -0.01544952392578125] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2750/5550 val_loss:3.112023 train_time:701555ms step_avg:255.11ms x-lambda: 0.6527191400527954 lambdas: [-0.013739409856498241, -0.01559701282531023, -0.01382373832166195, -0.006466049235314131, -0.01442521158605814, -0.01630912721157074, -0.01901307702064514, -0.014398917555809021, -0.013068211264908314, -0.019256893545389175, -0.013194872066378593, -0.013763277791440487] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:2875/5550 val_loss:3.103368 train_time:734111ms step_avg:255.34ms x-lambda: 0.6480101346969604 lambdas: [-0.012485855259001255, -0.015323420986533165, -0.012087378650903702, -0.005920101888477802, -0.012461153790354729, -0.015626342967152596, -0.01799594610929489, -0.013182457536458969, -0.012561038136482239, -0.019787972792983055, -0.012258620001375675, -0.013147708028554916] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3000/5550 val_loss:3.093715 train_time:766615ms step_avg:255.54ms x-lambda: 0.6467409729957581 lambdas: [-0.012439105659723282, -0.013908459804952145, -0.013296404853463173, -0.003931527957320213, -0.0120211411267519, -0.013807713985443115, -0.01653999090194702, -0.013463067822158337, -0.011190432123839855, -0.017864538356661797, -0.012111486867070198, -0.012082520872354507] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3125/5550 val_loss:3.082206 train_time:799183ms step_avg:255.74ms x-lambda: 0.641219437122345 lambdas: [-0.013697946444153786, -0.016581380739808083, -0.013773654587566853, -0.007164134178310633, -0.014859347604215145, -0.01626051403582096, -0.018759578466415405, -0.014930695295333862, -0.013447009958326817, -0.020536869764328003, -0.013205889612436295, -0.014602482318878174] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3250/5550 val_loss:3.070042 train_time:831700ms step_avg:255.91ms x-lambda: 0.6421456336975098 lambdas: [-0.011955708265304565, -0.015054754912853241, -0.01296556182205677, -0.005903737153857946, -0.013794018886983395, -0.014847894199192524, -0.01743030734360218, -0.01411927118897438, -0.011457826942205429, -0.018028516322374344, -0.012921462766826153, -0.012660127133131027] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3375/5550 val_loss:3.061884 train_time:864142ms step_avg:256.04ms x-lambda: 0.6410137414932251 lambdas: [-0.013049541972577572, -0.015313012525439262, -0.014077235944569111, -0.0060998741537332535, -0.014220992103219032, -0.013979579322040081, -0.01809307374060154, -0.013964906334877014, -0.01103474572300911, -0.019095472991466522, -0.012539856135845184, -0.013833284378051758] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3500/5550 val_loss:3.053340 train_time:896610ms step_avg:256.17ms x-lambda: 0.6386925578117371 lambdas: [-0.012954793870449066, -0.014684964902698994, -0.013536612503230572, -0.006297783460468054, -0.014777914620935917, -0.01567925326526165, -0.017038878053426743, -0.014047008007764816, -0.01298556849360466, -0.01899051107466221, -0.012119755148887634, -0.012297960929572582] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3625/5550 val_loss:3.043510 train_time:929104ms step_avg:256.30ms x-lambda: 0.6409903168678284 lambdas: [-0.012507524341344833, -0.014504035003483295, -0.011921900324523449, -0.005541613791137934, -0.01326331403106451, -0.014384481124579906, -0.016811201348900795, -0.013620097190141678, -0.011485964059829712, -0.01724942959845066, -0.01216921303421259, -0.013254828751087189] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3750/5550 val_loss:3.034370 train_time:961609ms step_avg:256.43ms x-lambda: 0.6411795616149902 lambdas: [-0.011090073734521866, -0.01371060311794281, -0.011556370183825493, -0.004089904949069023, -0.013147003017365932, -0.013345396146178246, -0.017019838094711304, -0.013634519651532173, -0.011296091601252556, -0.017629582434892654, -0.011336718685925007, -0.013206695206463337] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:3875/5550 val_loss:3.025323 train_time:994121ms step_avg:256.55ms x-lambda: 0.6469079852104187 lambdas: [-0.012003705836832523, -0.013597872108221054, -0.012348432093858719, -0.005886727944016457, -0.013659213669598103, -0.013385813683271408, -0.016693804413080215, -0.012668881565332413, -0.011267849244177341, -0.01676599308848381, -0.011115220375359058, -0.01143844798207283] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4000/5550 val_loss:3.015923 train_time:1026563ms step_avg:256.64ms x-lambda: 0.6491590142250061 lambdas: [-0.012153207324445248, -0.013774871826171875, -0.012815259397029877, -0.005013701971620321, -0.012382333166897297, -0.013439737260341644, -0.0164616908878088, -0.012542326003313065, -0.011772043071687222, -0.017540467903017998, -0.011202190071344376, -0.011759394779801369] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4125/5550 val_loss:3.006819 train_time:1059133ms step_avg:256.76ms x-lambda: 0.6523382067680359 lambdas: [-0.010437938384711742, -0.013635678216814995, -0.010750038549304008, -0.00416822824627161, -0.012762698344886303, -0.013396244496107101, -0.016442716121673584, -0.012738168239593506, -0.010562547482550144, -0.01667489856481552, -0.010761800222098827, -0.012583245523273945] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4250/5550 val_loss:2.998514 train_time:1091900ms step_avg:256.92ms x-lambda: 0.6565006971359253 lambdas: [-0.010942133143544197, -0.013321338221430779, -0.01229892298579216, -0.004682482220232487, -0.012738310731947422, -0.0127493254840374, -0.016887595877051353, -0.01220308430492878, -0.010224442929029465, -0.015280406922101974, -0.010359860956668854, -0.011644038371741772] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4375/5550 val_loss:2.989480 train_time:1124617ms step_avg:257.06ms x-lambda: 0.6596809029579163 lambdas: [-0.011671727523207664, -0.014094723388552666, -0.012255802750587463, -0.005711431615054607, -0.01327123399823904, -0.012843060307204723, -0.017881928011775017, -0.012935508042573929, -0.011204048059880733, -0.01720171794295311, -0.011289319954812527, -0.011653202585875988] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4500/5550 val_loss:2.980945 train_time:1157526ms step_avg:257.23ms x-lambda: 0.6650567650794983 lambdas: [-0.010139722377061844, -0.013724833726882935, -0.010796456597745419, -0.004431614186614752, -0.01324346475303173, -0.013436904177069664, -0.01640285737812519, -0.012903300113976002, -0.011052804999053478, -0.016325604170560837, -0.011466625146567822, -0.011403256095945835] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4625/5550 val_loss:2.972053 train_time:1190350ms step_avg:257.37ms x-lambda: 0.6720141172409058 lambdas: [-0.012444006279110909, -0.01365654543042183, -0.011080271564424038, -0.005353104788810015, -0.013941565528512001, -0.014585647732019424, -0.018526313826441765, -0.011378017254173756, -0.01251636166125536, -0.016421813517808914, -0.01197934988886118, -0.01171688362956047] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4750/5550 val_loss:2.962613 train_time:1223447ms step_avg:257.57ms x-lambda: 0.6766049265861511 lambdas: [-0.010103321634232998, -0.013430334627628326, -0.010786126367747784, -0.004629699978977442, -0.012186423875391483, -0.012661411426961422, -0.01591259054839611, -0.011377683840692043, -0.00947040319442749, -0.015608278103172779, -0.010097821243107319, -0.010590792633593082] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:4875/5550 val_loss:2.953675 train_time:1256606ms step_avg:257.77ms x-lambda: 0.6828399300575256 lambdas: [-0.010945777408778667, -0.013729272410273552, -0.011332692578434944, -0.004681003745645285, -0.013168076053261757, -0.012880679219961166, -0.015674302354454994, -0.01238599419593811, -0.01056116446852684, -0.016534704715013504, -0.009929551742970943, -0.011469143442809582] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5000/5550 val_loss:2.945486 train_time:1289781ms step_avg:257.96ms x-lambda: 0.6899116039276123 lambdas: [-0.00985751859843731, -0.012941930443048477, -0.01126506645232439, -0.004777389112859964, -0.01244779210537672, -0.012799571268260479, -0.015743127092719078, -0.011198529042303562, -0.010350054129958153, -0.017060397192835808, -0.009623110294342041, -0.011309805326163769] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5125/5550 val_loss:2.937824 train_time:1323199ms step_avg:258.19ms x-lambda: 0.697182834148407 lambdas: [-0.01087848749011755, -0.012270519509911537, -0.010743632912635803, -0.0043516322039067745, -0.013364621438086033, -0.012660856358706951, -0.016380930319428444, -0.011471757665276527, -0.01059188973158598, -0.015770208090543747, -0.010141363367438316, -0.01102473959326744] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5250/5550 val_loss:2.930630 train_time:1356651ms step_avg:258.41ms x-lambda: 0.7032735347747803 lambdas: [-0.009755647741258144, -0.0133462930098176, -0.011172509752213955, -0.0045425305142998695, -0.012067077681422234, -0.012124568223953247, -0.01568242907524109, -0.011819025501608849, -0.010444247163832188, -0.01599959470331669, -0.010023647919297218, -0.011293623596429825] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5375/5550 val_loss:2.924257 train_time:1390312ms step_avg:258.66ms x-lambda: 0.7101746201515198 lambdas: [-0.0098775839433074, -0.01294516958296299, -0.010851094499230385, -0.004614191595464945, -0.01317529659718275, -0.01252203993499279, -0.015972457826137543, -0.011493029072880745, -0.01083552185446024, -0.01648855209350586, -0.009592779912054539, -0.0108057064935565] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5500/5550 val_loss:2.919476 train_time:1424154ms step_avg:258.94ms x-lambda: 0.7157873511314392 lambdas: [-0.010574241168797016, -0.013125421479344368, -0.010858696885406971, -0.004469965118914843, -0.012929313816130161, -0.012531610205769539, -0.015879612416028976, -0.011576003395020962, -0.010770781897008419, -0.015698477625846863, -0.010447561740875244, -0.010924717411398888] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]
step:5550/5550 val_loss:2.918251 train_time:1437780ms step_avg:259.06ms x-lambda: 0.7169909477233887 lambdas: [-0.010318168438971043, -0.01290309987962246, -0.011421073228120804, -0.004439297132194042, -0.012629259377717972, -0.01237431075423956, -0.016338640823960304, -0.01189944613724947, -0.01067616231739521, -0.016034439206123352, -0.010297694243490696, -0.010854290798306465] skip-layers: [12, 4, 0, 1, 8, 14, 9, 6, 5, 3, 13, 2]



## 8000-add-skip-multiple-12-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.22ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:125/5550 val_loss:4.257257 train_time:29385ms step_avg:235.08ms x-lambda: 1.022711157798767 lambdas: [0.00812924187630415, -0.04110174626111984, 0.02433527633547783, 0.01808595284819603, 0.02730458788573742, 0.04375927150249481, 0.024801814928650856, 0.07504966109991074, 0.022350355982780457, -0.04890403896570206, 0.020685099065303802, 0.06464329361915588] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:250/5550 val_loss:3.857757 train_time:58938ms step_avg:235.75ms x-lambda: 0.9953467845916748 lambdas: [-0.015512656420469284, -0.10279598832130432, 0.02560013346374035, 0.012219304218888283, 0.011832175776362419, 0.05556199327111244, 0.027952874079346657, 0.07091709971427917, 0.025063350796699524, -0.13179072737693787, -0.038177069276571274, 0.11483879387378693] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:375/5550 val_loss:3.675818 train_time:88962ms step_avg:237.23ms x-lambda: 0.9851171970367432 lambdas: [-0.015704605728387833, -0.12225422263145447, 0.02780786156654358, 0.011203105561435223, -0.009764646179974079, 0.04351692646741867, 0.023725012317299843, 0.05974297598004341, 0.025604533031582832, -0.17818474769592285, -0.10205953568220139, 0.11988840252161026] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:500/5550 val_loss:3.563743 train_time:119274ms step_avg:238.55ms x-lambda: 0.9857177734375 lambdas: [-0.007149588782340288, -0.12538208067417145, 0.037322886288166046, 0.008526060730218887, -0.01816594786942005, 0.037981074303388596, 0.01710132136940956, 0.05346960201859474, 0.023962177336215973, -0.19814950227737427, -0.14418530464172363, 0.11749176681041718] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:625/5550 val_loss:3.482912 train_time:149812ms step_avg:239.70ms x-lambda: 0.9792842864990234 lambdas: [-8.55510588735342e-05, -0.12546522915363312, 0.04317592456936836, 0.0007120729424059391, -0.02222592756152153, 0.033666979521512985, 0.004674101248383522, 0.04755106568336487, 0.016863876953721046, -0.20544469356536865, -0.17387592792510986, 0.11121320724487305] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:750/5550 val_loss:3.428520 train_time:180610ms step_avg:240.81ms x-lambda: 0.9711581468582153 lambdas: [0.001162758213467896, -0.1268542855978012, 0.044022999703884125, -0.009018444456160069, -0.026148531585931778, 0.0281640887260437, -0.009987090714275837, 0.03902681916952133, 0.007236213888972998, -0.20483995974063873, -0.19109028577804565, 0.10027758777141571] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:875/5550 val_loss:3.382824 train_time:211558ms step_avg:241.78ms x-lambda: 0.9616276025772095 lambdas: [0.005380226299166679, -0.12296431511640549, 0.04427836462855339, -0.017790164798498154, -0.026857687160372734, 0.024934975430369377, -0.02366897091269493, 0.03553235903382301, -0.0011124159209430218, -0.19551289081573486, -0.20033594965934753, 0.09207502007484436] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1000/5550 val_loss:3.348127 train_time:242788ms step_avg:242.79ms x-lambda: 0.9545817971229553 lambdas: [0.00971931777894497, -0.11582420766353607, 0.04528180882334709, -0.023091282695531845, -0.02514413744211197, 0.02434270642697811, -0.033909328281879425, 0.034170497208833694, -0.006817154120653868, -0.1806483268737793, -0.20209833979606628, 0.08499312400817871] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1125/5550 val_loss:3.318665 train_time:274072ms step_avg:243.62ms x-lambda: 0.9438774585723877 lambdas: [0.008251703344285488, -0.11322883516550064, 0.04272783175110817, -0.03308172523975372, -0.02613179013133049, 0.0203861016780138, -0.04779978469014168, 0.028399519622325897, -0.016743306070566177, -0.16926774382591248, -0.20472604036331177, 0.07324332743883133] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1250/5550 val_loss:3.292581 train_time:305479ms step_avg:244.38ms x-lambda: 0.9382949471473694 lambdas: [0.009986533783376217, -0.10811907052993774, 0.04352204501628876, -0.03817681968212128, -0.023995498195290565, 0.020948214456439018, -0.05798960477113724, 0.027729306370019913, -0.0226745642721653, -0.15508969128131866, -0.20270714163780212, 0.06613176316022873] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1375/5550 val_loss:3.272088 train_time:337019ms step_avg:245.10ms x-lambda: 0.9293732047080994 lambdas: [0.009352455846965313, -0.1043238565325737, 0.04076376184821129, -0.044561631977558136, -0.024647412821650505, 0.017920207232236862, -0.06900744885206223, 0.024769049137830734, -0.030098140239715576, -0.14280781149864197, -0.20138253271579742, 0.05803631246089935] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1500/5550 val_loss:3.253458 train_time:368503ms step_avg:245.67ms x-lambda: 0.9245108962059021 lambdas: [0.011007633060216904, -0.09917307645082474, 0.04162661358714104, -0.04862363263964653, -0.022090628743171692, 0.018091842532157898, -0.07738931477069855, 0.024803154170513153, -0.03507028892636299, -0.13152162730693817, -0.19771715998649597, 0.05193639174103737] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1625/5550 val_loss:3.239424 train_time:400062ms step_avg:246.19ms x-lambda: 0.9182015061378479 lambdas: [0.011440539732575417, -0.09538543224334717, 0.04120955243706703, -0.053070809692144394, -0.020841050893068314, 0.018456656485795975, -0.0849318653345108, 0.024641532450914383, -0.03988029435276985, -0.12101276963949203, -0.19439107179641724, 0.04885801672935486] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1750/5550 val_loss:3.222770 train_time:431643ms step_avg:246.65ms x-lambda: 0.9099675416946411 lambdas: [0.010294556617736816, -0.09206727147102356, 0.040756821632385254, -0.05992196500301361, -0.02073710784316063, 0.016918323934078217, -0.09432829916477203, 0.02206612378358841, -0.047417495399713516, -0.11241451650857925, -0.18811637163162231, 0.04086913913488388] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:1875/5550 val_loss:3.204454 train_time:463266ms step_avg:247.07ms x-lambda: 0.9072498679161072 lambdas: [0.010695389471948147, -0.08799390494823456, 0.04000388830900192, -0.061683498322963715, -0.019047681242227554, 0.016450785100460052, -0.09818922728300095, 0.022994650527834892, -0.05033735930919647, -0.10385189950466156, -0.18459023535251617, 0.038543786853551865] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2000/5550 val_loss:3.187694 train_time:495080ms step_avg:247.54ms x-lambda: 0.9007836580276489 lambdas: [0.009606657549738884, -0.08611107617616653, 0.0376589410007, -0.0672217309474945, -0.02065931260585785, 0.015837807208299637, -0.10522904247045517, 0.019826868548989296, -0.05619702860713005, -0.09833995997905731, -0.1814112365245819, 0.03296712785959244] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2125/5550 val_loss:3.173562 train_time:526967ms step_avg:247.98ms x-lambda: 0.8971651792526245 lambdas: [0.008755375631153584, -0.0838715136051178, 0.036280740052461624, -0.07030106335878372, -0.021638453006744385, 0.01342335157096386, -0.11081089079380035, 0.018073519691824913, -0.06063727289438248, -0.09300152212381363, -0.17942743003368378, 0.02894236147403717] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2250/5550 val_loss:3.157885 train_time:558844ms step_avg:248.38ms x-lambda: 0.8945896029472351 lambdas: [0.008950703777372837, -0.08076464384794235, 0.036571111530065536, -0.07240023463964462, -0.019284220412373543, 0.014144002459943295, -0.11357118934392929, 0.018919186666607857, -0.0638873353600502, -0.0878346636891365, -0.17458491027355194, 0.02722802385687828] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2375/5550 val_loss:3.147276 train_time:590768ms step_avg:248.74ms x-lambda: 0.8920064568519592 lambdas: [0.009376130998134613, -0.0778682753443718, 0.03430389240384102, -0.07414635270833969, -0.01867743209004402, 0.013068259693682194, -0.11635881662368774, 0.017883654683828354, -0.06679949164390564, -0.08211930096149445, -0.17117996513843536, 0.025261152535676956] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2500/5550 val_loss:3.136490 train_time:622652ms step_avg:249.06ms x-lambda: 0.8904216885566711 lambdas: [0.010984539985656738, -0.07449240237474442, 0.03400202840566635, -0.07545308023691177, -0.019076429307460785, 0.013367950916290283, -0.11849832534790039, 0.018400929868221283, -0.06897646188735962, -0.07770735770463943, -0.16633367538452148, 0.025159278884530067] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2625/5550 val_loss:3.123741 train_time:654528ms step_avg:249.34ms x-lambda: 0.8861753940582275 lambdas: [0.008373362943530083, -0.07313638180494308, 0.03421541303396225, -0.07772035896778107, -0.019329382106661797, 0.012388589791953564, -0.12263656407594681, 0.01532054040580988, -0.07292012125253677, -0.07486223429441452, -0.1657964289188385, 0.021487658843398094] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2750/5550 val_loss:3.112949 train_time:686348ms step_avg:249.58ms x-lambda: 0.8838950395584106 lambdas: [0.008574041537940502, -0.07033433020114899, 0.033468879759311676, -0.07954323291778564, -0.018160972744226456, 0.012549210339784622, -0.12513914704322815, 0.015504197217524052, -0.07578076422214508, -0.07218869030475616, -0.16168354451656342, 0.02171977236866951] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:2875/5550 val_loss:3.103730 train_time:718252ms step_avg:249.83ms x-lambda: 0.8832727074623108 lambdas: [0.009094336070120335, -0.06821314245462418, 0.03375844284892082, -0.08058135211467743, -0.018156446516513824, 0.011903534643352032, -0.12518584728240967, 0.016770020127296448, -0.0776311531662941, -0.06843338161706924, -0.15948615968227386, 0.020309196785092354] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3000/5550 val_loss:3.093570 train_time:750103ms step_avg:250.03ms x-lambda: 0.8821001648902893 lambdas: [0.008172302506864071, -0.06798557937145233, 0.03148269280791283, -0.08168052136898041, -0.01787378638982773, 0.010906345210969448, -0.12832239270210266, 0.011977149173617363, -0.08093027025461197, -0.06840191781520844, -0.15735489130020142, 0.017274029552936554] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3125/5550 val_loss:3.081776 train_time:782038ms step_avg:250.25ms x-lambda: 0.8819799423217773 lambdas: [0.008805218152701855, -0.06816346198320389, 0.03244252875447273, -0.0830409973859787, -0.017565416172146797, 0.011661785654723644, -0.12766911089420319, 0.015437556430697441, -0.08242938667535782, -0.06553944945335388, -0.15527747571468353, 0.01755766198039055] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3250/5550 val_loss:3.070414 train_time:813941ms step_avg:250.44ms x-lambda: 0.88362056016922 lambdas: [0.00847784522920847, -0.06453754752874374, 0.0310702845454216, -0.08256407082080841, -0.01731850765645504, 0.011018780060112476, -0.1285182237625122, 0.013845465146005154, -0.08338422328233719, -0.06232127547264099, -0.15409977734088898, 0.015737146139144897] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3375/5550 val_loss:3.062966 train_time:845828ms step_avg:250.62ms x-lambda: 0.8841481804847717 lambdas: [0.007294178009033203, -0.06453431397676468, 0.03093061037361622, -0.08374301344156265, -0.01721358112990856, 0.010545521043241024, -0.12979017198085785, 0.01389968954026699, -0.08538059890270233, -0.06407447159290314, -0.15262466669082642, 0.017451947554945946] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3500/5550 val_loss:3.053132 train_time:877741ms step_avg:250.78ms x-lambda: 0.8835301399230957 lambdas: [0.008321181870996952, -0.06295683234930038, 0.029993951320648193, -0.0844736099243164, -0.017606306821107864, 0.008840828202664852, -0.1302516609430313, 0.013700392097234726, -0.08784037083387375, -0.059706829488277435, -0.14983902871608734, 0.01480239350348711] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3625/5550 val_loss:3.044287 train_time:909599ms step_avg:250.92ms x-lambda: 0.886695146560669 lambdas: [0.008480754680931568, -0.06074997037649155, 0.030004136264324188, -0.08317006379365921, -0.01620713248848915, 0.009188628755509853, -0.13010171055793762, 0.013193352147936821, -0.0887288749217987, -0.05896240472793579, -0.14658045768737793, 0.015793293714523315] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3750/5550 val_loss:3.035098 train_time:941521ms step_avg:251.07ms x-lambda: 0.8868282437324524 lambdas: [0.007768596988171339, -0.060663435608148575, 0.030061107128858566, -0.08351664245128632, -0.015859821811318398, 0.010081141255795956, -0.1319926679134369, 0.01370866410434246, -0.09065855294466019, -0.05721798539161682, -0.1451864242553711, 0.014387746341526508] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:3875/5550 val_loss:3.025737 train_time:973495ms step_avg:251.22ms x-lambda: 0.8910937905311584 lambdas: [0.007559139281511307, -0.06009436398744583, 0.028738586232066154, -0.08263640850782394, -0.01510187890380621, 0.00945522915571928, -0.13142481446266174, 0.013719386421144009, -0.09151066094636917, -0.05606424808502197, -0.14469869434833527, 0.014362934045493603] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4000/5550 val_loss:3.016115 train_time:1005416ms step_avg:251.35ms x-lambda: 0.894432783126831 lambdas: [0.008345874957740307, -0.05851708725094795, 0.030242040753364563, -0.08229978382587433, -0.01508193090558052, 0.010150766000151634, -0.13165521621704102, 0.013266957364976406, -0.09238895773887634, -0.05437318980693817, -0.14387986063957214, 0.013607649132609367] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4125/5550 val_loss:3.007104 train_time:1037357ms step_avg:251.48ms x-lambda: 0.8969753384590149 lambdas: [0.00825472455471754, -0.05835089087486267, 0.029328718781471252, -0.08338814228773117, -0.015404101461172104, 0.008246012032032013, -0.13209855556488037, 0.014538528397679329, -0.09427932649850845, -0.05406320095062256, -0.14315402507781982, 0.012088481336832047] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4250/5550 val_loss:2.998983 train_time:1069551ms step_avg:251.66ms x-lambda: 0.9011534452438354 lambdas: [0.007947421632707119, -0.05772954225540161, 0.029112711548805237, -0.08237884193658829, -0.01625436544418335, 0.009670884348452091, -0.1327206939458847, 0.013302627950906754, -0.09547051787376404, -0.05280550196766853, -0.14316369593143463, 0.012791626155376434] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4375/5550 val_loss:2.989962 train_time:1101780ms step_avg:251.84ms x-lambda: 0.9039442539215088 lambdas: [0.006752758752554655, -0.05745603144168854, 0.028544610366225243, -0.08268965780735016, -0.015087327919900417, 0.009222697466611862, -0.13385078310966492, 0.012601667083799839, -0.09771131724119186, -0.053497329354286194, -0.14307408034801483, 0.01224973239004612] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4500/5550 val_loss:2.981689 train_time:1134011ms step_avg:252.00ms x-lambda: 0.9094237089157104 lambdas: [0.007957834750413895, -0.05633199214935303, 0.028106139972805977, -0.08140405267477036, -0.013982832431793213, 0.009092185646295547, -0.1325373351573944, 0.013528943993151188, -0.09757418930530548, -0.05018487945199013, -0.14192889630794525, 0.012842406518757343] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4625/5550 val_loss:2.972342 train_time:1166473ms step_avg:252.21ms x-lambda: 0.9129374027252197 lambdas: [0.007162207737565041, -0.055514223873615265, 0.02779438905417919, -0.08027099072933197, -0.01614179089665413, 0.008773181587457657, -0.13384929299354553, 0.010976964607834816, -0.0984605923295021, -0.051622841507196426, -0.14277377724647522, 0.011300256475806236] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4750/5550 val_loss:2.963061 train_time:1199009ms step_avg:252.42ms x-lambda: 0.9182798266410828 lambdas: [0.0077326009050011635, -0.05459776148200035, 0.02819056436419487, -0.07999105751514435, -0.015233832411468029, 0.008963486179709435, -0.1327032595872879, 0.013894768431782722, -0.09916242212057114, -0.050447408109903336, -0.14221030473709106, 0.013089245185256004] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:4875/5550 val_loss:2.954330 train_time:1231659ms step_avg:252.65ms x-lambda: 0.9237462878227234 lambdas: [0.007527428679168224, -0.05402543768286705, 0.02686135098338127, -0.079715795814991, -0.014183491468429565, 0.008105961605906487, -0.13271091878414154, 0.012819993309676647, -0.0999702736735344, -0.04996972531080246, -0.14261995255947113, 0.012377738021314144] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5000/5550 val_loss:2.946064 train_time:1264444ms step_avg:252.89ms x-lambda: 0.9299808740615845 lambdas: [0.008008653298020363, -0.05480578914284706, 0.027352042496204376, -0.0788312554359436, -0.014854743145406246, 0.008050275966525078, -0.13302959501743317, 0.012180216610431671, -0.10058961063623428, -0.0491102933883667, -0.1419372260570526, 0.012526956386864185] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5125/5550 val_loss:2.938361 train_time:1297382ms step_avg:253.15ms x-lambda: 0.9347076416015625 lambdas: [0.007258162368088961, -0.052964117377996445, 0.027148202061653137, -0.07844127714633942, -0.014040992595255375, 0.008099416270852089, -0.1342790424823761, 0.012193133123219013, -0.10183105617761612, -0.0483328253030777, -0.14219148457050323, 0.01229031290858984] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5250/5550 val_loss:2.931152 train_time:1330465ms step_avg:253.42ms x-lambda: 0.9396305680274963 lambdas: [0.007572387810796499, -0.05237133800983429, 0.02671792358160019, -0.0779348760843277, -0.014570174738764763, 0.008530277758836746, -0.1338902860879898, 0.012109259143471718, -0.10255404561758041, -0.04816900193691254, -0.14154811203479767, 0.011807353235781193] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5375/5550 val_loss:2.924811 train_time:1363737ms step_avg:253.72ms x-lambda: 0.9456640481948853 lambdas: [0.0074334884993731976, -0.05340789631009102, 0.02663291245698929, -0.0772978812456131, -0.014228256419301033, 0.007768670096993446, -0.13426512479782104, 0.012355132028460503, -0.10338455438613892, -0.04802979901432991, -0.14325051009655, 0.012602662667632103] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5500/5550 val_loss:2.920042 train_time:1397279ms step_avg:254.05ms x-lambda: 0.9488078355789185 lambdas: [0.007240511942654848, -0.05249384418129921, 0.0259323101490736, -0.07762862741947174, -0.0138891926035285, 0.007050191983580589, -0.13423392176628113, 0.012156741693615913, -0.1040724441409111, -0.04869801551103592, -0.14301633834838867, 0.01220176462084055] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]
step:5550/5550 val_loss:2.918859 train_time:1410739ms step_avg:254.19ms x-lambda: 0.9496168494224548 lambdas: [0.007098594680428505, -0.052714891731739044, 0.025843054056167603, -0.07754524797201157, -0.013644772581756115, 0.007234449964016676, -0.1342751830816269, 0.0118939820677042, -0.10417552292346954, -0.04829339683055878, -0.14344272017478943, 0.01232238207012415] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4]



## 8000-add-skip-multiple-13-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.34ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:125/5550 val_loss:4.258074 train_time:29466ms step_avg:235.73ms x-lambda: 1.013745665550232 lambdas: [0.018848508596420288, 0.03016446717083454, 0.017795564606785774, 0.05492903292179108, 0.018626023083925247, -0.055391330271959305, 0.013102029450237751, 0.06608077883720398, 0.01582186669111252, 0.03416209667921066, 0.020703455433249474, 0.008333894424140453, 0.017817821353673935] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:250/5550 val_loss:3.854336 train_time:59094ms step_avg:236.38ms x-lambda: 0.9895748496055603 lambdas: [0.020825376734137535, 0.02942066080868244, -0.012725453823804855, 0.10278785973787308, -0.026208603754639626, -0.17206546664237976, 0.017367282882332802, 0.041425738483667374, 0.020012006163597107, 0.04264330863952637, 0.00342568033374846, 0.0003279114607721567, 0.02212865650653839] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:375/5550 val_loss:3.675354 train_time:89183ms step_avg:237.82ms x-lambda: 0.9802473783493042 lambdas: [0.018072938546538353, 0.0020327481906861067, -0.02651115506887436, 0.10927455127239227, -0.07798190414905548, -0.230450838804245, 0.025018656626343727, 0.030967192724347115, 0.021660521626472473, 0.034370701760053635, -0.01647227071225643, 0.0025011838879436255, 0.029772311449050903] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:500/5550 val_loss:3.562037 train_time:119677ms step_avg:239.35ms x-lambda: 0.9730146527290344 lambdas: [0.010671774856746197, -0.02894144505262375, -0.026507463306188583, 0.1086113303899765, -0.11475171893835068, -0.25682127475738525, 0.0238040741533041, 0.026862656697630882, 0.01567785069346428, 0.028413167223334312, -0.027449816465377808, -0.003192997071892023, 0.03695916756987572] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:625/5550 val_loss:3.485025 train_time:150364ms step_avg:240.58ms x-lambda: 0.9698038101196289 lambdas: [0.007263015955686569, -0.05414624139666557, -0.016245994716882706, 0.11079584062099457, -0.1325756162405014, -0.2626717984676361, 0.023108884692192078, 0.027188844978809357, 0.011451900005340576, 0.027841588482260704, -0.02801593579351902, -0.006659144535660744, 0.044031672179698944] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:750/5550 val_loss:3.428740 train_time:181311ms step_avg:241.75ms x-lambda: 0.9643884301185608 lambdas: [0.0016532607842236757, -0.07839594036340714, -0.010158337652683258, 0.10959421098232269, -0.140303373336792, -0.2609749436378479, 0.017625533044338226, 0.02390175126492977, 0.003011690452694893, 0.024594737216830254, -0.02789969928562641, -0.013702938333153725, 0.04371774569153786] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:875/5550 val_loss:3.381619 train_time:212333ms step_avg:242.67ms x-lambda: 0.9558641910552979 lambdas: [-0.0027838991954922676, -0.10007558763027191, -0.0047167446464300156, 0.10721603780984879, -0.14107146859169006, -0.25314152240753174, 0.011692244559526443, 0.022058775648474693, -0.005067762918770313, 0.022455798462033272, -0.026018397882580757, -0.02020825445652008, 0.04427466168999672] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1000/5550 val_loss:3.346706 train_time:243565ms step_avg:243.57ms x-lambda: 0.948613703250885 lambdas: [-0.007041994947940111, -0.11888010054826736, -0.0025368689093738794, 0.10299968719482422, -0.136674165725708, -0.23990759253501892, 0.005148833617568016, 0.02199000120162964, -0.013866393826901913, 0.01976134069263935, -0.025459041818976402, -0.027125148102641106, 0.04179153963923454] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1125/5550 val_loss:3.317669 train_time:274864ms step_avg:244.32ms x-lambda: 0.9413270354270935 lambdas: [-0.009570296853780746, -0.13684964179992676, -0.0002966573811136186, 0.09686077386140823, -0.13018840551376343, -0.227657288312912, -0.0021322693210095167, 0.017947876825928688, -0.022267941385507584, 0.016986684873700142, -0.02473246306180954, -0.03515561297535896, 0.038703855127096176] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1250/5550 val_loss:3.293955 train_time:306291ms step_avg:245.03ms x-lambda: 0.9367541074752808 lambdas: [-0.008507639169692993, -0.14830006659030914, 0.002622196450829506, 0.09381212294101715, -0.12124114483594894, -0.21343429386615753, -0.006717248819768429, 0.019046181812882423, -0.027309712022542953, 0.016782701015472412, -0.02156609669327736, -0.03910527378320694, 0.0383102148771286] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1375/5550 val_loss:3.270496 train_time:337906ms step_avg:245.75ms x-lambda: 0.9289306402206421 lambdas: [-0.008829199708998203, -0.16088150441646576, 0.001868432154878974, 0.08738298714160919, -0.1163368970155716, -0.20051541924476624, -0.014275617897510529, 0.01687464863061905, -0.034915775060653687, 0.014173315837979317, -0.023726971819996834, -0.046086762100458145, 0.03504492715001106] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1500/5550 val_loss:3.252310 train_time:369518ms step_avg:246.35ms x-lambda: 0.9228733777999878 lambdas: [-0.008321145549416542, -0.17073699831962585, 0.0023284959606826305, 0.08196180313825607, -0.10973747819662094, -0.18946951627731323, -0.02123510092496872, 0.016236651688814163, -0.04208706319332123, 0.012414530850946903, -0.022958004847168922, -0.05219310522079468, 0.03306880593299866] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1625/5550 val_loss:3.238823 train_time:401158ms step_avg:246.87ms x-lambda: 0.9190658330917358 lambdas: [-0.004823633469641209, -0.17798790335655212, 0.004608537536114454, 0.07916946709156036, -0.10182732343673706, -0.17850187420845032, -0.025972986593842506, 0.017305174842476845, -0.04641130194067955, 0.013669811189174652, -0.019731808453798294, -0.05535568669438362, 0.034523822367191315] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1750/5550 val_loss:3.220713 train_time:432782ms step_avg:247.30ms x-lambda: 0.9130758047103882 lambdas: [-0.0031393568497151136, -0.18470168113708496, 0.005072874017059803, 0.07347247749567032, -0.09753889590501785, -0.1682513803243637, -0.03262898325920105, 0.015285447239875793, -0.053089749068021774, 0.011587964370846748, -0.01973058097064495, -0.060889944434165955, 0.03244166448712349] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:1875/5550 val_loss:3.203423 train_time:464469ms step_avg:247.72ms x-lambda: 0.9095122218132019 lambdas: [0.0004585013084579259, -0.18944954872131348, 0.005373464431613684, 0.06972780078649521, -0.09089770168066025, -0.15749675035476685, -0.03783964365720749, 0.01482451893389225, -0.05727095156908035, 0.011447847820818424, -0.019083695486187935, -0.065211720764637, 0.03234716132283211] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2000/5550 val_loss:3.187158 train_time:496355ms step_avg:248.18ms x-lambda: 0.9066125750541687 lambdas: [0.0036940681748092175, -0.19336526095867157, 0.0057672481052577496, 0.06635534018278122, -0.0860743597149849, -0.1477760374546051, -0.043018050491809845, 0.013473160564899445, -0.06178417056798935, 0.011522263288497925, -0.01840723305940628, -0.06955957412719727, 0.030294790863990784] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2125/5550 val_loss:3.173360 train_time:528277ms step_avg:248.60ms x-lambda: 0.9032044410705566 lambdas: [0.006407366134226322, -0.19842125475406647, 0.004669620655477047, 0.06170836091041565, -0.08402001112699509, -0.1431606411933899, -0.048993729054927826, 0.012688090093433857, -0.06621713191270828, 0.009379041381180286, -0.01818605698645115, -0.07337014377117157, 0.02869550697505474] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2250/5550 val_loss:3.158345 train_time:560208ms step_avg:248.98ms x-lambda: 0.9022242426872253 lambdas: [0.010311749763786793, -0.19886143505573273, 0.004525891505181789, 0.05796542391180992, -0.08008698374032974, -0.1351202130317688, -0.05324237421154976, 0.012828268110752106, -0.06931914389133453, 0.010191626846790314, -0.018090317025780678, -0.07585732638835907, 0.028092369437217712] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2375/5550 val_loss:3.148066 train_time:592164ms step_avg:249.33ms x-lambda: 0.9002566337585449 lambdas: [0.01254783384501934, -0.20078007876873016, 0.004833623766899109, 0.054768502712249756, -0.07852993160486221, -0.12959609925746918, -0.05807441845536232, 0.011800521984696388, -0.07308875024318695, 0.008693274110555649, -0.018905136734247208, -0.07878647744655609, 0.0253509022295475] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2500/5550 val_loss:3.135367 train_time:624056ms step_avg:249.62ms x-lambda: 0.8994936943054199 lambdas: [0.016169490292668343, -0.2016994059085846, 0.005038467701524496, 0.05318029597401619, -0.07566291838884354, -0.12425096333026886, -0.06171146780252457, 0.012121987529098988, -0.07585303485393524, 0.009370687417685986, -0.01764216460287571, -0.08123001456260681, 0.02608969248831272] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2625/5550 val_loss:3.122926 train_time:655952ms step_avg:249.89ms x-lambda: 0.8984195590019226 lambdas: [0.019616132602095604, -0.2024282068014145, 0.005324575584381819, 0.052081119269132614, -0.07285432517528534, -0.11882738023996353, -0.06484497338533401, 0.011680989526212215, -0.07759065181016922, 0.009378875605762005, -0.015678079798817635, -0.08281917870044708, 0.02619021013379097] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2750/5550 val_loss:3.112914 train_time:687857ms step_avg:250.13ms x-lambda: 0.8974214196205139 lambdas: [0.020830895751714706, -0.2031756341457367, 0.004930272698402405, 0.049812670797109604, -0.07155527174472809, -0.11621338129043579, -0.06978701800107956, 0.010423571802675724, -0.08091548830270767, 0.007767985109239817, -0.017682086676359177, -0.08608084172010422, 0.02423970401287079] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:2875/5550 val_loss:3.103754 train_time:719787ms step_avg:250.36ms x-lambda: 0.8997558355331421 lambdas: [0.024728763848543167, -0.20346824824810028, 0.006026263348758221, 0.04784960299730301, -0.06864483654499054, -0.1098417118191719, -0.07112716138362885, 0.012244483456015587, -0.08141551166772842, 0.008939927443861961, -0.01504336018115282, -0.08632197231054306, 0.025771982967853546] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3000/5550 val_loss:3.093843 train_time:751698ms step_avg:250.57ms x-lambda: 0.9012489914894104 lambdas: [0.027384549379348755, -0.20297788083553314, 0.0054976483806967735, 0.04814130812883377, -0.06627190113067627, -0.10541529208421707, -0.07341758161783218, 0.011511076241731644, -0.08274401724338531, 0.0099681057035923, -0.013464619405567646, -0.08659016340970993, 0.02443584054708481] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3125/5550 val_loss:3.081816 train_time:783646ms step_avg:250.77ms x-lambda: 0.9007647037506104 lambdas: [0.027710722759366035, -0.2057400643825531, 0.004911884665489197, 0.04493354260921478, -0.06595669686794281, -0.10529669374227524, -0.07814057171344757, 0.011559811420738697, -0.08585510402917862, 0.007362781558185816, -0.01493508368730545, -0.09060071408748627, 0.022970076650381088] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3250/5550 val_loss:3.070396 train_time:815595ms step_avg:250.95ms x-lambda: 0.902984082698822 lambdas: [0.030060116201639175, -0.20556733012199402, 0.00542191369459033, 0.04299471527338028, -0.06427731364965439, -0.10252317786216736, -0.08010020107030869, 0.010903293266892433, -0.08692387491464615, 0.007357842288911343, -0.015209698118269444, -0.09170195460319519, 0.023425668478012085] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3375/5550 val_loss:3.062192 train_time:847522ms step_avg:251.12ms x-lambda: 0.904829740524292 lambdas: [0.03307613730430603, -0.20657837390899658, 0.004563176538795233, 0.04267305135726929, -0.06302919238805771, -0.09981884062290192, -0.08317886292934418, 0.010525290854275227, -0.08872323483228683, 0.006253459025174379, -0.014004223048686981, -0.09302569925785065, 0.02335554175078869] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3500/5550 val_loss:3.053868 train_time:879482ms step_avg:251.28ms x-lambda: 0.9067233204841614 lambdas: [0.03240183740854263, -0.2054276019334793, 0.004761376418173313, 0.03999760001897812, -0.06225866824388504, -0.0971473976969719, -0.08623607456684113, 0.009950654581189156, -0.09108176827430725, 0.005235473159700632, -0.014442681334912777, -0.09444106370210648, 0.02205543965101242] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3625/5550 val_loss:3.044371 train_time:911429ms step_avg:251.43ms x-lambda: 0.9099566340446472 lambdas: [0.03491118922829628, -0.2039848417043686, 0.005742562934756279, 0.04082312434911728, -0.059734512120485306, -0.09592760354280472, -0.08706097304821014, 0.009743452072143555, -0.09111271053552628, 0.006490360014140606, -0.01395049225538969, -0.0939091145992279, 0.021022366359829903] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3750/5550 val_loss:3.034302 train_time:943360ms step_avg:251.56ms x-lambda: 0.9115962982177734 lambdas: [0.03590984642505646, -0.20511122047901154, 0.004963419400155544, 0.039535459131002426, -0.05915690213441849, -0.09364907443523407, -0.08974859863519669, 0.010878253728151321, -0.09175723046064377, 0.007571122143417597, -0.013977923430502415, -0.09542880207300186, 0.021569492295384407] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:3875/5550 val_loss:3.025373 train_time:975365ms step_avg:251.71ms x-lambda: 0.9164097905158997 lambdas: [0.03818271681666374, -0.20568925142288208, 0.00497945724055171, 0.03821532428264618, -0.0584944449365139, -0.0911438912153244, -0.09060149639844894, 0.00998828187584877, -0.09171443432569504, 0.005166212562471628, -0.01360442116856575, -0.09503583610057831, 0.02062338776886463] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4000/5550 val_loss:3.016108 train_time:1007353ms step_avg:251.84ms x-lambda: 0.9205004572868347 lambdas: [0.03924256190657616, -0.20581434667110443, 0.005388164427131414, 0.03753984719514847, -0.059391237795352936, -0.08919823914766312, -0.09370008856058121, 0.009453202597796917, -0.09303183853626251, 0.005906820762902498, -0.014078738167881966, -0.09636174887418747, 0.021519122645258904] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4125/5550 val_loss:3.006880 train_time:1039385ms step_avg:251.97ms x-lambda: 0.924706220626831 lambdas: [0.04050567001104355, -0.20601493120193481, 0.005510988645255566, 0.036643143743276596, -0.05811033025383949, -0.08787339925765991, -0.09536971151828766, 0.011112893931567669, -0.09336677193641663, 0.005939335562288761, -0.01294427178800106, -0.0968242660164833, 0.020426476374268532] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4250/5550 val_loss:2.999095 train_time:1071592ms step_avg:252.14ms x-lambda: 0.9291046857833862 lambdas: [0.04178587347269058, -0.20658902823925018, 0.005638208240270615, 0.03761378303170204, -0.05815787985920906, -0.08649465441703796, -0.09749731421470642, 0.009905003011226654, -0.0940239205956459, 0.006467591971158981, -0.0129681546241045, -0.0964372307062149, 0.02136213891208172] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4375/5550 val_loss:2.989765 train_time:1103854ms step_avg:252.31ms x-lambda: 0.9326707124710083 lambdas: [0.04307851567864418, -0.2084789127111435, 0.0043517109006643295, 0.035286735743284225, -0.059032466262578964, -0.0870927944779396, -0.10039279609918594, 0.009180617518723011, -0.09585099667310715, 0.004734629765152931, -0.01252695731818676, -0.09840813279151917, 0.01985292136669159] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4500/5550 val_loss:2.981589 train_time:1136166ms step_avg:252.48ms x-lambda: 0.9382983446121216 lambdas: [0.04412192106246948, -0.20964857935905457, 0.004680717829614878, 0.034586939960718155, -0.05763745307922363, -0.08450368046760559, -0.10116258263587952, 0.009304383769631386, -0.09556148201227188, 0.004464763216674328, -0.01274512242525816, -0.09807439893484116, 0.02008441649377346] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4625/5550 val_loss:2.971908 train_time:1168606ms step_avg:252.67ms x-lambda: 0.9448033571243286 lambdas: [0.04614660143852234, -0.2090233564376831, 0.0044020479544997215, 0.0335560142993927, -0.057559750974178314, -0.08422700315713882, -0.1019834503531456, 0.008439823985099792, -0.09605122357606888, 0.005109719466418028, -0.013090208172798157, -0.09714044630527496, 0.019594989717006683] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4750/5550 val_loss:2.962784 train_time:1201151ms step_avg:252.87ms x-lambda: 0.9503951072692871 lambdas: [0.047370631247758865, -0.20977823436260223, 0.004011527169495821, 0.035015493631362915, -0.0570952445268631, -0.08267559111118317, -0.10330111533403397, 0.009696909226477146, -0.09601163119077682, 0.005640854127705097, -0.012708988972008228, -0.09739295393228531, 0.021397680044174194] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:4875/5550 val_loss:2.953945 train_time:1233925ms step_avg:253.11ms x-lambda: 0.9556527733802795 lambdas: [0.04863177612423897, -0.21102222800254822, 0.0035097321961075068, 0.034462377429008484, -0.0561426617205143, -0.08197399228811264, -0.10544285178184509, 0.009022935293614864, -0.09624729305505753, 0.004675744101405144, -0.013052765280008316, -0.09818290174007416, 0.019716886803507805] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5000/5550 val_loss:2.945770 train_time:1266780ms step_avg:253.36ms x-lambda: 0.9619064331054688 lambdas: [0.050485286861658096, -0.21261347830295563, 0.004238437861204147, 0.034289442002773285, -0.05672655627131462, -0.08049288392066956, -0.10617765039205551, 0.009681892581284046, -0.09670507162809372, 0.004628708586096764, -0.0126060014590621, -0.09780652076005936, 0.018952472135424614] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5125/5550 val_loss:2.938144 train_time:1299713ms step_avg:253.60ms x-lambda: 0.9674461483955383 lambdas: [0.051532287150621414, -0.21384041011333466, 0.004471542779356241, 0.03426877036690712, -0.056852031499147415, -0.08067171275615692, -0.10713822394609451, 0.008850924670696259, -0.09721384942531586, 0.004957996308803558, -0.011484270915389061, -0.09747005999088287, 0.019171562045812607] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5250/5550 val_loss:2.931037 train_time:1332865ms step_avg:253.88ms x-lambda: 0.9722011685371399 lambdas: [0.05274314805865288, -0.21374116837978363, 0.004425475839525461, 0.03309495002031326, -0.05677017569541931, -0.0790078267455101, -0.10798771679401398, 0.00954810343682766, -0.09709479659795761, 0.0046907090581953526, -0.011266733519732952, -0.09783820807933807, 0.019477523863315582] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5375/5550 val_loss:2.924571 train_time:1366100ms step_avg:254.16ms x-lambda: 0.9773184657096863 lambdas: [0.053488120436668396, -0.2148892730474472, 0.003471075091511011, 0.03357800841331482, -0.05685094743967056, -0.07934533059597015, -0.10889022052288055, 0.009578661993145943, -0.09754744917154312, 0.00445031700655818, -0.011599165387451649, -0.09757018834352493, 0.019162001088261604] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5500/5550 val_loss:2.919801 train_time:1399624ms step_avg:254.48ms x-lambda: 0.9804314970970154 lambdas: [0.05410832539200783, -0.2158118039369583, 0.0035396157763898373, 0.03318723291158676, -0.0568116270005703, -0.07929181307554245, -0.10949213057756424, 0.008745254948735237, -0.09788934141397476, 0.004462056327611208, -0.01121971383690834, -0.0975923091173172, 0.018317988142371178] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]
step:5550/5550 val_loss:2.918636 train_time:1413096ms step_avg:254.61ms x-lambda: 0.9813849329948425 lambdas: [0.054512869566679, -0.21602565050125122, 0.0033315967302769423, 0.033385131508111954, -0.05711738392710686, -0.07899342477321625, -0.10951631516218185, 0.008593011647462845, -0.09787671267986298, 0.004314510617405176, -0.011371552012860775, -0.09741619229316711, 0.01817326433956623] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12, 5, 6, 14, 7]



## 8000-add-skip-multiple-13-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.29ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:125/5550 val_loss:4.260069 train_time:29445ms step_avg:235.56ms x-lambda: 1.0260660648345947 lambdas: [0.014743407256901264, 0.019378390163183212, 0.02329380251467228, 0.025615209713578224, 0.03250440955162048, 0.019259639084339142, 0.018056947737932205, 0.022939156740903854, 0.02482818439602852, 0.040244340896606445, 0.059598080813884735, -0.039723508059978485, -0.016935918480157852] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:250/5550 val_loss:3.847234 train_time:59082ms step_avg:236.33ms x-lambda: 1.0274821519851685 lambdas: [0.016186684370040894, 0.02128615230321884, 0.02407201938331127, 0.021697163581848145, 0.019777385517954826, -0.03260202333331108, -0.019639452919363976, 0.028118573129177094, 0.0035344408825039864, 0.039721254259347916, 0.08926746994256973, -0.12778624892234802, -0.07465092837810516] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:375/5550 val_loss:3.676105 train_time:89180ms step_avg:237.81ms x-lambda: 1.0384904146194458 lambdas: [0.02543078549206257, 0.024246418848633766, 0.021237080916762352, 0.011955518275499344, -0.010759055614471436, -0.08180909603834152, -0.028699396178126335, 0.04007677733898163, -0.013390221633017063, 0.02981973998248577, 0.08937422186136246, -0.17075687646865845, -0.09073908627033234] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:500/5550 val_loss:3.559466 train_time:119663ms step_avg:239.33ms x-lambda: 1.0427109003067017 lambdas: [0.023962683975696564, 0.017855536192655563, 0.01049225963652134, -0.0033580665476620197, -0.04448046162724495, -0.11734753847122192, -0.028111739084124565, 0.04564569517970085, -0.023607371374964714, 0.021936431527137756, 0.08415906131267548, -0.1917988508939743, -0.09934967011213303] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:625/5550 val_loss:3.480535 train_time:150361ms step_avg:240.58ms x-lambda: 1.0454400777816772 lambdas: [0.023447895422577858, 0.012421054765582085, 0.001289671054109931, -0.014807666651904583, -0.07161261141300201, -0.1328975409269333, -0.018152287229895592, 0.052437808364629745, -0.022187139838933945, 0.02007056213915348, 0.0833764597773552, -0.19176475703716278, -0.09863370656967163] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:750/5550 val_loss:3.427637 train_time:181379ms step_avg:241.84ms x-lambda: 1.0431729555130005 lambdas: [0.019249461591243744, 0.004381885286420584, -0.01020833570510149, -0.02683008648455143, -0.0957350954413414, -0.13642668724060059, -0.012799134477972984, 0.05115560069680214, -0.023039421066641808, 0.016172543168067932, 0.07883754372596741, -0.18614409863948822, -0.10069215297698975] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:875/5550 val_loss:3.381031 train_time:212449ms step_avg:242.80ms x-lambda: 1.0357900857925415 lambdas: [0.013765721581876278, -0.005216160323470831, -0.02255529910326004, -0.03825641795992851, -0.11794959008693695, -0.13319247961044312, -0.008356232196092606, 0.049888405948877335, -0.022440938279032707, 0.014055529609322548, 0.07379534840583801, -0.17490728199481964, -0.09908941388130188] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1000/5550 val_loss:3.346442 train_time:243825ms step_avg:243.83ms x-lambda: 1.030737280845642 lambdas: [0.010688887909054756, -0.01241309940814972, -0.03237546980381012, -0.046366751194000244, -0.13560284674167633, -0.12439468502998352, -0.005179649218916893, 0.047635335475206375, -0.02054479904472828, 0.013302470557391644, 0.0703810453414917, -0.15938220918178558, -0.09498719125986099] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1125/5550 val_loss:3.317395 train_time:275194ms step_avg:244.62ms x-lambda: 1.0236685276031494 lambdas: [0.005334591958671808, -0.02101699821650982, -0.042044349014759064, -0.053033411502838135, -0.15063786506652832, -0.11435126513242722, -0.004153906833380461, 0.0458696186542511, -0.019647790119051933, 0.01144553255289793, 0.06382156908512115, -0.14584849774837494, -0.0945165827870369] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1250/5550 val_loss:3.294049 train_time:306686ms step_avg:245.35ms x-lambda: 1.0172450542449951 lambdas: [0.0031811140943318605, -0.02706698328256607, -0.04938286542892456, -0.05688245967030525, -0.16117985546588898, -0.10407575964927673, -0.0019753077067434788, 0.04438823461532593, -0.018675507977604866, 0.012186289764940739, 0.06082125008106232, -0.13315565884113312, -0.09093476086854935] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1375/5550 val_loss:3.271876 train_time:338291ms step_avg:246.03ms x-lambda: 1.0076712369918823 lambdas: [-0.002952589886263013, -0.03569110110402107, -0.05799775943160057, -0.060720719397068024, -0.17128817737102509, -0.09734054654836655, -0.0021267784759402275, 0.041187793016433716, -0.01955227181315422, 0.009343341924250126, 0.05473685637116432, -0.12212461233139038, -0.08864099532365799] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1500/5550 val_loss:3.253800 train_time:369867ms step_avg:246.58ms x-lambda: 1.0032463073730469 lambdas: [-0.004663282074034214, -0.03999713808298111, -0.06250792741775513, -0.060007452964782715, -0.17629864811897278, -0.08850281685590744, 0.00041039567440748215, 0.04154762998223305, -0.016292747110128403, 0.01126549206674099, 0.052288055419921875, -0.11243084073066711, -0.08449207246303558] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1625/5550 val_loss:3.235669 train_time:401513ms step_avg:247.08ms x-lambda: 0.9937891364097595 lambdas: [-0.010031154379248619, -0.04851212352514267, -0.07099317759275436, -0.06304384768009186, -0.18395602703094482, -0.08413976430892944, -0.0010210962500423193, 0.03948786482214928, -0.017233585938811302, 0.009255929850041866, 0.0477147214114666, -0.10622601211071014, -0.08317544311285019] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1750/5550 val_loss:3.220276 train_time:433114ms step_avg:247.49ms x-lambda: 0.9861608743667603 lambdas: [-0.01378327514976263, -0.05506717041134834, -0.07664770632982254, -0.06270988285541534, -0.18771815299987793, -0.07786380499601364, -0.0004425529623404145, 0.03792397305369377, -0.01725059002637863, 0.008823801763355732, 0.04432917758822441, -0.09748012572526932, -0.08006620407104492] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:1875/5550 val_loss:3.202665 train_time:464786ms step_avg:247.89ms x-lambda: 0.9802799224853516 lambdas: [-0.016815993934869766, -0.060764238238334656, -0.08194810897111893, -0.062008652836084366, -0.19086626172065735, -0.07368084788322449, -0.0009153038263320923, 0.03506847470998764, -0.01861419528722763, 0.007268442772328854, 0.03959428146481514, -0.09243442118167877, -0.07894525676965714] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2000/5550 val_loss:3.187583 train_time:496662ms step_avg:248.33ms x-lambda: 0.9729732871055603 lambdas: [-0.019818004220724106, -0.06506054848432541, -0.08530765771865845, -0.05907857045531273, -0.19057640433311462, -0.06832564622163773, 0.0011225419584661722, 0.0348261334002018, -0.015330370515584946, 0.008984623476862907, 0.038466814905405045, -0.08478785306215286, -0.0738767609000206] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2125/5550 val_loss:3.172741 train_time:528587ms step_avg:248.75ms x-lambda: 0.9675685167312622 lambdas: [-0.021395407617092133, -0.06904231011867523, -0.08958307653665543, -0.05728835240006447, -0.19206523895263672, -0.0655350461602211, -0.00023090047761797905, 0.03397068381309509, -0.015762321650981903, 0.008436853997409344, 0.036745525896549225, -0.0804005041718483, -0.07189047336578369] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2250/5550 val_loss:3.158695 train_time:560535ms step_avg:249.13ms x-lambda: 0.9621562361717224 lambdas: [-0.024107547476887703, -0.0741216391324997, -0.09422927349805832, -0.055872153490781784, -0.19309504330158234, -0.06300439685583115, -0.0010576392523944378, 0.03221385180950165, -0.01676146127283573, 0.0065305233001708984, 0.03254666551947594, -0.0763302743434906, -0.07042976468801498] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2375/5550 val_loss:3.147201 train_time:592467ms step_avg:249.46ms x-lambda: 0.9590539336204529 lambdas: [-0.02425597608089447, -0.07624823600053787, -0.09596196562051773, -0.0528099462389946, -0.1903906911611557, -0.05884547159075737, 0.0010919508058577776, 0.03156557306647301, -0.014345875009894371, 0.007563669700175524, 0.033504992723464966, -0.07147613912820816, -0.06822524219751358] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2500/5550 val_loss:3.134956 train_time:624355ms step_avg:249.74ms x-lambda: 0.9536375999450684 lambdas: [-0.02664163149893284, -0.08071521669626236, -0.09952686727046967, -0.05103461816906929, -0.19277408719062805, -0.05876903608441353, -0.00033689758856780827, 0.030195409432053566, -0.016189394518733025, 0.0066555822268128395, 0.030742213129997253, -0.06963783502578735, -0.06806677579879761] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2625/5550 val_loss:3.123944 train_time:656236ms step_avg:249.99ms x-lambda: 0.949262797832489 lambdas: [-0.02767983265221119, -0.08413314074277878, -0.10203922539949417, -0.04930994287133217, -0.1926393210887909, -0.05650656297802925, -0.0012671584263443947, 0.02957278862595558, -0.015076522715389729, 0.00578300841152668, 0.02834821119904518, -0.0653795599937439, -0.06540148705244064] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2750/5550 val_loss:3.113380 train_time:688132ms step_avg:250.23ms x-lambda: 0.9456815719604492 lambdas: [-0.028151562437415123, -0.08626703172922134, -0.10404840856790543, -0.047031864523887634, -0.190926194190979, -0.053181242197752, -0.0009739202214404941, 0.029541466385126114, -0.01389837171882391, 0.006780275609344244, 0.027660038322210312, -0.06236303597688675, -0.06318385899066925] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:2875/5550 val_loss:3.103719 train_time:720049ms step_avg:250.45ms x-lambda: 0.9435155391693115 lambdas: [-0.028719978407025337, -0.08833598345518112, -0.10550493746995926, -0.04464181140065193, -0.19060663878917694, -0.05143345519900322, -0.0008017654181458056, 0.027847547084093094, -0.013882596977055073, 0.00642719492316246, 0.026488393545150757, -0.0601738765835762, -0.061730075627565384] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3000/5550 val_loss:3.092508 train_time:752024ms step_avg:250.67ms x-lambda: 0.9412776231765747 lambdas: [-0.02793230675160885, -0.09019852429628372, -0.10698895901441574, -0.04342351853847504, -0.19005489349365234, -0.0499388724565506, 0.0008554152445867658, 0.02820545807480812, -0.012643695808947086, 0.006747981067746878, 0.025260193273425102, -0.05786430090665817, -0.05982351675629616] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3125/5550 val_loss:3.082490 train_time:784062ms step_avg:250.90ms x-lambda: 0.9383409023284912 lambdas: [-0.029497403651475906, -0.09304549545049667, -0.11014095693826675, -0.04385119676589966, -0.19115857779979706, -0.04967856407165527, -0.0010537435300648212, 0.026140524074435234, -0.014355221763253212, 0.005209620110690594, 0.024633165448904037, -0.05735621973872185, -0.059186648577451706] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3250/5550 val_loss:3.070445 train_time:816026ms step_avg:251.08ms x-lambda: 0.9385123252868652 lambdas: [-0.02887602522969246, -0.0944298580288887, -0.1114274263381958, -0.04143480956554413, -0.18984971940517426, -0.048159290105104446, -0.0011749697150662541, 0.02691994421184063, -0.014166168868541718, 0.005151091609150171, 0.023664165288209915, -0.053837645798921585, -0.05891464650630951] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3375/5550 val_loss:3.062207 train_time:848008ms step_avg:251.26ms x-lambda: 0.9378394484519958 lambdas: [-0.028096430003643036, -0.09564460068941116, -0.11127110570669174, -0.03783828392624855, -0.18874821066856384, -0.04437640309333801, -3.791693598031998e-05, 0.026535730808973312, -0.011806312948465347, 0.00698233675211668, 0.02485729567706585, -0.05429752171039581, -0.05731326341629028] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3500/5550 val_loss:3.053637 train_time:879995ms step_avg:251.43ms x-lambda: 0.9355728626251221 lambdas: [-0.028592845425009727, -0.09814739972352982, -0.11434534937143326, -0.038809675723314285, -0.18915408849716187, -0.046487774699926376, -0.0013180985115468502, 0.0248671006411314, -0.01442214660346508, 0.004482181742787361, 0.020889656618237495, -0.0532325804233551, -0.057687994092702866] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3625/5550 val_loss:3.044577 train_time:911948ms step_avg:251.57ms x-lambda: 0.936954140663147 lambdas: [-0.025986801832914352, -0.09787201881408691, -0.1136803850531578, -0.036594655364751816, -0.18768061697483063, -0.04519716650247574, 0.0010673212818801403, 0.026464451104402542, -0.012475275434553623, 0.005140666849911213, 0.02171820029616356, -0.05025888606905937, -0.05563635379076004] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3750/5550 val_loss:3.035268 train_time:943932ms step_avg:251.72ms x-lambda: 0.9347048401832581 lambdas: [-0.02719256654381752, -0.10098002851009369, -0.11595941334962845, -0.03633585572242737, -0.18776804208755493, -0.04496800899505615, -0.0011044417042285204, 0.025768842548131943, -0.012730246409773827, 0.004801190923899412, 0.019895803183317184, -0.04950162023305893, -0.056980572640895844] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:3875/5550 val_loss:3.026413 train_time:975932ms step_avg:251.85ms x-lambda: 0.9386319518089294 lambdas: [-0.02370474301278591, -0.09991006553173065, -0.11585191637277603, -0.034500204026699066, -0.1873578280210495, -0.043774884194135666, -0.000704763107933104, 0.023310024291276932, -0.01184516865760088, 0.004901943728327751, 0.020733153447508812, -0.04797232896089554, -0.05474201589822769] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4000/5550 val_loss:3.016417 train_time:1007909ms step_avg:251.98ms x-lambda: 0.9398150444030762 lambdas: [-0.024403756484389305, -0.10220300406217575, -0.11767468601465225, -0.0338408537209034, -0.18724694848060608, -0.04364073649048805, -0.0013258695835247636, 0.02447233721613884, -0.012374227866530418, 0.0047331941314041615, 0.0190518107265234, -0.047736771404743195, -0.054689355194568634] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4125/5550 val_loss:3.007192 train_time:1039933ms step_avg:252.10ms x-lambda: 0.9415291547775269 lambdas: [-0.023029262199997902, -0.10307887941598892, -0.11856255680322647, -0.03353313356637955, -0.18736183643341064, -0.043759651482105255, -0.0010877256281673908, 0.024816300719976425, -0.011133173480629921, 0.00478533236309886, 0.019060306251049042, -0.04706419259309769, -0.054159119725227356] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4250/5550 val_loss:2.999151 train_time:1072130ms step_avg:252.27ms x-lambda: 0.9441235065460205 lambdas: [-0.021258661523461342, -0.1036965399980545, -0.1187114417552948, -0.03253021463751793, -0.18694718182086945, -0.04285116121172905, -6.634858436882496e-06, 0.0237360130995512, -0.011603650636970997, 0.004988727159798145, 0.019358735531568527, -0.045168012380599976, -0.053146809339523315] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4375/5550 val_loss:2.989702 train_time:1104379ms step_avg:252.43ms x-lambda: 0.9461367130279541 lambdas: [-0.02103988453745842, -0.10618870705366135, -0.12120504677295685, -0.03285173326730728, -0.18865159153938293, -0.04433407634496689, -0.0010218911338597536, 0.02266628108918667, -0.011452394537627697, 0.004378490149974823, 0.019310524687170982, -0.045077599585056305, -0.05444948002696037] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4500/5550 val_loss:2.981672 train_time:1136656ms step_avg:252.59ms x-lambda: 0.9483897686004639 lambdas: [-0.020107433199882507, -0.10653384029865265, -0.12158570438623428, -0.03287571668624878, -0.18867315351963043, -0.0422840416431427, -0.0014662545872852206, 0.02361106313765049, -0.012130851857364178, 0.003446361981332302, 0.018793117254972458, -0.04442239925265312, -0.053731027990579605] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4625/5550 val_loss:2.972493 train_time:1169058ms step_avg:252.77ms x-lambda: 0.9529123306274414 lambdas: [-0.0178960133343935, -0.10679229348897934, -0.12164998799562454, -0.032148100435733795, -0.18778948485851288, -0.042973924428224564, -0.0022879806347191334, 0.022484565153717995, -0.011433339677751064, 0.0033046051394194365, 0.01792941614985466, -0.0440385527908802, -0.05262865498661995] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4750/5550 val_loss:2.962948 train_time:1201565ms step_avg:252.96ms x-lambda: 0.9577182531356812 lambdas: [-0.01637166365981102, -0.10717028379440308, -0.12276168167591095, -0.03199739381670952, -0.18780463933944702, -0.042150478810071945, -0.0011423463001847267, 0.022994264960289, -0.01085688266903162, 0.004553342238068581, 0.018646759912371635, -0.04296919330954552, -0.05157719925045967] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:4875/5550 val_loss:2.954203 train_time:1234284ms step_avg:253.19ms x-lambda: 0.9615023136138916 lambdas: [-0.015141339041292667, -0.10745387524366379, -0.12422937154769897, -0.03114127553999424, -0.18842792510986328, -0.04255952686071396, -0.0015964839840307832, 0.02071021869778633, -0.011503254063427448, 0.003888918086886406, 0.018264753744006157, -0.04230769723653793, -0.05153772607445717] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5000/5550 val_loss:2.946048 train_time:1267091ms step_avg:253.42ms x-lambda: 0.9657631516456604 lambdas: [-0.014636218547821045, -0.10876993834972382, -0.12528015673160553, -0.02970539592206478, -0.18872134387493134, -0.04224102199077606, -0.0006485754274763167, 0.021952617913484573, -0.009738501161336899, 0.003851403947919607, 0.018288161605596542, -0.042256131768226624, -0.05109208822250366] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5125/5550 val_loss:2.938426 train_time:1300063ms step_avg:253.67ms x-lambda: 0.9705406427383423 lambdas: [-0.01287687849253416, -0.10851287841796875, -0.12599967420101166, -0.029440052807331085, -0.1896308809518814, -0.04189203679561615, -0.0009008267079479992, 0.02201288938522339, -0.010044450871646404, 0.0040667238645255566, 0.017898395657539368, -0.040984347462654114, -0.05144870653748512] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5250/5550 val_loss:2.931390 train_time:1333206ms step_avg:253.94ms x-lambda: 0.9737467169761658 lambdas: [-0.012477769516408443, -0.10957370698451996, -0.12634479999542236, -0.02862362749874592, -0.1892881989479065, -0.04174824804067612, -0.0010669814655557275, 0.022008199244737625, -0.009201373904943466, 0.0039797816425561905, 0.01728978380560875, -0.040363848209381104, -0.051144517958164215] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5375/5550 val_loss:2.924804 train_time:1366434ms step_avg:254.22ms x-lambda: 0.9780420064926147 lambdas: [-0.011466603726148605, -0.10983819514513016, -0.1267627775669098, -0.028033673763275146, -0.19080288708209991, -0.042484723031520844, -0.0017804503440856934, 0.02160889096558094, -0.010847199708223343, 0.0038382194470614195, 0.017379019409418106, -0.041069287806749344, -0.05201577767729759] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5500/5550 val_loss:2.920074 train_time:1399977ms step_avg:254.54ms x-lambda: 0.9809820652008057 lambdas: [-0.011186742223799229, -0.11043310910463333, -0.12795983254909515, -0.027838965877890587, -0.19082990288734436, -0.04222826659679413, -0.0020482472609728575, 0.020711129531264305, -0.009587851352989674, 0.003347368910908699, 0.017517946660518646, -0.040750227868556976, -0.05167373642325401] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]
step:5550/5550 val_loss:2.918894 train_time:1413451ms step_avg:254.68ms x-lambda: 0.9815983772277832 lambdas: [-0.011082119308412075, -0.11063969135284424, -0.12802346050739288, -0.027623312547802925, -0.19087539613246918, -0.042527589946985245, -0.0019620785024017096, 0.020657621324062347, -0.009635528549551964, 0.0035354248248040676, 0.017315415665507317, -0.0408400222659111, -0.05136244371533394] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]



## 8000-add-skip-multiple-13-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.34ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:125/5550 val_loss:4.269200 train_time:29464ms step_avg:235.71ms x-lambda: 1.0194003582000732 lambdas: [0.06987249851226807, -0.004051053896546364, -0.0425364188849926, -0.05880541354417801, 0.06481126695871353, 0.041944049298763275, 0.024922730401158333, 0.0211443230509758, 0.015639835968613625, 0.017852064222097397, 0.03429063409566879, 0.025981681421399117, 0.02355879917740822] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:250/5550 val_loss:3.849734 train_time:59117ms step_avg:236.47ms x-lambda: 1.0014972686767578 lambdas: [0.07044936716556549, -0.03456427529454231, -0.10475368052721024, -0.14600197970867157, 0.1165386289358139, 0.051260996609926224, 0.007705921307206154, 0.028468145057559013, -0.016964787617325783, -0.042273666709661484, 0.028423137962818146, 0.030901707708835602, 0.03012462891638279] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:375/5550 val_loss:3.675531 train_time:89175ms step_avg:237.80ms x-lambda: 1.0037771463394165 lambdas: [0.06302032619714737, -0.036111004650592804, -0.12359362840652466, -0.18965120613574982, 0.12930765748023987, 0.04226336628198624, -0.009553341194987297, 0.03629846125841141, -0.025045379996299744, -0.09837514162063599, 0.00016041705384850502, 0.02826247178018093, 0.032331474125385284] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:500/5550 val_loss:3.559686 train_time:119572ms step_avg:239.14ms x-lambda: 1.0024104118347168 lambdas: [0.05507354065775871, -0.03124130144715309, -0.12974214553833008, -0.21186265349388123, 0.1335780769586563, 0.033975668251514435, -0.0186622217297554, 0.042858291417360306, -0.022809097543358803, -0.13357573747634888, -0.029354779049754143, 0.020834164693951607, 0.026284271851181984] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:625/5550 val_loss:3.479816 train_time:150170ms step_avg:240.27ms x-lambda: 0.9961068630218506 lambdas: [0.049674540758132935, -0.022876497358083725, -0.13079862296581268, -0.2178012579679489, 0.1363675892353058, 0.029392417520284653, -0.02064491994678974, 0.047032300382852554, -0.015582488849759102, -0.15213969349861145, -0.05472371727228165, 0.015407226979732513, 0.018344992771744728] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:750/5550 val_loss:3.428217 train_time:181060ms step_avg:241.41ms x-lambda: 0.9832736849784851 lambdas: [0.04220419004559517, -0.018886703997850418, -0.13322819769382477, -0.21632683277130127, 0.13438373804092407, 0.0232774056494236, -0.021703114733099937, 0.04576577618718147, -0.011366739869117737, -0.15948499739170074, -0.07738842815160751, 0.007400756236165762, 0.0055831605568528175] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:875/5550 val_loss:3.382451 train_time:212043ms step_avg:242.34ms x-lambda: 0.9669949412345886 lambdas: [0.03794374316930771, -0.013461894355714321, -0.13114427030086517, -0.20620006322860718, 0.13112251460552216, 0.019399620592594147, -0.01974894292652607, 0.04568547382950783, -0.007576771546155214, -0.1590786576271057, -0.09671293199062347, 0.0014173316303640604, -0.006475744768977165] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1000/5550 val_loss:3.347962 train_time:243355ms step_avg:243.35ms x-lambda: 0.9520899057388306 lambdas: [0.035765718668699265, -0.00855381041765213, -0.12828218936920166, -0.19195489585399628, 0.1254647821187973, 0.01659565605223179, -0.01811503805220127, 0.04317028447985649, -0.004128283821046352, -0.1529538780450821, -0.11136770993471146, -0.002193635329604149, -0.017910584807395935] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1125/5550 val_loss:3.318185 train_time:274721ms step_avg:244.20ms x-lambda: 0.9350326657295227 lambdas: [0.0320512130856514, -0.007595055270940065, -0.12770052254199982, -0.1797643005847931, 0.11768122017383575, 0.013721953146159649, -0.01834314689040184, 0.040733758360147476, -0.003077311208471656, -0.1466955542564392, -0.12599380314350128, -0.006169419270008802, -0.03089676983654499] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1250/5550 val_loss:3.294770 train_time:306163ms step_avg:244.93ms x-lambda: 0.9203073382377625 lambdas: [0.029577694833278656, -0.006112969480454922, -0.1258632242679596, -0.167424276471138, 0.11040464043617249, 0.012692650780081749, -0.018197592347860336, 0.038680411875247955, -0.002063529333099723, -0.1410692185163498, -0.13719511032104492, -0.007672262378036976, -0.041919611394405365] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1375/5550 val_loss:3.273187 train_time:337770ms step_avg:245.65ms x-lambda: 0.9036468267440796 lambdas: [0.02644052542746067, -0.004515223205089569, -0.12238118797540665, -0.15360809862613678, 0.1021086722612381, 0.009811509400606155, -0.017002539709210396, 0.03669116273522377, -0.0014111396158114076, -0.1346544474363327, -0.14695504307746887, -0.008406958542764187, -0.052719876170158386] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1500/5550 val_loss:3.253502 train_time:369347ms step_avg:246.23ms x-lambda: 0.8911780118942261 lambdas: [0.026215415447950363, -0.0013145040720701218, -0.11767628788948059, -0.14124427735805511, 0.09592055529356003, 0.010535793378949165, -0.015385309234261513, 0.03704804927110672, 0.0011465480783954263, -0.1253347396850586, -0.15188051760196686, -0.006009504199028015, -0.061452288180589676] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1625/5550 val_loss:3.237488 train_time:401025ms step_avg:246.78ms x-lambda: 0.8754590153694153 lambdas: [0.024785855785012245, -0.0016802109312266111, -0.1167697161436081, -0.1326572448015213, 0.09039631485939026, 0.008718603290617466, -0.015048432163894176, 0.03588948771357536, 0.0014232161920517683, -0.12066666036844254, -0.1603836864233017, -0.004679737146943808, -0.07177586853504181] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1750/5550 val_loss:3.222143 train_time:432650ms step_avg:247.23ms x-lambda: 0.8610833883285522 lambdas: [0.02290990762412548, -0.0006406018510460854, -0.11233095079660416, -0.12214073538780212, 0.08405329287052155, 0.00948016345500946, -0.014204246923327446, 0.034665655344724655, 0.0030495459213852882, -0.11301901191473007, -0.16429077088832855, -0.0031051768455654383, -0.08124825358390808] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:1875/5550 val_loss:3.204939 train_time:464335ms step_avg:247.65ms x-lambda: 0.8493325710296631 lambdas: [0.021397950127720833, -0.0009846745524555445, -0.11011730134487152, -0.11533336341381073, 0.07849441468715668, 0.00676925852894783, -0.015090346336364746, 0.03269967436790466, 0.0027494097594171762, -0.10916603356599808, -0.16855129599571228, 2.859346568584442e-05, -0.08993639796972275] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2000/5550 val_loss:3.189021 train_time:496212ms step_avg:248.11ms x-lambda: 0.8372343182563782 lambdas: [0.02111087180674076, 0.0011597108095884323, -0.10626956075429916, -0.10604891180992126, 0.07458173483610153, 0.007808245252817869, -0.012770775705575943, 0.03144422918558121, 0.004161595366895199, -0.10284092277288437, -0.16912919282913208, 0.004093723837286234, -0.09629961848258972] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2125/5550 val_loss:3.174010 train_time:528133ms step_avg:248.53ms x-lambda: 0.8276562094688416 lambdas: [0.02031729742884636, 0.0008160548168234527, -0.10232380777597427, -0.10051175951957703, 0.07183801382780075, 0.007103040814399719, -0.01279805600643158, 0.03101213090121746, 0.0045687975361943245, -0.10052135586738586, -0.17217426002025604, 0.007428979035466909, -0.10265600681304932] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2250/5550 val_loss:3.161939 train_time:560063ms step_avg:248.92ms x-lambda: 0.8183978199958801 lambdas: [0.018615983426570892, -0.0002931507769972086, -0.10159898549318314, -0.0950222983956337, 0.06425460427999496, 0.00485744746401906, -0.014205762185156345, 0.028288109228014946, 0.0018093832768499851, -0.09817618876695633, -0.174196258187294, 0.009247804060578346, -0.10989700257778168] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2375/5550 val_loss:3.148254 train_time:592007ms step_avg:249.27ms x-lambda: 0.8112732768058777 lambdas: [0.01997208222746849, 0.0007462204084731638, -0.09800630807876587, -0.08939919620752335, 0.06210826709866524, 0.0058679948560893536, -0.012640126049518585, 0.02888275496661663, 0.004611557349562645, -0.09335871040821075, -0.17357279360294342, 0.012656698934733868, -0.11337848752737045] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2500/5550 val_loss:3.136810 train_time:623883ms step_avg:249.55ms x-lambda: 0.8049921989440918 lambdas: [0.019417645409703255, 0.0012086927890777588, -0.09521505236625671, -0.0856790691614151, 0.06054261326789856, 0.005985110532492399, -0.01286549773067236, 0.027403753250837326, 0.003152489895001054, -0.09148774296045303, -0.17494772374629974, 0.016024649143218994, -0.11775625497102737] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2625/5550 val_loss:3.124679 train_time:655749ms step_avg:249.81ms x-lambda: 0.7988811731338501 lambdas: [0.01891348324716091, 0.0017525668954476714, -0.09374075382947922, -0.08099127560853958, 0.057232413440942764, 0.0046409908682107925, -0.01236146129667759, 0.027014847844839096, 0.0039012774359434843, -0.08870777487754822, -0.17542283236980438, 0.01845601573586464, -0.12227538228034973] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2750/5550 val_loss:3.114317 train_time:687621ms step_avg:250.04ms x-lambda: 0.7927934527397156 lambdas: [0.01710689440369606, 0.0010047141695395112, -0.09181781113147736, -0.07869690656661987, 0.05506433919072151, 0.004359785467386246, -0.012572849169373512, 0.026208873838186264, 0.0022817417047917843, -0.08761721849441528, -0.17539851367473602, 0.019962167367339134, -0.12750066816806793] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:2875/5550 val_loss:3.105026 train_time:719542ms step_avg:250.28ms x-lambda: 0.7907465100288391 lambdas: [0.01730925776064396, 0.0025824159383773804, -0.0882086306810379, -0.07347331196069717, 0.053490351885557175, 0.005391256418079138, -0.01100410707294941, 0.02733027935028076, 0.004017730243504047, -0.08386749029159546, -0.17483071982860565, 0.023740727454423904, -0.12950685620307922] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3000/5550 val_loss:3.095228 train_time:751516ms step_avg:250.51ms x-lambda: 0.7888222932815552 lambdas: [0.016086705029010773, 0.0023432900197803974, -0.08684898167848587, -0.07176301628351212, 0.053230103105306625, 0.006171591114252806, -0.009401700459420681, 0.025734126567840576, 0.005073387175798416, -0.08155608177185059, -0.17446503043174744, 0.025600183755159378, -0.13187266886234283] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3125/5550 val_loss:3.082786 train_time:783532ms step_avg:250.73ms x-lambda: 0.7837694883346558 lambdas: [0.016270441934466362, 0.0015199509216472507, -0.08627178519964218, -0.07153767347335815, 0.05046149343252182, 0.005219907499849796, -0.01075297873467207, 0.025088440626859665, 0.0030260789208114147, -0.08228736370801926, -0.17728827893733978, 0.02672024443745613, -0.1363867223262787] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3250/5550 val_loss:3.071678 train_time:815524ms step_avg:250.93ms x-lambda: 0.7838454842567444 lambdas: [0.016438279300928116, 0.0012965105706825852, -0.0843760073184967, -0.0685969889163971, 0.04790132865309715, 0.004212803672999144, -0.010911605320870876, 0.023912619799375534, 0.003426498966291547, -0.0802360400557518, -0.1765202134847641, 0.028194501996040344, -0.13822586834430695] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3375/5550 val_loss:3.062500 train_time:847411ms step_avg:251.08ms x-lambda: 0.7823590636253357 lambdas: [0.01645568199455738, 0.001039145514369011, -0.0829479843378067, -0.0663846954703331, 0.04791541025042534, 0.003492610529065132, -0.010058035142719746, 0.024351103231310844, 0.003989973105490208, -0.07890674471855164, -0.17576059699058533, 0.030285373330116272, -0.13963326811790466] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3500/5550 val_loss:3.054226 train_time:879344ms step_avg:251.24ms x-lambda: 0.7807635068893433 lambdas: [0.014990095980465412, 0.0012823350261896849, -0.08233386278152466, -0.06444784998893738, 0.04439385235309601, 0.003655108856037259, -0.01074094045907259, 0.02500518411397934, 0.0047081527300179005, -0.0780491903424263, -0.17684806883335114, 0.030709408223628998, -0.14220091700553894] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3625/5550 val_loss:3.045615 train_time:911253ms step_avg:251.38ms x-lambda: 0.7806146144866943 lambdas: [0.016194593161344528, 0.0007105994736775756, -0.08158405870199203, -0.06358354538679123, 0.04451910778880119, 0.0037388508208096027, -0.010715566575527191, 0.02265940234065056, 0.00538239860907197, -0.07596000283956528, -0.17512507736682892, 0.03333372250199318, -0.14393460750579834] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3750/5550 val_loss:3.035511 train_time:943160ms step_avg:251.51ms x-lambda: 0.7814512848854065 lambdas: [0.015779998153448105, 0.0018253476591780782, -0.08061075210571289, -0.061763960868120193, 0.044662874191999435, 0.004203453194350004, -0.010660040192306042, 0.02374142035841942, 0.004114524926990271, -0.07422538846731186, -0.17553682625293732, 0.0335066057741642, -0.14596526324748993] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:3875/5550 val_loss:3.027110 train_time:975159ms step_avg:251.65ms x-lambda: 0.7862461805343628 lambdas: [0.014560717158019543, 0.0018402771092951298, -0.07883316278457642, -0.06065967679023743, 0.04305501654744148, 0.0029127614106982946, -0.00955403782427311, 0.022840067744255066, 0.00335722416639328, -0.07342971861362457, -0.17748045921325684, 0.03600582107901573, -0.14629074931144714] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4000/5550 val_loss:3.017390 train_time:1007128ms step_avg:251.78ms x-lambda: 0.7879583239555359 lambdas: [0.015126222744584084, 0.0019732338842004538, -0.07696571946144104, -0.05908038094639778, 0.04211411625146866, 0.0033863773569464684, -0.010023850947618484, 0.021856186911463737, 0.003769711824133992, -0.0733148604631424, -0.17647451162338257, 0.03675784170627594, -0.1485779881477356] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4125/5550 val_loss:3.008271 train_time:1039141ms step_avg:251.91ms x-lambda: 0.7903605699539185 lambdas: [0.016379835084080696, 0.0014051846228539944, -0.07548105716705322, -0.05745987594127655, 0.04086637496948242, 0.002577853621914983, -0.008577180095016956, 0.02281799539923668, 0.0043861581943929195, -0.07229073345661163, -0.17709533870220184, 0.03718957677483559, -0.15048305690288544] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4250/5550 val_loss:2.999927 train_time:1071354ms step_avg:252.08ms x-lambda: 0.7938272953033447 lambdas: [0.01459830068051815, 0.0006263697287067771, -0.07629965990781784, -0.05577937141060829, 0.04151317849755287, 0.003957510460168123, -0.009443474933505058, 0.022418780252337456, 0.004638971295207739, -0.07251321524381638, -0.17779499292373657, 0.03836280480027199, -0.1518448442220688] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4375/5550 val_loss:2.990875 train_time:1103598ms step_avg:252.25ms x-lambda: 0.7959502339363098 lambdas: [0.014361065812408924, 0.0012031018268316984, -0.07548870891332626, -0.0566382072865963, 0.04000210762023926, 0.0033597396686673164, -0.010181029327213764, 0.021643752232193947, 0.0038773943670094013, -0.07352857291698456, -0.17856329679489136, 0.03885999321937561, -0.1541137397289276] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4500/5550 val_loss:2.982616 train_time:1135881ms step_avg:252.42ms x-lambda: 0.8006055355072021 lambdas: [0.014825456775724888, 0.001228738809004426, -0.07457998394966125, -0.05509832873940468, 0.038642700761556625, 0.0028456291183829308, -0.009565946646034718, 0.02072952315211296, 0.0032468053977936506, -0.07180483639240265, -0.17916631698608398, 0.03920634835958481, -0.15582850575447083] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4625/5550 val_loss:2.973315 train_time:1168311ms step_avg:252.61ms x-lambda: 0.8064906597137451 lambdas: [0.014121029525995255, 0.0012772738700732589, -0.07365567237138748, -0.05557866767048836, 0.0387737937271595, 0.0026456983759999275, -0.009789394214749336, 0.020238563418388367, 0.0033477656543254852, -0.07314254343509674, -0.17914290726184845, 0.04078756272792816, -0.15589383244514465] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4750/5550 val_loss:2.964002 train_time:1200865ms step_avg:252.81ms x-lambda: 0.8119075894355774 lambdas: [0.01564398966729641, 0.001980578526854515, -0.07169678807258606, -0.053868237882852554, 0.03926074877381325, 0.0036668782122433186, -0.008403798565268517, 0.021972008049488068, 0.004022074397653341, -0.0716870129108429, -0.1797720491886139, 0.04246512055397034, -0.1565733551979065] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:4875/5550 val_loss:2.955227 train_time:1233574ms step_avg:253.04ms x-lambda: 0.8160268068313599 lambdas: [0.014477531425654888, 0.0012145903892815113, -0.0719337984919548, -0.053850207477808, 0.037230152636766434, 0.0019433149136602879, -0.009663132950663567, 0.020222123712301254, 0.002772696316242218, -0.07201427221298218, -0.18054133653640747, 0.04348205029964447, -0.15727238357067108] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5000/5550 val_loss:2.947163 train_time:1266364ms step_avg:253.27ms x-lambda: 0.822119414806366 lambdas: [0.014568069018423557, 0.0014513529604300857, -0.07118482887744904, -0.052489083260297775, 0.03774847835302353, 0.0021472671069204807, -0.008823301643133163, 0.021140573546290398, 0.0031280138064175844, -0.07157572358846664, -0.18112905323505402, 0.04511210694909096, -0.15878048539161682] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5125/5550 val_loss:2.939452 train_time:1299296ms step_avg:253.52ms x-lambda: 0.8269110918045044 lambdas: [0.01397403422743082, 0.0021429702173918486, -0.07071983814239502, -0.051885005086660385, 0.0374104306101799, 0.0027929742354899645, -0.008992642164230347, 0.020438747480511665, 0.0033044368028640747, -0.07144560664892197, -0.18222665786743164, 0.045355360954999924, -0.1601962000131607] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5250/5550 val_loss:2.932225 train_time:1332433ms step_avg:253.80ms x-lambda: 0.8315462470054626 lambdas: [0.013740605674684048, 0.0020566065795719624, -0.07080285996198654, -0.051397938281297684, 0.036320991814136505, 0.002715298207476735, -0.008088722825050354, 0.02043956145644188, 0.0037137928884476423, -0.07158512622117996, -0.18165437877178192, 0.0463101789355278, -0.16156432032585144] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5375/5550 val_loss:2.925848 train_time:1365667ms step_avg:254.08ms x-lambda: 0.8371016979217529 lambdas: [0.014545708894729614, 0.0022026444785296917, -0.07074267417192459, -0.05181669816374779, 0.03676038980484009, 0.0022106501273810863, -0.008972423151135445, 0.02005927637219429, 0.0033057888504117727, -0.07176421582698822, -0.1832018792629242, 0.04775940626859665, -0.16207242012023926] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5500/5550 val_loss:2.921067 train_time:1399208ms step_avg:254.40ms x-lambda: 0.8401111364364624 lambdas: [0.013885620050132275, 0.0007644807919859886, -0.07039022445678711, -0.05122357979416847, 0.0372568815946579, 0.002066479530185461, -0.008570317178964615, 0.019556380808353424, 0.002821097383275628, -0.07164733856916428, -0.1832275390625, 0.04826972261071205, -0.16279421746730804] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
step:5550/5550 val_loss:2.919865 train_time:1412693ms step_avg:254.54ms x-lambda: 0.8410781025886536 lambdas: [0.013987100683152676, 0.0009919459698721766, -0.07022250443696976, -0.05155845731496811, 0.03765394166111946, 0.002061098115518689, -0.008408928290009499, 0.01940126344561577, 0.0029255952686071396, -0.07193911075592041, -0.18344919383525848, 0.048247747123241425, -0.1627664715051651] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]



## 8000-add-skip-multiple-13-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.22ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:125/5550 val_loss:4.261153 train_time:29469ms step_avg:235.75ms x-lambda: 1.0471315383911133 lambdas: [-0.0023769864346832037, 0.029475755989551544, 0.01679503731429577, 0.008762730285525322, 0.01368288230150938, 0.01608833484351635, 0.022741401568055153, 0.00806784350425005, 0.038321029394865036, 0.002024737186729908, 0.028865698724985123, 0.040710654109716415, 0.02796962484717369] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:250/5550 val_loss:3.850452 train_time:59054ms step_avg:236.22ms x-lambda: 1.100672960281372 lambdas: [-0.024689020588994026, 0.0058884769678115845, 0.0014807201223447919, -0.012396146543323994, 0.002080154838040471, 0.001131096389144659, 0.006122496910393238, -0.005956768989562988, 0.007213676813989878, -0.011341788806021214, -0.004471571184694767, 0.011960605159401894, 0.013668665662407875] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:375/5550 val_loss:3.677226 train_time:89049ms step_avg:237.47ms x-lambda: 1.1140848398208618 lambdas: [-0.03036333993077278, -0.015605720691382885, -0.009129899553954601, -0.021478334441781044, -0.006208517123013735, -0.016806436702609062, -0.010433518327772617, -0.011854493990540504, -0.018002472817897797, -0.015159578062593937, -0.023235652595758438, -0.010857952758669853, -0.006433345377445221] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:500/5550 val_loss:3.561488 train_time:119382ms step_avg:238.76ms x-lambda: 1.1018403768539429 lambdas: [-0.0324518121778965, -0.02562401071190834, -0.016325734555721283, -0.027211764827370644, -0.010407638736069202, -0.02216174639761448, -0.018770253285765648, -0.015164751559495926, -0.026923026889562607, -0.017787979915738106, -0.0328216478228569, -0.02344675362110138, -0.017698002979159355] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:625/5550 val_loss:3.481082 train_time:149998ms step_avg:240.00ms x-lambda: 1.0748218297958374 lambdas: [-0.033962152898311615, -0.03254739195108414, -0.019715599715709686, -0.028612185269594193, -0.012728839181363583, -0.025223221629858017, -0.022473525255918503, -0.015464955940842628, -0.031569771468639374, -0.02218620292842388, -0.03743357956409454, -0.028645239770412445, -0.02227000892162323] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:750/5550 val_loss:3.429169 train_time:180945ms step_avg:241.26ms x-lambda: 1.0392986536026 lambdas: [-0.03308195248246193, -0.03371331840753555, -0.02064185030758381, -0.026970334351062775, -0.014165842905640602, -0.026992112398147583, -0.025291437283158302, -0.017668135464191437, -0.031351398676633835, -0.02484734356403351, -0.03692399710416794, -0.030519705265760422, -0.02267763949930668] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:875/5550 val_loss:3.383060 train_time:211917ms step_avg:242.19ms x-lambda: 0.9977754354476929 lambdas: [-0.03126278147101402, -0.032369960099458694, -0.018777253106236458, -0.02448471076786518, -0.014589844271540642, -0.02439911663532257, -0.024400804191827774, -0.017412913963198662, -0.029691586270928383, -0.024203704670071602, -0.03388833999633789, -0.028946928679943085, -0.022903181612491608] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1000/5550 val_loss:3.347852 train_time:243156ms step_avg:243.16ms x-lambda: 0.9562726616859436 lambdas: [-0.030377961695194244, -0.030196135863661766, -0.01941562257707119, -0.021807806566357613, -0.013552756048738956, -0.024839317426085472, -0.024599364027380943, -0.01670229807496071, -0.028851982206106186, -0.02357577532529831, -0.031209005042910576, -0.029136590659618378, -0.021176287904381752] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1125/5550 val_loss:3.318436 train_time:274450ms step_avg:243.96ms x-lambda: 0.9173029065132141 lambdas: [-0.030144406482577324, -0.030956216156482697, -0.019303876906633377, -0.023110387846827507, -0.015054738149046898, -0.024095678701996803, -0.025999320670962334, -0.0176023468375206, -0.02929937094449997, -0.02292276732623577, -0.031252726912498474, -0.02755851298570633, -0.0219875480979681] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1250/5550 val_loss:3.292734 train_time:305880ms step_avg:244.70ms x-lambda: 0.880398154258728 lambdas: [-0.028188273310661316, -0.03039938397705555, -0.018429450690746307, -0.02119310572743416, -0.014652369543910027, -0.02337927743792534, -0.02381429634988308, -0.01717200130224228, -0.027147391811013222, -0.022176411002874374, -0.02942388691008091, -0.028211725875735283, -0.02087024599313736] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1375/5550 val_loss:3.273946 train_time:337477ms step_avg:245.44ms x-lambda: 0.8444180488586426 lambdas: [-0.02756163850426674, -0.029239313676953316, -0.01896941289305687, -0.022529102861881256, -0.013636983931064606, -0.024079561233520508, -0.023902451619505882, -0.016204839572310448, -0.02589062973856926, -0.02274937927722931, -0.027974369004368782, -0.027158960700035095, -0.020720427855849266] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1500/5550 val_loss:3.253356 train_time:369048ms step_avg:246.03ms x-lambda: 0.8187993764877319 lambdas: [-0.02663177065551281, -0.028094088658690453, -0.017337141558527946, -0.020338093861937523, -0.013505603186786175, -0.02166077494621277, -0.02307530678808689, -0.0160030759871006, -0.025086939334869385, -0.021047985181212425, -0.026790572330355644, -0.026925213634967804, -0.01990371197462082] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1625/5550 val_loss:3.236079 train_time:400683ms step_avg:246.57ms x-lambda: 0.7919213175773621 lambdas: [-0.025141876190900803, -0.025851057842373848, -0.016649937257170677, -0.01896781474351883, -0.01249206904321909, -0.02079230546951294, -0.02248586155474186, -0.016628868877887726, -0.023396428674459457, -0.01942571811378002, -0.024755854159593582, -0.024479085579514503, -0.01866529881954193] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1750/5550 val_loss:3.221092 train_time:432349ms step_avg:247.06ms x-lambda: 0.7676637172698975 lambdas: [-0.022244231775403023, -0.024642473086714745, -0.014270395040512085, -0.016797538846731186, -0.010902074165642262, -0.018678167834877968, -0.02022186852991581, -0.013707835227251053, -0.02106700837612152, -0.01699536107480526, -0.022510657086968422, -0.024334944784641266, -0.01740509271621704] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:1875/5550 val_loss:3.206013 train_time:464094ms step_avg:247.52ms x-lambda: 0.7470707297325134 lambdas: [-0.02487110160291195, -0.025248875841498375, -0.016701700165867805, -0.018313201144337654, -0.013100686483085155, -0.020256929099559784, -0.021298788487911224, -0.01614307425916195, -0.02192515879869461, -0.01938101463019848, -0.024229316040873528, -0.025666018947958946, -0.017957575619220734] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2000/5550 val_loss:3.186994 train_time:496030ms step_avg:248.02ms x-lambda: 0.7284124493598938 lambdas: [-0.021611742675304413, -0.02250666730105877, -0.013108705170452595, -0.017115190625190735, -0.011734726838767529, -0.01750112883746624, -0.018357282504439354, -0.012539923191070557, -0.02083289995789528, -0.01654890552163124, -0.022179948166012764, -0.023209402337670326, -0.014853043481707573] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2125/5550 val_loss:3.172669 train_time:527938ms step_avg:248.44ms x-lambda: 0.7162793278694153 lambdas: [-0.02122589573264122, -0.021651268005371094, -0.013440622016787529, -0.015969013795256615, -0.009958749637007713, -0.016461415216326714, -0.01885964348912239, -0.0136391781270504, -0.01932215318083763, -0.01642570272088051, -0.02054319716989994, -0.022051004692912102, -0.01562487706542015] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2250/5550 val_loss:3.158681 train_time:559865ms step_avg:248.83ms x-lambda: 0.7045491337776184 lambdas: [-0.02026759646832943, -0.02176976576447487, -0.013066318817436695, -0.015208045020699501, -0.010083961300551891, -0.016120199114084244, -0.017800547182559967, -0.013105056248605251, -0.018967607989907265, -0.01535283774137497, -0.02021232433617115, -0.02082868665456772, -0.015062984079122543] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2375/5550 val_loss:3.147970 train_time:591806ms step_avg:249.18ms x-lambda: 0.6948652863502502 lambdas: [-0.018190188333392143, -0.01967734284698963, -0.011890639550983906, -0.013792439363896847, -0.008713765069842339, -0.015284988097846508, -0.016380805522203445, -0.011113240383565426, -0.018755003809928894, -0.01410883478820324, -0.018798954784870148, -0.019331615418195724, -0.013972793705761433] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2500/5550 val_loss:3.135755 train_time:623680ms step_avg:249.47ms x-lambda: 0.6854989528656006 lambdas: [-0.01879141293466091, -0.020007893443107605, -0.012330630794167519, -0.015043589286506176, -0.009924815967679024, -0.015754515305161476, -0.016259655356407166, -0.012198400683701038, -0.018853312358260155, -0.013985864818096161, -0.01936490833759308, -0.019717609509825706, -0.01389544177800417] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2625/5550 val_loss:3.123861 train_time:655580ms step_avg:249.74ms x-lambda: 0.6787049770355225 lambdas: [-0.017765887081623077, -0.02032489702105522, -0.012873238883912563, -0.012858466245234013, -0.009338630363345146, -0.015256824903190136, -0.01732887700200081, -0.010603921487927437, -0.018396176397800446, -0.014169984497129917, -0.018112609162926674, -0.02059187926352024, -0.012852971442043781] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2750/5550 val_loss:3.112897 train_time:687467ms step_avg:249.99ms x-lambda: 0.6724306344985962 lambdas: [-0.018068084493279457, -0.019897649064660072, -0.0126994913443923, -0.014338244684040546, -0.009610832668840885, -0.014639237895607948, -0.017059586942195892, -0.010761057026684284, -0.01712888292968273, -0.014495650306344032, -0.017983177676796913, -0.019541338086128235, -0.013370996341109276] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:2875/5550 val_loss:3.104470 train_time:719449ms step_avg:250.24ms x-lambda: 0.6685698628425598 lambdas: [-0.017387721687555313, -0.017886709421873093, -0.010154394432902336, -0.012845482677221298, -0.008036499843001366, -0.013627315871417522, -0.014683475717902184, -0.009651293978095055, -0.016212698072195053, -0.012844262644648552, -0.016795935109257698, -0.018374821171164513, -0.011838654987514019] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3000/5550 val_loss:3.094496 train_time:751421ms step_avg:250.47ms x-lambda: 0.6656171679496765 lambdas: [-0.016155961900949478, -0.01759207993745804, -0.009144454263150692, -0.011601218022406101, -0.007074334658682346, -0.012338211759924889, -0.014121036976575851, -0.009597568772733212, -0.015703624114394188, -0.011966804973781109, -0.016503993421792984, -0.017482858151197433, -0.011391466483473778] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3125/5550 val_loss:3.082489 train_time:783381ms step_avg:250.68ms x-lambda: 0.6607963442802429 lambdas: [-0.016163451597094536, -0.018650103360414505, -0.010510558262467384, -0.012680239044129848, -0.010064604692161083, -0.013510084711015224, -0.01646539755165577, -0.012113988399505615, -0.017491133883595467, -0.014028741978108883, -0.017554080113768578, -0.019325843080878258, -0.012806977145373821] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3250/5550 val_loss:3.070846 train_time:815334ms step_avg:250.87ms x-lambda: 0.6596015095710754 lambdas: [-0.016961202025413513, -0.01835973747074604, -0.010744104161858559, -0.011930116452276707, -0.009713797830045223, -0.013241616077721119, -0.0153626324608922, -0.01103183627128601, -0.016464224085211754, -0.012264620512723923, -0.017933454364538193, -0.01814408041536808, -0.013244327157735825] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3375/5550 val_loss:3.064581 train_time:847228ms step_avg:251.03ms x-lambda: 0.6583714485168457 lambdas: [-0.017281027510762215, -0.019108884036540985, -0.012481365352869034, -0.01169147901237011, -0.01050947979092598, -0.0146742332726717, -0.016485609114170074, -0.011211425065994263, -0.016842825338244438, -0.014989380724728107, -0.01685146614909172, -0.01974477246403694, -0.014822658151388168] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3500/5550 val_loss:3.054776 train_time:879187ms step_avg:251.20ms x-lambda: 0.6572867631912231 lambdas: [-0.017549928277730942, -0.018128056079149246, -0.011669520288705826, -0.012690529227256775, -0.010420234873890877, -0.015213891863822937, -0.016033394262194633, -0.01192411221563816, -0.016440890729427338, -0.013723783195018768, -0.01723007671535015, -0.01946534588932991, -0.01320676226168871] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3625/5550 val_loss:3.044921 train_time:911109ms step_avg:251.34ms x-lambda: 0.6593319773674011 lambdas: [-0.01699347421526909, -0.016731765121221542, -0.01031157560646534, -0.012408276088535786, -0.008761768229305744, -0.012624185532331467, -0.013845408335328102, -0.010499398224055767, -0.015664633363485336, -0.012305950745940208, -0.017386863008141518, -0.01610662043094635, -0.011955995112657547] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3750/5550 val_loss:3.035044 train_time:943056ms step_avg:251.48ms x-lambda: 0.6581010222434998 lambdas: [-0.015031380578875542, -0.017894361168146133, -0.011096888221800327, -0.010888908989727497, -0.008522134274244308, -0.011927871033549309, -0.014327764511108398, -0.010683546774089336, -0.015907591208815575, -0.012799330987036228, -0.016600528731942177, -0.01791093870997429, -0.012408719398081303] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:3875/5550 val_loss:3.026189 train_time:975098ms step_avg:251.64ms x-lambda: 0.6642886996269226 lambdas: [-0.016097376123070717, -0.015679845586419106, -0.010096888989210129, -0.011180189438164234, -0.007913741283118725, -0.01240275613963604, -0.01384254265576601, -0.010630784556269646, -0.01530427485704422, -0.011606018990278244, -0.01514583732932806, -0.017245367169380188, -0.011356518603861332] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4000/5550 val_loss:3.016316 train_time:1007138ms step_avg:251.78ms x-lambda: 0.6670814752578735 lambdas: [-0.015012997202575207, -0.015403407625854015, -0.009210839867591858, -0.010626072995364666, -0.008928404189646244, -0.0129171684384346, -0.014184573665261269, -0.009943932294845581, -0.01480258721858263, -0.010927172377705574, -0.015186499804258347, -0.01650143414735794, -0.010751365683972836] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4125/5550 val_loss:3.007401 train_time:1039216ms step_avg:251.93ms x-lambda: 0.6697549819946289 lambdas: [-0.015468192286789417, -0.016603384166955948, -0.010061406530439854, -0.011902821250259876, -0.008211588487029076, -0.012793157249689102, -0.01489751785993576, -0.009305641986429691, -0.015314272604882717, -0.01242237351834774, -0.015080010518431664, -0.01597266085445881, -0.010991551913321018] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4250/5550 val_loss:2.999165 train_time:1071499ms step_avg:252.12ms x-lambda: 0.6734328269958496 lambdas: [-0.014611908234655857, -0.015871131792664528, -0.009126096963882446, -0.011165760457515717, -0.007301974575966597, -0.011700584553182125, -0.012955236248672009, -0.010354004800319672, -0.014222746714949608, -0.01078023947775364, -0.015162190422415733, -0.016049010679125786, -0.01076569128781557] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4375/5550 val_loss:2.990410 train_time:1103751ms step_avg:252.29ms x-lambda: 0.6773168444633484 lambdas: [-0.01665254682302475, -0.016659380868077278, -0.011250639334321022, -0.012650128453969955, -0.009279830381274223, -0.013455725274980068, -0.01343791838735342, -0.011033225804567337, -0.015573890879750252, -0.010961221531033516, -0.01578557677567005, -0.01707507111132145, -0.013027820736169815] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4500/5550 val_loss:2.982046 train_time:1136039ms step_avg:252.45ms x-lambda: 0.681279718875885 lambdas: [-0.015374710783362389, -0.016068698838353157, -0.010094943456351757, -0.011299080215394497, -0.007818028330802917, -0.012190951965749264, -0.014081072993576527, -0.010497279465198517, -0.016118831932544708, -0.011902292259037495, -0.016067354008555412, -0.016681602224707603, -0.011693233624100685] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4625/5550 val_loss:2.972734 train_time:1168476ms step_avg:252.64ms x-lambda: 0.6890168190002441 lambdas: [-0.01656351424753666, -0.01558331772685051, -0.010828619822859764, -0.011093412525951862, -0.007885628379881382, -0.012423908337950706, -0.014754650183022022, -0.009050941094756126, -0.014898324385285378, -0.012184971012175083, -0.016245946288108826, -0.016178324818611145, -0.012183166109025478] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4750/5550 val_loss:2.963152 train_time:1201010ms step_avg:252.84ms x-lambda: 0.695006251335144 lambdas: [-0.014797287061810493, -0.015493523329496384, -0.009672882035374641, -0.01087390910834074, -0.007599023636430502, -0.012204769067466259, -0.01320620533078909, -0.010422580875456333, -0.014551247470080853, -0.010043337941169739, -0.014602705836296082, -0.01581621915102005, -0.011047407053411007] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:4875/5550 val_loss:2.954539 train_time:1233714ms step_avg:253.07ms x-lambda: 0.7012269496917725 lambdas: [-0.014731273986399174, -0.016278626397252083, -0.008700503036379814, -0.011063572950661182, -0.008718819357454777, -0.012503517791628838, -0.013673457317054272, -0.010045217350125313, -0.015266663394868374, -0.011025089770555496, -0.014813577756285667, -0.015640635043382645, -0.011444885283708572] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5000/5550 val_loss:2.946321 train_time:1266487ms step_avg:253.30ms x-lambda: 0.7091041207313538 lambdas: [-0.014321594499051571, -0.0147322379052639, -0.010160497389733791, -0.0103404326364398, -0.008404861204326153, -0.012174858711659908, -0.013677330687642097, -0.010559501126408577, -0.01371304877102375, -0.010944054462015629, -0.01494689006358385, -0.015785478055477142, -0.01062780525535345] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5125/5550 val_loss:2.938703 train_time:1299407ms step_avg:253.54ms x-lambda: 0.7162325978279114 lambdas: [-0.0151300597935915, -0.014623389579355717, -0.009937613271176815, -0.011002403683960438, -0.0073752375319600105, -0.011585621163249016, -0.012898596934974194, -0.009880653582513332, -0.014027593657374382, -0.010228474624454975, -0.015113215893507004, -0.015730123966932297, -0.010501296259462833] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5250/5550 val_loss:2.931443 train_time:1332548ms step_avg:253.82ms x-lambda: 0.7226441502571106 lambdas: [-0.013879138045012951, -0.015028189867734909, -0.010386558249592781, -0.010832805186510086, -0.007821501232683659, -0.011586375534534454, -0.012876623310148716, -0.00848628394305706, -0.014979231171309948, -0.010797489434480667, -0.015319310128688812, -0.015442455187439919, -0.010945674031972885] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5375/5550 val_loss:2.925006 train_time:1365792ms step_avg:254.10ms x-lambda: 0.7325047850608826 lambdas: [-0.01451529748737812, -0.01444725040346384, -0.009626436047255993, -0.011597649194300175, -0.007822200655937195, -0.011936887167394161, -0.013043220154941082, -0.01071353629231453, -0.014914634637534618, -0.011837325990200043, -0.01392770279198885, -0.01565845124423504, -0.010853719897568226] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5500/5550 val_loss:2.920221 train_time:1399344ms step_avg:254.43ms x-lambda: 0.736897885799408 lambdas: [-0.014592637307941914, -0.015436324290931225, -0.009839260950684547, -0.011397650465369225, -0.00787209440022707, -0.012137405574321747, -0.013370689935982227, -0.0099062230437994, -0.01437621284276247, -0.010871746577322483, -0.014626697637140751, -0.015629973262548447, -0.011318240314722061] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]
step:5550/5550 val_loss:2.919060 train_time:1412837ms step_avg:254.57ms x-lambda: 0.7383370995521545 lambdas: [-0.014724190346896648, -0.015151121653616428, -0.009469306096434593, -0.0108171496540308, -0.007783944718539715, -0.0119527792558074, -0.013284842483699322, -0.009668759070336819, -0.014575664885342121, -0.011036890558898449, -0.01462408248335123, -0.016088219359517097, -0.01099163107573986] skip-layers: [3, 11, 5, 13, 2, 1, 10, 14, 8, 9, 6, 0, 12]



## 8000-add-skip-multiple-13-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.18ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:125/5550 val_loss:4.259967 train_time:29445ms step_avg:235.56ms x-lambda: 1.025826096534729 lambdas: [-0.0008877431973814964, -0.03391629830002785, 0.025420568883419037, 0.016741514205932617, 0.029252391308546066, 0.046342480927705765, 0.025415435433387756, 0.0762278288602829, 0.02268429845571518, -0.06130914390087128, 0.024845939129590988, 0.06856837123632431, 0.02430426888167858] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:250/5550 val_loss:3.851527 train_time:59069ms step_avg:236.27ms x-lambda: 1.0289407968521118 lambdas: [-0.029776349663734436, -0.07924320548772812, 0.028715457767248154, 0.012756526470184326, 0.011112376116216183, 0.05269031226634979, 0.027664296329021454, 0.0707319900393486, 0.025398410856723785, -0.14849236607551575, -0.023390891030430794, 0.11053956300020218, -0.005153774283826351] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:375/5550 val_loss:3.673865 train_time:89082ms step_avg:237.55ms x-lambda: 1.0378663539886475 lambdas: [-0.03267187997698784, -0.09064342826604843, 0.036253638565540314, 0.013236919417977333, -0.00958251766860485, 0.042000897228717804, 0.018626650795340538, 0.060075800865888596, 0.021306253969669342, -0.1946292668581009, -0.07965344190597534, 0.11324024200439453, -0.01573934033513069] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:500/5550 val_loss:3.559965 train_time:119465ms step_avg:238.93ms x-lambda: 1.0368499755859375 lambdas: [-0.0293272677809, -0.09313629567623138, 0.04091257601976395, 0.004308151081204414, -0.02317727915942669, 0.03432351350784302, 0.001012182328850031, 0.05141829326748848, 0.0073259081691503525, -0.21719710528850555, -0.1256166696548462, 0.10902848839759827, -0.017180241644382477] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:625/5550 val_loss:3.479842 train_time:150005ms step_avg:240.01ms x-lambda: 1.0333950519561768 lambdas: [-0.023460378870368004, -0.09022147953510284, 0.04431900009512901, -0.004353565629571676, -0.028033021837472916, 0.030605588108301163, -0.016094259917736053, 0.0456678606569767, -0.00599026819691062, -0.2219380885362625, -0.15544870495796204, 0.10432892292737961, -0.011069274507462978] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:750/5550 val_loss:3.428871 train_time:180860ms step_avg:241.15ms x-lambda: 1.0287703275680542 lambdas: [-0.018814612179994583, -0.08784106373786926, 0.045846324414014816, -0.01215012464672327, -0.028296612203121185, 0.027728557586669922, -0.03208565711975098, 0.04110449180006981, -0.01903972215950489, -0.21646277606487274, -0.17268216609954834, 0.09737487137317657, -0.006477367132902145] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:875/5550 val_loss:3.383377 train_time:211821ms step_avg:242.08ms x-lambda: 1.0200022459030151 lambdas: [-0.01395627111196518, -0.08398029953241348, 0.04553750902414322, -0.02096761018037796, -0.026949023827910423, 0.026262592524290085, -0.0483216717839241, 0.03821954503655434, -0.03258519992232323, -0.20590858161449432, -0.1837916523218155, 0.09083858132362366, -0.0029536932706832886] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1000/5550 val_loss:3.349277 train_time:243051ms step_avg:243.05ms x-lambda: 1.0125911235809326 lambdas: [-0.010880284942686558, -0.0814049169421196, 0.043928805738687515, -0.0280442014336586, -0.02669116109609604, 0.024700380861759186, -0.06435269117355347, 0.035519231110811234, -0.045292071998119354, -0.19155845046043396, -0.19006675481796265, 0.0815812274813652, 0.0006454363465309143] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1125/5550 val_loss:3.320333 train_time:274326ms step_avg:243.85ms x-lambda: 1.0045784711837769 lambdas: [-0.010308424942195415, -0.08020740747451782, 0.04047310724854469, -0.03680774196982384, -0.02658712863922119, 0.021124424412846565, -0.08020307123661041, 0.030952047556638718, -0.05929527431726456, -0.178744837641716, -0.19416925311088562, 0.07222098112106323, 0.001366137876175344] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1250/5550 val_loss:3.294358 train_time:305723ms step_avg:244.58ms x-lambda: 0.9998912811279297 lambdas: [-0.008474214933812618, -0.07725362479686737, 0.03936753794550896, -0.04124683514237404, -0.025276105850934982, 0.019589046016335487, -0.09267111867666245, 0.029003672301769257, -0.06908024847507477, -0.165407195687294, -0.1952144056558609, 0.06407064944505692, 0.00388350710272789] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1375/5550 val_loss:3.273084 train_time:337338ms step_avg:245.34ms x-lambda: 0.9922913908958435 lambdas: [-0.0075836097821593285, -0.07413577288389206, 0.036680545657873154, -0.04747828468680382, -0.024621732532978058, 0.018788060173392296, -0.10467853397130966, 0.026655614376068115, -0.07959865033626556, -0.15198121964931488, -0.19405175745487213, 0.05646025016903877, 0.004081678576767445] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1500/5550 val_loss:3.255044 train_time:368955ms step_avg:245.97ms x-lambda: 0.9869458079338074 lambdas: [-0.007563149556517601, -0.07312092185020447, 0.03551633283495903, -0.05147126689553261, -0.02447529137134552, 0.01660754531621933, -0.11571614444255829, 0.025125689804553986, -0.08870109915733337, -0.1418197751045227, -0.1941826343536377, 0.049744438380002975, 0.00598427839577198] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1625/5550 val_loss:3.238504 train_time:400620ms step_avg:246.54ms x-lambda: 0.9825960993766785 lambdas: [-0.004660565871745348, -0.07003040611743927, 0.03560785576701164, -0.055131230503320694, -0.021385954692959785, 0.017444875091314316, -0.12458070367574692, 0.024532008916139603, -0.09656902402639389, -0.1317388415336609, -0.19165728986263275, 0.04665151610970497, 0.00795560423284769] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1750/5550 val_loss:3.223007 train_time:432264ms step_avg:247.01ms x-lambda: 0.9768274426460266 lambdas: [-0.004912904929369688, -0.0681505873799324, 0.03391141816973686, -0.059923239052295685, -0.021574217826128006, 0.01744934730231762, -0.1343117356300354, 0.02316427230834961, -0.1059359610080719, -0.12234411388635635, -0.18894073367118835, 0.04111349582672119, 0.008475727401673794] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:1875/5550 val_loss:3.205698 train_time:463978ms step_avg:247.45ms x-lambda: 0.9750986099243164 lambdas: [-0.0037522027269005775, -0.06477338075637817, 0.034192245453596115, -0.061381448060274124, -0.019564861431717873, 0.016174351796507835, -0.13950058817863464, 0.023106178268790245, -0.11164910346269608, -0.11293869465589523, -0.18539324402809143, 0.037892621010541916, 0.009768732823431492] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2000/5550 val_loss:3.189870 train_time:495887ms step_avg:247.94ms x-lambda: 0.9730646014213562 lambdas: [-0.0032148980535566807, -0.06312377750873566, 0.032033927738666534, -0.06457369029521942, -0.018607698380947113, 0.016291964799165726, -0.14619991183280945, 0.02229497767984867, -0.1190376803278923, -0.10459259152412415, -0.1813179850578308, 0.03425019606947899, 0.009165419265627861] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2125/5550 val_loss:3.174302 train_time:527847ms step_avg:248.40ms x-lambda: 0.9710884094238281 lambdas: [-0.0026478469371795654, -0.06226915121078491, 0.031017346307635307, -0.06728629022836685, -0.01829197257757187, 0.015329758636653423, -0.1519012302160263, 0.021067237481474876, -0.1256047934293747, -0.09975160658359528, -0.1799796223640442, 0.031290702521800995, 0.009279986843466759] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2250/5550 val_loss:3.160949 train_time:559772ms step_avg:248.79ms x-lambda: 0.9713566303253174 lambdas: [-0.0024230554699897766, -0.060244616121053696, 0.03061368688941002, -0.06830647587776184, -0.01765221543610096, 0.015170689672231674, -0.1557561755180359, 0.020651308819651604, -0.13078638911247253, -0.09352237731218338, -0.17686763405799866, 0.030513335019350052, 0.010048833675682545] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2375/5550 val_loss:3.149718 train_time:591700ms step_avg:249.14ms x-lambda: 0.9702771902084351 lambdas: [-0.002279828302562237, -0.05871611088514328, 0.029044251888990402, -0.06988410651683807, -0.01758035272359848, 0.014119293540716171, -0.16004635393619537, 0.01906469836831093, -0.13673780858516693, -0.08890151232481003, -0.17329034209251404, 0.028022032231092453, 0.011669699102640152] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2500/5550 val_loss:3.138169 train_time:623571ms step_avg:249.43ms x-lambda: 0.9700425267219543 lambdas: [-0.0022645394783467054, -0.05705185979604721, 0.027903730049729347, -0.0706445574760437, -0.01604188047349453, 0.014244621619582176, -0.1633203625679016, 0.019256768748164177, -0.14175103604793549, -0.08464153110980988, -0.1699577271938324, 0.026183784008026123, 0.010854905471205711] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2625/5550 val_loss:3.125309 train_time:655436ms step_avg:249.69ms x-lambda: 0.9685792922973633 lambdas: [-0.0017849855357781053, -0.05595303699374199, 0.02728119120001793, -0.07247927784919739, -0.017212800681591034, 0.012961108237504959, -0.16660888493061066, 0.018490035086870193, -0.14670145511627197, -0.08090183138847351, -0.16801603138446808, 0.02480871044099331, 0.011320977471768856] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2750/5550 val_loss:3.115350 train_time:687289ms step_avg:249.92ms x-lambda: 0.9684450626373291 lambdas: [-0.002379330340772867, -0.05568040907382965, 0.02664625644683838, -0.07404506206512451, -0.016306588426232338, 0.011930251494050026, -0.17008648812770844, 0.016562465578317642, -0.15144363045692444, -0.07899253070354462, -0.16575130820274353, 0.022349227219820023, 0.010343814268708229] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:2875/5550 val_loss:3.106076 train_time:719204ms step_avg:250.16ms x-lambda: 0.9700408577919006 lambdas: [-0.0006756305228918791, -0.05368184298276901, 0.025977279990911484, -0.0742044672369957, -0.015070019289851189, 0.012478729709982872, -0.1710238754749298, 0.017495617270469666, -0.1540944129228592, -0.07430712133646011, -0.16378232836723328, 0.02168041095137596, 0.01108460407704115] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3000/5550 val_loss:3.095596 train_time:751173ms step_avg:250.39ms x-lambda: 0.9710482954978943 lambdas: [-0.0016129347495734692, -0.05196942761540413, 0.026296982541680336, -0.07442318648099899, -0.014153356663882732, 0.01154252327978611, -0.17222249507904053, 0.01650679111480713, -0.15810656547546387, -0.07087892293930054, -0.16062934696674347, 0.021396290510892868, 0.011712626554071903] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3125/5550 val_loss:3.084474 train_time:783170ms step_avg:250.61ms x-lambda: 0.9728525876998901 lambdas: [-0.0007621694239787757, -0.05192875862121582, 0.025430450215935707, -0.07478069514036179, -0.013904866762459278, 0.011492724530398846, -0.17353717982769012, 0.017233945429325104, -0.16194695234298706, -0.07047536969184875, -0.15813586115837097, 0.020629527047276497, 0.012189590372145176] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3250/5550 val_loss:3.072613 train_time:815090ms step_avg:250.80ms x-lambda: 0.9740497469902039 lambdas: [-0.0019238428212702274, -0.05180556699633598, 0.024698881432414055, -0.07588434219360352, -0.01580486074090004, 0.010329945012927055, -0.17568446695804596, 0.01613275520503521, -0.16527672111988068, -0.06701809167861938, -0.1586604118347168, 0.01928965002298355, 0.01099126785993576] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3375/5550 val_loss:3.063539 train_time:846989ms step_avg:250.96ms x-lambda: 0.9761354327201843 lambdas: [-0.0007165164570324123, -0.05096600577235222, 0.0239870548248291, -0.07667569816112518, -0.014039425179362297, 0.011291190050542355, -0.17722611129283905, 0.015397995710372925, -0.16883224248886108, -0.0672040730714798, -0.15680401027202606, 0.01926819235086441, 0.011633653193712234] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3500/5550 val_loss:3.056024 train_time:878927ms step_avg:251.12ms x-lambda: 0.9774522185325623 lambdas: [-0.002372395945712924, -0.05071978271007538, 0.022481214255094528, -0.07781418412923813, -0.014866997487843037, 0.008980507962405682, -0.17907212674617767, 0.014696034602820873, -0.1723220944404602, -0.06476256251335144, -0.15462413430213928, 0.016785509884357452, 0.009757447987794876] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3625/5550 val_loss:3.046449 train_time:910848ms step_avg:251.27ms x-lambda: 0.9813271164894104 lambdas: [-0.002778222318738699, -0.04989927262067795, 0.02334134839475155, -0.07640085369348526, -0.014341164380311966, 0.008955196477472782, -0.17877976596355438, 0.015482890419661999, -0.17424775660037994, -0.06185974180698395, -0.15162795782089233, 0.017829500138759613, 0.01205002423375845] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3750/5550 val_loss:3.037219 train_time:942762ms step_avg:251.40ms x-lambda: 0.983440101146698 lambdas: [-0.0015971376560628414, -0.04878760874271393, 0.022515205666422844, -0.07646627724170685, -0.013817687518894672, 0.01031105313450098, -0.18056641519069672, 0.0159076526761055, -0.17708958685398102, -0.06061890721321106, -0.1522861272096634, 0.016185734421014786, 0.011378834955394268] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:3875/5550 val_loss:3.028244 train_time:974770ms step_avg:251.55ms x-lambda: 0.9881933927536011 lambdas: [-0.002036870224401355, -0.04840916767716408, 0.022471792995929718, -0.07487902790307999, -0.01397598534822464, 0.009392183274030685, -0.18066267669200897, 0.014841422438621521, -0.17933763563632965, -0.059161100536584854, -0.15138770639896393, 0.0169040709733963, 0.01121288351714611] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4000/5550 val_loss:3.018735 train_time:1006732ms step_avg:251.68ms x-lambda: 0.9927077293395996 lambdas: [-0.00036101421574130654, -0.047819022089242935, 0.02207191102206707, -0.07468349486589432, -0.013176019303500652, 0.009386049583554268, -0.18180082738399506, 0.015091569162905216, -0.1820022016763687, -0.05924280732870102, -0.14903903007507324, 0.01655508205294609, 0.011372651904821396] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4125/5550 val_loss:3.009537 train_time:1038754ms step_avg:251.82ms x-lambda: 0.996316134929657 lambdas: [-0.002617811318486929, -0.04778822138905525, 0.022749681025743484, -0.07524100691080093, -0.01371278427541256, 0.008828666992485523, -0.18265189230442047, 0.015419195406138897, -0.1848589926958084, -0.05771040543913841, -0.14816388487815857, 0.015606626868247986, 0.012012884952127934] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4250/5550 val_loss:3.001190 train_time:1070948ms step_avg:251.99ms x-lambda: 1.0009747743606567 lambdas: [-0.0018875390524044633, -0.04715237393975258, 0.021447427570819855, -0.07397601008415222, -0.013470723293721676, 0.00985740777105093, -0.18289004266262054, 0.01464963797479868, -0.1859866827726364, -0.05703791230916977, -0.14890162646770477, 0.01618782803416252, 0.010997971519827843] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4375/5550 val_loss:2.992297 train_time:1103200ms step_avg:252.16ms x-lambda: 1.004585862159729 lambdas: [-0.0010067556286230683, -0.04808294400572777, 0.021371759474277496, -0.07491228729486465, -0.012798983603715897, 0.008607283234596252, -0.18494005501270294, 0.014490778557956219, -0.18915030360221863, -0.05654199793934822, -0.14833442866802216, 0.015420573763549328, 0.010920855216681957] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4500/5550 val_loss:2.983765 train_time:1135482ms step_avg:252.33ms x-lambda: 1.0094807147979736 lambdas: [-0.0009705385309644043, -0.046242475509643555, 0.020126881077885628, -0.07433014363050461, -0.01317854505032301, 0.007937636226415634, -0.1862293779850006, 0.014284921810030937, -0.19110746681690216, -0.05408453196287155, -0.14736300706863403, 0.014222306199371815, 0.010609157383441925] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4625/5550 val_loss:2.974426 train_time:1167876ms step_avg:252.51ms x-lambda: 1.0161628723144531 lambdas: [-0.0013907129177823663, -0.045946888625621796, 0.0210735984146595, -0.07239034026861191, -0.012971621006727219, 0.007770290598273277, -0.1855158656835556, 0.014774739742279053, -0.1914178729057312, -0.05363485962152481, -0.14680364727973938, 0.014382240362465382, 0.01054298970848322] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4750/5550 val_loss:2.965391 train_time:1200406ms step_avg:252.72ms x-lambda: 1.021054744720459 lambdas: [-0.0004443331272341311, -0.04537847638130188, 0.021850647404789925, -0.07282422482967377, -0.0117479944601655, 0.00846901535987854, -0.18694375455379486, 0.015623187646269798, -0.19385546445846558, -0.054112594574689865, -0.14620991051197052, 0.015021373517811298, 0.011625361628830433] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:4875/5550 val_loss:2.956439 train_time:1233156ms step_avg:252.96ms x-lambda: 1.0265313386917114 lambdas: [-0.0019562586676329374, -0.04579239338636398, 0.020511368289589882, -0.07201983779668808, -0.01277311984449625, 0.007351244799792767, -0.18855498731136322, 0.014886022545397282, -0.1954551339149475, -0.05346081033349037, -0.14777885377407074, 0.014269244857132435, 0.010884411633014679] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5000/5550 val_loss:2.948376 train_time:1265914ms step_avg:253.18ms x-lambda: 1.0321956872940063 lambdas: [-0.00039187975926324725, -0.044796884059906006, 0.019718050956726074, -0.07170984894037247, -0.012157874181866646, 0.007983445189893246, -0.1888526976108551, 0.014947568066418171, -0.19695653021335602, -0.05262002348899841, -0.14648617804050446, 0.01486901380121708, 0.010705527849495411] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5125/5550 val_loss:2.940648 train_time:1298852ms step_avg:253.43ms x-lambda: 1.0369858741760254 lambdas: [-8.371194417122751e-05, -0.04490809515118599, 0.020331181585788727, -0.07115352898836136, -0.01205675769597292, 0.007712969556450844, -0.18956606090068817, 0.014300317503511906, -0.19776779413223267, -0.05226607993245125, -0.1478414386510849, 0.014552603475749493, 0.010508573614060879] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5250/5550 val_loss:2.933561 train_time:1331966ms step_avg:253.71ms x-lambda: 1.0414875745773315 lambdas: [-1.945006806636229e-05, -0.04503251612186432, 0.02003219909965992, -0.07076403498649597, -0.012148207984864712, 0.0077425935305655, -0.18997299671173096, 0.014139949344098568, -0.1992812603712082, -0.05103076994419098, -0.14632613956928253, 0.015049034729599953, 0.010828403756022453] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5375/5550 val_loss:2.927217 train_time:1365204ms step_avg:253.99ms x-lambda: 1.0455219745635986 lambdas: [9.643597877584398e-05, -0.04551789164543152, 0.019549140706658363, -0.07017511874437332, -0.011461814865469933, 0.006962024141103029, -0.19036665558815002, 0.014218779280781746, -0.19965718686580658, -0.05162232741713524, -0.14731590449810028, 0.014171186834573746, 0.010557727888226509] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5500/5550 val_loss:2.922416 train_time:1398727ms step_avg:254.31ms x-lambda: 1.0485590696334839 lambdas: [-0.0006901499000377953, -0.04562446475028992, 0.01918588951230049, -0.06970158964395523, -0.011752521619200706, 0.006805026438087225, -0.1911110281944275, 0.013986732810735703, -0.20025695860385895, -0.05108720436692238, -0.14736849069595337, 0.014221440069377422, 0.010140863247215748] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]
step:5550/5550 val_loss:2.921226 train_time:1412205ms step_avg:254.45ms x-lambda: 1.0492830276489258 lambdas: [-0.0007959840004332364, -0.045546773821115494, 0.01904924027621746, -0.06970217823982239, -0.011288912035524845, 0.007018789183348417, -0.19101639091968536, 0.0140774454921484, -0.2004031538963318, -0.05072673782706261, -0.14773885905742645, 0.014679206535220146, 0.009865956380963326] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13, 3, 9, 4, 8]



## 8000-add-skip-multiple-14-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.24ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:125/5550 val_loss:4.268432 train_time:29498ms step_avg:235.99ms x-lambda: 1.03753662109375 lambdas: [0.0003036737907677889, 0.02367202751338482, 0.014789563603699207, -0.00023332121782004833, 0.013023987412452698, 0.033361781388521194, 0.04014085978269577, 0.03479009121656418, 0.013816340826451778, 0.007861348800361156, 0.020875228568911552, 0.010161655023694038, 0.025658998638391495, 0.024835485965013504] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:250/5550 val_loss:3.859338 train_time:59132ms step_avg:236.53ms x-lambda: 1.0773231983184814 lambdas: [-0.02158445119857788, -0.000347974244505167, -0.004234889522194862, -0.022711291909217834, -0.010196479968726635, 0.016644015908241272, 0.024438360705971718, 0.015586677007377148, -0.005471932701766491, -0.01321902871131897, 0.003322348464280367, -0.0009797620587050915, -0.0026280395686626434, 0.009891068562865257] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:375/5550 val_loss:3.677968 train_time:89135ms step_avg:237.69ms x-lambda: 1.0969830751419067 lambdas: [-0.030853834003210068, -0.014649039134383202, -0.019427821040153503, -0.02874414436519146, -0.0215869452804327, -0.00012166134547442198, 0.0014507068553939462, -0.010021103546023369, -0.0187385156750679, -0.023311015218496323, -0.011903753504157066, -0.015515923500061035, -0.01816457323729992, -0.011086169630289078] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:500/5550 val_loss:3.563000 train_time:119586ms step_avg:239.17ms x-lambda: 1.0888590812683105 lambdas: [-0.034536462277173996, -0.021508092060685158, -0.02814057469367981, -0.03100821189582348, -0.029057594016194344, -0.012800261378288269, -0.012379374355077744, -0.021347451955080032, -0.02743150293827057, -0.02979738637804985, -0.021565115079283714, -0.020774636417627335, -0.025452371686697006, -0.01975865475833416] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:625/5550 val_loss:3.484232 train_time:150245ms step_avg:240.39ms x-lambda: 1.0684680938720703 lambdas: [-0.035870105028152466, -0.022785712033510208, -0.028891487047076225, -0.02947666123509407, -0.029295481741428375, -0.017633749172091484, -0.017691895365715027, -0.02480224147439003, -0.02761242911219597, -0.0272472333163023, -0.022612180560827255, -0.021030673757195473, -0.027382176369428635, -0.022059407085180283] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:750/5550 val_loss:3.429265 train_time:181205ms step_avg:241.61ms x-lambda: 1.03299880027771 lambdas: [-0.03803318366408348, -0.025764957070350647, -0.033661358058452606, -0.03202139586210251, -0.030914362519979477, -0.021835746243596077, -0.02277817577123642, -0.027363872155547142, -0.029394911602139473, -0.030356111004948616, -0.028142457827925682, -0.024765893816947937, -0.029345303773880005, -0.025268645957112312] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:875/5550 val_loss:3.383507 train_time:212271ms step_avg:242.60ms x-lambda: 0.9939262270927429 lambdas: [-0.03674280270934105, -0.0253326203674078, -0.03316359221935272, -0.030539030209183693, -0.028465300798416138, -0.0218045711517334, -0.022341737523674965, -0.027304966002702713, -0.026891840621829033, -0.028755666688084602, -0.02572595700621605, -0.022868935018777847, -0.028560971841216087, -0.02404310554265976] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1000/5550 val_loss:3.349082 train_time:243632ms step_avg:243.63ms x-lambda: 0.952233612537384 lambdas: [-0.035655178129673004, -0.026596179232001305, -0.03371565416455269, -0.029202274978160858, -0.028970923274755478, -0.023016685619950294, -0.02471480891108513, -0.029587889090180397, -0.027653606608510017, -0.02900600992143154, -0.026775972917675972, -0.0244295597076416, -0.029965417459607124, -0.025133924558758736] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1125/5550 val_loss:3.319755 train_time:275021ms step_avg:244.46ms x-lambda: 0.9160928726196289 lambdas: [-0.03412322700023651, -0.024663111194968224, -0.03271044045686722, -0.0271146260201931, -0.02814352884888649, -0.022609608247876167, -0.023891912773251534, -0.02821727842092514, -0.027714628726243973, -0.027116861194372177, -0.025442613288760185, -0.02395852841436863, -0.028080325573682785, -0.02418321557343006] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1250/5550 val_loss:3.293865 train_time:306576ms step_avg:245.26ms x-lambda: 0.8827935457229614 lambdas: [-0.0320291742682457, -0.0235611442476511, -0.029875969514250755, -0.025185536593198776, -0.025889026001095772, -0.020888185128569603, -0.022964604198932648, -0.027836186811327934, -0.026012497022747993, -0.025583557784557343, -0.025112543255090714, -0.021752556785941124, -0.02631036750972271, -0.023404933512210846] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1375/5550 val_loss:3.272208 train_time:338277ms step_avg:246.02ms x-lambda: 0.8483074307441711 lambdas: [-0.030576655641198158, -0.023478752002120018, -0.028535889461636543, -0.02384992502629757, -0.024676384404301643, -0.01982131041586399, -0.022078895941376686, -0.02711452730000019, -0.02491488680243492, -0.024042561650276184, -0.023120587691664696, -0.021310728043317795, -0.02561664767563343, -0.02219294011592865] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1500/5550 val_loss:3.253941 train_time:369964ms step_avg:246.64ms x-lambda: 0.8240054249763489 lambdas: [-0.02713979221880436, -0.020248770713806152, -0.026391897350549698, -0.02125679701566696, -0.02141122706234455, -0.01809593290090561, -0.02079932577908039, -0.024340342730283737, -0.021865475922822952, -0.021226318553090096, -0.02063721977174282, -0.01998799666762352, -0.023555118590593338, -0.020326508209109306] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1625/5550 val_loss:3.237518 train_time:401697ms step_avg:247.20ms x-lambda: 0.7970594763755798 lambdas: [-0.027158772572875023, -0.021388180553913116, -0.027221504598855972, -0.021076679229736328, -0.02305157482624054, -0.018151406198740005, -0.019916247576475143, -0.023576432839035988, -0.022705210372805595, -0.02159753255546093, -0.02102426253259182, -0.019498730078339577, -0.022877713665366173, -0.01898868754506111] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1750/5550 val_loss:3.221969 train_time:433424ms step_avg:247.67ms x-lambda: 0.7716638445854187 lambdas: [-0.025017358362674713, -0.019740190356969833, -0.02471109852194786, -0.019782233983278275, -0.020555146038532257, -0.016564158722758293, -0.018894698470830917, -0.021958790719509125, -0.01979750767350197, -0.020661823451519012, -0.020381378009915352, -0.018226400017738342, -0.02275053784251213, -0.019198186695575714] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:1875/5550 val_loss:3.203051 train_time:465210ms step_avg:248.11ms x-lambda: 0.7517125010490417 lambdas: [-0.024566208943724632, -0.01974964328110218, -0.023984679952263832, -0.019403204321861267, -0.02003641426563263, -0.017643854022026062, -0.019056186079978943, -0.02252899669110775, -0.02019467204809189, -0.02021161839365959, -0.020905140787363052, -0.019107311964035034, -0.021184829995036125, -0.019645029678940773] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2000/5550 val_loss:3.188887 train_time:497200ms step_avg:248.60ms x-lambda: 0.7333763241767883 lambdas: [-0.023102816194295883, -0.019134677946567535, -0.023053955286741257, -0.018062306568026543, -0.018963245674967766, -0.016674669459462166, -0.017345033586025238, -0.020679965615272522, -0.01943652331829071, -0.018846305087208748, -0.01823701150715351, -0.01600676216185093, -0.020370448008179665, -0.018784010782837868] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2125/5550 val_loss:3.173945 train_time:529219ms step_avg:249.04ms x-lambda: 0.7210047841072083 lambdas: [-0.022269979119300842, -0.018127895891666412, -0.022560587152838707, -0.017420746386051178, -0.018608640879392624, -0.017220161855220795, -0.017777053639292717, -0.021111637353897095, -0.019063986837863922, -0.01880667731165886, -0.019188158214092255, -0.017478520050644875, -0.02050035633146763, -0.017746366560459137] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2250/5550 val_loss:3.159598 train_time:561182ms step_avg:249.41ms x-lambda: 0.7088935375213623 lambdas: [-0.0218756515532732, -0.017660219222307205, -0.021967105567455292, -0.017627941444516182, -0.018036533147096634, -0.016633495688438416, -0.018590454012155533, -0.019981838762760162, -0.017058255150914192, -0.017616549506783485, -0.017688099294900894, -0.01572996936738491, -0.0191261675208807, -0.016738509759306908] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2375/5550 val_loss:3.148373 train_time:593187ms step_avg:249.76ms x-lambda: 0.6984421014785767 lambdas: [-0.020137876272201538, -0.01773807220160961, -0.021284783259034157, -0.01691913604736328, -0.01793506182730198, -0.01679578796029091, -0.01907237060368061, -0.020132657140493393, -0.01880444958806038, -0.017208432778716087, -0.019507624208927155, -0.017018765211105347, -0.019918913021683693, -0.01670638471841812] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2500/5550 val_loss:3.137153 train_time:625136ms step_avg:250.05ms x-lambda: 0.6911444067955017 lambdas: [-0.01948550157248974, -0.01669173873960972, -0.020631536841392517, -0.01451098918914795, -0.015301499515771866, -0.014199059456586838, -0.01666261814534664, -0.019009575247764587, -0.016938626766204834, -0.01709427684545517, -0.0176656823605299, -0.015422498807311058, -0.018961142748594284, -0.01577887497842312] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2625/5550 val_loss:3.125601 train_time:657101ms step_avg:250.32ms x-lambda: 0.6830416917800903 lambdas: [-0.01997954770922661, -0.017166947945952415, -0.021847840398550034, -0.015837576240301132, -0.01748228631913662, -0.016637694090604782, -0.017738545313477516, -0.018852220848202705, -0.017394261434674263, -0.017643650993704796, -0.017484508454799652, -0.016581259667873383, -0.01950305886566639, -0.01628897152841091] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2750/5550 val_loss:3.114600 train_time:689053ms step_avg:250.56ms x-lambda: 0.6761171817779541 lambdas: [-0.019222598522901535, -0.016040999442338943, -0.02013789489865303, -0.016016298905014992, -0.017489777877926826, -0.01590712182223797, -0.01632028818130493, -0.018524235114455223, -0.017987491562962532, -0.01669365167617798, -0.01607632078230381, -0.016005469486117363, -0.018519308418035507, -0.016899075359106064] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:2875/5550 val_loss:3.105264 train_time:721012ms step_avg:250.79ms x-lambda: 0.6721376180648804 lambdas: [-0.017643414437770844, -0.015524549409747124, -0.019448066130280495, -0.01354848314076662, -0.013869808986783028, -0.01379579957574606, -0.015579268336296082, -0.018995065242052078, -0.01614762470126152, -0.014561924152076244, -0.015824243426322937, -0.014052320271730423, -0.01676538586616516, -0.015128988772630692] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3000/5550 val_loss:3.093756 train_time:753003ms step_avg:251.00ms x-lambda: 0.6688907742500305 lambdas: [-0.01793719083070755, -0.015568055212497711, -0.019343381747603416, -0.01468583568930626, -0.014287931844592094, -0.01496616005897522, -0.015658695250749588, -0.017040075734257698, -0.01573309674859047, -0.01571895368397236, -0.015306180343031883, -0.013672969304025173, -0.01702333241701126, -0.014222756959497929] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3125/5550 val_loss:3.083796 train_time:785011ms step_avg:251.20ms x-lambda: 0.6655333042144775 lambdas: [-0.018661154434084892, -0.016690753400325775, -0.021039385348558426, -0.014912590384483337, -0.016102124005556107, -0.015650654211640358, -0.01663701981306076, -0.018343275412917137, -0.01738356240093708, -0.016860641539096832, -0.016050469130277634, -0.01569538749754429, -0.017378849908709526, -0.016399763524532318] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3250/5550 val_loss:3.071614 train_time:817050ms step_avg:251.40ms x-lambda: 0.665604293346405 lambdas: [-0.016575610265135765, -0.015184804797172546, -0.01880214922130108, -0.014200759120285511, -0.014303639531135559, -0.01397243607789278, -0.015873992815613747, -0.017278505489230156, -0.015459926798939705, -0.014994767494499683, -0.015399057418107986, -0.014829134568572044, -0.017233777791261673, -0.013736926019191742] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3375/5550 val_loss:3.063972 train_time:849066ms step_avg:251.58ms x-lambda: 0.6642209887504578 lambdas: [-0.018169226124882698, -0.015514039434492588, -0.019521305337548256, -0.013957149349153042, -0.0151405930519104, -0.014925839379429817, -0.01667344756424427, -0.01765894889831543, -0.016072062775492668, -0.015774831175804138, -0.016178682446479797, -0.014410596340894699, -0.01859300024807453, -0.0159487072378397] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3500/5550 val_loss:3.054699 train_time:881047ms step_avg:251.73ms x-lambda: 0.6625637412071228 lambdas: [-0.017853910103440285, -0.01574498787522316, -0.01906389743089676, -0.014941776171326637, -0.014272225089371204, -0.015095305629074574, -0.016609711572527885, -0.017837194725871086, -0.01627987250685692, -0.01458128821104765, -0.016224388033151627, -0.014683938585221767, -0.017124023288488388, -0.014865350909531116] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3625/5550 val_loss:3.045230 train_time:913006ms step_avg:251.86ms x-lambda: 0.6645212173461914 lambdas: [-0.0167235117405653, -0.013880393467843533, -0.01760157011449337, -0.012967622838914394, -0.012249798513948917, -0.014103632420301437, -0.014046595431864262, -0.016549760475754738, -0.014378511346876621, -0.014400199055671692, -0.014012722298502922, -0.014075858518481255, -0.01639608107507229, -0.01425531879067421] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3750/5550 val_loss:3.035458 train_time:944956ms step_avg:251.99ms x-lambda: 0.6638965606689453 lambdas: [-0.015624496154487133, -0.012923896312713623, -0.01825156807899475, -0.01273581013083458, -0.013545474037528038, -0.013786916621029377, -0.014608019962906837, -0.01682237908244133, -0.014570022001862526, -0.014078058302402496, -0.01440555602312088, -0.014191148802638054, -0.015682576224207878, -0.013757896609604359] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:3875/5550 val_loss:3.027021 train_time:977007ms step_avg:252.13ms x-lambda: 0.6699984669685364 lambdas: [-0.016437187790870667, -0.014701568521559238, -0.01706155762076378, -0.012221687473356724, -0.013037383556365967, -0.014139065518975258, -0.015189946629106998, -0.016553102061152458, -0.013964814133942127, -0.014770515263080597, -0.01403303723782301, -0.012974181212484837, -0.016508974134922028, -0.014318658038973808] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4000/5550 val_loss:3.017461 train_time:1009008ms step_avg:252.25ms x-lambda: 0.6709721684455872 lambdas: [-0.016955846920609474, -0.014157172292470932, -0.018535209819674492, -0.012282785028219223, -0.012477662414312363, -0.013483097776770592, -0.015404317528009415, -0.01612834818661213, -0.0138991205021739, -0.014422406442463398, -0.01382576022297144, -0.01343903224915266, -0.015312083065509796, -0.014594074338674545] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4125/5550 val_loss:3.008106 train_time:1041071ms step_avg:252.38ms x-lambda: 0.6748870015144348 lambdas: [-0.015733588486909866, -0.013029515743255615, -0.016834136098623276, -0.01227935217320919, -0.012837116606533527, -0.013483618386089802, -0.014257324859499931, -0.015894010663032532, -0.013911334797739983, -0.01283357385545969, -0.014011186547577381, -0.013652894645929337, -0.01566220633685589, -0.013633445836603642] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4250/5550 val_loss:3.000056 train_time:1073313ms step_avg:252.54ms x-lambda: 0.677761435508728 lambdas: [-0.017068227753043175, -0.012285087257623672, -0.017778456211090088, -0.01237893383949995, -0.011840896680951118, -0.012814003974199295, -0.013935924507677555, -0.017513398081064224, -0.011906793341040611, -0.013932948000729084, -0.013599644415080547, -0.013805229216814041, -0.01490629743784666, -0.013795880600810051] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4375/5550 val_loss:2.990659 train_time:1105592ms step_avg:252.71ms x-lambda: 0.680711567401886 lambdas: [-0.016185743734240532, -0.014505348168313503, -0.017107246443629265, -0.01258519385010004, -0.012776058167219162, -0.013963703066110611, -0.015752989798784256, -0.016469595953822136, -0.013579608872532845, -0.013699791394174099, -0.015393989160656929, -0.01314371544867754, -0.015302589163184166, -0.014910966157913208] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4500/5550 val_loss:2.982319 train_time:1137905ms step_avg:252.87ms x-lambda: 0.6863007545471191 lambdas: [-0.014937685802578926, -0.013790306635200977, -0.017188699916005135, -0.01209336332976818, -0.01268451102077961, -0.013251655735075474, -0.014583584852516651, -0.016050683334469795, -0.014129300601780415, -0.014169758185744286, -0.014721648767590523, -0.013038159348070621, -0.015282806009054184, -0.013365224003791809] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4625/5550 val_loss:2.973335 train_time:1170376ms step_avg:253.05ms x-lambda: 0.6929662227630615 lambdas: [-0.01667422614991665, -0.0141746886074543, -0.017577679827809334, -0.009955598041415215, -0.0108941113576293, -0.015183255076408386, -0.015258239582180977, -0.01587391458451748, -0.014022434130311012, -0.014661730267107487, -0.016362115740776062, -0.012621515430510044, -0.016445258632302284, -0.015621262602508068] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4750/5550 val_loss:2.963875 train_time:1202921ms step_avg:253.25ms x-lambda: 0.6985252499580383 lambdas: [-0.014923726208508015, -0.013198288157582283, -0.01656460016965866, -0.011186989024281502, -0.011708326637744904, -0.013219034299254417, -0.014941597357392311, -0.01486339420080185, -0.012589984573423862, -0.011756139807403088, -0.015330986119806767, -0.013376802206039429, -0.014606500044465065, -0.013209996744990349] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:4875/5550 val_loss:2.954945 train_time:1235670ms step_avg:253.47ms x-lambda: 0.704996645450592 lambdas: [-0.015517583116889, -0.014300944283604622, -0.017142795026302338, -0.012454614974558353, -0.012088760733604431, -0.013577674515545368, -0.014980628155171871, -0.016279611736536026, -0.013237075880169868, -0.013421755284070969, -0.014157865196466446, -0.013643869198858738, -0.01585627906024456, -0.012971273623406887] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5000/5550 val_loss:2.947006 train_time:1268511ms step_avg:253.70ms x-lambda: 0.7108185887336731 lambdas: [-0.015228640288114548, -0.013095290400087833, -0.01733344979584217, -0.011506644077599049, -0.01204165443778038, -0.013848488219082355, -0.014247028157114983, -0.015280242078006268, -0.013204463757574558, -0.01354979071766138, -0.014928553253412247, -0.012614903971552849, -0.014866313897073269, -0.013380061835050583] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5125/5550 val_loss:2.939264 train_time:1301475ms step_avg:253.95ms x-lambda: 0.7185113430023193 lambdas: [-0.014986930415034294, -0.01332052145153284, -0.016522075980901718, -0.011440055444836617, -0.011835084296762943, -0.013725198805332184, -0.015019774436950684, -0.015999365597963333, -0.013030094094574451, -0.012526481412351131, -0.013993554748594761, -0.012909377925097942, -0.014823811128735542, -0.013445260934531689] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5250/5550 val_loss:2.931995 train_time:1334641ms step_avg:254.22ms x-lambda: 0.7242587804794312 lambdas: [-0.014606386423110962, -0.012551791965961456, -0.017039954662322998, -0.011303510516881943, -0.011365361511707306, -0.013008867390453815, -0.015361424535512924, -0.0154501311480999, -0.012945972383022308, -0.01311060693114996, -0.014082061126828194, -0.012871205806732178, -0.015492883510887623, -0.013261869549751282] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5375/5550 val_loss:2.925667 train_time:1367948ms step_avg:254.50ms x-lambda: 0.7316267490386963 lambdas: [-0.014675190672278404, -0.01350642740726471, -0.01689274050295353, -0.011384718120098114, -0.011747811920940876, -0.013589964248239994, -0.015252984128892422, -0.015487282536923885, -0.01337506901472807, -0.01367732509970665, -0.01363355666399002, -0.012299814261496067, -0.014728744514286518, -0.012770276516675949] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5500/5550 val_loss:2.920861 train_time:1401511ms step_avg:254.82ms x-lambda: 0.7364909052848816 lambdas: [-0.01520367618650198, -0.013619049452245235, -0.016749700531363487, -0.011944201774895191, -0.011947098188102245, -0.013280654326081276, -0.015184948220849037, -0.015719445422291756, -0.013692794367671013, -0.013347111642360687, -0.014123298227787018, -0.012552511878311634, -0.015143092721700668, -0.0131337009370327] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]
step:5550/5550 val_loss:2.919666 train_time:1414999ms step_avg:254.95ms x-lambda: 0.7375054955482483 lambdas: [-0.01500009372830391, -0.013718622736632824, -0.016747064888477325, -0.011789942160248756, -0.011596892029047012, -0.013174626976251602, -0.014946192502975464, -0.01571517065167427, -0.013191827572882175, -0.013269001618027687, -0.014160610735416412, -0.013041824102401733, -0.01556883193552494, -0.013756049796938896] skip-layers: [13, 0, 7, 2, 12, 11, 5, 10, 4, 14, 1, 3, 8, 6]



## 8000-add-skip-multiple-7-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:125/5550 val_loss:4.262842 train_time:29190ms step_avg:233.52ms x-lambda: 1.0342769622802734 lambdas: [0.04025881737470627, 0.043332312256097794, 0.030160952359437943, 0.07456249743700027, 0.02944442816078663, -0.03816748410463333, 0.033254459500312805] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:250/5550 val_loss:3.842973 train_time:58508ms step_avg:234.03ms x-lambda: 1.0048750638961792 lambdas: [0.03920154646039009, 0.021179016679525375, -0.005519171245396137, 0.09749825298786163, -0.027601586654782295, -0.15132662653923035, 0.03698684275150299] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:375/5550 val_loss:3.672548 train_time:88257ms step_avg:235.35ms x-lambda: 0.9906021952629089 lambdas: [0.03811947628855705, -0.014691829681396484, -0.009347926825284958, 0.09226195514202118, -0.07550139725208282, -0.2009434700012207, 0.04641139134764671] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:500/5550 val_loss:3.557544 train_time:118334ms step_avg:236.67ms x-lambda: 0.9760007858276367 lambdas: [0.031112922355532646, -0.05364999547600746, -0.001959366723895073, 0.08148886263370514, -0.11430414766073227, -0.22243928909301758, 0.04471588134765625] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:625/5550 val_loss:3.478332 train_time:148648ms step_avg:237.84ms x-lambda: 0.9629529118537903 lambdas: [0.02800077758729458, -0.0855901837348938, 0.0124234389513731, 0.07542137056589127, -0.13520288467407227, -0.22256356477737427, 0.042142100632190704] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:750/5550 val_loss:3.426719 train_time:179263ms step_avg:239.02ms x-lambda: 0.9462401866912842 lambdas: [0.02348671853542328, -0.11391901224851608, 0.02039308287203312, 0.06584057211875916, -0.14519132673740387, -0.21809349954128265, 0.03522159904241562] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:875/5550 val_loss:3.381476 train_time:209968ms step_avg:239.96ms x-lambda: 0.9272782802581787 lambdas: [0.02143448032438755, -0.1377352774143219, 0.027767671272158623, 0.060675326734781265, -0.14701542258262634, -0.20523212850093842, 0.02800336480140686] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1000/5550 val_loss:3.346772 train_time:240964ms step_avg:240.96ms x-lambda: 0.906797468662262 lambdas: [0.018444467335939407, -0.16046474874019623, 0.027896851301193237, 0.05198218300938606, -0.1470314860343933, -0.19231072068214417, 0.017493225634098053] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1125/5550 val_loss:3.318202 train_time:272001ms step_avg:241.78ms x-lambda: 0.8881104588508606 lambdas: [0.018528178334236145, -0.17738041281700134, 0.030484728515148163, 0.04448745399713516, -0.14252892136573792, -0.178585484623909, 0.008323771879076958] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1250/5550 val_loss:3.293591 train_time:303167ms step_avg:242.53ms x-lambda: 0.8747640252113342 lambdas: [0.021021896973252296, -0.18888641893863678, 0.03473847359418869, 0.04228346422314644, -0.1340869516134262, -0.16471856832504272, 0.001989788841456175] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1375/5550 val_loss:3.271639 train_time:334517ms step_avg:243.29ms x-lambda: 0.8555143475532532 lambdas: [0.02189459279179573, -0.20085971057415009, 0.03369908034801483, 0.03776051849126816, -0.12956732511520386, -0.1534045934677124, -0.007937351241707802] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1500/5550 val_loss:3.253392 train_time:365852ms step_avg:243.90ms x-lambda: 0.8443533182144165 lambdas: [0.025530386716127396, -0.2104170173406601, 0.03361949324607849, 0.034213922917842865, -0.12292920798063278, -0.14385782182216644, -0.015354680828750134] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1625/5550 val_loss:3.237522 train_time:397237ms step_avg:244.45ms x-lambda: 0.8290373682975769 lambdas: [0.02875511720776558, -0.21850967407226562, 0.03533035144209862, 0.03226739168167114, -0.11728371679782867, -0.13409385085105896, -0.024729972705245018] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1750/5550 val_loss:3.221217 train_time:428589ms step_avg:244.91ms x-lambda: 0.8144050240516663 lambdas: [0.030459392815828323, -0.2263411432504654, 0.03505131974816322, 0.028134187683463097, -0.11439226567745209, -0.12590669095516205, -0.03384322673082352] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:1875/5550 val_loss:3.204913 train_time:460009ms step_avg:245.34ms x-lambda: 0.80597323179245 lambdas: [0.03682948276400566, -0.23006665706634521, 0.03667910769581795, 0.028092507272958755, -0.10776117444038391, -0.11745352298021317, -0.03823338449001312] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2000/5550 val_loss:3.189168 train_time:491623ms step_avg:245.81ms x-lambda: 0.793698787689209 lambdas: [0.040172796696424484, -0.233694389462471, 0.03552183508872986, 0.0257660411298275, -0.10456077009439468, -0.11051370948553085, -0.046278636902570724] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2125/5550 val_loss:3.173102 train_time:523283ms step_avg:246.25ms x-lambda: 0.7851005792617798 lambdas: [0.04156829044222832, -0.23913787305355072, 0.033172883093357086, 0.022867176681756973, -0.10252442955970764, -0.1077406257390976, -0.05347317457199097] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2250/5550 val_loss:3.158710 train_time:554940ms step_avg:246.64ms x-lambda: 0.7789581418037415 lambdas: [0.045267052948474884, -0.24133415520191193, 0.03368169441819191, 0.021092679351568222, -0.09934978932142258, -0.1015896126627922, -0.05942355841398239] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2375/5550 val_loss:3.147140 train_time:586630ms step_avg:247.00ms x-lambda: 0.7729212045669556 lambdas: [0.04825543984770775, -0.24316710233688354, 0.032213401049375534, 0.018997488543391228, -0.09677563607692719, -0.09733697772026062, -0.0645914301276207] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2500/5550 val_loss:3.136334 train_time:618246ms step_avg:247.30ms x-lambda: 0.7688145041465759 lambdas: [0.051332972943782806, -0.243842214345932, 0.03171106055378914, 0.01976369507610798, -0.09394621104001999, -0.09231039881706238, -0.06923367083072662] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2625/5550 val_loss:3.124419 train_time:649889ms step_avg:247.58ms x-lambda: 0.7646245360374451 lambdas: [0.05401155352592468, -0.24517294764518738, 0.03238360956311226, 0.018504474312067032, -0.09000891447067261, -0.08724173903465271, -0.07414702326059341] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2750/5550 val_loss:3.113162 train_time:681525ms step_avg:247.83ms x-lambda: 0.7611450552940369 lambdas: [0.057040516287088394, -0.24606561660766602, 0.032119251787662506, 0.018534552305936813, -0.08829552680253983, -0.0853000357747078, -0.07901355624198914] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:2875/5550 val_loss:3.103507 train_time:713182ms step_avg:248.06ms x-lambda: 0.7591404914855957 lambdas: [0.05922640115022659, -0.24741899967193604, 0.029843032360076904, 0.016916198655962944, -0.08859562128782272, -0.08289245516061783, -0.08277932554483414] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3000/5550 val_loss:3.093343 train_time:744856ms step_avg:248.29ms x-lambda: 0.7583160400390625 lambdas: [0.06108501926064491, -0.24770838022232056, 0.030286233872175217, 0.015991777181625366, -0.08432455360889435, -0.08020557463169098, -0.08601053804159164] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3125/5550 val_loss:3.083129 train_time:776544ms step_avg:248.49ms x-lambda: 0.7559353113174438 lambdas: [0.06062277778983116, -0.24902017414569855, 0.028973832726478577, 0.014283467084169388, -0.08477572351694107, -0.08024850487709045, -0.09124504774808884] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3250/5550 val_loss:3.070942 train_time:808222ms step_avg:248.68ms x-lambda: 0.7576207518577576 lambdas: [0.06331585347652435, -0.2485799640417099, 0.03007478639483452, 0.014999795705080032, -0.08237714320421219, -0.0761629268527031, -0.09261865168809891] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3375/5550 val_loss:3.061879 train_time:839866ms step_avg:248.85ms x-lambda: 0.7579564452171326 lambdas: [0.0645131766796112, -0.24941758811473846, 0.0295600313693285, 0.01443489920347929, -0.08082341402769089, -0.07478605210781097, -0.096617691218853] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3500/5550 val_loss:3.054075 train_time:871543ms step_avg:249.01ms x-lambda: 0.7574824690818787 lambdas: [0.06500227004289627, -0.25028935074806213, 0.02736414223909378, 0.012251434847712517, -0.08122918754816055, -0.07418835163116455, -0.100743368268013] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3625/5550 val_loss:3.044550 train_time:903194ms step_avg:249.16ms x-lambda: 0.7605494260787964 lambdas: [0.0680612251162529, -0.24893143773078918, 0.029314745217561722, 0.01268500741571188, -0.07861104607582092, -0.07213754951953888, -0.10180152207612991] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3750/5550 val_loss:3.035142 train_time:934834ms step_avg:249.29ms x-lambda: 0.7611035108566284 lambdas: [0.06909486651420593, -0.248676136136055, 0.029289696365594864, 0.012967213056981564, -0.07679237425327301, -0.0696137472987175, -0.10491804778575897] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:3875/5550 val_loss:3.025718 train_time:966556ms step_avg:249.43ms x-lambda: 0.7666594386100769 lambdas: [0.07053808122873306, -0.2505812644958496, 0.028027165681123734, 0.012501860037446022, -0.07791143655776978, -0.06892268359661102, -0.10583028942346573] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4000/5550 val_loss:3.016794 train_time:998251ms step_avg:249.56ms x-lambda: 0.7689469456672668 lambdas: [0.07170721143484116, -0.2508091926574707, 0.027080507948994637, 0.011946785263717175, -0.07679544389247894, -0.06837483495473862, -0.10911636799573898] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4125/5550 val_loss:3.007302 train_time:1029989ms step_avg:249.69ms x-lambda: 0.7734602093696594 lambdas: [0.0718197226524353, -0.251047283411026, 0.02740505337715149, 0.012154732830822468, -0.07532669603824615, -0.06678157299757004, -0.11091414839029312] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4250/5550 val_loss:2.999374 train_time:1061947ms step_avg:249.87ms x-lambda: 0.7773287892341614 lambdas: [0.07448571175336838, -0.25095072388648987, 0.028185853734612465, 0.012455266900360584, -0.07564479857683182, -0.06608262658119202, -0.11225155740976334] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4375/5550 val_loss:2.990106 train_time:1093936ms step_avg:250.04ms x-lambda: 0.7796964645385742 lambdas: [0.07313749194145203, -0.2526187300682068, 0.027589695528149605, 0.011853497475385666, -0.0760948434472084, -0.0662066638469696, -0.11613259464502335] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4500/5550 val_loss:2.982300 train_time:1125969ms step_avg:250.22ms x-lambda: 0.7845126390457153 lambdas: [0.0744711384177208, -0.2539934515953064, 0.02750411070883274, 0.009768184274435043, -0.07539677619934082, -0.06312096118927002, -0.11748341470956802] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4625/5550 val_loss:2.972607 train_time:1158138ms step_avg:250.41ms x-lambda: 0.7908453941345215 lambdas: [0.07575416564941406, -0.2525551915168762, 0.02638639695942402, 0.010837857611477375, -0.07479790598154068, -0.06349649280309677, -0.11833621561527252] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4750/5550 val_loss:2.963202 train_time:1190398ms step_avg:250.61ms x-lambda: 0.7975522875785828 lambdas: [0.07700636237859726, -0.2533796429634094, 0.026638124138116837, 0.010274392552673817, -0.07433706521987915, -0.06268612295389175, -0.11946100741624832] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:4875/5550 val_loss:2.954434 train_time:1222854ms step_avg:250.84ms x-lambda: 0.8028876781463623 lambdas: [0.07788218557834625, -0.255352258682251, 0.026030994951725006, 0.010608354583382607, -0.07396440953016281, -0.0618269257247448, -0.12082209438085556] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5000/5550 val_loss:2.946278 train_time:1255419ms step_avg:251.08ms x-lambda: 0.8102177977561951 lambdas: [0.07910624146461487, -0.2550787329673767, 0.026320811361074448, 0.009798132814466953, -0.07531385868787766, -0.06202152371406555, -0.12273621559143066] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5125/5550 val_loss:2.938655 train_time:1288094ms step_avg:251.34ms x-lambda: 0.8162524104118347 lambdas: [0.08023262023925781, -0.25660914182662964, 0.025549694895744324, 0.00934492889791727, -0.07458081841468811, -0.061217308044433594, -0.12443573027849197] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5250/5550 val_loss:2.931444 train_time:1320975ms step_avg:251.61ms x-lambda: 0.821069598197937 lambdas: [0.08089141547679901, -0.2563296854496002, 0.026234038174152374, 0.00937412679195404, -0.07445789873600006, -0.060527075082063675, -0.12565255165100098] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5375/5550 val_loss:2.925069 train_time:1353966ms step_avg:251.90ms x-lambda: 0.8262138366699219 lambdas: [0.0812033861875534, -0.25790178775787354, 0.025127075612545013, 0.009092533960938454, -0.07428831607103348, -0.06002043932676315, -0.12660717964172363] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5500/5550 val_loss:2.920247 train_time:1387236ms step_avg:252.22ms x-lambda: 0.8301933407783508 lambdas: [0.0823141559958458, -0.25779446959495544, 0.024990342557430267, 0.009015599265694618, -0.07430308312177658, -0.0600321888923645, -0.12687937915325165] skip-layers: [11, 10, 8, 4, 9, 3, 13]
step:5550/5550 val_loss:2.919064 train_time:1400616ms step_avg:252.36ms x-lambda: 0.8310113549232483 lambdas: [0.08226797729730606, -0.25866544246673584, 0.024613777175545692, 0.009082348085939884, -0.07469955086708069, -0.059735387563705444, -0.12718792259693146] skip-layers: [11, 10, 8, 4, 9, 3, 13]



## 8000-add-skip-multiple-7-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.12ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:125/5550 val_loss:4.254300 train_time:29162ms step_avg:233.29ms x-lambda: 1.0263612270355225 lambdas: [0.01976366899907589, 0.024896234273910522, 0.028651874512434006, 0.03218410909175873, 0.04197441786527634, 0.027876123785972595, 0.02801544964313507] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:250/5550 val_loss:3.852252 train_time:58513ms step_avg:234.05ms x-lambda: 1.0029754638671875 lambdas: [0.010313400998711586, 0.02179868333041668, 0.027205858379602432, 0.026478054001927376, 0.028170857578516006, -0.024455640465021133, -0.0075333621352910995] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:375/5550 val_loss:3.672759 train_time:88294ms step_avg:235.45ms x-lambda: 0.9905007481575012 lambdas: [0.008698321878910065, 0.01953553780913353, 0.022681592032313347, 0.014767831191420555, -0.025563914328813553, -0.07370712608098984, -0.017711171880364418] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:500/5550 val_loss:3.554587 train_time:118417ms step_avg:236.83ms x-lambda: 0.9789681434631348 lambdas: [0.0049086399376392365, 0.016416771337389946, 0.018853917717933655, 0.007973679341375828, -0.07653573900461197, -0.092920683324337, -0.00960907805711031] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:625/5550 val_loss:3.479679 train_time:148695ms step_avg:237.91ms x-lambda: 0.9650871157646179 lambdas: [0.00021489663049578667, 0.012956475839018822, 0.015240850858390331, 0.004060828126966953, -0.12299420684576035, -0.09677180647850037, -0.00010767090134322643] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:750/5550 val_loss:3.425457 train_time:179312ms step_avg:239.08ms x-lambda: 0.9539028406143188 lambdas: [-0.005646673031151295, 0.0068297372199594975, 0.010244032368063927, 0.0007718034903518856, -0.16503320634365082, -0.09424890577793121, 0.0028398477006703615] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:875/5550 val_loss:3.380889 train_time:210035ms step_avg:240.04ms x-lambda: 0.9397537708282471 lambdas: [-0.012195038609206676, 0.000645967258606106, 0.004802451003342867, -0.0001872192951850593, -0.20215517282485962, -0.08568976074457169, 0.007847122848033905] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1000/5550 val_loss:3.346391 train_time:241017ms step_avg:241.02ms x-lambda: 0.9292479157447815 lambdas: [-0.015208658762276173, -0.0027087226044386625, 0.002940131351351738, 0.0045613874681293964, -0.22945240139961243, -0.07444943487644196, 0.009996271692216396] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1125/5550 val_loss:3.316936 train_time:272044ms step_avg:241.82ms x-lambda: 0.9173355102539062 lambdas: [-0.02165783941745758, -0.009947601705789566, -0.0024000334087759256, 0.007836611941456795, -0.25691190361976624, -0.0665992721915245, 0.008978011086583138] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1250/5550 val_loss:3.292737 train_time:303199ms step_avg:242.56ms x-lambda: 0.9091646671295166 lambdas: [-0.02382146753370762, -0.013578251004219055, -0.004287499934434891, 0.014916865155100822, -0.27592483162879944, -0.057641271501779556, 0.011039228178560734] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1375/5550 val_loss:3.271034 train_time:334566ms step_avg:243.32ms x-lambda: 0.8961777687072754 lambdas: [-0.029208319261670113, -0.019830385223031044, -0.008270232938230038, 0.020909735932946205, -0.2939147353172302, -0.051541201770305634, 0.00931373331695795] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1500/5550 val_loss:3.252804 train_time:365860ms step_avg:243.91ms x-lambda: 0.8868597149848938 lambdas: [-0.03324456512928009, -0.025437457486987114, -0.011540014296770096, 0.028429806232452393, -0.30962878465652466, -0.04676301032304764, 0.008810671046376228] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1625/5550 val_loss:3.235785 train_time:397266ms step_avg:244.47ms x-lambda: 0.8773033022880554 lambdas: [-0.035901326686143875, -0.02938106656074524, -0.01232768315821886, 0.039143770933151245, -0.3199250400066376, -0.039564017206430435, 0.01100653875619173] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1750/5550 val_loss:3.220687 train_time:428626ms step_avg:244.93ms x-lambda: 0.8662611842155457 lambdas: [-0.04133271053433418, -0.035781025886535645, -0.016597559675574303, 0.04538404196500778, -0.33085525035858154, -0.03577376902103424, 0.009307580068707466] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:1875/5550 val_loss:3.202177 train_time:460024ms step_avg:245.35ms x-lambda: 0.8600388765335083 lambdas: [-0.04211954027414322, -0.03847809508442879, -0.01668829843401909, 0.05509292706847191, -0.3380013406276703, -0.031201152130961418, 0.01107657141983509] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2000/5550 val_loss:3.187077 train_time:491631ms step_avg:245.82ms x-lambda: 0.8525409698486328 lambdas: [-0.044882092624902725, -0.04320106282830238, -0.01904614455997944, 0.06405658274888992, -0.34280136227607727, -0.02792254462838173, 0.010295908898115158] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2125/5550 val_loss:3.172831 train_time:523285ms step_avg:246.25ms x-lambda: 0.8470540046691895 lambdas: [-0.047291021794080734, -0.047716766595840454, -0.021219126880168915, 0.07076534628868103, -0.34854573011398315, -0.0266635213047266, 0.010316881351172924] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2250/5550 val_loss:3.158138 train_time:554950ms step_avg:246.64ms x-lambda: 0.8422486782073975 lambdas: [-0.049113668501377106, -0.051645997911691666, -0.024125512689352036, 0.07789725065231323, -0.3530115485191345, -0.022945120930671692, 0.008217724971473217] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2375/5550 val_loss:3.146687 train_time:586627ms step_avg:247.00ms x-lambda: 0.8380341529846191 lambdas: [-0.05054846778512001, -0.054751649498939514, -0.02508305013179779, 0.0842728242278099, -0.35503700375556946, -0.021363699808716774, 0.009200972504913807] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2500/5550 val_loss:3.135578 train_time:618250ms step_avg:247.30ms x-lambda: 0.8352698683738708 lambdas: [-0.05116744339466095, -0.05801621451973915, -0.025999661535024643, 0.09099630266427994, -0.357328325510025, -0.01915917359292507, 0.008049516007304192] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2625/5550 val_loss:3.124697 train_time:649876ms step_avg:247.57ms x-lambda: 0.832685649394989 lambdas: [-0.05127634480595589, -0.06096351146697998, -0.02791137434542179, 0.09530265629291534, -0.3587058484554291, -0.01778859831392765, 0.009839026257395744] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2750/5550 val_loss:3.112243 train_time:681511ms step_avg:247.82ms x-lambda: 0.8293814063072205 lambdas: [-0.052972111850976944, -0.06507264822721481, -0.02945253998041153, 0.09970422834157944, -0.36043280363082886, -0.01648000441491604, 0.007546666078269482] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:2875/5550 val_loss:3.103283 train_time:713191ms step_avg:248.07ms x-lambda: 0.8277889490127563 lambdas: [-0.053651127964258194, -0.06749545782804489, -0.030557505786418915, 0.10401967912912369, -0.3624175190925598, -0.015539051033556461, 0.008186757564544678] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3000/5550 val_loss:3.091859 train_time:744844ms step_avg:248.28ms x-lambda: 0.8260593414306641 lambdas: [-0.05426399037241936, -0.07029550522565842, -0.03215256705880165, 0.10661384463310242, -0.3632810413837433, -0.015228628180921078, 0.007263556122779846] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3125/5550 val_loss:3.082272 train_time:776533ms step_avg:248.49ms x-lambda: 0.8247005343437195 lambdas: [-0.055581290274858475, -0.07373447716236115, -0.033310793340206146, 0.10959388315677643, -0.3648471534252167, -0.014708046801388264, 0.005957308225333691] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3250/5550 val_loss:3.070067 train_time:808195ms step_avg:248.68ms x-lambda: 0.8256634473800659 lambdas: [-0.05491216108202934, -0.07509519159793854, -0.03341873735189438, 0.11345224827528, -0.3648446798324585, -0.01354052871465683, 0.0061752405017614365] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3375/5550 val_loss:3.061059 train_time:839865ms step_avg:248.85ms x-lambda: 0.8260125517845154 lambdas: [-0.05494943633675575, -0.07733790576457977, -0.03427327424287796, 0.11656907945871353, -0.3662014305591583, -0.01197495311498642, 0.006197975482791662] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3500/5550 val_loss:3.052614 train_time:871563ms step_avg:249.02ms x-lambda: 0.8259140849113464 lambdas: [-0.05565439909696579, -0.07964608073234558, -0.034755390137434006, 0.11877793073654175, -0.36584487557411194, -0.012742923572659492, 0.005539555102586746] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3625/5550 val_loss:3.043555 train_time:903225ms step_avg:249.17ms x-lambda: 0.8276623487472534 lambdas: [-0.054340578615665436, -0.08025068044662476, -0.03513438627123833, 0.121808260679245, -0.3658740818500519, -0.010565905831754208, 0.006661491468548775] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3750/5550 val_loss:3.034673 train_time:934877ms step_avg:249.30ms x-lambda: 0.8275916576385498 lambdas: [-0.054975274950265884, -0.08198701590299606, -0.0354558564722538, 0.12347956001758575, -0.3657899796962738, -0.009943107143044472, 0.006440712139010429] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:3875/5550 val_loss:3.025211 train_time:966607ms step_avg:249.45ms x-lambda: 0.8310463428497314 lambdas: [-0.05338934436440468, -0.08276746422052383, -0.03508161008358002, 0.12616273760795593, -0.3666653335094452, -0.011252248659729958, 0.005376461427658796] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4000/5550 val_loss:3.016311 train_time:998299ms step_avg:249.57ms x-lambda: 0.8331610560417175 lambdas: [-0.05337641015648842, -0.08480469137430191, -0.03513139858841896, 0.12812809646129608, -0.3673143982887268, -0.010751240886747837, 0.0050399526953697205] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4125/5550 val_loss:3.007070 train_time:1030047ms step_avg:249.71ms x-lambda: 0.8368588089942932 lambdas: [-0.052599791437387466, -0.08584512770175934, -0.035644058138132095, 0.12959742546081543, -0.3670607805252075, -0.009094184264540672, 0.0054403552785515785] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4250/5550 val_loss:2.998960 train_time:1061984ms step_avg:249.88ms x-lambda: 0.8405092358589172 lambdas: [-0.051794204860925674, -0.08623386174440384, -0.03604823723435402, 0.1308021992444992, -0.3684083819389343, -0.009359484538435936, 0.005648779217153788] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4375/5550 val_loss:2.989516 train_time:1094003ms step_avg:250.06ms x-lambda: 0.8426972031593323 lambdas: [-0.05244357883930206, -0.08830761909484863, -0.03669426962733269, 0.13220317661762238, -0.3699400722980499, -0.010515943169593811, 0.006059820763766766] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4500/5550 val_loss:2.981653 train_time:1126035ms step_avg:250.23ms x-lambda: 0.8461975455284119 lambdas: [-0.05191440135240555, -0.09010081738233566, -0.03749549388885498, 0.13335847854614258, -0.370749831199646, -0.00985171552747488, 0.0052674864418804646] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4625/5550 val_loss:2.972212 train_time:1158221ms step_avg:250.43ms x-lambda: 0.8515135049819946 lambdas: [-0.04959239438176155, -0.089444600045681, -0.03658890351653099, 0.13429556787014008, -0.37031906843185425, -0.010404594242572784, 0.0038794074207544327] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4750/5550 val_loss:2.963099 train_time:1190487ms step_avg:250.63ms x-lambda: 0.8563109040260315 lambdas: [-0.04942557215690613, -0.09094485640525818, -0.036207832396030426, 0.13683705031871796, -0.37163421511650085, -0.009446119889616966, 0.004619913175702095] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:4875/5550 val_loss:2.954144 train_time:1222929ms step_avg:250.86ms x-lambda: 0.8606084585189819 lambdas: [-0.049653150141239166, -0.09275117516517639, -0.03641928732395172, 0.13808149099349976, -0.3734266757965088, -0.0100261764600873, 0.003207901958376169] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5000/5550 val_loss:2.946135 train_time:1255475ms step_avg:251.09ms x-lambda: 0.8677375912666321 lambdas: [-0.04856346175074577, -0.09308727085590363, -0.03648386523127556, 0.14027336239814758, -0.3745754659175873, -0.011027305386960506, 0.003815773641690612] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5125/5550 val_loss:2.938376 train_time:1288178ms step_avg:251.35ms x-lambda: 0.872691810131073 lambdas: [-0.048294104635715485, -0.09371760487556458, -0.03670955076813698, 0.14107255637645721, -0.3764572739601135, -0.010326792486011982, 0.003905782476067543] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5250/5550 val_loss:2.931284 train_time:1321056ms step_avg:251.63ms x-lambda: 0.8776306509971619 lambdas: [-0.047940693795681, -0.09453663975000381, -0.03729026019573212, 0.14244838058948517, -0.3758780360221863, -0.009721916168928146, 0.0031780125573277473] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5375/5550 val_loss:2.924927 train_time:1354043ms step_avg:251.92ms x-lambda: 0.8824794888496399 lambdas: [-0.04759436845779419, -0.0949244350194931, -0.037123147398233414, 0.14337533712387085, -0.37713930010795593, -0.010593822225928307, 0.0026857806369662285] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5500/5550 val_loss:2.920134 train_time:1387303ms step_avg:252.24ms x-lambda: 0.8856369256973267 lambdas: [-0.04723178222775459, -0.09537898749113083, -0.03742791339755058, 0.14404736459255219, -0.3783254027366638, -0.010334298945963383, 0.0023767619859427214] skip-layers: [14, 13, 12, 11, 10, 9, 8]
step:5550/5550 val_loss:2.918956 train_time:1400670ms step_avg:252.37ms x-lambda: 0.8863834142684937 lambdas: [-0.047231607139110565, -0.09551753103733063, -0.03739522397518158, 0.1444561630487442, -0.37843266129493713, -0.010813324712216854, 0.002857363549992442] skip-layers: [14, 13, 12, 11, 10, 9, 8]



## 8000-add-skip-multiple-7-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.23ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:125/5550 val_loss:4.267917 train_time:29201ms step_avg:233.61ms x-lambda: 1.0484133958816528 lambdas: [0.08404824137687683, 0.0015604642685502768, -0.03066772222518921, -0.023446179926395416, 0.08194579929113388, 0.06328374147415161, 0.05116066336631775] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:250/5550 val_loss:3.847759 train_time:58528ms step_avg:234.11ms x-lambda: 1.043892502784729 lambdas: [0.0747092142701149, -0.04562302306294441, -0.09433668851852417, -0.1028362512588501, 0.118049755692482, 0.06034845858812332, 0.021766409277915955] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:375/5550 val_loss:3.671720 train_time:88306ms step_avg:235.48ms x-lambda: 1.0290985107421875 lambdas: [0.0627877488732338, -0.054939527064561844, -0.11143016815185547, -0.14041171967983246, 0.12259569019079208, 0.043508756905794144, -0.00831181462854147] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:500/5550 val_loss:3.557756 train_time:118406ms step_avg:236.81ms x-lambda: 0.9929922819137573 lambdas: [0.05428921803832054, -0.05631360039114952, -0.11899768561124802, -0.1585746556520462, 0.12037856876850128, 0.031612955033779144, -0.02821424789726734] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:625/5550 val_loss:3.479110 train_time:148686ms step_avg:237.90ms x-lambda: 0.951389491558075 lambdas: [0.05105137825012207, -0.05136376991868019, -0.11873804777860641, -0.16030541062355042, 0.1195569857954979, 0.02769165113568306, -0.03549068048596382] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:750/5550 val_loss:3.427622 train_time:179306ms step_avg:239.07ms x-lambda: 0.9093965888023376 lambdas: [0.04497041180729866, -0.04834561049938202, -0.1194797158241272, -0.15814438462257385, 0.11143956333398819, 0.022418789565563202, -0.0422784797847271] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:875/5550 val_loss:3.382075 train_time:210022ms step_avg:240.02ms x-lambda: 0.8663386702537537 lambdas: [0.042017530649900436, -0.04224105551838875, -0.11476388573646545, -0.14964401721954346, 0.1030934602022171, 0.01915741339325905, -0.04333183914422989] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1000/5550 val_loss:3.346200 train_time:240994ms step_avg:240.99ms x-lambda: 0.8299610614776611 lambdas: [0.0403163768351078, -0.03682712838053703, -0.10863859206438065, -0.13704954087734222, 0.09490792453289032, 0.019516319036483765, -0.04288998991250992] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1125/5550 val_loss:3.319534 train_time:272039ms step_avg:241.81ms x-lambda: 0.79497230052948 lambdas: [0.035707369446754456, -0.0348501093685627, -0.10642054677009583, -0.1269606500864029, 0.0830930545926094, 0.01476284023374319, -0.044404685497283936] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1250/5550 val_loss:3.293258 train_time:303215ms step_avg:242.57ms x-lambda: 0.7689915299415588 lambdas: [0.035695966333150864, -0.0296942088752985, -0.10102743655443192, -0.11377941817045212, 0.0758112445473671, 0.01651955023407936, -0.04057638719677925] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1375/5550 val_loss:3.271348 train_time:334565ms step_avg:243.32ms x-lambda: 0.7419438362121582 lambdas: [0.032354939728975296, -0.028388144448399544, -0.09739501029253006, -0.10433018952608109, 0.06792283803224564, 0.014150882139801979, -0.040841009467840195] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1500/5550 val_loss:3.252758 train_time:365900ms step_avg:243.93ms x-lambda: 0.7196789979934692 lambdas: [0.031483929604291916, -0.02528383582830429, -0.09375231713056564, -0.09737298637628555, 0.06041934713721275, 0.013511818833649158, -0.039702579379081726] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1625/5550 val_loss:3.239053 train_time:397302ms step_avg:244.49ms x-lambda: 0.698979914188385 lambdas: [0.0313023179769516, -0.023192409425973892, -0.09050775319337845, -0.08915126323699951, 0.05612026900053024, 0.014295336790382862, -0.037814464420080185] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1750/5550 val_loss:3.222765 train_time:428671ms step_avg:244.95ms x-lambda: 0.6777567863464355 lambdas: [0.02801649272441864, -0.022199591621756554, -0.08727819472551346, -0.08298622071743011, 0.04975748807191849, 0.012949655763804913, -0.037097059190273285] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:1875/5550 val_loss:3.203984 train_time:460104ms step_avg:245.39ms x-lambda: 0.6638314127922058 lambdas: [0.027343278750777245, -0.020389895886182785, -0.08495452255010605, -0.07808275520801544, 0.045324988663196564, 0.011394467204809189, -0.03787505626678467] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2000/5550 val_loss:3.188372 train_time:491718ms step_avg:245.86ms x-lambda: 0.6475424766540527 lambdas: [0.026568591594696045, -0.019280150532722473, -0.0819554477930069, -0.07199998944997787, 0.04226013273000717, 0.012129672802984715, -0.03517633676528931] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2125/5550 val_loss:3.173504 train_time:523383ms step_avg:246.30ms x-lambda: 0.6389005780220032 lambdas: [0.025389133021235466, -0.018476003780961037, -0.0792013630270958, -0.0689663290977478, 0.039496783167123795, 0.010947642847895622, -0.03529703617095947] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2250/5550 val_loss:3.159645 train_time:555039ms step_avg:246.68ms x-lambda: 0.6305348873138428 lambdas: [0.024816494435071945, -0.017881404608488083, -0.07696502655744553, -0.06412769109010696, 0.036031901836395264, 0.010402796790003777, -0.03462627902626991] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2375/5550 val_loss:3.148290 train_time:586734ms step_avg:247.05ms x-lambda: 0.6238676905632019 lambdas: [0.02406373620033264, -0.016632763668894768, -0.0744713619351387, -0.06096549332141876, 0.034068018198013306, 0.009698757901787758, -0.03430221229791641] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2500/5550 val_loss:3.137747 train_time:618360ms step_avg:247.34ms x-lambda: 0.6172217726707458 lambdas: [0.024668660014867783, -0.015301423147320747, -0.07315581291913986, -0.05837734416127205, 0.032233551144599915, 0.01061762124300003, -0.032221000641584396] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2625/5550 val_loss:3.125610 train_time:649994ms step_avg:247.62ms x-lambda: 0.6120262145996094 lambdas: [0.021948782727122307, -0.014347145333886147, -0.07202396541833878, -0.05525960773229599, 0.030189093202352524, 0.010303971357643604, -0.03260556235909462] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2750/5550 val_loss:3.114541 train_time:681640ms step_avg:247.87ms x-lambda: 0.6071265339851379 lambdas: [0.021635079756379128, -0.01439516432583332, -0.0702330693602562, -0.05304565653204918, 0.02920645661652088, 0.008824657648801804, -0.03268459439277649] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:2875/5550 val_loss:3.105637 train_time:713317ms step_avg:248.11ms x-lambda: 0.6041638851165771 lambdas: [0.021739400923252106, -0.014087999239563942, -0.06857923418283463, -0.050880707800388336, 0.027404475957155228, 0.008868351578712463, -0.03201298043131828] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3000/5550 val_loss:3.094440 train_time:744963ms step_avg:248.32ms x-lambda: 0.6041855812072754 lambdas: [0.019887952134013176, -0.01315630879253149, -0.06682893633842468, -0.04942284896969795, 0.02714412845671177, 0.010015889070928097, -0.03095233626663685] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3125/5550 val_loss:3.084532 train_time:776653ms step_avg:248.53ms x-lambda: 0.6001259684562683 lambdas: [0.019964469596743584, -0.013999435119330883, -0.06752932071685791, -0.04923132061958313, 0.024029772728681564, 0.00784563459455967, -0.030931321904063225] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3250/5550 val_loss:3.072181 train_time:808322ms step_avg:248.71ms x-lambda: 0.6030647158622742 lambdas: [0.02096114121377468, -0.0130350012332201, -0.06510794907808304, -0.046957504004240036, 0.02381877601146698, 0.008415707387030125, -0.030226686969399452] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3375/5550 val_loss:3.063435 train_time:839982ms step_avg:248.88ms x-lambda: 0.6020530462265015 lambdas: [0.019719133153557777, -0.012646696530282497, -0.06456594169139862, -0.0458015613257885, 0.0240410715341568, 0.008270497433841228, -0.03107031062245369] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3500/5550 val_loss:3.054703 train_time:871698ms step_avg:249.06ms x-lambda: 0.6028769016265869 lambdas: [0.019756073132157326, -0.012870678678154945, -0.06418048590421677, -0.04535302519798279, 0.022295435890555382, 0.00660948920994997, -0.030458426102995872] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3625/5550 val_loss:3.046391 train_time:903347ms step_avg:249.20ms x-lambda: 0.6045706272125244 lambdas: [0.019256198778748512, -0.012774144299328327, -0.0632510632276535, -0.04345398396253586, 0.02167687378823757, 0.006628585048019886, -0.029625071212649345] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3750/5550 val_loss:3.036335 train_time:934992ms step_avg:249.33ms x-lambda: 0.6044785380363464 lambdas: [0.01898537389934063, -0.011955107562243938, -0.06166893616318703, -0.042435646057128906, 0.021758314222097397, 0.007360256742686033, -0.028757208958268166] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:3875/5550 val_loss:3.027450 train_time:966735ms step_avg:249.48ms x-lambda: 0.6107815504074097 lambdas: [0.0198746956884861, -0.011120648123323917, -0.061267632991075516, -0.041744742542505264, 0.02136525698006153, 0.006900927051901817, -0.028838172554969788] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4000/5550 val_loss:3.017960 train_time:998438ms step_avg:249.61ms x-lambda: 0.6128963232040405 lambdas: [0.019161079078912735, -0.011051543988287449, -0.06098921224474907, -0.04044321924448013, 0.021195095032453537, 0.007161582354456186, -0.028790626674890518] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4125/5550 val_loss:3.008867 train_time:1030192ms step_avg:249.74ms x-lambda: 0.6194578409194946 lambdas: [0.01967705972492695, -0.010760923847556114, -0.05993867293000221, -0.04022882878780365, 0.01943923905491829, 0.006764284800738096, -0.02795696258544922] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4250/5550 val_loss:3.000568 train_time:1062145ms step_avg:249.92ms x-lambda: 0.6214993000030518 lambdas: [0.018549427390098572, -0.010362704284489155, -0.058236848562955856, -0.039933960884809494, 0.021349187940359116, 0.00797702930867672, -0.028328895568847656] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4375/5550 val_loss:2.991434 train_time:1094151ms step_avg:250.09ms x-lambda: 0.6257379055023193 lambdas: [0.018842313438653946, -0.00995100848376751, -0.05909016355872154, -0.040095455944538116, 0.019747134298086166, 0.005986337084323168, -0.028071358799934387] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4500/5550 val_loss:2.983458 train_time:1126186ms step_avg:250.26ms x-lambda: 0.6316143274307251 lambdas: [0.019179821014404297, -0.010952441953122616, -0.05894456431269646, -0.03823091462254524, 0.01845495216548443, 0.006165586411952972, -0.028846969828009605] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4625/5550 val_loss:2.974109 train_time:1158371ms step_avg:250.46ms x-lambda: 0.6404661536216736 lambdas: [0.017555397003889084, -0.009996432811021805, -0.05741154029965401, -0.03859628736972809, 0.017849603667855263, 0.0059279790148139, -0.028867194429039955] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4750/5550 val_loss:2.964571 train_time:1190637ms step_avg:250.66ms x-lambda: 0.6455897092819214 lambdas: [0.019080573692917824, -0.009726797230541706, -0.05681257322430611, -0.03761793300509453, 0.019098620861768723, 0.007173025049269199, -0.027954641729593277] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:4875/5550 val_loss:2.955850 train_time:1223133ms step_avg:250.90ms x-lambda: 0.6526740193367004 lambdas: [0.017916662618517876, -0.009541111998260021, -0.05707911029458046, -0.0370180606842041, 0.018922973424196243, 0.0048974486999213696, -0.027555668726563454] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5000/5550 val_loss:2.947820 train_time:1255742ms step_avg:251.15ms x-lambda: 0.6597874164581299 lambdas: [0.018310191109776497, -0.0096364114433527, -0.057067688554525375, -0.03673848137259483, 0.018017634749412537, 0.005518687888979912, -0.027510598301887512] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5125/5550 val_loss:2.940195 train_time:1288481ms step_avg:251.41ms x-lambda: 0.6675633192062378 lambdas: [0.018142595887184143, -0.008883891627192497, -0.05596047267317772, -0.036227915436029434, 0.018772223964333534, 0.005247900728136301, -0.02713189460337162] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5250/5550 val_loss:2.933052 train_time:1321377ms step_avg:251.69ms x-lambda: 0.674917459487915 lambdas: [0.017981089651584625, -0.009793371893465519, -0.05635254830121994, -0.03546828031539917, 0.017984477803111076, 0.005707922857254744, -0.026887234300374985] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5375/5550 val_loss:2.926400 train_time:1354436ms step_avg:251.99ms x-lambda: 0.6830899715423584 lambdas: [0.018265096470713615, -0.008407097309827805, -0.05598454549908638, -0.03576912730932236, 0.017935195937752724, 0.005429611075669527, -0.02766328491270542] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5500/5550 val_loss:2.921658 train_time:1387684ms step_avg:252.31ms x-lambda: 0.6881565451622009 lambdas: [0.01778011955320835, -0.009201194159686565, -0.05617349222302437, -0.03608844801783562, 0.017806053161621094, 0.005025989841669798, -0.027078138664364815] skip-layers: [0, 1, 2, 3, 4, 5, 6]
step:5550/5550 val_loss:2.920461 train_time:1401047ms step_avg:252.44ms x-lambda: 0.6895509362220764 lambdas: [0.01746578887104988, -0.009072970598936081, -0.055859364569187164, -0.036069389432668686, 0.01783883385360241, 0.005120531655848026, -0.027386460453271866] skip-layers: [0, 1, 2, 3, 4, 5, 6]



## 8000-add-skip-multiple-7-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:125/5550 val_loss:4.262715 train_time:29186ms step_avg:233.48ms x-lambda: 1.0641697645187378 lambdas: [-0.005207301117479801, 0.023866131901741028, 0.03171556442975998, 0.03658859804272652, 0.003145789261907339, 0.06066055968403816, 0.02764931134879589] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:250/5550 val_loss:3.854016 train_time:58549ms step_avg:234.19ms x-lambda: 1.0606352090835571 lambdas: [-0.0021215402521193027, -0.003997692372649908, -0.0012867324985563755, -0.00043043121695518494, -0.0046300808899104595, -0.0010711152572184801, -0.0020142521243542433] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:375/5550 val_loss:3.682036 train_time:88342ms step_avg:235.58ms x-lambda: 1.0305408239364624 lambdas: [0.00431805057451129, -0.022463729605078697, -0.020845286548137665, -0.02397858537733555, -0.007691184990108013, -0.03155526518821716, -0.017950933426618576] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:500/5550 val_loss:3.564918 train_time:118495ms step_avg:236.99ms x-lambda: 0.9867887496948242 lambdas: [0.008371966890990734, -0.028846189379692078, -0.02591702900826931, -0.03136403113603592, -0.007331166882067919, -0.04063455015420914, -0.02218397706747055] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:625/5550 val_loss:3.483575 train_time:148859ms step_avg:238.17ms x-lambda: 0.9345644116401672 lambdas: [0.0043135713785886765, -0.03227318078279495, -0.02949240803718567, -0.03499114140868187, -0.009904785081744194, -0.044354572892189026, -0.025332119315862656] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:750/5550 val_loss:3.431000 train_time:179482ms step_avg:239.31ms x-lambda: 0.8923707008361816 lambdas: [0.004213392268866301, -0.029168669134378433, -0.025220481678843498, -0.0336311049759388, -0.009355108253657818, -0.04148317128419876, -0.022518616169691086] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:875/5550 val_loss:3.385772 train_time:210202ms step_avg:240.23ms x-lambda: 0.8492091298103333 lambdas: [0.003928725607693195, -0.027218934148550034, -0.02402786910533905, -0.030635084956884384, -0.008788208477199078, -0.03860054910182953, -0.021196376532316208] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1000/5550 val_loss:3.351131 train_time:241186ms step_avg:241.19ms x-lambda: 0.8115373849868774 lambdas: [0.0014822531957179308, -0.028212714940309525, -0.02447565458714962, -0.029781220480799675, -0.009802755899727345, -0.03779995068907738, -0.02174738049507141] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1125/5550 val_loss:3.319929 train_time:272201ms step_avg:241.96ms x-lambda: 0.7806509137153625 lambdas: [0.0017496527871116996, -0.024169765412807465, -0.020069997757673264, -0.02695501782000065, -0.008746068924665451, -0.0329408273100853, -0.018515776842832565] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1250/5550 val_loss:3.295523 train_time:303391ms step_avg:242.71ms x-lambda: 0.7509092092514038 lambdas: [0.001558228163048625, -0.023516302928328514, -0.020247334614396095, -0.025802234187722206, -0.007996178232133389, -0.031994130462408066, -0.018756471574306488] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1375/5550 val_loss:3.274483 train_time:334742ms step_avg:243.45ms x-lambda: 0.7263311147689819 lambdas: [0.001627436955459416, -0.023312613368034363, -0.018499793484807014, -0.02549646981060505, -0.009428998455405235, -0.0311430674046278, -0.018200727179646492] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1500/5550 val_loss:3.256346 train_time:366087ms step_avg:244.06ms x-lambda: 0.7074704766273499 lambdas: [0.0021177742164582014, -0.021031023934483528, -0.01698377914726734, -0.02172727882862091, -0.007618045900017023, -0.02814689464867115, -0.016160985454916954] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1625/5550 val_loss:3.241265 train_time:397496ms step_avg:244.61ms x-lambda: 0.6866987347602844 lambdas: [0.00014198907592799515, -0.022140230983495712, -0.01758524961769581, -0.021894827485084534, -0.0077915191650390625, -0.028260601684451103, -0.01704232394695282] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1750/5550 val_loss:3.224575 train_time:428872ms step_avg:245.07ms x-lambda: 0.6669175624847412 lambdas: [-0.00011056126095354557, -0.020945636555552483, -0.01730906404554844, -0.021831003949046135, -0.00829262938350439, -0.026388656347990036, -0.0150507977232337] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:1875/5550 val_loss:3.207465 train_time:460292ms step_avg:245.49ms x-lambda: 0.6579460501670837 lambdas: [0.0017298448365181684, -0.017665226012468338, -0.013101395219564438, -0.018506629392504692, -0.005728623364120722, -0.022950749844312668, -0.012552290223538876] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2000/5550 val_loss:3.190022 train_time:491905ms step_avg:245.95ms x-lambda: 0.6421798467636108 lambdas: [0.0022696983069181442, -0.01805052161216736, -0.013945862650871277, -0.01910524070262909, -0.007124738302081823, -0.023070186376571655, -0.013552277348935604] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2125/5550 val_loss:3.175615 train_time:523548ms step_avg:246.38ms x-lambda: 0.6351715326309204 lambdas: [4.2586878407746553e-05, -0.017285943031311035, -0.012553886510431767, -0.019383657723665237, -0.005521062295883894, -0.022737780585885048, -0.013635012321174145] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2250/5550 val_loss:3.161620 train_time:555209ms step_avg:246.76ms x-lambda: 0.6255174279212952 lambdas: [0.00037903880001977086, -0.016787823289632797, -0.013025498017668724, -0.018039019778370857, -0.007353689055889845, -0.02171361818909645, -0.012632311321794987] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2375/5550 val_loss:3.150042 train_time:586905ms step_avg:247.12ms x-lambda: 0.6206189393997192 lambdas: [0.0022972633596509695, -0.015645623207092285, -0.012540689669549465, -0.015998171642422676, -0.006192407105118036, -0.020478256046772003, -0.011911725625395775] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2500/5550 val_loss:3.138117 train_time:618539ms step_avg:247.42ms x-lambda: 0.6146200895309448 lambdas: [0.0019279101397842169, -0.016249828040599823, -0.01155913807451725, -0.018103064969182014, -0.007090357132256031, -0.019440189003944397, -0.011881271377205849] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2625/5550 val_loss:3.126530 train_time:650179ms step_avg:247.69ms x-lambda: 0.6121062636375427 lambdas: [0.0011681313626468182, -0.014939510263502598, -0.011829436756670475, -0.015336975455284119, -0.00486923148855567, -0.019948158413171768, -0.010767349041998386] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2750/5550 val_loss:3.115477 train_time:681806ms step_avg:247.93ms x-lambda: 0.6077859997749329 lambdas: [0.000899527280125767, -0.013911533169448376, -0.011425260454416275, -0.015564094297587872, -0.004632199183106422, -0.01819279044866562, -0.010786139406263828] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:2875/5550 val_loss:3.106550 train_time:713467ms step_avg:248.16ms x-lambda: 0.6058445572853088 lambdas: [0.0025876236613839865, -0.013522441498935223, -0.01033537182956934, -0.015669750049710274, -0.004358728416264057, -0.018309645354747772, -0.00964135117828846] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3000/5550 val_loss:3.096226 train_time:745122ms step_avg:248.37ms x-lambda: 0.6038782596588135 lambdas: [-0.0009026326006278396, -0.016347207129001617, -0.012582029215991497, -0.016803577542304993, -0.006997525226324797, -0.019804708659648895, -0.012494873255491257] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3125/5550 val_loss:3.086179 train_time:776806ms step_avg:248.58ms x-lambda: 0.6029717326164246 lambdas: [-0.0010177340591326356, -0.014899885281920433, -0.013290761969983578, -0.015544281341135502, -0.0069504790008068085, -0.020247163251042366, -0.012430773116648197] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3250/5550 val_loss:3.073104 train_time:808462ms step_avg:248.76ms x-lambda: 0.6038438677787781 lambdas: [0.0008761307690292597, -0.013933203183114529, -0.010851259343326092, -0.014693789184093475, -0.005395588930696249, -0.017346179112792015, -0.010484685190021992] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3375/5550 val_loss:3.064889 train_time:840113ms step_avg:248.92ms x-lambda: 0.60451340675354 lambdas: [0.0003526468062773347, -0.014914900995790958, -0.011262917891144753, -0.015931762754917145, -0.006534618325531483, -0.018340498208999634, -0.011260642670094967] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3500/5550 val_loss:3.055197 train_time:871791ms step_avg:249.08ms x-lambda: 0.6055195331573486 lambdas: [0.0011970449704676867, -0.01376083493232727, -0.010929570533335209, -0.014984366483986378, -0.00603592349216342, -0.017914336174726486, -0.010941018350422382] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3625/5550 val_loss:3.046878 train_time:903449ms step_avg:249.23ms x-lambda: 0.6084684729576111 lambdas: [0.0012191161513328552, -0.013248041272163391, -0.010378536768257618, -0.015212132595479488, -0.006011362187564373, -0.01718936860561371, -0.010887784883379936] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3750/5550 val_loss:3.036964 train_time:935111ms step_avg:249.36ms x-lambda: 0.6088330149650574 lambdas: [0.0011081949342042208, -0.013453339226543903, -0.010005570948123932, -0.013966627418994904, -0.005499052815139294, -0.017018571496009827, -0.009912213310599327] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:3875/5550 val_loss:3.027822 train_time:966849ms step_avg:249.51ms x-lambda: 0.6159040331840515 lambdas: [0.0008386475965380669, -0.013128330931067467, -0.00983044970780611, -0.014848948456346989, -0.006638829596340656, -0.01669570431113243, -0.009794104844331741] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4000/5550 val_loss:3.018606 train_time:998552ms step_avg:249.64ms x-lambda: 0.6186637282371521 lambdas: [0.0001655503874644637, -0.012820759788155556, -0.009404018521308899, -0.013823573477566242, -0.005692536476999521, -0.015737345442175865, -0.009923315607011318] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4125/5550 val_loss:3.009117 train_time:1030293ms step_avg:249.77ms x-lambda: 0.6228698492050171 lambdas: [0.0004002354689873755, -0.012694507837295532, -0.008968501351773739, -0.012340761721134186, -0.005036765243858099, -0.01684270054101944, -0.010176175273954868] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4250/5550 val_loss:3.000923 train_time:1062264ms step_avg:249.94ms x-lambda: 0.6283991932868958 lambdas: [0.000252176309004426, -0.012351523153483868, -0.009215089492499828, -0.013130813837051392, -0.006035630591213703, -0.01634244993329048, -0.009269556030631065] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4375/5550 val_loss:2.991455 train_time:1094260ms step_avg:250.12ms x-lambda: 0.6325933337211609 lambdas: [0.00022234255447983742, -0.01302468404173851, -0.009441783651709557, -0.013631196692585945, -0.0061378637328743935, -0.01706412248313427, -0.009951965883374214] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4500/5550 val_loss:2.983472 train_time:1126264ms step_avg:250.28ms x-lambda: 0.6383390426635742 lambdas: [0.0014443794498220086, -0.01225533802062273, -0.009184951893985271, -0.014208816923201084, -0.004812540952116251, -0.016000036150217056, -0.009313720278441906] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4625/5550 val_loss:2.974341 train_time:1158465ms step_avg:250.48ms x-lambda: 0.6473139524459839 lambdas: [0.00034846150083467364, -0.013676703907549381, -0.008387163281440735, -0.013781667686998844, -0.006262172944843769, -0.01620117574930191, -0.011117750778794289] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4750/5550 val_loss:2.964744 train_time:1190741ms step_avg:250.68ms x-lambda: 0.6526097655296326 lambdas: [0.000366091204341501, -0.012060744687914848, -0.0075098201632499695, -0.013092190027236938, -0.004713909700512886, -0.015200132504105568, -0.008754678070545197] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:4875/5550 val_loss:2.955991 train_time:1223201ms step_avg:250.91ms x-lambda: 0.6594141125679016 lambdas: [0.0012960594613105059, -0.012624088674783707, -0.009700339287519455, -0.012900621630251408, -0.00486421212553978, -0.016381358727812767, -0.008995695039629936] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5000/5550 val_loss:2.947549 train_time:1255759ms step_avg:251.15ms x-lambda: 0.6661248803138733 lambdas: [0.0008635379490442574, -0.011846919544041157, -0.008400551974773407, -0.01342837419360876, -0.005276220850646496, -0.015452259220182896, -0.009400238282978535] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5125/5550 val_loss:2.940027 train_time:1288434ms step_avg:251.40ms x-lambda: 0.6747717261314392 lambdas: [-0.00029512218316085637, -0.011400053277611732, -0.00803065299987793, -0.012908512726426125, -0.005051831714808941, -0.014326179400086403, -0.009313059970736504] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5250/5550 val_loss:2.933035 train_time:1321317ms step_avg:251.68ms x-lambda: 0.6821856498718262 lambdas: [0.0005398246576078236, -0.012259027920663357, -0.008591847494244576, -0.012965837493538857, -0.004505503922700882, -0.01523367315530777, -0.00862164981663227] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5375/5550 val_loss:2.926554 train_time:1354314ms step_avg:251.97ms x-lambda: 0.6909149885177612 lambdas: [0.00025671476032584906, -0.011727191507816315, -0.00786696095019579, -0.01258811540901661, -0.005391969345510006, -0.014590171165764332, -0.008936174213886261] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5500/5550 val_loss:2.921729 train_time:1387570ms step_avg:252.29ms x-lambda: 0.6955378651618958 lambdas: [0.0004790170642081648, -0.012243217788636684, -0.007999053224921227, -0.013183104805648327, -0.0050796945579349995, -0.01529790461063385, -0.009405259974300861] skip-layers: [14, 5, 11, 13, 6, 3, 9]
step:5550/5550 val_loss:2.920545 train_time:1400935ms step_avg:252.42ms x-lambda: 0.696874737739563 lambdas: [0.0007283093873411417, -0.01232393179088831, -0.008598314598202705, -0.01314222626388073, -0.005273069255053997, -0.015280673280358315, -0.009318357333540916] skip-layers: [14, 5, 11, 13, 6, 3, 9]



## 8000-add-skip-multiple-7-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.26ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:125/5550 val_loss:4.262344 train_time:29211ms step_avg:233.69ms x-lambda: 1.0423606634140015 lambdas: [0.018329141661524773, -0.016928469762206078, 0.03759114816784859, 0.03372287005186081, 0.03754723444581032, 0.05207286402583122, 0.04522930458188057] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:250/5550 val_loss:3.846721 train_time:58562ms step_avg:234.25ms x-lambda: 1.012555718421936 lambdas: [-0.02867324836552143, -0.09935558587312698, 0.024861788377165794, 0.02411307767033577, 0.001778848236426711, 0.045001253485679626, 0.04111924394965172] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:375/5550 val_loss:3.671137 train_time:88357ms step_avg:235.62ms x-lambda: 0.986785888671875 lambdas: [-0.03434155881404877, -0.13081714510917664, 0.02044682577252388, 0.016809405758976936, -0.026818934828042984, 0.031371764838695526, 0.03140716627240181] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:500/5550 val_loss:3.556734 train_time:118500ms step_avg:237.00ms x-lambda: 0.9660235047340393 lambdas: [-0.03334859758615494, -0.15052801370620728, 0.018215078860521317, 0.0011019327212125063, -0.04818972200155258, 0.01990113966166973, 0.012805525213479996] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:625/5550 val_loss:3.476852 train_time:148869ms step_avg:238.19ms x-lambda: 0.9517417550086975 lambdas: [-0.024993225932121277, -0.1589304357767105, 0.023023471236228943, -0.011245088651776314, -0.05556730926036835, 0.019043153151869774, -0.004460636526346207] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:750/5550 val_loss:3.426684 train_time:179568ms step_avg:239.42ms x-lambda: 0.9363459348678589 lambdas: [-0.02088593877851963, -0.16572800278663635, 0.022400548681616783, -0.025362355634570122, -0.06296893954277039, 0.015143373049795628, -0.025402922183275223] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:875/5550 val_loss:3.380081 train_time:210340ms step_avg:240.39ms x-lambda: 0.9211370944976807 lambdas: [-0.014193596318364143, -0.16425000131130219, 0.02347201481461525, -0.03739728778600693, -0.06440446525812149, 0.01498298067599535, -0.04470068961381912] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1000/5550 val_loss:3.344767 train_time:241402ms step_avg:241.40ms x-lambda: 0.9095649123191833 lambdas: [-0.00754299433901906, -0.15833812952041626, 0.02460727095603943, -0.04617481678724289, -0.06355754286050797, 0.016162347048521042, -0.06069447472691536] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1125/5550 val_loss:3.315727 train_time:272513ms step_avg:242.23ms x-lambda: 0.8976004123687744 lambdas: [-0.003798567922785878, -0.1535601019859314, 0.023094842210412025, -0.05513031780719757, -0.06282533705234528, 0.01449207216501236, -0.07470043748617172] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1250/5550 val_loss:3.290211 train_time:303733ms step_avg:242.99ms x-lambda: 0.8853006958961487 lambdas: [-0.0029320325702428818, -0.1487293690443039, 0.021398240700364113, -0.06373000890016556, -0.061957258731126785, 0.012381656095385551, -0.0892796739935875] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1375/5550 val_loss:3.271294 train_time:335140ms step_avg:243.74ms x-lambda: 0.8751283884048462 lambdas: [-0.0013553263852372766, -0.1426527500152588, 0.019807759672403336, -0.07013809680938721, -0.059985801577568054, 0.010730059817433357, -0.10148295015096664] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1500/5550 val_loss:3.250578 train_time:366483ms step_avg:244.32ms x-lambda: 0.8675925731658936 lambdas: [0.0008409740403294563, -0.13616040349006653, 0.020790960639715195, -0.07480483502149582, -0.058583617210388184, 0.011783313006162643, -0.11107150465250015] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1625/5550 val_loss:3.235563 train_time:397903ms step_avg:244.86ms x-lambda: 0.856894314289093 lambdas: [0.0012726823333650827, -0.13215534389019012, 0.018503928557038307, -0.0810462012887001, -0.05779115855693817, 0.01080714724957943, -0.12229721248149872] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1750/5550 val_loss:3.223048 train_time:429318ms step_avg:245.32ms x-lambda: 0.8499221801757812 lambdas: [0.003188157919794321, -0.12489750981330872, 0.022311115637421608, -0.08477537333965302, -0.053238727152347565, 0.012905575335025787, -0.12977883219718933] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:1875/5550 val_loss:3.202000 train_time:460796ms step_avg:245.76ms x-lambda: 0.8429839611053467 lambdas: [0.0025377655401825905, -0.12042393535375595, 0.018719883635640144, -0.08994272351264954, -0.05331427976489067, 0.009925518184900284, -0.1377095878124237] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2000/5550 val_loss:3.187499 train_time:492447ms step_avg:246.22ms x-lambda: 0.8379642367362976 lambdas: [0.003750741947442293, -0.11547452956438065, 0.018518827855587006, -0.09349704533815384, -0.05130516737699509, 0.01002566423267126, -0.14408418536186218] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2125/5550 val_loss:3.172391 train_time:524115ms step_avg:246.64ms x-lambda: 0.8337804079055786 lambdas: [0.0032748098019510508, -0.1117948442697525, 0.016611477360129356, -0.09635366499423981, -0.05088794231414795, 0.009421090595424175, -0.15105921030044556] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2250/5550 val_loss:3.158259 train_time:555824ms step_avg:247.03ms x-lambda: 0.8308157324790955 lambdas: [0.0041346619836986065, -0.10755466669797897, 0.016549721360206604, -0.09939707070589066, -0.04994858056306839, 0.008682463318109512, -0.15691915154457092] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2375/5550 val_loss:3.146561 train_time:587534ms step_avg:247.38ms x-lambda: 0.8279198408126831 lambdas: [0.0022809968795627356, -0.10405471920967102, 0.015431201085448265, -0.10091511160135269, -0.04912542551755905, 0.008044544607400894, -0.162102609872818] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2500/5550 val_loss:3.134882 train_time:619206ms step_avg:247.68ms x-lambda: 0.8272379040718079 lambdas: [0.0037671951577067375, -0.1001763641834259, 0.015629488974809647, -0.10202932357788086, -0.04703603312373161, 0.008044280111789703, -0.16571173071861267] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2625/5550 val_loss:3.123578 train_time:650847ms step_avg:247.94ms x-lambda: 0.8244545459747314 lambdas: [0.005260390229523182, -0.09732931107282639, 0.015613672323524952, -0.10332703590393066, -0.04523742198944092, 0.007952260784804821, -0.16951075196266174] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2750/5550 val_loss:3.113002 train_time:682529ms step_avg:248.19ms x-lambda: 0.822982668876648 lambdas: [0.004212599713355303, -0.09431272745132446, 0.014620817266404629, -0.10534997284412384, -0.04345012083649635, 0.008466880768537521, -0.17402786016464233] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:2875/5550 val_loss:3.103993 train_time:714217ms step_avg:248.42ms x-lambda: 0.8231631517410278 lambdas: [0.004781479947268963, -0.09237054735422134, 0.014795600436627865, -0.10593486577272415, -0.04373835027217865, 0.0068809171207249165, -0.17624977231025696] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3000/5550 val_loss:3.092755 train_time:745922ms step_avg:248.64ms x-lambda: 0.8231425285339355 lambdas: [0.004001367371529341, -0.09097258746623993, 0.012693281285464764, -0.10799659788608551, -0.04317877069115639, 0.006464088335633278, -0.18024848401546478] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3125/5550 val_loss:3.082046 train_time:777659ms step_avg:248.85ms x-lambda: 0.8236808180809021 lambdas: [0.003928649239242077, -0.08807659894227982, 0.012451338581740856, -0.10934805870056152, -0.042200684547424316, 0.006528541445732117, -0.18330815434455872] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3250/5550 val_loss:3.070504 train_time:809345ms step_avg:249.03ms x-lambda: 0.8256685733795166 lambdas: [0.005782479420304298, -0.08696818351745605, 0.014139501377940178, -0.10877121239900589, -0.04243960604071617, 0.007022669073194265, -0.18388018012046814] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3375/5550 val_loss:3.063542 train_time:841018ms step_avg:249.19ms x-lambda: 0.8261650204658508 lambdas: [0.0037586907856166363, -0.08714478462934494, 0.011483568698167801, -0.10982829332351685, -0.041786979883909225, 0.006466072052717209, -0.18626569211483002] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3500/5550 val_loss:3.053407 train_time:872733ms step_avg:249.35ms x-lambda: 0.8272004127502441 lambdas: [0.004371786490082741, -0.08321742713451385, 0.012106411159038544, -0.11019986122846603, -0.041472576558589935, 0.005901028867810965, -0.18845915794372559] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3625/5550 val_loss:3.044379 train_time:904440ms step_avg:249.50ms x-lambda: 0.830690324306488 lambdas: [0.004471227526664734, -0.08244210481643677, 0.011528448201715946, -0.10862436890602112, -0.0394739955663681, 0.007686448749154806, -0.18959839642047882] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3750/5550 val_loss:3.034933 train_time:936118ms step_avg:249.63ms x-lambda: 0.8332186341285706 lambdas: [0.004662628751248121, -0.07951360195875168, 0.012345900759100914, -0.10969026386737823, -0.03818928450345993, 0.007058987393975258, -0.1924886703491211] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:3875/5550 val_loss:3.026023 train_time:967890ms step_avg:249.78ms x-lambda: 0.8379605412483215 lambdas: [0.005162626970559359, -0.0791502371430397, 0.011633648537099361, -0.10839661210775375, -0.03801640123128891, 0.005916347727179527, -0.19341397285461426] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4000/5550 val_loss:3.016454 train_time:999621ms step_avg:249.91ms x-lambda: 0.8417053818702698 lambdas: [0.005015831906348467, -0.0780404806137085, 0.01093997061252594, -0.10957475006580353, -0.03859191760420799, 0.00507716927677393, -0.19554491341114044] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4125/5550 val_loss:3.007243 train_time:1031410ms step_avg:250.04ms x-lambda: 0.8463948965072632 lambdas: [0.004392759408801794, -0.07772006094455719, 0.010881902649998665, -0.10958842188119888, -0.037316881120204926, 0.005779772065579891, -0.19771331548690796] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4250/5550 val_loss:2.999093 train_time:1063392ms step_avg:250.21ms x-lambda: 0.8503884673118591 lambdas: [0.005301579367369413, -0.07429556548595428, 0.012231241911649704, -0.1092296838760376, -0.03644657880067825, 0.005674529820680618, -0.19867154955863953] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4375/5550 val_loss:2.989876 train_time:1095400ms step_avg:250.38ms x-lambda: 0.8537015318870544 lambdas: [0.004757806658744812, -0.07641768455505371, 0.010416481643915176, -0.11058279126882553, -0.037001706659793854, 0.005464574787765741, -0.2012632042169571] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4500/5550 val_loss:2.981782 train_time:1127448ms step_avg:250.54ms x-lambda: 0.8592252731323242 lambdas: [0.004738096613436937, -0.07455029338598251, 0.008771706372499466, -0.11038769781589508, -0.03726116940379143, 0.005734060890972614, -0.20279760658740997] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4625/5550 val_loss:2.972449 train_time:1159647ms step_avg:250.73ms x-lambda: 0.8673445582389832 lambdas: [0.004159918054938316, -0.07370881736278534, 0.008490635082125664, -0.1090015172958374, -0.03689655661582947, 0.004766150843352079, -0.20354463160037994] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4750/5550 val_loss:2.963165 train_time:1191939ms step_avg:250.93ms x-lambda: 0.8731358051300049 lambdas: [0.005771270953118801, -0.07350525259971619, 0.009841462597250938, -0.10910291224718094, -0.03619546815752983, 0.005619203206151724, -0.20413854718208313] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:4875/5550 val_loss:2.954284 train_time:1224446ms step_avg:251.17ms x-lambda: 0.8785907626152039 lambdas: [0.005286787170916796, -0.07202454656362534, 0.008901510387659073, -0.10966923087835312, -0.03556665778160095, 0.003907041624188423, -0.20461125671863556] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5000/5550 val_loss:2.946261 train_time:1257053ms step_avg:251.41ms x-lambda: 0.88530433177948 lambdas: [0.005196873564273119, -0.07163804024457932, 0.008675758726894855, -0.10939684510231018, -0.034542303532361984, 0.0036519053392112255, -0.20532424747943878] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5125/5550 val_loss:2.938307 train_time:1289800ms step_avg:251.67ms x-lambda: 0.8910406231880188 lambdas: [0.005166139453649521, -0.07133133709430695, 0.009380975738167763, -0.10941240191459656, -0.03416558727622032, 0.003703259164467454, -0.2070617973804474] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5250/5550 val_loss:2.931248 train_time:1322750ms step_avg:251.95ms x-lambda: 0.8966591954231262 lambdas: [0.005181711632758379, -0.07086672633886337, 0.008805807679891586, -0.10921511054039001, -0.033656250685453415, 0.004626634996384382, -0.20730505883693695] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5375/5550 val_loss:2.924917 train_time:1355774ms step_avg:252.24ms x-lambda: 0.9031931757926941 lambdas: [0.005190371535718441, -0.0708065778017044, 0.007960423827171326, -0.1093531996011734, -0.034003254026174545, 0.004056114703416824, -0.20766620337963104] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5500/5550 val_loss:2.920014 train_time:1389070ms step_avg:252.56ms x-lambda: 0.9068815112113953 lambdas: [0.004402283113449812, -0.07059980928897858, 0.007377068046480417, -0.10911858081817627, -0.03356192633509636, 0.00394953740760684, -0.20770367980003357] skip-layers: [1, 2, 7, 14, 6, 5, 12]
step:5550/5550 val_loss:2.918820 train_time:1402464ms step_avg:252.70ms x-lambda: 0.9074960350990295 lambdas: [0.004652524832636118, -0.07026518136262894, 0.007506641559302807, -0.10931704193353653, -0.03347175195813179, 0.0038051679730415344, -0.20776940882205963] skip-layers: [1, 2, 7, 14, 6, 5, 12]



## 8000-add-skip-multiple-8-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.42ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:125/5550 val_loss:4.257489 train_time:29193ms step_avg:233.54ms x-lambda: 1.0232625007629395 lambdas: [0.02820705808699131, 0.04103455692529678, 0.025018353015184402, 0.0729021355509758, 0.0275840163230896, -0.05594094842672348, 0.021385498344898224, 0.07820020616054535] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:250/5550 val_loss:3.854312 train_time:58588ms step_avg:234.35ms x-lambda: 1.0095311403274536 lambdas: [0.02101662941277027, 0.0473824180662632, -0.006688082590699196, 0.12925180792808533, -0.009938803501427174, -0.1750182956457138, 0.014988740906119347, 0.04549386352300644] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:375/5550 val_loss:3.678996 train_time:88366ms step_avg:235.64ms x-lambda: 1.0140317678451538 lambdas: [0.007064149249345064, 0.02794046513736248, -0.020175127312541008, 0.1372278928756714, -0.05467871204018593, -0.23460407555103302, 0.013731186278164387, 0.031075716018676758] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:500/5550 val_loss:3.563585 train_time:118461ms step_avg:236.92ms x-lambda: 1.0099949836730957 lambdas: [-0.011106779798865318, 0.004964579828083515, -0.020043063908815384, 0.13718877732753754, -0.08773574233055115, -0.26166531443595886, 0.003813614835962653, 0.0243466105312109] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:625/5550 val_loss:3.481951 train_time:148785ms step_avg:238.06ms x-lambda: 1.0053110122680664 lambdas: [-0.026682578027248383, -0.014202347956597805, -0.007576005533337593, 0.14020761847496033, -0.10548898577690125, -0.2688099443912506, -0.005711670964956284, 0.022608205676078796] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:750/5550 val_loss:3.429634 train_time:179428ms step_avg:239.24ms x-lambda: 0.9954848885536194 lambdas: [-0.04306354746222496, -0.031296506524086, 0.0007490843418054283, 0.1398603618144989, -0.11406083405017853, -0.2677018940448761, -0.017848802730441093, 0.02042141743004322] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:875/5550 val_loss:3.384022 train_time:210158ms step_avg:240.18ms x-lambda: 0.9835670590400696 lambdas: [-0.05968436226248741, -0.04800033196806908, 0.006161662749946117, 0.13626545667648315, -0.11712111532688141, -0.25991547107696533, -0.03163003548979759, 0.017238009721040726] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1000/5550 val_loss:3.348295 train_time:241177ms step_avg:241.18ms x-lambda: 0.972849428653717 lambdas: [-0.073691226541996, -0.061386823654174805, 0.009274858981370926, 0.13323546946048737, -0.11457373201847076, -0.24692735075950623, -0.04379123076796532, 0.016482776030898094] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1125/5550 val_loss:3.319734 train_time:272231ms step_avg:241.98ms x-lambda: 0.961503803730011 lambdas: [-0.08640478551387787, -0.07314653694629669, 0.01220483798533678, 0.12782886624336243, -0.11019783467054367, -0.23459511995315552, -0.05608029663562775, 0.013924552127718925] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1250/5550 val_loss:3.294248 train_time:303424ms step_avg:242.74ms x-lambda: 0.9513009786605835 lambdas: [-0.09580206871032715, -0.08120344579219818, 0.014144457876682281, 0.1231846958398819, -0.10397078096866608, -0.22102409601211548, -0.06751468032598495, 0.014101313427090645] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1375/5550 val_loss:3.272690 train_time:334817ms step_avg:243.50ms x-lambda: 0.942230761051178 lambdas: [-0.10256702452898026, -0.08803636580705643, 0.016569076105952263, 0.11808204650878906, -0.09935101121664047, -0.2068554162979126, -0.07650237530469894, 0.014585722237825394] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1500/5550 val_loss:3.255563 train_time:366157ms step_avg:244.10ms x-lambda: 0.9330122470855713 lambdas: [-0.11187849193811417, -0.09481307864189148, 0.016031697392463684, 0.11144699901342392, -0.09572925418615341, -0.19811402261257172, -0.08811304718255997, 0.011422855779528618] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1625/5550 val_loss:3.238110 train_time:397579ms step_avg:244.66ms x-lambda: 0.9259047508239746 lambdas: [-0.11671508103609085, -0.09864360094070435, 0.01909632422029972, 0.10662086308002472, -0.08990035206079483, -0.18467554450035095, -0.09670693427324295, 0.012981283478438854] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1750/5550 val_loss:3.223357 train_time:428964ms step_avg:245.12ms x-lambda: 0.916752815246582 lambdas: [-0.1228867918252945, -0.10211227834224701, 0.01810876466333866, 0.09990663081407547, -0.0858268216252327, -0.1748403012752533, -0.10742615908384323, 0.010593755170702934] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:1875/5550 val_loss:3.204349 train_time:460416ms step_avg:245.56ms x-lambda: 0.9122808575630188 lambdas: [-0.12590865790843964, -0.1037696972489357, 0.020419951528310776, 0.09626612067222595, -0.08099706470966339, -0.16580979526042938, -0.11436155438423157, 0.010825257748365402] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2000/5550 val_loss:3.189011 train_time:492052ms step_avg:246.03ms x-lambda: 0.9051640033721924 lambdas: [-0.12949296832084656, -0.10492759943008423, 0.019290348514914513, 0.09155319631099701, -0.07813426852226257, -0.15538224577903748, -0.12345700711011887, 0.010167826898396015] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2125/5550 val_loss:3.174301 train_time:523745ms step_avg:246.47ms x-lambda: 0.9033643007278442 lambdas: [-0.1309383362531662, -0.10601850599050522, 0.019609501585364342, 0.08880864828824997, -0.07598990947008133, -0.14880365133285522, -0.1293509602546692, 0.010262180119752884] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2250/5550 val_loss:3.160160 train_time:555439ms step_avg:246.86ms x-lambda: 0.8983689546585083 lambdas: [-0.13356411457061768, -0.10700447112321854, 0.019216781482100487, 0.08256607502698898, -0.07390136271715164, -0.14150024950504303, -0.13752256333827972, 0.00941381324082613] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2375/5550 val_loss:3.149041 train_time:587153ms step_avg:247.22ms x-lambda: 0.8953389525413513 lambdas: [-0.13489486277103424, -0.10682306438684464, 0.019380755722522736, 0.07828878611326218, -0.07169376313686371, -0.1353701949119568, -0.14264492690563202, 0.00868395995348692] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2500/5550 val_loss:3.137173 train_time:618802ms step_avg:247.52ms x-lambda: 0.8931688070297241 lambdas: [-0.13448145985603333, -0.10604111850261688, 0.019840864464640617, 0.07648499310016632, -0.06899261474609375, -0.1293591558933258, -0.14830312132835388, 0.009845051914453506] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2625/5550 val_loss:3.125128 train_time:650455ms step_avg:247.79ms x-lambda: 0.8901959657669067 lambdas: [-0.13539524376392365, -0.10656136274337769, 0.019604701548814774, 0.07342927902936935, -0.06674382090568542, -0.12507399916648865, -0.1530517190694809, 0.008476421236991882] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2750/5550 val_loss:3.114240 train_time:682117ms step_avg:248.04ms x-lambda: 0.8893632888793945 lambdas: [-0.1375177800655365, -0.1063607856631279, 0.01864333637058735, 0.07217690348625183, -0.06517529487609863, -0.12128059566020966, -0.15840372443199158, 0.008055977523326874] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:2875/5550 val_loss:3.105067 train_time:713815ms step_avg:248.28ms x-lambda: 0.8906478881835938 lambdas: [-0.13548119366168976, -0.10561884194612503, 0.020135601982474327, 0.06910163164138794, -0.06345518678426743, -0.11524251103401184, -0.16176047921180725, 0.009045113809406757] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3000/5550 val_loss:3.094961 train_time:745496ms step_avg:248.50ms x-lambda: 0.8907331824302673 lambdas: [-0.13564357161521912, -0.10527749359607697, 0.018129456788301468, 0.0678052306175232, -0.061953820288181305, -0.11174274981021881, -0.16587093472480774, 0.008166425861418247] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3125/5550 val_loss:3.083586 train_time:777211ms step_avg:248.71ms x-lambda: 0.8892974257469177 lambdas: [-0.13794179260730743, -0.10799530148506165, 0.017172640189528465, 0.06427939981222153, -0.0637001022696495, -0.11138293147087097, -0.1723107546567917, 0.007525214925408363] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3250/5550 val_loss:3.071606 train_time:808901ms step_avg:248.89ms x-lambda: 0.8918496966362 lambdas: [-0.13660261034965515, -0.10575582832098007, 0.018756913021206856, 0.06358470022678375, -0.062312670052051544, -0.10782089084386826, -0.17458072304725647, 0.008329489268362522] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3375/5550 val_loss:3.062564 train_time:840585ms step_avg:249.06ms x-lambda: 0.8927126526832581 lambdas: [-0.13700003921985626, -0.10564548522233963, 0.017251484096050262, 0.06243221089243889, -0.06162358075380325, -0.10577099025249481, -0.17761936783790588, 0.0083213672041893] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3500/5550 val_loss:3.054200 train_time:872289ms step_avg:249.23ms x-lambda: 0.8941362500190735 lambdas: [-0.1368250995874405, -0.10521649569272995, 0.01674831286072731, 0.059561099857091904, -0.06026560813188553, -0.10275547951459885, -0.1814510077238083, 0.007716864347457886] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3625/5550 val_loss:3.045259 train_time:903977ms step_avg:249.37ms x-lambda: 0.8978497982025146 lambdas: [-0.1361342966556549, -0.10332052409648895, 0.018716463819146156, 0.058941733092069626, -0.057901669293642044, -0.09907154738903046, -0.18353962898254395, 0.007509937044233084] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3750/5550 val_loss:3.035823 train_time:935669ms step_avg:249.51ms x-lambda: 0.898573637008667 lambdas: [-0.13742582499980927, -0.10309452563524246, 0.018477579578757286, 0.058433469384908676, -0.05812837556004524, -0.09792966395616531, -0.1868443340063095, 0.008004928939044476] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:3875/5550 val_loss:3.026951 train_time:967421ms step_avg:249.66ms x-lambda: 0.9040508270263672 lambdas: [-0.13655313849449158, -0.1031324565410614, 0.017215631902217865, 0.05743873864412308, -0.056452661752700806, -0.09643702208995819, -0.18906809389591217, 0.008040864020586014] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4000/5550 val_loss:3.017255 train_time:999169ms step_avg:249.79ms x-lambda: 0.9079470634460449 lambdas: [-0.13750548660755157, -0.10361739993095398, 0.017238641157746315, 0.05680010840296745, -0.05755571648478508, -0.09424787759780884, -0.1924949288368225, 0.007058178540319204] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4125/5550 val_loss:3.008200 train_time:1030945ms step_avg:249.93ms x-lambda: 0.9124491810798645 lambdas: [-0.13638800382614136, -0.1033506691455841, 0.018141644075512886, 0.054522693157196045, -0.05617692321538925, -0.09198130667209625, -0.1943812370300293, 0.008021744899451733] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4250/5550 val_loss:2.999987 train_time:1062941ms step_avg:250.10ms x-lambda: 0.9176920652389526 lambdas: [-0.13635320961475372, -0.1035686582326889, 0.01709938235580921, 0.055372972041368484, -0.05704324319958687, -0.0929211676120758, -0.1957421451807022, 0.007497348356992006] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4375/5550 val_loss:2.990682 train_time:1094959ms step_avg:250.28ms x-lambda: 0.9209508299827576 lambdas: [-0.1369284838438034, -0.10407393425703049, 0.015700779855251312, 0.053222984075546265, -0.05675354227423668, -0.0914800837635994, -0.19884167611598969, 0.00683890376240015] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4500/5550 val_loss:2.982789 train_time:1126984ms step_avg:250.44ms x-lambda: 0.9254005551338196 lambdas: [-0.13673724234104156, -0.10433041304349899, 0.0162894856184721, 0.05194833502173424, -0.055796921253204346, -0.08985496312379837, -0.20126467943191528, 0.0070671094581484795] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4625/5550 val_loss:2.973109 train_time:1159187ms step_avg:250.64ms x-lambda: 0.9319663047790527 lambdas: [-0.1353786289691925, -0.10281268507242203, 0.01674654893577099, 0.0508849211037159, -0.056128986179828644, -0.08835554867982864, -0.20145250856876373, 0.007138851098716259] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4750/5550 val_loss:2.963935 train_time:1191465ms step_avg:250.83ms x-lambda: 0.9380474090576172 lambdas: [-0.13631241023540497, -0.10233913362026215, 0.017196083441376686, 0.052783865481615067, -0.05660052224993706, -0.087065190076828, -0.20236600935459137, 0.007781404070556164] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:4875/5550 val_loss:2.955041 train_time:1223938ms step_avg:251.06ms x-lambda: 0.9443702697753906 lambdas: [-0.1362404227256775, -0.10430922359228134, 0.01610744744539261, 0.05127902701497078, -0.05635221302509308, -0.0861392617225647, -0.2041282057762146, 0.006815105676651001] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5000/5550 val_loss:2.946828 train_time:1256534ms step_avg:251.31ms x-lambda: 0.9512396454811096 lambdas: [-0.13630516827106476, -0.10419780761003494, 0.015909504145383835, 0.05230378359556198, -0.05665342137217522, -0.08591371029615402, -0.2054929882287979, 0.007246330846101046] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5125/5550 val_loss:2.939327 train_time:1289239ms step_avg:251.56ms x-lambda: 0.9570074677467346 lambdas: [-0.13675978779792786, -0.1051080971956253, 0.015991676598787308, 0.05075984075665474, -0.05562356486916542, -0.08538008481264114, -0.20710906386375427, 0.006714428309351206] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5250/5550 val_loss:2.932195 train_time:1322141ms step_avg:251.84ms x-lambda: 0.9625905752182007 lambdas: [-0.13742978870868683, -0.10353484749794006, 0.014738091267645359, 0.04918261989951134, -0.055040281265974045, -0.08357065171003342, -0.20807597041130066, 0.006863655522465706] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5375/5550 val_loss:2.925572 train_time:1355169ms step_avg:252.12ms x-lambda: 0.9680335521697998 lambdas: [-0.13708031177520752, -0.10482918471097946, 0.014983014203608036, 0.05041738972067833, -0.05617669224739075, -0.08421023190021515, -0.20849153399467468, 0.00714302621781826] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5500/5550 val_loss:2.920762 train_time:1388470ms step_avg:252.45ms x-lambda: 0.9717530012130737 lambdas: [-0.13735125958919525, -0.10443652421236038, 0.014398262836039066, 0.05019788816571236, -0.055778052657842636, -0.08430508524179459, -0.20878063142299652, 0.006500112824141979] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]
step:5550/5550 val_loss:2.919608 train_time:1401858ms step_avg:252.59ms x-lambda: 0.9725801348686218 lambdas: [-0.13750754296779633, -0.10456477105617523, 0.014404883608222008, 0.05010700225830078, -0.056143444031476974, -0.08404764533042908, -0.20908169448375702, 0.00646944111213088] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0]



## 8000-add-skip-multiple-8-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:125/5550 val_loss:4.268861 train_time:29200ms step_avg:233.60ms x-lambda: 1.026191234588623 lambdas: [0.018514780327677727, 0.023863960057497025, 0.026638368144631386, 0.029438413679599762, 0.040181513875722885, 0.02448909357190132, 0.02397982031106949, 0.027093933895230293] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:250/5550 val_loss:3.857778 train_time:58629ms step_avg:234.52ms x-lambda: 0.9967995882034302 lambdas: [-0.0023544784635305405, 0.01985963061451912, 0.020241785794496536, 0.01938422955572605, 0.04504700005054474, -0.03245076537132263, -0.009234647266566753, 0.025857774540781975] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:375/5550 val_loss:3.679197 train_time:88458ms step_avg:235.89ms x-lambda: 0.9967018961906433 lambdas: [-0.0033363851252943277, 0.02041587606072426, 0.011061226949095726, 0.0021737716160714626, 0.010342773981392384, -0.09377600997686386, -0.015719415619969368, 0.02357887476682663] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:500/5550 val_loss:3.561067 train_time:118629ms step_avg:237.26ms x-lambda: 0.9912403225898743 lambdas: [-0.009960214607417583, 0.016051622107625008, 0.00040710181929171085, -0.011675553396344185, -0.026853661984205246, -0.13143634796142578, -0.006066194735467434, 0.022463414818048477] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:625/5550 val_loss:3.483388 train_time:149019ms step_avg:238.43ms x-lambda: 0.9916971921920776 lambdas: [-0.01254913117736578, 0.014203320257365704, -0.007330926135182381, -0.019879408180713654, -0.057795558124780655, -0.14931653439998627, 0.006842655595391989, 0.023623760789632797] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:750/5550 val_loss:3.429542 train_time:179730ms step_avg:239.64ms x-lambda: 0.9863919615745544 lambdas: [-0.019589122384786606, 0.008722061291337013, -0.01791154406964779, -0.02843445912003517, -0.0859878808259964, -0.1563008725643158, 0.013852326199412346, 0.0226164311170578] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:875/5550 val_loss:3.382466 train_time:210523ms step_avg:240.60ms x-lambda: 0.9792848825454712 lambdas: [-0.024694276973605156, 0.00273128435947001, -0.026863615959882736, -0.033707067370414734, -0.11030451953411102, -0.15474891662597656, 0.01861077919602394, 0.02130584791302681] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1000/5550 val_loss:3.348141 train_time:241537ms step_avg:241.54ms x-lambda: 0.972785234451294 lambdas: [-0.029892751947045326, -0.0030976906418800354, -0.0359981395304203, -0.03691241517663002, -0.12991011142730713, -0.14998078346252441, 0.02098442241549492, 0.01945125311613083] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1125/5550 val_loss:3.318027 train_time:272591ms step_avg:242.30ms x-lambda: 0.9664101600646973 lambdas: [-0.03532973676919937, -0.010410631075501442, -0.04530124366283417, -0.03880060464143753, -0.14818470180034637, -0.1446303278207779, 0.02171245589852333, 0.016919629648327827] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1250/5550 val_loss:3.293660 train_time:303775ms step_avg:243.02ms x-lambda: 0.9623116850852966 lambdas: [-0.03827782720327377, -0.015430026687681675, -0.052154526114463806, -0.037958480417728424, -0.1612914502620697, -0.13900016248226166, 0.022911066189408302, 0.01726020686328411] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1375/5550 val_loss:3.272320 train_time:335166ms step_avg:243.76ms x-lambda: 0.954903244972229 lambdas: [-0.04415847361087799, -0.02267262153327465, -0.059575967490673065, -0.036936260759830475, -0.17351748049259186, -0.13189683854579926, 0.02357321046292782, 0.01420418918132782] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1500/5550 val_loss:3.251952 train_time:366519ms step_avg:244.35ms x-lambda: 0.9528902173042297 lambdas: [-0.04633983597159386, -0.027253251522779465, -0.0654466524720192, -0.03336722031235695, -0.1818723976612091, -0.12504759430885315, 0.025532957166433334, 0.01497182622551918] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1625/5550 val_loss:3.237181 train_time:397931ms step_avg:244.88ms x-lambda: 0.9470997452735901 lambdas: [-0.05110874027013779, -0.03289617970585823, -0.07123283296823502, -0.02963876724243164, -0.19011953473091125, -0.1188623458147049, 0.025539090856909752, 0.014929352328181267] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1750/5550 val_loss:3.220554 train_time:429316ms step_avg:245.32ms x-lambda: 0.9409019351005554 lambdas: [-0.05568394064903259, -0.038772474974393845, -0.07757682353258133, -0.02671191655099392, -0.1950123906135559, -0.11249666661024094, 0.024881849065423012, 0.014666728675365448] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:1875/5550 val_loss:3.202094 train_time:460786ms step_avg:245.75ms x-lambda: 0.9387967586517334 lambdas: [-0.058178890496492386, -0.043770212680101395, -0.08278782665729523, -0.022493964061141014, -0.20025035738945007, -0.10823884606361389, 0.024358250200748444, 0.012114269658923149] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2000/5550 val_loss:3.186378 train_time:492410ms step_avg:246.21ms x-lambda: 0.9331358075141907 lambdas: [-0.06282781809568405, -0.04911915957927704, -0.08748996257781982, -0.01763245463371277, -0.20312537252902985, -0.1029864251613617, 0.02508872002363205, 0.012399829924106598] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2125/5550 val_loss:3.172296 train_time:524097ms step_avg:246.63ms x-lambda: 0.9328667521476746 lambdas: [-0.06408392637968063, -0.05282999947667122, -0.09201715141534805, -0.013438515365123749, -0.20628049969673157, -0.0996762290596962, 0.02467426098883152, 0.0113673759624362] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2250/5550 val_loss:3.158659 train_time:555802ms step_avg:247.02ms x-lambda: 0.931570291519165 lambdas: [-0.06640893965959549, -0.05656423419713974, -0.09496360272169113, -0.00874380674213171, -0.20732778310775757, -0.09639746695756912, 0.025372372940182686, 0.010930610820651054] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2375/5550 val_loss:3.146706 train_time:587515ms step_avg:247.37ms x-lambda: 0.9297130107879639 lambdas: [-0.06874420493841171, -0.06002328544855118, -0.09897501021623611, -0.00597815215587616, -0.20815669000148773, -0.09176146239042282, 0.02483213134109974, 0.010045208968222141] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2500/5550 val_loss:3.134582 train_time:619151ms step_avg:247.66ms x-lambda: 0.9278525114059448 lambdas: [-0.07139624655246735, -0.06347176432609558, -0.10227620601654053, -0.002301090629771352, -0.20973125100135803, -0.09081260859966278, 0.023680517449975014, 0.00955973844975233] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2625/5550 val_loss:3.123571 train_time:650795ms step_avg:247.92ms x-lambda: 0.9282989501953125 lambdas: [-0.07252389937639236, -0.06687210500240326, -0.10546224564313889, 0.001031373394653201, -0.2098446488380432, -0.08770709484815598, 0.024486491456627846, 0.00936388410627842] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2750/5550 val_loss:3.112136 train_time:682456ms step_avg:248.17ms x-lambda: 0.9284988641738892 lambdas: [-0.07405325025320053, -0.06983867287635803, -0.10871808975934982, 0.002810804173350334, -0.20989225804805756, -0.08407973498106003, 0.025269147008657455, 0.009301133453845978] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:2875/5550 val_loss:3.103142 train_time:714148ms step_avg:248.40ms x-lambda: 0.9285818934440613 lambdas: [-0.07586728036403656, -0.07255209237337112, -0.1108141764998436, 0.007080967538058758, -0.2106713205575943, -0.0820692703127861, 0.024337105453014374, 0.00934720877557993] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3000/5550 val_loss:3.092160 train_time:745841ms step_avg:248.61ms x-lambda: 0.9279565811157227 lambdas: [-0.07713202387094498, -0.07544108480215073, -0.11315536499023438, 0.008683595806360245, -0.2122715562582016, -0.08033021539449692, 0.02350730635225773, 0.0087188221514225] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3125/5550 val_loss:3.081646 train_time:777585ms step_avg:248.83ms x-lambda: 0.9289054274559021 lambdas: [-0.08004344254732132, -0.07906495779752731, -0.11661091446876526, 0.010480226017534733, -0.2130538523197174, -0.0788574367761612, 0.021474121138453484, 0.007445154245942831] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3250/5550 val_loss:3.069969 train_time:809265ms step_avg:249.00ms x-lambda: 0.9312483668327332 lambdas: [-0.08019832521677017, -0.08034618943929672, -0.11686413735151291, 0.013096441514790058, -0.21217787265777588, -0.07827742397785187, 0.022210288792848587, 0.008252857252955437] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3375/5550 val_loss:3.061324 train_time:840953ms step_avg:249.17ms x-lambda: 0.9337118864059448 lambdas: [-0.08128082752227783, -0.08329731225967407, -0.11875859647989273, 0.015209496021270752, -0.21381840109825134, -0.07592624425888062, 0.022734327241778374, 0.007204373367130756] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3500/5550 val_loss:3.052949 train_time:872654ms step_avg:249.33ms x-lambda: 0.934747576713562 lambdas: [-0.08329618722200394, -0.08574547618627548, -0.12140800058841705, 0.0162969958037138, -0.21258936822414398, -0.07532189041376114, 0.021976560354232788, 0.005975300911813974] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3625/5550 val_loss:3.043944 train_time:904344ms step_avg:249.47ms x-lambda: 0.9384050965309143 lambdas: [-0.08289775252342224, -0.08591810613870621, -0.12186167389154434, 0.01747129298746586, -0.2117667943239212, -0.07397536188364029, 0.021747153252363205, 0.0064795613288879395] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3750/5550 val_loss:3.034288 train_time:936023ms step_avg:249.61ms x-lambda: 0.9409627318382263 lambdas: [-0.08371601998806, -0.08730434626340866, -0.1229781061410904, 0.019178487360477448, -0.21214303374290466, -0.07317937165498734, 0.02368185482919216, 0.00628093583509326] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:3875/5550 val_loss:3.026406 train_time:967794ms step_avg:249.75ms x-lambda: 0.9460418224334717 lambdas: [-0.08184518665075302, -0.08736994117498398, -0.1241569072008133, 0.020898787304759026, -0.21316425502300262, -0.07221768796443939, 0.022601213306188583, 0.0060235559940338135] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4000/5550 val_loss:3.016750 train_time:999527ms step_avg:249.88ms x-lambda: 0.9499170780181885 lambdas: [-0.0849594697356224, -0.08989568054676056, -0.12595108151435852, 0.023191101849079132, -0.21348382532596588, -0.0714203342795372, 0.021166838705539703, 0.005436254665255547] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4125/5550 val_loss:3.007074 train_time:1031310ms step_avg:250.01ms x-lambda: 0.9538000226020813 lambdas: [-0.08593843877315521, -0.09111086279153824, -0.12642288208007812, 0.024097170680761337, -0.21305620670318604, -0.07067415118217468, 0.022217275574803352, 0.005801909603178501] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4250/5550 val_loss:2.998750 train_time:1063319ms step_avg:250.19ms x-lambda: 0.9587226510047913 lambdas: [-0.08521562069654465, -0.09129946678876877, -0.12777294218540192, 0.024824904277920723, -0.21392707526683807, -0.07053271681070328, 0.022507093846797943, 0.005006819032132626] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4375/5550 val_loss:2.989339 train_time:1095354ms step_avg:250.37ms x-lambda: 0.9630732536315918 lambdas: [-0.08722321689128876, -0.09353499859571457, -0.12924259901046753, 0.025531571358442307, -0.21373715996742249, -0.0695730671286583, 0.021313516423106194, 0.005826566368341446] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4500/5550 val_loss:2.981385 train_time:1127444ms step_avg:250.54ms x-lambda: 0.9676067233085632 lambdas: [-0.08777397125959396, -0.09447217732667923, -0.13020777702331543, 0.026578493416309357, -0.21509048342704773, -0.06856438517570496, 0.021344151347875595, 0.005642452277243137] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4625/5550 val_loss:2.971962 train_time:1159648ms step_avg:250.73ms x-lambda: 0.9733473658561707 lambdas: [-0.08689729869365692, -0.09445173293352127, -0.1303301900625229, 0.027098005637526512, -0.21443894505500793, -0.0687248483300209, 0.021184207871556282, 0.004424563143402338] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4750/5550 val_loss:2.962813 train_time:1191960ms step_avg:250.94ms x-lambda: 0.9796931147575378 lambdas: [-0.0869772657752037, -0.09532883018255234, -0.1303420066833496, 0.029014170169830322, -0.2147105187177658, -0.06857620924711227, 0.02073890157043934, 0.0058249058201909065] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:4875/5550 val_loss:2.953960 train_time:1224437ms step_avg:251.17ms x-lambda: 0.9852526187896729 lambdas: [-0.08755557239055634, -0.09657841920852661, -0.13131673634052277, 0.029812999069690704, -0.2168724089860916, -0.0677792951464653, 0.020994754508137703, 0.0035199960693717003] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5000/5550 val_loss:2.945767 train_time:1257044ms step_avg:251.41ms x-lambda: 0.9918755292892456 lambdas: [-0.08734636008739471, -0.09715382754802704, -0.13217851519584656, 0.03039602003991604, -0.21617747843265533, -0.06775876879692078, 0.019504031166434288, 0.004400934092700481] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5125/5550 val_loss:2.938217 train_time:1289803ms step_avg:251.67ms x-lambda: 0.9972318410873413 lambdas: [-0.0874946117401123, -0.09779772162437439, -0.13279958069324493, 0.03103172779083252, -0.21835963428020477, -0.06753858178853989, 0.019874505698680878, 0.004398967605084181] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5250/5550 val_loss:2.931092 train_time:1322736ms step_avg:251.95ms x-lambda: 1.001899003982544 lambdas: [-0.08797474950551987, -0.0984743982553482, -0.13285160064697266, 0.032037150114774704, -0.2169879525899887, -0.06729686260223389, 0.020153192803263664, 0.004034020937979221] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5375/5550 val_loss:2.924625 train_time:1355774ms step_avg:252.24ms x-lambda: 1.0066783428192139 lambdas: [-0.0877821296453476, -0.0984630212187767, -0.13345977663993835, 0.03251234069466591, -0.21821542084217072, -0.06783967465162277, 0.020081371068954468, 0.004355959128588438] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5500/5550 val_loss:2.919888 train_time:1389071ms step_avg:252.56ms x-lambda: 1.0101401805877686 lambdas: [-0.08731147646903992, -0.09867872297763824, -0.13389164209365845, 0.03308798372745514, -0.21890179812908173, -0.06757320463657379, 0.01960425078868866, 0.003995456732809544] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]
step:5550/5550 val_loss:2.918705 train_time:1402451ms step_avg:252.69ms x-lambda: 1.0108915567398071 lambdas: [-0.0873660296201706, -0.09886866062879562, -0.13428352773189545, 0.03308850899338722, -0.219040647149086, -0.06767050176858902, 0.019638791680336, 0.0035939658991992474] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7]



## 8000-add-skip-multiple-8-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.17ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:125/5550 val_loss:4.267126 train_time:29239ms step_avg:233.91ms x-lambda: 1.0379201173782349 lambdas: [0.08022348582744598, -0.002140113152563572, -0.027087785303592682, -0.03703548014163971, 0.07570338994264603, 0.054395586252212524, 0.04147220775485039, 0.038295019418001175] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:250/5550 val_loss:3.851572 train_time:58612ms step_avg:234.45ms x-lambda: 1.0148143768310547 lambdas: [0.07501144707202911, -0.04043357074260712, -0.08815516531467438, -0.11661265045404434, 0.11221446841955185, 0.05390338599681854, 0.01711862161755562, 0.03195918723940849] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:375/5550 val_loss:3.675778 train_time:88441ms step_avg:235.84ms x-lambda: 0.9995089173316956 lambdas: [0.06560181081295013, -0.04472588747739792, -0.10704346001148224, -0.15650317072868347, 0.11769309639930725, 0.039464712142944336, -0.014005245640873909, 0.021578473970294] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:500/5550 val_loss:3.559812 train_time:118588ms step_avg:237.18ms x-lambda: 0.9749475121498108 lambdas: [0.05892033502459526, -0.04060560464859009, -0.11334280669689178, -0.1751934438943863, 0.11958248168230057, 0.03247569501399994, -0.03271905705332756, 0.01980217546224594] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:625/5550 val_loss:3.481230 train_time:148972ms step_avg:238.36ms x-lambda: 0.9339378476142883 lambdas: [0.05078835412859917, -0.03689977899193764, -0.11773614585399628, -0.18415546417236328, 0.117813840508461, 0.026138804852962494, -0.04669903963804245, 0.016617123037576675] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:750/5550 val_loss:3.427512 train_time:179666ms step_avg:239.55ms x-lambda: 0.9000916481018066 lambdas: [0.047583773732185364, -0.03054800070822239, -0.11760401725769043, -0.18207679688930511, 0.11673769354820251, 0.023943474516272545, -0.05203017592430115, 0.017807669937610626] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:875/5550 val_loss:3.383482 train_time:210410ms step_avg:240.47ms x-lambda: 0.8592590689659119 lambdas: [0.04230808466672897, -0.025845995172858238, -0.11586777120828629, -0.17724668979644775, 0.11161614954471588, 0.020662838593125343, -0.05527515709400177, 0.016277143731713295] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1000/5550 val_loss:3.348185 train_time:241445ms step_avg:241.44ms x-lambda: 0.8249488472938538 lambdas: [0.04116705432534218, -0.018991190940141678, -0.11030620336532593, -0.16479261219501495, 0.10653095692396164, 0.020748576149344444, -0.05514233186841011, 0.01677289977669716] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1125/5550 val_loss:3.319450 train_time:272491ms step_avg:242.21ms x-lambda: 0.792007565498352 lambdas: [0.034607354551553726, -0.018429582938551903, -0.10942590236663818, -0.15622548758983612, 0.09753964841365814, 0.01652493327856064, -0.056672945618629456, 0.014713644050061703] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1250/5550 val_loss:3.292969 train_time:303691ms step_avg:242.95ms x-lambda: 0.7642983198165894 lambdas: [0.03335408866405487, -0.016016945242881775, -0.1056487187743187, -0.14574630558490753, 0.09071580320596695, 0.017382381483912468, -0.055363141000270844, 0.01406641025096178] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1375/5550 val_loss:3.272702 train_time:335056ms step_avg:243.68ms x-lambda: 0.7382538914680481 lambdas: [0.03203745558857918, -0.013314885087311268, -0.09991631656885147, -0.1350426971912384, 0.08395568281412125, 0.015047973021864891, -0.05532735213637352, 0.012427507899701595] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1500/5550 val_loss:3.252161 train_time:366404ms step_avg:244.27ms x-lambda: 0.7178694605827332 lambdas: [0.03099146857857704, -0.01094649825245142, -0.09688401222229004, -0.1274048388004303, 0.07781916111707687, 0.014852694235742092, -0.05268499255180359, 0.012541624717414379] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1625/5550 val_loss:3.236877 train_time:397815ms step_avg:244.81ms x-lambda: 0.6955010890960693 lambdas: [0.029413966462016106, -0.009891466237604618, -0.09418829530477524, -0.11925630271434784, 0.0731709897518158, 0.01445478294044733, -0.051434680819511414, 0.011748136021196842] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1750/5550 val_loss:3.225230 train_time:429215ms step_avg:245.27ms x-lambda: 0.6771657466888428 lambdas: [0.02911994978785515, -0.006696608848869801, -0.08794822543859482, -0.10800193250179291, 0.0692254975438118, 0.015958385542035103, -0.047840509563684464, 0.014246178790926933] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:1875/5550 val_loss:3.203498 train_time:460678ms step_avg:245.70ms x-lambda: 0.6624236702919006 lambdas: [0.02575167827308178, -0.007590674329549074, -0.08759797364473343, -0.10490860044956207, 0.06282885372638702, 0.012705632485449314, -0.049422286450862885, 0.01168377697467804] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2000/5550 val_loss:3.188530 train_time:492328ms step_avg:246.16ms x-lambda: 0.6467396020889282 lambdas: [0.02514095976948738, -0.006950677372515202, -0.08400531858205795, -0.09710542112588882, 0.05797688663005829, 0.013434408232569695, -0.04741910845041275, 0.01049230806529522] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2125/5550 val_loss:3.173270 train_time:524011ms step_avg:246.59ms x-lambda: 0.6383565664291382 lambdas: [0.024797828868031502, -0.005389554426074028, -0.08206478506326675, -0.09344116598367691, 0.05526161938905716, 0.012457689270377159, -0.04699784889817238, 0.00910763256251812] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2250/5550 val_loss:3.160070 train_time:555701ms step_avg:246.98ms x-lambda: 0.6296509504318237 lambdas: [0.023591112345457077, -0.006048848852515221, -0.0793236792087555, -0.08821238577365875, 0.05118270590901375, 0.011993028223514557, -0.04550528526306152, 0.008690886199474335] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2375/5550 val_loss:3.148322 train_time:587439ms step_avg:247.34ms x-lambda: 0.6226775050163269 lambdas: [0.021984299644827843, -0.005666640121489763, -0.0772155374288559, -0.08401905745267868, 0.048464126884937286, 0.011073742993175983, -0.0448838509619236, 0.00853825081139803] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2500/5550 val_loss:3.136640 train_time:619104ms step_avg:247.64ms x-lambda: 0.6167062520980835 lambdas: [0.022947560995817184, -0.005288973916321993, -0.0743527039885521, -0.0813320204615593, 0.04734790697693825, 0.011854368261992931, -0.04402993246912956, 0.007749063428491354] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2625/5550 val_loss:3.125978 train_time:650771ms step_avg:247.91ms x-lambda: 0.6129288077354431 lambdas: [0.02191636711359024, -0.004384438507258892, -0.0724058747291565, -0.0753055289387703, 0.0455673411488533, 0.012370824813842773, -0.04077094420790672, 0.008143027313053608] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2750/5550 val_loss:3.114068 train_time:682419ms step_avg:248.15ms x-lambda: 0.6083651185035706 lambdas: [0.020685069262981415, -0.0032080216333270073, -0.07160432636737823, -0.07438021153211594, 0.04238125681877136, 0.011188131757080555, -0.040706854313611984, 0.00755343958735466] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:2875/5550 val_loss:3.104628 train_time:714122ms step_avg:248.39ms x-lambda: 0.6053245663642883 lambdas: [0.02090035378932953, -0.004048285074532032, -0.0697779431939125, -0.07118504494428635, 0.04073571786284447, 0.009875151328742504, -0.04051380977034569, 0.006331903859972954] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3000/5550 val_loss:3.093931 train_time:745805ms step_avg:248.60ms x-lambda: 0.6050308346748352 lambdas: [0.02005169168114662, -0.004184435587376356, -0.06846132129430771, -0.06984030455350876, 0.03946813568472862, 0.009859660640358925, -0.039288245141506195, 0.005917626898735762] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3125/5550 val_loss:3.082629 train_time:777542ms step_avg:248.81ms x-lambda: 0.6024119853973389 lambdas: [0.020319251343607903, -0.003441463690251112, -0.0676722377538681, -0.06932833045721054, 0.038398515433073044, 0.009795599617064, -0.03891485184431076, 0.005467097274959087] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3250/5550 val_loss:3.071523 train_time:809235ms step_avg:249.00ms x-lambda: 0.6045236587524414 lambdas: [0.01972902938723564, -0.0032653468661010265, -0.06554021686315536, -0.06480904668569565, 0.03631915524601936, 0.009600778110325336, -0.03828567638993263, 0.006420808378607035] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3375/5550 val_loss:3.062974 train_time:840915ms step_avg:249.16ms x-lambda: 0.6036007404327393 lambdas: [0.018327943980693817, -0.00395627599209547, -0.06572791934013367, -0.06492175161838531, 0.03543887287378311, 0.007952213287353516, -0.03677556663751602, 0.004527289420366287] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3500/5550 val_loss:3.054604 train_time:872615ms step_avg:249.32ms x-lambda: 0.6027722954750061 lambdas: [0.017310643568634987, -0.004596291109919548, -0.06498900055885315, -0.06256678700447083, 0.033656567335128784, 0.00768772279843688, -0.03852357715368271, 0.0038877581246197224] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3625/5550 val_loss:3.045257 train_time:904309ms step_avg:249.46ms x-lambda: 0.6082684397697449 lambdas: [0.01852596364915371, -0.004222479648888111, -0.06210686266422272, -0.059824202209711075, 0.03408549353480339, 0.008142838254570961, -0.03523911163210869, 0.0038589017931371927] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3750/5550 val_loss:3.035681 train_time:935987ms step_avg:249.60ms x-lambda: 0.6087489128112793 lambdas: [0.019146395847201347, -0.0030329932924360037, -0.06207174435257912, -0.05859082192182541, 0.03304423391819, 0.008994546718895435, -0.035438425838947296, 0.0045648496598005295] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:3875/5550 val_loss:3.026881 train_time:967762ms step_avg:249.75ms x-lambda: 0.6134865283966064 lambdas: [0.019024277105927467, -0.0036526727490127087, -0.06146595999598503, -0.05850367993116379, 0.03239859640598297, 0.007634573150426149, -0.035278137773275375, 0.0036501928698271513] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4000/5550 val_loss:3.017443 train_time:999497ms step_avg:249.87ms x-lambda: 0.617779552936554 lambdas: [0.018558062613010406, -0.002098425989970565, -0.060004059225320816, -0.05668962746858597, 0.032223641872406006, 0.008124479092657566, -0.03415871784090996, 0.0032836063764989376] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4125/5550 val_loss:3.008164 train_time:1031256ms step_avg:250.00ms x-lambda: 0.6237754821777344 lambdas: [0.01938699372112751, -0.0034398725256323814, -0.058915529400110245, -0.05686243996024132, 0.03143727779388428, 0.0069375415332615376, -0.03426093980669975, 0.0030204039067029953] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4250/5550 val_loss:2.999871 train_time:1063245ms step_avg:250.18ms x-lambda: 0.627770721912384 lambdas: [0.01753157563507557, -0.003233673283830285, -0.05859486386179924, -0.05540778115391731, 0.030551576986908913, 0.008598907850682735, -0.03341241553425789, 0.0028799641877412796] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4375/5550 val_loss:2.990809 train_time:1095272ms step_avg:250.35ms x-lambda: 0.63167405128479 lambdas: [0.01808604784309864, -0.0029233312234282494, -0.05972882732748985, -0.05454040691256523, 0.030245309695601463, 0.007006313186138868, -0.03283240646123886, 0.0025525956880301237] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4500/5550 val_loss:2.982875 train_time:1127334ms step_avg:250.52ms x-lambda: 0.6369686126708984 lambdas: [0.01697864569723606, -0.0024795345962047577, -0.05943101644515991, -0.053962767124176025, 0.028709687292575836, 0.006789383944123983, -0.03230081498622894, 0.0019018342718482018] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4625/5550 val_loss:2.973348 train_time:1159541ms step_avg:250.71ms x-lambda: 0.644873321056366 lambdas: [0.017536889761686325, -0.0029047667048871517, -0.058079272508621216, -0.052651502192020416, 0.02820737287402153, 0.006049646995961666, -0.032871440052986145, 0.0011623554164543748] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4750/5550 val_loss:2.963938 train_time:1191833ms step_avg:250.91ms x-lambda: 0.6527019739151001 lambdas: [0.01805347204208374, -0.0022539489436894655, -0.05735612288117409, -0.0532093420624733, 0.02930947206914425, 0.007132465485483408, -0.03240799531340599, 0.0021343319676816463] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:4875/5550 val_loss:2.955251 train_time:1224328ms step_avg:251.14ms x-lambda: 0.6595283150672913 lambdas: [0.017374476417899132, -0.002682681195437908, -0.05698896571993828, -0.05220155045390129, 0.028621148318052292, 0.006786346901208162, -0.03330574929714203, 0.000887710542883724] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5000/5550 val_loss:2.946954 train_time:1256902ms step_avg:251.38ms x-lambda: 0.6678590178489685 lambdas: [0.01755041442811489, -0.0030535776168107986, -0.057017646729946136, -0.050344619899988174, 0.02905164286494255, 0.005973696708679199, -0.0311468206346035, 0.00038377600139938295] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5125/5550 val_loss:2.939479 train_time:1289612ms step_avg:251.63ms x-lambda: 0.6751227378845215 lambdas: [0.016983335837721825, -0.002158238785341382, -0.05658372491598129, -0.05135937035083771, 0.028601089492440224, 0.006373945623636246, -0.031204093247652054, 0.0010539884679019451] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5250/5550 val_loss:2.932207 train_time:1322527ms step_avg:251.91ms x-lambda: 0.6834550499916077 lambdas: [0.017408544197678566, -0.0022424275521188974, -0.05612700432538986, -0.05063464865088463, 0.027535421773791313, 0.006303487811237574, -0.029963292181491852, 1.4564837329089642e-05] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5375/5550 val_loss:2.925801 train_time:1355562ms step_avg:252.20ms x-lambda: 0.6930293440818787 lambdas: [0.017802102491259575, -0.0028993936721235514, -0.055793143808841705, -0.05040576308965683, 0.02812742255628109, 0.006432482972741127, -0.030665244907140732, 0.00020925496937707067] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5500/5550 val_loss:2.921004 train_time:1388864ms step_avg:252.52ms x-lambda: 0.6983433961868286 lambdas: [0.01701500080525875, -0.0028675019275397062, -0.05633462220430374, -0.05011351406574249, 0.028098858892917633, 0.0061445292085409164, -0.030355578288435936, -0.00011464403360150754] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]
step:5550/5550 val_loss:2.919829 train_time:1402244ms step_avg:252.66ms x-lambda: 0.699893057346344 lambdas: [0.017102936282753944, -0.002812942024320364, -0.05650120601058006, -0.05032096430659294, 0.027944307774305344, 0.005715286824852228, -0.029772819951176643, -0.0006602762150578201] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7]



## 8000-add-skip-multiple-8-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.36ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:125/5550 val_loss:4.265404 train_time:29235ms step_avg:233.88ms x-lambda: 1.060584545135498 lambdas: [0.006993476301431656, 0.03549141064286232, 0.05118881165981293, 0.001510826637968421, 0.027316905558109283, -0.002190621569752693, 0.026855820789933205, 0.02519252896308899] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:250/5550 val_loss:3.853358 train_time:58563ms step_avg:234.25ms x-lambda: 1.0655118227005005 lambdas: [-0.03051842376589775, 0.005526701919734478, 1.5933415852487087e-05, 0.0025492897257208824, 0.0013953292509540915, -0.014914684928953648, -0.0018741738749668002, -0.0025713841896504164] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:375/5550 val_loss:3.676956 train_time:88363ms step_avg:235.63ms x-lambda: 1.044315218925476 lambdas: [-0.035599857568740845, -0.011055728420615196, -0.023283405229449272, -0.0038944673724472523, -0.01038607582449913, -0.013394689187407494, -0.015209909528493881, -0.023555371910333633] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:500/5550 val_loss:3.561369 train_time:118557ms step_avg:237.11ms x-lambda: 1.0003345012664795 lambdas: [-0.03901611641049385, -0.018818533048033714, -0.03297842666506767, -0.00899154506623745, -0.019174156710505486, -0.016044288873672485, -0.022678304463624954, -0.033525388687849045] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:625/5550 val_loss:3.484002 train_time:148978ms step_avg:238.36ms x-lambda: 0.9538122415542603 lambdas: [-0.036340124905109406, -0.019415808841586113, -0.03190423920750618, -0.007287775166332722, -0.017281372100114822, -0.01650736853480339, -0.023395279422402382, -0.03301380202174187] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:750/5550 val_loss:3.431903 train_time:179623ms step_avg:239.50ms x-lambda: 0.9078768491744995 lambdas: [-0.03654130920767784, -0.02068047970533371, -0.03118448704481125, -0.01171899400651455, -0.01854771375656128, -0.019634945318102837, -0.024717846885323524, -0.032809872180223465] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:875/5550 val_loss:3.386172 train_time:210373ms step_avg:240.43ms x-lambda: 0.8631237149238586 lambdas: [-0.031602632254362106, -0.016667915508151054, -0.026612043380737305, -0.009956336580216885, -0.0163503959774971, -0.016306810081005096, -0.02192200906574726, -0.029247848317027092] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1000/5550 val_loss:3.349086 train_time:241400ms step_avg:241.40ms x-lambda: 0.8241239190101624 lambdas: [-0.029362574219703674, -0.017803721129894257, -0.02533099241554737, -0.01072879508137703, -0.015200595371425152, -0.016690155491232872, -0.020353060215711594, -0.02772861160337925] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1125/5550 val_loss:3.321707 train_time:272492ms step_avg:242.22ms x-lambda: 0.7887676358222961 lambdas: [-0.02854190021753311, -0.016728300601243973, -0.02471458911895752, -0.010939671657979488, -0.015522344037890434, -0.017210308462381363, -0.019452543929219246, -0.02795713022351265] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1250/5550 val_loss:3.294886 train_time:303697ms step_avg:242.96ms x-lambda: 0.7599207162857056 lambdas: [-0.025145970284938812, -0.01505306363105774, -0.022374235093593597, -0.010050657205283642, -0.014565608464181423, -0.015653254464268684, -0.0183403342962265, -0.02463485300540924] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1375/5550 val_loss:3.274879 train_time:335083ms step_avg:243.70ms x-lambda: 0.7322304248809814 lambdas: [-0.02573755756020546, -0.01474493183195591, -0.022184714674949646, -0.010604266077280045, -0.013511627912521362, -0.01677095890045166, -0.017542125657200813, -0.02356606349349022] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1500/5550 val_loss:3.256008 train_time:366451ms step_avg:244.30ms x-lambda: 0.7113575339317322 lambdas: [-0.021614501252770424, -0.012906006537377834, -0.019958825781941414, -0.008377137593925, -0.012148440815508366, -0.01415959745645523, -0.014608928933739662, -0.021291742101311684] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1625/5550 val_loss:3.242305 train_time:397894ms step_avg:244.86ms x-lambda: 0.6906461715698242 lambdas: [-0.018966928124427795, -0.011754512786865234, -0.01669210009276867, -0.00751385698094964, -0.010095578618347645, -0.012079514563083649, -0.01382876094430685, -0.019176585599780083] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1750/5550 val_loss:3.225409 train_time:429328ms step_avg:245.33ms x-lambda: 0.6695033311843872 lambdas: [-0.018892239779233932, -0.011047410778701305, -0.01745108887553215, -0.007513954769819975, -0.010334841907024384, -0.011771170422434807, -0.01272678840905428, -0.018664944916963577] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:1875/5550 val_loss:3.209955 train_time:460796ms step_avg:245.76ms x-lambda: 0.6587429046630859 lambdas: [-0.015371428802609444, -0.010941867716610432, -0.013955590315163136, -0.005767454858869314, -0.008158388547599316, -0.010140434838831425, -0.01126109529286623, -0.01789923943579197] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2000/5550 val_loss:3.192454 train_time:492488ms step_avg:246.24ms x-lambda: 0.6428475975990295 lambdas: [-0.015862319618463516, -0.008847033604979515, -0.014949514530599117, -0.006498444359749556, -0.009275740943849087, -0.009655858390033245, -0.011749358847737312, -0.016151489689946175] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2125/5550 val_loss:3.175423 train_time:524212ms step_avg:246.69ms x-lambda: 0.6324155330657959 lambdas: [-0.01617540419101715, -0.011196472682058811, -0.014250093139708042, -0.00806334801018238, -0.00882691890001297, -0.010767125524580479, -0.011561587452888489, -0.017994146794080734] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2250/5550 val_loss:3.161588 train_time:555932ms step_avg:247.08ms x-lambda: 0.6246167421340942 lambdas: [-0.015396637842059135, -0.01067234855145216, -0.014306308701634407, -0.0077489824034273624, -0.009758969768881798, -0.010484631173312664, -0.011955290101468563, -0.0164455808699131] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2375/5550 val_loss:3.150391 train_time:587660ms step_avg:247.44ms x-lambda: 0.6167987585067749 lambdas: [-0.015825506299734116, -0.011470666155219078, -0.01450333558022976, -0.008135531097650528, -0.009008645080029964, -0.010432081297039986, -0.011506574228405952, -0.0168510340154171] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2500/5550 val_loss:3.137967 train_time:619327ms step_avg:247.73ms x-lambda: 0.612634003162384 lambdas: [-0.015398572199046612, -0.009549782611429691, -0.013343504630029202, -0.006782874930649996, -0.009228994138538837, -0.009553597308695316, -0.009561716578900814, -0.014949986711144447] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2625/5550 val_loss:3.126824 train_time:651009ms step_avg:248.00ms x-lambda: 0.6071638464927673 lambdas: [-0.013473286293447018, -0.010053080506622791, -0.01449784729629755, -0.007357672322541475, -0.009598901495337486, -0.009557118639349937, -0.010877559892833233, -0.015443296171724796] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2750/5550 val_loss:3.116992 train_time:682699ms step_avg:248.25ms x-lambda: 0.6018591523170471 lambdas: [-0.013195689767599106, -0.010602327063679695, -0.013075415045022964, -0.007132730446755886, -0.00932239554822445, -0.010750515386462212, -0.010691294446587563, -0.015774965286254883] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:2875/5550 val_loss:3.107244 train_time:714427ms step_avg:248.50ms x-lambda: 0.6014037728309631 lambdas: [-0.012966184876859188, -0.008817089721560478, -0.01220661774277687, -0.006933630909770727, -0.007425965275615454, -0.009011761285364628, -0.009365142323076725, -0.013961472548544407] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3000/5550 val_loss:3.095321 train_time:746133ms step_avg:248.71ms x-lambda: 0.600893497467041 lambdas: [-0.012140633538365364, -0.008155195973813534, -0.011921459808945656, -0.006386479362845421, -0.008198271505534649, -0.009010301902890205, -0.009366447106003761, -0.0143164386972785] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3125/5550 val_loss:3.085156 train_time:777895ms step_avg:248.93ms x-lambda: 0.5984970331192017 lambdas: [-0.012147709727287292, -0.010767092928290367, -0.013369495049118996, -0.006867772433906794, -0.008442988619208336, -0.008990452624857426, -0.009388940408825874, -0.01413443498313427] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3250/5550 val_loss:3.073350 train_time:809604ms step_avg:249.11ms x-lambda: 0.5997429490089417 lambdas: [-0.01059377659112215, -0.008567394688725471, -0.011374368332326412, -0.005956810899078846, -0.0068394578993320465, -0.007630972657352686, -0.008509441278874874, -0.013178044930100441] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3375/5550 val_loss:3.064257 train_time:841317ms step_avg:249.28ms x-lambda: 0.6001230478286743 lambdas: [-0.011352583765983582, -0.009206213988363743, -0.012308080680668354, -0.0070632388815283775, -0.00795256718993187, -0.008944704197347164, -0.008524074219167233, -0.013378621079027653] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3500/5550 val_loss:3.055755 train_time:873027ms step_avg:249.44ms x-lambda: 0.6001209616661072 lambdas: [-0.012220836244523525, -0.008845801465213299, -0.011388590559363365, -0.006477094255387783, -0.00864260084927082, -0.008865103125572205, -0.009134432300925255, -0.013160187751054764] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3625/5550 val_loss:3.046895 train_time:904738ms step_avg:249.58ms x-lambda: 0.6034270524978638 lambdas: [-0.010152524337172508, -0.00781099870800972, -0.010706898756325245, -0.005671825259923935, -0.007725616917014122, -0.007809716276824474, -0.008169458247721195, -0.012293531559407711] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3750/5550 val_loss:3.037355 train_time:936451ms step_avg:249.72ms x-lambda: 0.6030136942863464 lambdas: [-0.010342597961425781, -0.008393890224397182, -0.011248662136495113, -0.0059049613773822784, -0.006577916443347931, -0.006959396414458752, -0.008659128099679947, -0.011802694760262966] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:3875/5550 val_loss:3.028538 train_time:968246ms step_avg:249.87ms x-lambda: 0.6108530759811401 lambdas: [-0.010119275189936161, -0.007585299666970968, -0.0107020428404212, -0.004267761949449778, -0.007452811114490032, -0.007168026641011238, -0.008420031517744064, -0.012234221212565899] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4000/5550 val_loss:3.019087 train_time:1000016ms step_avg:250.00ms x-lambda: 0.612888753414154 lambdas: [-0.00975184515118599, -0.007979566231369972, -0.009690302424132824, -0.004990327171981335, -0.007425617426633835, -0.007060511969029903, -0.007371604908257723, -0.011935160495340824] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4125/5550 val_loss:3.009543 train_time:1031826ms step_avg:250.14ms x-lambda: 0.6171160936355591 lambdas: [-0.009218593128025532, -0.006708293687552214, -0.009826074354350567, -0.0062125567346811295, -0.006321520544588566, -0.007287048734724522, -0.007836420089006424, -0.011701763607561588] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4250/5550 val_loss:3.001464 train_time:1063822ms step_avg:250.31ms x-lambda: 0.6210944652557373 lambdas: [-0.009801198728382587, -0.007887580431997776, -0.009524802677333355, -0.006805368699133396, -0.006955835502594709, -0.007322357501834631, -0.006821234244853258, -0.01253283116966486] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4375/5550 val_loss:2.992417 train_time:1095862ms step_avg:250.48ms x-lambda: 0.6246433258056641 lambdas: [-0.010400859639048576, -0.008051819168031216, -0.01036922913044691, -0.005765163339674473, -0.006626325659453869, -0.0082169808447361, -0.00781317800283432, -0.013162353076040745] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4500/5550 val_loss:2.983868 train_time:1127938ms step_avg:250.65ms x-lambda: 0.6298628449440002 lambdas: [-0.009192770346999168, -0.008117226883769035, -0.009773679077625275, -0.0060091400519013405, -0.007080972194671631, -0.006390067748725414, -0.00797575619071722, -0.01234196126461029] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4625/5550 val_loss:2.974525 train_time:1160167ms step_avg:250.85ms x-lambda: 0.6378292441368103 lambdas: [-0.011260109022259712, -0.00825134664773941, -0.010503939352929592, -0.005327886901795864, -0.008222753182053566, -0.008629117161035538, -0.009025797247886658, -0.010673854500055313] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4750/5550 val_loss:2.965133 train_time:1192485ms step_avg:251.05ms x-lambda: 0.6437024474143982 lambdas: [-0.009090197272598743, -0.007590609602630138, -0.009082658216357231, -0.005650656763464212, -0.006152388174086809, -0.006975824013352394, -0.006580515298992395, -0.010406583547592163] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:4875/5550 val_loss:2.956193 train_time:1224987ms step_avg:251.28ms x-lambda: 0.6504930853843689 lambdas: [-0.008995161391794682, -0.007520124316215515, -0.009918720461428165, -0.006285683251917362, -0.006428792141377926, -0.007349451072514057, -0.0075300270691514015, -0.012069972231984138] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5000/5550 val_loss:2.948112 train_time:1257601ms step_avg:251.52ms x-lambda: 0.6576675772666931 lambdas: [-0.00893264077603817, -0.00733958650380373, -0.009777790866792202, -0.005694819614291191, -0.006615904159843922, -0.007343387696892023, -0.006732403766363859, -0.010695329867303371] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5125/5550 val_loss:2.940493 train_time:1290341ms step_avg:251.77ms x-lambda: 0.6660746932029724 lambdas: [-0.008539261296391487, -0.0073411837220191956, -0.009177178144454956, -0.004883012268692255, -0.006429729983210564, -0.006794049870222807, -0.007352475076913834, -0.010721847414970398] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5250/5550 val_loss:2.933249 train_time:1323311ms step_avg:252.06ms x-lambda: 0.6717427372932434 lambdas: [-0.008345684967935085, -0.007228770758956671, -0.009586555883288383, -0.005601102486252785, -0.006045193877071142, -0.006305588409304619, -0.007739831227809191, -0.010541576892137527] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5375/5550 val_loss:2.926876 train_time:1356363ms step_avg:252.35ms x-lambda: 0.6798794865608215 lambdas: [-0.008374324068427086, -0.00821816548705101, -0.008919957093894482, -0.004987756256014109, -0.005950198974460363, -0.006728662643581629, -0.007327756844460964, -0.010791890323162079] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5500/5550 val_loss:2.922071 train_time:1389719ms step_avg:252.68ms x-lambda: 0.6855475902557373 lambdas: [-0.00865335576236248, -0.007575483527034521, -0.009122507646679878, -0.005536424461752176, -0.006318412255495787, -0.007455800659954548, -0.007539008278399706, -0.010999809950590134] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]
step:5550/5550 val_loss:2.920882 train_time:1403116ms step_avg:252.81ms x-lambda: 0.6867868304252625 lambdas: [-0.008568967692553997, -0.0073389881290495396, -0.009523610584437847, -0.005604292266070843, -0.0064618284814059734, -0.0072991615161299706, -0.007629339583218098, -0.010735643096268177] skip-layers: [3, 7, 4, 1, 2, 0, 9, 11]



## 8000-add-skip-multiple-8-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.16ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:125/5550 val_loss:4.268173 train_time:29295ms step_avg:234.36ms x-lambda: 1.03215491771698 lambdas: [0.007967691868543625, -0.038411904126405716, 0.03718862682580948, 0.02550903521478176, 0.04173567146062851, 0.05577037110924721, 0.03529944270849228, 0.08410894870758057] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:250/5550 val_loss:3.849736 train_time:58726ms step_avg:234.90ms x-lambda: 0.9947705268859863 lambdas: [-0.037140559405088425, -0.12983837723731995, 0.0271175317466259, 0.007368004880845547, 0.020688751712441444, 0.07131221890449524, 0.029947485774755478, 0.0679800882935524] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:375/5550 val_loss:3.674958 train_time:88696ms step_avg:236.52ms x-lambda: 0.9713838696479797 lambdas: [-0.03789052739739418, -0.16289177536964417, 0.017716335132718086, 0.0021341145038604736, -0.00870860368013382, 0.06153939291834831, 0.018371116369962692, 0.059640731662511826] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:500/5550 val_loss:3.559350 train_time:118909ms step_avg:237.82ms x-lambda: 0.9506282210350037 lambdas: [-0.03353751823306084, -0.18162371218204498, 0.013431904837489128, -0.012116562575101852, -0.02996792644262314, 0.04981298744678497, -0.002756854984909296, 0.05132518336176872] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:625/5550 val_loss:3.481504 train_time:149333ms step_avg:238.93ms x-lambda: 0.936435341835022 lambdas: [-0.023227479308843613, -0.19042618572711945, 0.015899617224931717, -0.024186424911022186, -0.03925243765115738, 0.04515736550092697, -0.02455434389412403, 0.04828901216387749] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:750/5550 val_loss:3.428095 train_time:180059ms step_avg:240.08ms x-lambda: 0.9260092973709106 lambdas: [-0.015682676807045937, -0.19412606954574585, 0.015997519716620445, -0.035544004291296005, -0.044046927243471146, 0.04106364771723747, -0.04750186949968338, 0.043897904455661774] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:875/5550 val_loss:3.382641 train_time:210879ms step_avg:241.00ms x-lambda: 0.9112471342086792 lambdas: [-0.010078239254653454, -0.19385959208011627, 0.014858096837997437, -0.04917887970805168, -0.04768262058496475, 0.03609858453273773, -0.07094183564186096, 0.03846780210733414] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1000/5550 val_loss:3.349424 train_time:241970ms step_avg:241.97ms x-lambda: 0.9031699895858765 lambdas: [-0.0028108919505029917, -0.18676474690437317, 0.016079865396022797, -0.05761575698852539, -0.04692362621426582, 0.03519085794687271, -0.08999963849782944, 0.03758452087640762] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1125/5550 val_loss:3.321515 train_time:273089ms step_avg:242.75ms x-lambda: 0.8926372528076172 lambdas: [-0.001936486572958529, -0.18227341771125793, 0.012166785076260567, -0.06877319514751434, -0.05000980943441391, 0.02835194580256939, -0.11079008132219315, 0.031659726053476334] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1250/5550 val_loss:3.294091 train_time:304373ms step_avg:243.50ms x-lambda: 0.8875887989997864 lambdas: [0.0026198578998446465, -0.17255350947380066, 0.013695325702428818, -0.07395272701978683, -0.046390924602746964, 0.02807510644197464, -0.12498904019594193, 0.031533196568489075] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1375/5550 val_loss:3.273119 train_time:335832ms step_avg:244.24ms x-lambda: 0.8800799250602722 lambdas: [0.0032693021930754185, -0.16514432430267334, 0.012037993408739567, -0.08172150701284409, -0.04631113260984421, 0.026217730715870857, -0.14123943448066711, 0.02886996604502201] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1500/5550 val_loss:3.254478 train_time:367251ms step_avg:244.83ms x-lambda: 0.8758843541145325 lambdas: [0.002928616479039192, -0.15890054404735565, 0.011274569667875767, -0.08736652880907059, -0.04555891826748848, 0.02319355122745037, -0.15613746643066406, 0.02767328917980194] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1625/5550 val_loss:3.239883 train_time:398747ms step_avg:245.38ms x-lambda: 0.8720930814743042 lambdas: [0.006284821778535843, -0.14932358264923096, 0.013747304677963257, -0.09190242737531662, -0.041518229991197586, 0.024960579350590706, -0.16769848763942719, 0.027892032638192177] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1750/5550 val_loss:3.222712 train_time:430190ms step_avg:245.82ms x-lambda: 0.8674268126487732 lambdas: [0.00532453553751111, -0.14348188042640686, 0.012544057331979275, -0.09832098335027695, -0.041513841599226, 0.021867932751774788, -0.18039683997631073, 0.025371327996253967] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:1875/5550 val_loss:3.207299 train_time:461720ms step_avg:246.25ms x-lambda: 0.8682064414024353 lambdas: [0.007821631617844105, -0.13485194742679596, 0.01324147917330265, -0.10095258802175522, -0.03862159326672554, 0.022654730826616287, -0.18926750123500824, 0.026161527261137962] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2000/5550 val_loss:3.189315 train_time:493411ms step_avg:246.71ms x-lambda: 0.8646258115768433 lambdas: [0.006538840010762215, -0.1311139613389969, 0.01055874302983284, -0.10828439146280289, -0.03855819255113602, 0.01996140368282795, -0.2008844017982483, 0.02265656180679798] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2125/5550 val_loss:3.174916 train_time:525154ms step_avg:247.13ms x-lambda: 0.8647271990776062 lambdas: [0.006302315276116133, -0.1254260540008545, 0.009706016629934311, -0.11191423237323761, -0.037986449897289276, 0.01896902173757553, -0.20989550650119781, 0.022379383444786072] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2250/5550 val_loss:3.161138 train_time:556901ms step_avg:247.51ms x-lambda: 0.8655401468276978 lambdas: [0.004891626071184874, -0.12143371254205704, 0.008428320288658142, -0.11656942218542099, -0.038400642573833466, 0.015748582780361176, -0.21879473328590393, 0.020677588880062103] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2375/5550 val_loss:3.149601 train_time:588675ms step_avg:247.86ms x-lambda: 0.8668616414070129 lambdas: [0.006475101690739393, -0.11566482484340668, 0.009189711883664131, -0.11888252198696136, -0.03497658297419548, 0.017313338816165924, -0.22459830343723297, 0.021234720945358276] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2500/5550 val_loss:3.137413 train_time:620364ms step_avg:248.15ms x-lambda: 0.8677836060523987 lambdas: [0.006241475697606802, -0.11276093870401382, 0.008405926637351513, -0.12293006479740143, -0.035228949040174484, 0.015609195455908775, -0.231153205037117, 0.021270647644996643] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2625/5550 val_loss:3.125637 train_time:652077ms step_avg:248.41ms x-lambda: 0.8689260482788086 lambdas: [0.004868297837674618, -0.10926896333694458, 0.0072069247253239155, -0.1265171319246292, -0.03479756414890289, 0.015065517276525497, -0.23719342052936554, 0.018738023936748505] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2750/5550 val_loss:3.114751 train_time:683812ms step_avg:248.66ms x-lambda: 0.8712196946144104 lambdas: [0.0062109194695949554, -0.10559671372175217, 0.00783461332321167, -0.1297038197517395, -0.032906852662563324, 0.014594695530831814, -0.2428661435842514, 0.01956113614141941] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:2875/5550 val_loss:3.105904 train_time:715584ms step_avg:248.90ms x-lambda: 0.8754520416259766 lambdas: [0.006818865425884724, -0.10093118995428085, 0.008228475227952003, -0.13097761571407318, -0.03163532540202141, 0.015466641634702682, -0.24581357836723328, 0.019245237112045288] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3000/5550 val_loss:3.094926 train_time:747325ms step_avg:249.11ms x-lambda: 0.8779276609420776 lambdas: [0.0070174261927604675, -0.09877514839172363, 0.007708294317126274, -0.13424918055534363, -0.0313299298286438, 0.014123058877885342, -0.25034579634666443, 0.01871848665177822] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3125/5550 val_loss:3.083757 train_time:779116ms step_avg:249.32ms x-lambda: 0.8802029490470886 lambdas: [0.00506034167483449, -0.09683670103549957, 0.006259026005864143, -0.1391092985868454, -0.03154638409614563, 0.013761181384325027, -0.25638213753700256, 0.018372341990470886] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3250/5550 val_loss:3.072330 train_time:810870ms step_avg:249.50ms x-lambda: 0.8854259848594666 lambdas: [0.006562234368175268, -0.09444986283779144, 0.00628992635756731, -0.14046435058116913, -0.03160572797060013, 0.01302923634648323, -0.25856348872184753, 0.018331807106733322] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3375/5550 val_loss:3.063887 train_time:842631ms step_avg:249.67ms x-lambda: 0.8885046243667603 lambdas: [0.005138250067830086, -0.09385377168655396, 0.006139503791928291, -0.1448872834444046, -0.0307941697537899, 0.01251566968858242, -0.263088196516037, 0.017068160697817802] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3500/5550 val_loss:3.055353 train_time:874389ms step_avg:249.83ms x-lambda: 0.8928024768829346 lambdas: [0.005720020271837711, -0.09167806804180145, 0.005345406010746956, -0.14777003228664398, -0.03151506185531616, 0.010596446692943573, -0.2657325267791748, 0.015053153969347477] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3625/5550 val_loss:3.046202 train_time:906136ms step_avg:249.97ms x-lambda: 0.8990813493728638 lambdas: [0.005719051696360111, -0.09053242206573486, 0.0051875668577849865, -0.14886559545993805, -0.02955567091703415, 0.0114997373893857, -0.2680102586746216, 0.017142686992883682] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3750/5550 val_loss:3.036388 train_time:937888ms step_avg:250.10ms x-lambda: 0.9030674695968628 lambdas: [0.006514118053019047, -0.08802253007888794, 0.005452112760394812, -0.15219438076019287, -0.02928680181503296, 0.011621793732047081, -0.26974013447761536, 0.017517201602458954] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:3875/5550 val_loss:3.027260 train_time:969727ms step_avg:250.25ms x-lambda: 0.9098831415176392 lambdas: [0.0060911523178219795, -0.08629585057497025, 0.004570354241877794, -0.153469055891037, -0.027964206412434578, 0.01167227327823639, -0.27193838357925415, 0.016598215326666832] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4000/5550 val_loss:3.018183 train_time:1001511ms step_avg:250.38ms x-lambda: 0.916415274143219 lambdas: [0.005672783125191927, -0.08332335948944092, 0.0045472439378499985, -0.15638579428195953, -0.027948474511504173, 0.010845579206943512, -0.27481138706207275, 0.017025716602802277] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4125/5550 val_loss:3.009017 train_time:1033338ms step_avg:250.51ms x-lambda: 0.9225507378578186 lambdas: [0.00569074647501111, -0.08244255930185318, 0.005015987437218428, -0.15878303349018097, -0.028111856430768967, 0.010927285067737103, -0.27716031670570374, 0.016758553683757782] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4250/5550 val_loss:3.000929 train_time:1065371ms step_avg:250.68ms x-lambda: 0.9295659065246582 lambdas: [0.005675490479916334, -0.08113639056682587, 0.004516955465078354, -0.15990382432937622, -0.02700018137693405, 0.011654611676931381, -0.27915436029434204, 0.015753887593746185] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4375/5550 val_loss:2.991566 train_time:1097473ms step_avg:250.85ms x-lambda: 0.9347519874572754 lambdas: [0.004557002801448107, -0.08113028854131699, 0.002668981207534671, -0.16395671665668488, -0.027478469535708427, 0.009666666388511658, -0.2819773554801941, 0.01628980040550232] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4500/5550 val_loss:2.983285 train_time:1129572ms step_avg:251.02ms x-lambda: 0.9411562085151672 lambdas: [0.004706292413175106, -0.0793243795633316, 0.002983669750392437, -0.16565915942192078, -0.02697836048901081, 0.01017114706337452, -0.2843320667743683, 0.014952457509934902] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4625/5550 val_loss:2.973947 train_time:1161831ms step_avg:251.21ms x-lambda: 0.9485594630241394 lambdas: [0.0054047489538788795, -0.0784701406955719, 0.003528161207213998, -0.16620232164859772, -0.026154911145567894, 0.009720595553517342, -0.2846143841743469, 0.015383826568722725] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4750/5550 val_loss:2.964729 train_time:1194183ms step_avg:251.41ms x-lambda: 0.9551872611045837 lambdas: [0.006442626938223839, -0.07796719670295715, 0.003115706145763397, -0.16755317151546478, -0.026375552639365196, 0.01094700489193201, -0.2859431207180023, 0.017033260315656662] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:4875/5550 val_loss:2.955764 train_time:1226696ms step_avg:251.63ms x-lambda: 0.9621719121932983 lambdas: [0.005426118150353432, -0.07688653469085693, 0.002763430355116725, -0.1691422313451767, -0.026405492797493935, 0.0086226686835289, -0.28776559233665466, 0.015044483356177807] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5000/5550 val_loss:2.947600 train_time:1259333ms step_avg:251.87ms x-lambda: 0.9696667790412903 lambdas: [0.0061614857986569405, -0.07683997601270676, 0.002177648013457656, -0.1708870530128479, -0.02604377642273903, 0.009039655327796936, -0.28903624415397644, 0.01570145972073078] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5125/5550 val_loss:2.939915 train_time:1292095ms step_avg:252.12ms x-lambda: 0.9759845733642578 lambdas: [0.005412743892520666, -0.07527631521224976, 0.0024219092447310686, -0.1721275895833969, -0.025249769911170006, 0.01027305144816637, -0.29002508521080017, 0.015706226229667664] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5250/5550 val_loss:2.932587 train_time:1325066ms step_avg:252.39ms x-lambda: 0.9818754196166992 lambdas: [0.005838284268975258, -0.07498181611299515, 0.002599326428025961, -0.17298486828804016, -0.024140793830156326, 0.008860141038894653, -0.29075297713279724, 0.015618808567523956] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5375/5550 val_loss:2.926283 train_time:1358135ms step_avg:252.68ms x-lambda: 0.9875617623329163 lambdas: [0.005315955262631178, -0.07519260793924332, 0.0013732998631894588, -0.17353716492652893, -0.025110328570008278, 0.008899524807929993, -0.2915763556957245, 0.015728570520877838] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5500/5550 val_loss:2.921443 train_time:1391460ms step_avg:252.99ms x-lambda: 0.9910947680473328 lambdas: [0.005143639165908098, -0.07487690448760986, 0.001582515542395413, -0.1739719659090042, -0.024836579337716103, 0.008435462601482868, -0.29206788539886475, 0.015220503322780132] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]
step:5550/5550 val_loss:2.920255 train_time:1404864ms step_avg:253.13ms x-lambda: 0.9918546676635742 lambdas: [0.005070629063993692, -0.07485359907150269, 0.00125594693236053, -0.17410065233707428, -0.02465483359992504, 0.00848434492945671, -0.2922784686088562, 0.015077516436576843] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0]



## 8000-add-skip-multiple-9-method-btw-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.16ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:125/5550 val_loss:4.260932 train_time:29232ms step_avg:233.86ms x-lambda: 1.022186517715454 lambdas: [0.029937995597720146, 0.03221460059285164, 0.01605510711669922, 0.06300953030586243, 0.018003514036536217, -0.053353309631347656, 0.022302381694316864, 0.07917431741952896, 0.026074957102537155] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:250/5550 val_loss:3.847618 train_time:58688ms step_avg:234.75ms x-lambda: 1.0052188634872437 lambdas: [0.03988135978579521, 0.01668853498995304, -0.019428923726081848, 0.09155081957578659, -0.029455451294779778, -0.15936541557312012, 0.030067944899201393, 0.04223180189728737, 0.03766758367419243] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:375/5550 val_loss:3.674065 train_time:88655ms step_avg:236.41ms x-lambda: 1.0005154609680176 lambdas: [0.04500272497534752, -0.021090812981128693, -0.03145376220345497, 0.0855206698179245, -0.07233385741710663, -0.205322727560997, 0.038536760956048965, 0.02533690072596073, 0.04544704034924507] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:500/5550 val_loss:3.557976 train_time:118889ms step_avg:237.78ms x-lambda: 0.9874023199081421 lambdas: [0.0435836985707283, -0.0619659498333931, -0.028417132794857025, 0.07776537537574768, -0.10230958461761475, -0.22290578484535217, 0.03455718606710434, 0.01786908693611622, 0.04324670881032944] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:625/5550 val_loss:3.480877 train_time:149324ms step_avg:238.92ms x-lambda: 0.9730386137962341 lambdas: [0.04638560116291046, -0.09581560641527176, -0.014702326618134975, 0.07571399956941605, -0.11332763731479645, -0.22181600332260132, 0.029660426080226898, 0.01597648859024048, 0.042228180915117264] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:750/5550 val_loss:3.426185 train_time:179998ms step_avg:240.00ms x-lambda: 0.954127311706543 lambdas: [0.04723764583468437, -0.12854261696338654, -0.007860931567847729, 0.07043720781803131, -0.11669685691595078, -0.21520531177520752, 0.01995146833360195, 0.012178223580121994, 0.03774036839604378] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:875/5550 val_loss:3.381257 train_time:210778ms step_avg:240.89ms x-lambda: 0.9321722984313965 lambdas: [0.05087430030107498, -0.15625210106372833, -0.001603547716513276, 0.06749429553747177, -0.11261408030986786, -0.20294128358364105, 0.009414817206561565, 0.01243952289223671, 0.034468960016965866] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1000/5550 val_loss:3.346000 train_time:241825ms step_avg:241.82ms x-lambda: 0.9129443168640137 lambdas: [0.05457499995827675, -0.18098720908164978, 0.0016717270482331514, 0.06174363195896149, -0.10542228817939758, -0.18806710839271545, -0.0020154034718871117, 0.011686750687658787, 0.030819842591881752] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1125/5550 val_loss:3.316209 train_time:272924ms step_avg:242.60ms x-lambda: 0.8920744061470032 lambdas: [0.06014386564493179, -0.20255017280578613, 0.003798124846071005, 0.055852264165878296, -0.09716647118330002, -0.17474891245365143, -0.013673728331923485, 0.009139585308730602, 0.027904145419597626] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1250/5550 val_loss:3.293442 train_time:304174ms step_avg:243.34ms x-lambda: 0.8757736086845398 lambdas: [0.06755402684211731, -0.21768797934055328, 0.006307429168373346, 0.052749987691640854, -0.0878489762544632, -0.16116423904895782, -0.022288016974925995, 0.009709631092846394, 0.02705358900129795] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1375/5550 val_loss:3.271564 train_time:335596ms step_avg:244.07ms x-lambda: 0.8564450144767761 lambdas: [0.07324279844760895, -0.2334984689950943, 0.0055536068975925446, 0.047140054404735565, -0.08242214471101761, -0.15077994763851166, -0.03429044410586357, 0.007709808647632599, 0.02393333800137043] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1500/5550 val_loss:3.253701 train_time:366970ms step_avg:244.65ms x-lambda: 0.8416004776954651 lambdas: [0.08093158155679703, -0.2460039258003235, 0.00652515422552824, 0.04323930665850639, -0.07723104953765869, -0.1411663144826889, -0.04443956911563873, 0.007256207522004843, 0.02297569252550602] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1625/5550 val_loss:3.237075 train_time:398423ms step_avg:245.18ms x-lambda: 0.8284114599227905 lambdas: [0.08897901326417923, -0.2557145953178406, 0.009300589561462402, 0.041677940636873245, -0.07075130939483643, -0.1311434656381607, -0.052719030529260635, 0.007405182346701622, 0.022511379793286324] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1750/5550 val_loss:3.222416 train_time:429870ms step_avg:245.64ms x-lambda: 0.8134375810623169 lambdas: [0.0959891751408577, -0.26341426372528076, 0.00947286281734705, 0.03779161348938942, -0.06441398710012436, -0.1234375610947609, -0.06195985525846481, 0.0073356530629098415, 0.0213166493922472] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:1875/5550 val_loss:3.203197 train_time:461362ms step_avg:246.06ms x-lambda: 0.8024551868438721 lambdas: [0.10241673141717911, -0.27112385630607605, 0.009321492165327072, 0.03521411120891571, -0.061331674456596375, -0.11713676899671555, -0.07036026567220688, 0.006523171905428171, 0.020516540855169296] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2000/5550 val_loss:3.188815 train_time:493046ms step_avg:246.52ms x-lambda: 0.7923081517219543 lambdas: [0.10925827920436859, -0.27594614028930664, 0.009688906371593475, 0.03414636477828026, -0.05753275752067566, -0.10910681635141373, -0.07800289243459702, 0.006163625046610832, 0.020378069952130318] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2125/5550 val_loss:3.174612 train_time:524781ms step_avg:246.96ms x-lambda: 0.7871519327163696 lambdas: [0.11505603045225143, -0.2799215614795685, 0.010618377476930618, 0.03274008631706238, -0.05543878301978111, -0.10389455407857895, -0.08370665460824966, 0.0064271315932273865, 0.020697928965091705] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2250/5550 val_loss:3.161154 train_time:556521ms step_avg:247.34ms x-lambda: 0.7793010473251343 lambdas: [0.11769343912601471, -0.2854444682598114, 0.009187450632452965, 0.027951858937740326, -0.053584568202495575, -0.10109110176563263, -0.09272047132253647, 0.004161754623055458, 0.017698530107736588] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2375/5550 val_loss:3.148089 train_time:588262ms step_avg:247.69ms x-lambda: 0.7742048501968384 lambdas: [0.12312107533216476, -0.28647133708000183, 0.010403763502836227, 0.027572324499487877, -0.05068320780992508, -0.09559886902570724, -0.09771756827831268, 0.004484056029468775, 0.018001871183514595] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2500/5550 val_loss:3.135659 train_time:619964ms step_avg:247.99ms x-lambda: 0.7696388959884644 lambdas: [0.12762829661369324, -0.28821051120758057, 0.00969354435801506, 0.02707800455391407, -0.04931844770908356, -0.09198320657014847, -0.10263197124004364, 0.006226241122931242, 0.017807966098189354] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2625/5550 val_loss:3.125576 train_time:651682ms step_avg:248.26ms x-lambda: 0.7646549940109253 lambdas: [0.13019128143787384, -0.2913993000984192, 0.008920732885599136, 0.02481727860867977, -0.04900219663977623, -0.089411161839962, -0.10845303535461426, 0.005011190660297871, 0.015793034806847572] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2750/5550 val_loss:3.113667 train_time:683404ms step_avg:248.51ms x-lambda: 0.7627466917037964 lambdas: [0.13414138555526733, -0.2922526001930237, 0.009447092190384865, 0.024022623896598816, -0.04611571133136749, -0.08613689988851547, -0.11235906928777695, 0.004619194194674492, 0.015583460219204426] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:2875/5550 val_loss:3.104536 train_time:715150ms step_avg:248.75ms x-lambda: 0.7611860632896423 lambdas: [0.13830621540546417, -0.29317978024482727, 0.01018232386559248, 0.023733098059892654, -0.04452788829803467, -0.081467404961586, -0.11589110642671585, 0.005970579572021961, 0.016118932515382767] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3000/5550 val_loss:3.093717 train_time:746878ms step_avg:248.96ms x-lambda: 0.7619741559028625 lambdas: [0.14086948335170746, -0.2932223677635193, 0.009038281626999378, 0.023752499371767044, -0.043410271406173706, -0.0795518010854721, -0.11919406056404114, 0.00506183784455061, 0.01598253846168518] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3125/5550 val_loss:3.083188 train_time:778633ms step_avg:249.16ms x-lambda: 0.7588689923286438 lambdas: [0.1415964514017105, -0.2967950701713562, 0.008027971722185612, 0.021254612132906914, -0.04369322583079338, -0.07892634719610214, -0.12393224239349365, 0.0032363245263695717, 0.013989165425300598] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3250/5550 val_loss:3.071369 train_time:810370ms step_avg:249.34ms x-lambda: 0.7622948884963989 lambdas: [0.14490634202957153, -0.2953813672065735, 0.00992030743509531, 0.021433671936392784, -0.042373720556497574, -0.07489557564258575, -0.12529605627059937, 0.005604763515293598, 0.0148015096783638] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3375/5550 val_loss:3.062698 train_time:842082ms step_avg:249.51ms x-lambda: 0.7603033185005188 lambdas: [0.14633148908615112, -0.29852578043937683, 0.00839968305081129, 0.019724909216165543, -0.04143662750720978, -0.07486123591661453, -0.12865443527698517, 0.0037916437722742558, 0.013422654941678047] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3500/5550 val_loss:3.054020 train_time:873809ms step_avg:249.66ms x-lambda: 0.7615915536880493 lambdas: [0.1484401375055313, -0.29788368940353394, 0.0075548565946519375, 0.018495865166187286, -0.0411221981048584, -0.07273956388235092, -0.13193906843662262, 0.0036834320053458214, 0.013000891543924809] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3625/5550 val_loss:3.045298 train_time:905563ms step_avg:249.81ms x-lambda: 0.7634682059288025 lambdas: [0.15089727938175201, -0.29797473549842834, 0.009179758839309216, 0.017329508438706398, -0.03906266763806343, -0.07217667251825333, -0.13419577479362488, 0.003755588084459305, 0.013602367602288723] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3750/5550 val_loss:3.035975 train_time:937291ms step_avg:249.94ms x-lambda: 0.7635191082954407 lambdas: [0.15236492455005646, -0.29774805903434753, 0.008741109631955624, 0.018438445404171944, -0.03917527571320534, -0.06983531266450882, -0.13639891147613525, 0.0046824561432003975, 0.012838189490139484] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:3875/5550 val_loss:3.026628 train_time:969101ms step_avg:250.09ms x-lambda: 0.7686865925788879 lambdas: [0.15359140932559967, -0.3006255626678467, 0.008266644552350044, 0.01849054917693138, -0.03907191753387451, -0.06874750554561615, -0.1366347223520279, 0.004065710585564375, 0.01341202948242426] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4000/5550 val_loss:3.017116 train_time:1000880ms step_avg:250.22ms x-lambda: 0.7724614143371582 lambdas: [0.15605273842811584, -0.3012334406375885, 0.0076355780474841595, 0.01819942146539688, -0.03797184303402901, -0.06717319786548615, -0.13882260024547577, 0.00506663927808404, 0.013673165813088417] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4125/5550 val_loss:3.008238 train_time:1032716ms step_avg:250.36ms x-lambda: 0.7763093709945679 lambdas: [0.1577378660440445, -0.3021332323551178, 0.008608977310359478, 0.017111457884311676, -0.036914657801389694, -0.06661800295114517, -0.14155103266239166, 0.005015943199396133, 0.012513106688857079] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4250/5550 val_loss:2.999721 train_time:1064742ms step_avg:250.53ms x-lambda: 0.7812676429748535 lambdas: [0.15878814458847046, -0.3033217787742615, 0.009020112454891205, 0.017425693571567535, -0.0383324958384037, -0.06567351520061493, -0.14194712042808533, 0.0035539502277970314, 0.012949216179549694] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4375/5550 val_loss:2.990960 train_time:1096793ms step_avg:250.70ms x-lambda: 0.7845728397369385 lambdas: [0.160156711935997, -0.30401110649108887, 0.007694920990616083, 0.016476750373840332, -0.03780539706349373, -0.06555360555648804, -0.14406445622444153, 0.003979963716119528, 0.012167515233159065] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4500/5550 val_loss:2.982795 train_time:1128878ms step_avg:250.86ms x-lambda: 0.7891477346420288 lambdas: [0.16144858300685883, -0.30524879693984985, 0.0076045086607337, 0.01576710306107998, -0.03877362981438637, -0.06370086967945099, -0.14637310802936554, 0.004477287642657757, 0.011088074184954166] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4625/5550 val_loss:2.973140 train_time:1161115ms step_avg:251.05ms x-lambda: 0.796466052532196 lambdas: [0.16288886964321136, -0.3055063784122467, 0.00787417683750391, 0.016109328716993332, -0.03833961486816406, -0.06301333010196686, -0.14646673202514648, 0.004680256824940443, 0.011591351591050625] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4750/5550 val_loss:2.964123 train_time:1193425ms step_avg:251.25ms x-lambda: 0.8019095659255981 lambdas: [0.16488151252269745, -0.30688613653182983, 0.007663233671337366, 0.01642640121281147, -0.0379394069314003, -0.06314381957054138, -0.1476467400789261, 0.004539732821285725, 0.012297254055738449] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:4875/5550 val_loss:2.955157 train_time:1225958ms step_avg:251.48ms x-lambda: 0.807971715927124 lambdas: [0.1663287878036499, -0.3086654543876648, 0.006694822572171688, 0.015939678996801376, -0.038050465285778046, -0.0615294873714447, -0.14878171682357788, 0.004914420191198587, 0.01114486251026392] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5000/5550 val_loss:2.946937 train_time:1258574ms step_avg:251.71ms x-lambda: 0.8141948580741882 lambdas: [0.16847527027130127, -0.3094109296798706, 0.006758726667612791, 0.015376016497612, -0.03792386129498482, -0.06093091890215874, -0.14971351623535156, 0.004098730161786079, 0.011207724921405315] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5125/5550 val_loss:2.939369 train_time:1291317ms step_avg:251.96ms x-lambda: 0.8204558491706848 lambdas: [0.1701500415802002, -0.3111005425453186, 0.007275873329490423, 0.015489459969103336, -0.038717303425073624, -0.060512714087963104, -0.15059009194374084, 0.003782096318900585, 0.010921427048742771] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5250/5550 val_loss:2.932321 train_time:1324288ms step_avg:252.25ms x-lambda: 0.8262077569961548 lambdas: [0.17085883021354675, -0.3116823434829712, 0.0074030933901667595, 0.014563494361937046, -0.037159714847803116, -0.059954963624477386, -0.151117205619812, 0.00429330300539732, 0.011043633334338665] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5375/5550 val_loss:2.925847 train_time:1357352ms step_avg:252.53ms x-lambda: 0.8315269947052002 lambdas: [0.17198356986045837, -0.31354278326034546, 0.0062778545543551445, 0.014309081248939037, -0.03763509541749954, -0.05955800786614418, -0.15148155391216278, 0.0041483608074486256, 0.010842906311154366] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5500/5550 val_loss:2.920925 train_time:1390673ms step_avg:252.85ms x-lambda: 0.8355377912521362 lambdas: [0.17311732470989227, -0.3142881989479065, 0.006268593017011881, 0.014125515706837177, -0.03803064674139023, -0.05972705036401749, -0.1521652638912201, 0.0040489849634468555, 0.010407594032585621] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]
step:5550/5550 val_loss:2.919761 train_time:1404064ms step_avg:252.98ms x-lambda: 0.8364578485488892 lambdas: [0.17353855073451996, -0.3146606683731079, 0.006142777390778065, 0.014378122054040432, -0.03848141431808472, -0.05962332338094711, -0.15219402313232422, 0.0038426625542342663, 0.010552046820521355] skip-layers: [11, 10, 8, 4, 9, 3, 13, 0, 12]



## 8000-add-skip-multiple-9-method-htl-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.15ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:125/5550 val_loss:4.264975 train_time:29412ms step_avg:235.30ms x-lambda: 1.0251102447509766 lambdas: [0.01892157271504402, 0.023806344717741013, 0.028210610151290894, 0.031045490875840187, 0.0327388271689415, 0.021790849044919014, 0.020717570558190346, 0.025165408849716187, 0.026447832584381104] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:250/5550 val_loss:3.851861 train_time:59033ms step_avg:236.13ms x-lambda: 0.99297034740448 lambdas: [0.006787845864892006, 0.02183343656361103, 0.02819932997226715, 0.026675909757614136, 0.005214447155594826, -0.035372294485569, -0.01850653812289238, 0.027582088485360146, -0.0038817354943603277] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:375/5550 val_loss:3.673186 train_time:88939ms step_avg:237.17ms x-lambda: 0.9722716808319092 lambdas: [0.00815135519951582, 0.026424244046211243, 0.028034986928105354, 0.020243598148226738, -0.04570439085364342, -0.07405310869216919, -0.02699446864426136, 0.038610734045505524, -0.030450541526079178] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:500/5550 val_loss:3.556469 train_time:119394ms step_avg:238.79ms x-lambda: 0.954319417476654 lambdas: [0.0035496021155267954, 0.02653406374156475, 0.025089824572205544, 0.015795912593603134, -0.09243549406528473, -0.08910457789897919, -0.023568807169795036, 0.05049008131027222, -0.04179307818412781] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:625/5550 val_loss:3.480401 train_time:150071ms step_avg:240.11ms x-lambda: 0.9380720853805542 lambdas: [-0.004249639809131622, 0.023173440247774124, 0.019686413928866386, 0.01174227800220251, -0.13512469828128815, -0.08992437273263931, -0.017400415614247322, 0.055179864168167114, -0.04792124032974243] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:750/5550 val_loss:3.427337 train_time:181040ms step_avg:241.39ms x-lambda: 0.9268717765808105 lambdas: [-0.011406537145376205, 0.01856909692287445, 0.012709168717265129, 0.007287982385605574, -0.1727868616580963, -0.08283678442239761, -0.013198250904679298, 0.05664651095867157, -0.04867860674858093] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:875/5550 val_loss:3.380713 train_time:212110ms step_avg:242.41ms x-lambda: 0.9141947627067566 lambdas: [-0.01936861127614975, 0.013033853843808174, 0.005953237414360046, 0.005485254805535078, -0.20395830273628235, -0.07135751098394394, -0.011401288211345673, 0.05573615804314613, -0.04811083897948265] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1000/5550 val_loss:3.345901 train_time:243434ms step_avg:243.43ms x-lambda: 0.9049633741378784 lambdas: [-0.024887485429644585, 0.007708562072366476, -0.0013972315937280655, 0.004427287727594376, -0.23036213219165802, -0.05992724373936653, -0.01083754189312458, 0.05567687004804611, -0.04440984129905701] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1125/5550 val_loss:3.317154 train_time:274799ms step_avg:244.27ms x-lambda: 0.8960813879966736 lambdas: [-0.03229910880327225, 0.0012717102654278278, -0.008413511328399181, 0.005381239112466574, -0.25144967436790466, -0.04998286813497543, -0.010393458418548107, 0.052939511835575104, -0.043685346841812134] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1250/5550 val_loss:3.293104 train_time:306296ms step_avg:245.04ms x-lambda: 0.8907159566879272 lambdas: [-0.03569500893354416, -0.0029458622448146343, -0.013125837780535221, 0.009285158477723598, -0.2668738067150116, -0.04063459113240242, -0.010246502235531807, 0.05181106925010681, -0.04043307527899742] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1375/5550 val_loss:3.272213 train_time:337947ms step_avg:245.78ms x-lambda: 0.8804953098297119 lambdas: [-0.04276341572403908, -0.011020342819392681, -0.021599894389510155, 0.010287553071975708, -0.28280091285705566, -0.03506753221154213, -0.011723626405000687, 0.048368778079748154, -0.041192661970853806] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1500/5550 val_loss:3.252151 train_time:369578ms step_avg:246.39ms x-lambda: 0.8775857090950012 lambdas: [-0.045261893421411514, -0.015032174997031689, -0.02553083561360836, 0.01674738898873329, -0.29110682010650635, -0.027209369465708733, -0.010653827339410782, 0.04797255992889404, -0.03760504722595215] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1625/5550 val_loss:3.236313 train_time:401239ms step_avg:246.92ms x-lambda: 0.8713977932929993 lambdas: [-0.049745265394449234, -0.021193865686655045, -0.0312616340816021, 0.0210995152592659, -0.29916664958000183, -0.022408904507756233, -0.008988413959741592, 0.04702218249440193, -0.03499693423509598] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1750/5550 val_loss:3.221276 train_time:432785ms step_avg:247.31ms x-lambda: 0.8658904433250427 lambdas: [-0.0545855388045311, -0.02776072360575199, -0.03725768253207207, 0.024738382548093796, -0.3048798143863678, -0.018411900848150253, -0.010400017723441124, 0.045932382345199585, -0.035280127078294754] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:1875/5550 val_loss:3.203556 train_time:464416ms step_avg:247.69ms x-lambda: 0.8636016249656677 lambdas: [-0.0559704415500164, -0.03199606016278267, -0.04185037687420845, 0.029496319591999054, -0.3080189824104309, -0.014466186985373497, -0.009158515371382236, 0.04486444592475891, -0.032123371958732605] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2000/5550 val_loss:3.188406 train_time:496179ms step_avg:248.09ms x-lambda: 0.8605084419250488 lambdas: [-0.06050964072346687, -0.038105759769678116, -0.04629175364971161, 0.034786343574523926, -0.3100939095020294, -0.011293635703623295, -0.009885716252028942, 0.043517354875802994, -0.029612991958856583] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2125/5550 val_loss:3.173376 train_time:528023ms step_avg:248.48ms x-lambda: 0.8586864471435547 lambdas: [-0.06397418677806854, -0.044933415949344635, -0.052796944975852966, 0.037740301340818405, -0.31479141116142273, -0.010161547921597958, -0.010019970126450062, 0.040133036673069, -0.03153663128614426] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2250/5550 val_loss:3.158238 train_time:559862ms step_avg:248.83ms x-lambda: 0.8592023253440857 lambdas: [-0.06606709957122803, -0.0494249053299427, -0.05679912865161896, 0.04207899421453476, -0.3143014907836914, -0.007373321335762739, -0.009928660467267036, 0.04035501927137375, -0.03020166978240013] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2375/5550 val_loss:3.147369 train_time:591729ms step_avg:249.15ms x-lambda: 0.8578771352767944 lambdas: [-0.06831615418195724, -0.05434170737862587, -0.060305967926979065, 0.045945730060338974, -0.3141483962535858, -0.006155237089842558, -0.009617607109248638, 0.03849181532859802, -0.029220860451459885] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2500/5550 val_loss:3.135153 train_time:623531ms step_avg:249.41ms x-lambda: 0.8588420152664185 lambdas: [-0.07008440047502518, -0.058913860470056534, -0.06439860165119171, 0.05014108121395111, -0.3141487240791321, -0.004990403074771166, -0.010583688504993916, 0.038329627364873886, -0.02783207781612873] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2625/5550 val_loss:3.123758 train_time:655360ms step_avg:249.66ms x-lambda: 0.8588497042655945 lambdas: [-0.07146006077528, -0.062468647956848145, -0.06820321083068848, 0.05190718546509743, -0.3143513798713684, -0.003179905703291297, -0.01081346720457077, 0.03689195215702057, -0.027992406859993935] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2750/5550 val_loss:3.113004 train_time:687152ms step_avg:249.87ms x-lambda: 0.8590213656425476 lambdas: [-0.07374513149261475, -0.06683230400085449, -0.07161565124988556, 0.055262863636016846, -0.3125678300857544, -0.0022902744822204113, -0.011630340479314327, 0.03742603957653046, -0.026308918371796608] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:2875/5550 val_loss:3.103867 train_time:719096ms step_avg:250.12ms x-lambda: 0.8608206510543823 lambdas: [-0.07515739649534225, -0.06980273872613907, -0.07366105914115906, 0.05817580968141556, -0.3119699954986572, -0.0018966676434502006, -0.00883287563920021, 0.036450937390327454, -0.02500510960817337] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3000/5550 val_loss:3.093957 train_time:751053ms step_avg:250.35ms x-lambda: 0.8635877370834351 lambdas: [-0.07574649155139923, -0.07237812131643295, -0.07537385821342468, 0.06162776052951813, -0.30950841307640076, 6.672064773738384e-05, -0.008790750987827778, 0.03626664727926254, -0.02415505051612854] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3125/5550 val_loss:3.081944 train_time:783053ms step_avg:250.58ms x-lambda: 0.8642674684524536 lambdas: [-0.07886610925197601, -0.0770266056060791, -0.0795784667134285, 0.06172112002968788, -0.3120439350605011, -0.0011389236897230148, -0.01086931861937046, 0.03505847975611687, -0.024690471589565277] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3250/5550 val_loss:3.070600 train_time:815045ms step_avg:250.78ms x-lambda: 0.8665478229522705 lambdas: [-0.0804879292845726, -0.07967004179954529, -0.07994379103183746, 0.06490030139684677, -0.31186696887016296, -0.0003866506740450859, -0.010842164978384972, 0.03484305739402771, -0.02435084991157055] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3375/5550 val_loss:3.061682 train_time:846971ms step_avg:250.95ms x-lambda: 0.8694937825202942 lambdas: [-0.08132307231426239, -0.08226276189088821, -0.08260928839445114, 0.06588387489318848, -0.3110535442829132, 0.0005534489173442125, -0.01105200033634901, 0.033458638936281204, -0.02376406453549862] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3500/5550 val_loss:3.053159 train_time:878842ms step_avg:251.10ms x-lambda: 0.8712695837020874 lambdas: [-0.0832400918006897, -0.08506041020154953, -0.08425230532884598, 0.06663358211517334, -0.3095508813858032, 0.001294377725571394, -0.01067537534981966, 0.03182203695178032, -0.02495589852333069] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3625/5550 val_loss:3.044311 train_time:910669ms step_avg:251.22ms x-lambda: 0.8750867247581482 lambdas: [-0.08314616233110428, -0.08691301196813583, -0.08483190089464188, 0.06859327107667923, -0.30856966972351074, 0.0027895187959074974, -0.009137313812971115, 0.03210604190826416, -0.022393913939595222] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3750/5550 val_loss:3.035169 train_time:942514ms step_avg:251.34ms x-lambda: 0.8767517805099487 lambdas: [-0.08478207141160965, -0.08944316953420639, -0.08741997182369232, 0.06981570273637772, -0.30820947885513306, 0.0014584808377549052, -0.010888339020311832, 0.03253430873155594, -0.02276773191988468] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:3875/5550 val_loss:3.026256 train_time:974432ms step_avg:251.47ms x-lambda: 0.8823752999305725 lambdas: [-0.0844467505812645, -0.09029459208250046, -0.08738637715578079, 0.07208899408578873, -0.30827268958091736, 0.0018581798067316413, -0.01074907649308443, 0.0311061292886734, -0.022958679124712944] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4000/5550 val_loss:3.016638 train_time:1006354ms step_avg:251.59ms x-lambda: 0.8873443007469177 lambdas: [-0.08528175950050354, -0.09263276308774948, -0.0884258821606636, 0.07407102733850479, -0.3084002733230591, 0.002544507384300232, -0.011114312335848808, 0.03055712580680847, -0.02162807248532772] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4125/5550 val_loss:3.007501 train_time:1038313ms step_avg:251.71ms x-lambda: 0.8913084864616394 lambdas: [-0.08673536777496338, -0.09491083025932312, -0.09009438753128052, 0.07603047788143158, -0.30784153938293457, 0.0034521492198109627, -0.010474856942892075, 0.03191197291016579, -0.020884891971945763] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4250/5550 val_loss:2.999218 train_time:1070477ms step_avg:251.88ms x-lambda: 0.8958247303962708 lambdas: [-0.08610190451145172, -0.09556914865970612, -0.09014467895030975, 0.0770052894949913, -0.3080367147922516, 0.003145010909065604, -0.010410242713987827, 0.03117077238857746, -0.021622177213430405] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4375/5550 val_loss:2.990119 train_time:1102632ms step_avg:252.03ms x-lambda: 0.8992902636528015 lambdas: [-0.0884295254945755, -0.0988854169845581, -0.0925348773598671, 0.0770622119307518, -0.30884334444999695, 0.0016124106477946043, -0.011012212373316288, 0.029787158593535423, -0.02145838551223278] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4500/5550 val_loss:2.982038 train_time:1134834ms step_avg:252.19ms x-lambda: 0.9049122929573059 lambdas: [-0.08854389935731888, -0.09971510618925095, -0.09373690187931061, 0.07769966125488281, -0.30979403853416443, 0.001136235659942031, -0.01089944876730442, 0.029826851561665535, -0.02140466868877411] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4625/5550 val_loss:2.972836 train_time:1167174ms step_avg:252.36ms x-lambda: 0.9124928116798401 lambdas: [-0.08654576539993286, -0.0996960774064064, -0.09376461803913116, 0.0782359167933464, -0.30841970443725586, 0.0018277503550052643, -0.012586724944412708, 0.027680527418851852, -0.02306986413896084] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4750/5550 val_loss:2.963510 train_time:1199610ms step_avg:252.55ms x-lambda: 0.9174814224243164 lambdas: [-0.08800597488880157, -0.10122036188840866, -0.09327903389930725, 0.081722192466259, -0.3098036050796509, 0.003147982759401202, -0.01173587515950203, 0.031135383993387222, -0.019463561475276947] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:4875/5550 val_loss:2.954530 train_time:1232304ms step_avg:252.78ms x-lambda: 0.9220543503761292 lambdas: [-0.08892650902271271, -0.10272997617721558, -0.09422861784696579, 0.08225417882204056, -0.310881108045578, 0.0023633353412151337, -0.01172424666583538, 0.029452621936798096, -0.02063903771340847] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5000/5550 val_loss:2.946175 train_time:1265117ms step_avg:253.02ms x-lambda: 0.9277744889259338 lambdas: [-0.08941084146499634, -0.10397742688655853, -0.09449615329504013, 0.08324387669563293, -0.3119705021381378, 0.0012638411717489362, -0.010593281127512455, 0.028637319803237915, -0.0199299156665802] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5125/5550 val_loss:2.938620 train_time:1298066ms step_avg:253.28ms x-lambda: 0.9335091710090637 lambdas: [-0.0891733393073082, -0.105207160115242, -0.09544099867343903, 0.0844995453953743, -0.3141113221645355, 0.002118160016834736, -0.01115769799798727, 0.02827468514442444, -0.01981942169368267] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5250/5550 val_loss:2.931422 train_time:1331188ms step_avg:253.56ms x-lambda: 0.9384837746620178 lambdas: [-0.08919959515333176, -0.10552330315113068, -0.09547103196382523, 0.08534674346446991, -0.313728928565979, 0.002451232634484768, -0.011702636256814003, 0.028761273249983788, -0.019001061096787453] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5375/5550 val_loss:2.925036 train_time:1364439ms step_avg:253.85ms x-lambda: 0.9437776207923889 lambdas: [-0.08918774127960205, -0.10646851360797882, -0.09574320912361145, 0.08655738830566406, -0.3158327043056488, 0.0014432420721277595, -0.011504551395773888, 0.027786288410425186, -0.01988377794623375] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5500/5550 val_loss:2.920244 train_time:1397894ms step_avg:254.16ms x-lambda: 0.9460294246673584 lambdas: [-0.08935148268938065, -0.10667194426059723, -0.09629622846841812, 0.08710084855556488, -0.3160286545753479, 0.0017830731812864542, -0.011460976675152779, 0.027713609859347343, -0.01928046904504299] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]
step:5550/5550 val_loss:2.919054 train_time:1411310ms step_avg:254.29ms x-lambda: 0.9466290473937988 lambdas: [-0.0893859937787056, -0.10693161934614182, -0.09628479927778244, 0.08729887753725052, -0.3163788914680481, 0.001191580668091774, -0.01171530969440937, 0.02741500921547413, -0.019208211451768875] skip-layers: [14, 13, 12, 11, 10, 9, 8, 7, 6]



## 8000-add-skip-multiple-9-method-lth-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.18ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:125/5550 val_loss:4.255776 train_time:29379ms step_avg:235.03ms x-lambda: 1.03069007396698 lambdas: [0.08080774545669556, 0.006072581745684147, -0.028682852163910866, -0.04193843528628349, 0.07183343172073364, 0.05183982849121094, 0.03670050576329231, 0.03126940876245499, 0.029802650213241577] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:250/5550 val_loss:3.856403 train_time:58967ms step_avg:235.87ms x-lambda: 1.0002580881118774 lambdas: [0.07679630070924759, -0.03132866695523262, -0.09058547019958496, -0.12849745154380798, 0.1237875372171402, 0.06374389678239822, 0.01989838108420372, 0.033494733273983, -0.00826488807797432] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:375/5550 val_loss:3.677291 train_time:89030ms step_avg:237.41ms x-lambda: 0.9821007251739502 lambdas: [0.0662044882774353, -0.03648586571216583, -0.10880785435438156, -0.17495110630989075, 0.13507412374019623, 0.05095449835062027, -0.010205072350800037, 0.03246355429291725, -0.038460180163383484] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:500/5550 val_loss:3.559744 train_time:119431ms step_avg:238.86ms x-lambda: 0.960096001625061 lambdas: [0.058981753885746, -0.0317792184650898, -0.11429890245199203, -0.19783304631710052, 0.136683389544487, 0.040890954434871674, -0.031737059354782104, 0.03650131821632385, -0.058784544467926025] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:625/5550 val_loss:3.481580 train_time:150056ms step_avg:240.09ms x-lambda: 0.9256364107131958 lambdas: [0.049485381692647934, -0.028824852779507637, -0.11861168593168259, -0.2083984762430191, 0.13424897193908691, 0.03309611603617668, -0.04900837689638138, 0.03837651014328003, -0.07358795404434204] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:750/5550 val_loss:3.428644 train_time:181009ms step_avg:241.34ms x-lambda: 0.8933698534965515 lambdas: [0.04456283897161484, -0.024106444790959358, -0.1191127821803093, -0.2082192450761795, 0.13070398569107056, 0.03032933734357357, -0.05533880367875099, 0.0415918305516243, -0.07975496351718903] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:875/5550 val_loss:3.382620 train_time:212014ms step_avg:242.30ms x-lambda: 0.8565834760665894 lambdas: [0.040598418563604355, -0.01852390728890896, -0.11692866683006287, -0.2018338143825531, 0.12557353079319, 0.028468897566199303, -0.05764765292406082, 0.04376290366053581, -0.08129257708787918] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1000/5550 val_loss:3.346920 train_time:243289ms step_avg:243.29ms x-lambda: 0.8255879878997803 lambdas: [0.03869452700018883, -0.013600481674075127, -0.11264139413833618, -0.1897682398557663, 0.11889107525348663, 0.026218324899673462, -0.056762851774692535, 0.044929035007953644, -0.08127647638320923] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1125/5550 val_loss:3.317793 train_time:274632ms step_avg:244.12ms x-lambda: 0.7948830127716064 lambdas: [0.03523542732000351, -0.010764834471046925, -0.10954611748456955, -0.17834433913230896, 0.1099633276462555, 0.024031782522797585, -0.05655714496970177, 0.043833471834659576, -0.08200711756944656] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1250/5550 val_loss:3.294076 train_time:306031ms step_avg:244.82ms x-lambda: 0.7689117789268494 lambdas: [0.03301437571644783, -0.007871200330555439, -0.10591156035661697, -0.1671278327703476, 0.10134533792734146, 0.02348131127655506, -0.05563608929514885, 0.04387989267706871, -0.08171422779560089] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1375/5550 val_loss:3.272962 train_time:337539ms step_avg:245.48ms x-lambda: 0.7412722706794739 lambdas: [0.028782952576875687, -0.008218486793339252, -0.10518860071897507, -0.15771199762821198, 0.09079767018556595, 0.018766261637210846, -0.05648142844438553, 0.04034222662448883, -0.08456415683031082] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1500/5550 val_loss:3.251132 train_time:369018ms step_avg:246.01ms x-lambda: 0.7219565510749817 lambdas: [0.02887391299009323, -0.0056677162647247314, -0.10032857209444046, -0.14616644382476807, 0.08490213006734848, 0.019829316064715385, -0.053420163691043854, 0.042552635073661804, -0.07987198233604431] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1625/5550 val_loss:3.236148 train_time:400546ms step_avg:246.49ms x-lambda: 0.6990265846252441 lambdas: [0.026612933725118637, -0.004259335342794657, -0.09669646620750427, -0.13623306155204773, 0.07864164561033249, 0.0191158689558506, -0.05106084793806076, 0.041548389941453934, -0.07905837148427963] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1750/5550 val_loss:3.223371 train_time:432063ms step_avg:246.89ms x-lambda: 0.680791974067688 lambdas: [0.026816900819540024, -0.0025159716606140137, -0.09110058099031448, -0.1250828355550766, 0.07330266386270523, 0.019788168370723724, -0.04790158569812775, 0.042848166078329086, -0.07592587172985077] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:1875/5550 val_loss:3.203596 train_time:463647ms step_avg:247.28ms x-lambda: 0.6658862829208374 lambdas: [0.025047890841960907, -0.0011015618219971657, -0.08865313231945038, -0.11896809190511703, 0.06692200154066086, 0.018850643187761307, -0.04707658290863037, 0.04092050716280937, -0.07609554380178452] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2000/5550 val_loss:3.187357 train_time:495424ms step_avg:247.71ms x-lambda: 0.6490975022315979 lambdas: [0.022875547409057617, -0.0017713801935315132, -0.08719480037689209, -0.11142586171627045, 0.059881992638111115, 0.017321672290563583, -0.047231271862983704, 0.038220036774873734, -0.07579365372657776] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2125/5550 val_loss:3.173527 train_time:527241ms step_avg:248.11ms x-lambda: 0.6421740055084229 lambdas: [0.023429447785019875, -0.0015659767668694258, -0.08359981328248978, -0.10570427030324936, 0.05796360597014427, 0.017394622787833214, -0.044816698879003525, 0.03897586464881897, -0.07395032793283463] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2250/5550 val_loss:3.158557 train_time:559059ms step_avg:248.47ms x-lambda: 0.6316465735435486 lambdas: [0.02167576365172863, -0.002610171912238002, -0.08328883349895477, -0.10012001544237137, 0.05334020406007767, 0.015536610968410969, -0.04551392421126366, 0.03738521412014961, -0.07394608110189438] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2375/5550 val_loss:3.147493 train_time:590905ms step_avg:248.80ms x-lambda: 0.6246970891952515 lambdas: [0.02195880189538002, -0.0009389571496285498, -0.07993126660585403, -0.09535921365022659, 0.05003539100289345, 0.014521406032145023, -0.042759351432323456, 0.03730162978172302, -0.07169464975595474] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2500/5550 val_loss:3.136402 train_time:622692ms step_avg:249.08ms x-lambda: 0.6189946532249451 lambdas: [0.021814614534378052, -0.0007996666245162487, -0.07719903439283371, -0.09102204442024231, 0.04749055951833725, 0.01604795828461647, -0.04274115711450577, 0.03577082231640816, -0.0721542090177536] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2625/5550 val_loss:3.124796 train_time:654480ms step_avg:249.33ms x-lambda: 0.6135428547859192 lambdas: [0.020392222329974174, -0.0003295305650681257, -0.07512537389993668, -0.08681774884462357, 0.044459544122219086, 0.014494216069579124, -0.04019574075937271, 0.036983609199523926, -0.07100026309490204] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2750/5550 val_loss:3.113380 train_time:686257ms step_avg:249.55ms x-lambda: 0.6082445383071899 lambdas: [0.019328877329826355, 0.00024577468866482377, -0.07396585494279861, -0.08469326049089432, 0.04348703473806381, 0.014019905589520931, -0.038739122450351715, 0.036194875836372375, -0.06980884820222855] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:2875/5550 val_loss:3.103513 train_time:718087ms step_avg:249.77ms x-lambda: 0.6060792207717896 lambdas: [0.020750075578689575, 0.00023624952882528305, -0.07166937738656998, -0.08018410950899124, 0.04166898876428604, 0.013958212919533253, -0.03807713836431503, 0.03456136956810951, -0.06956510245800018] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3000/5550 val_loss:3.092414 train_time:749910ms step_avg:249.97ms x-lambda: 0.6035009026527405 lambdas: [0.01807435229420662, -0.0008397017372772098, -0.07082273066043854, -0.07854463905096054, 0.039240241050720215, 0.01411193422973156, -0.03767498582601547, 0.034841958433389664, -0.06967238336801529] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3125/5550 val_loss:3.082273 train_time:781767ms step_avg:250.17ms x-lambda: 0.6017419099807739 lambdas: [0.01818687655031681, -0.0012641504872590303, -0.06997658312320709, -0.07714343070983887, 0.03655114397406578, 0.011512146331369877, -0.039505742490291595, 0.0335029698908329, -0.07150936871767044] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3250/5550 val_loss:3.070542 train_time:813595ms step_avg:250.34ms x-lambda: 0.6032556295394897 lambdas: [0.018415668979287148, -0.0006152635905891657, -0.06894408911466599, -0.07331156730651855, 0.035975564271211624, 0.012556850910186768, -0.036991506814956665, 0.03318418934941292, -0.06895451247692108] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3375/5550 val_loss:3.061966 train_time:845394ms step_avg:250.49ms x-lambda: 0.6019430756568909 lambdas: [0.017776144668459892, -0.0012538863811641932, -0.06837741285562515, -0.07362214475870132, 0.034855425357818604, 0.012180943042039871, -0.03628391772508621, 0.032256558537483215, -0.06941384822130203] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3500/5550 val_loss:3.052968 train_time:877241ms step_avg:250.64ms x-lambda: 0.6022274494171143 lambdas: [0.01685693860054016, -0.0004987624706700444, -0.06568681448698044, -0.06985106319189072, 0.03240690007805824, 0.011807282455265522, -0.03655907139182091, 0.03294479474425316, -0.07106298208236694] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3625/5550 val_loss:3.044789 train_time:909046ms step_avg:250.77ms x-lambda: 0.6058887243270874 lambdas: [0.017503609880805016, -0.00029806693783029914, -0.06444042176008224, -0.06882878392934799, 0.03309086337685585, 0.011989528313279152, -0.03379983454942703, 0.03295666724443436, -0.06649874150753021] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3750/5550 val_loss:3.034743 train_time:940871ms step_avg:250.90ms x-lambda: 0.6052067279815674 lambdas: [0.01671106182038784, -0.00035314555861987174, -0.06501490622758865, -0.065412737429142, 0.03092866577208042, 0.012577605433762074, -0.034579258412122726, 0.03262903913855553, -0.0673503503203392] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:3875/5550 val_loss:3.025905 train_time:972742ms step_avg:251.03ms x-lambda: 0.6113609075546265 lambdas: [0.016515986993908882, -0.00015402732242364436, -0.06381262093782425, -0.06587167084217072, 0.03132709488272667, 0.011211514472961426, -0.03437846526503563, 0.03170592337846756, -0.0689539983868599] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4000/5550 val_loss:3.016331 train_time:1004611ms step_avg:251.15ms x-lambda: 0.614137589931488 lambdas: [0.017480207607150078, -0.0007485284004360437, -0.06233157590031624, -0.06286736577749252, 0.02948988974094391, 0.011267516762018204, -0.03491661325097084, 0.03242034092545509, -0.06786521524190903] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4125/5550 val_loss:3.007049 train_time:1036520ms step_avg:251.28ms x-lambda: 0.6185920834541321 lambdas: [0.017851825803518295, -0.0006235265755094588, -0.061782147735357285, -0.06255804747343063, 0.028453249484300613, 0.010967417620122433, -0.03203783556818962, 0.03234300762414932, -0.06705030798912048] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4250/5550 val_loss:2.998836 train_time:1068623ms step_avg:251.44ms x-lambda: 0.6216481328010559 lambdas: [0.016154080629348755, -0.000435881462180987, -0.061289530247449875, -0.061910081654787064, 0.030073434114456177, 0.011086316779255867, -0.031625889241695404, 0.03168626129627228, -0.06644134968519211] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4375/5550 val_loss:2.989612 train_time:1100739ms step_avg:251.60ms x-lambda: 0.6255253553390503 lambdas: [0.01591232232749462, -0.0009319349192082882, -0.06096076965332031, -0.062076419591903687, 0.02795987017452717, 0.009935417212545872, -0.03188658505678177, 0.03148442879319191, -0.06752923130989075] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4500/5550 val_loss:2.981644 train_time:1132929ms step_avg:251.76ms x-lambda: 0.6314675211906433 lambdas: [0.01622905395925045, -0.0013650556793436408, -0.0603313148021698, -0.0597674660384655, 0.02706266939640045, 0.009941989555954933, -0.03190859779715538, 0.030252212658524513, -0.06785392761230469] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4625/5550 val_loss:2.972023 train_time:1165232ms step_avg:251.94ms x-lambda: 0.6390523314476013 lambdas: [0.015665296465158463, -0.001020733150653541, -0.059303004294633865, -0.05893800035119057, 0.02698482573032379, 0.009315771982073784, -0.03158294036984444, 0.029038874432444572, -0.06744054704904556] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4750/5550 val_loss:2.962943 train_time:1197635ms step_avg:252.13ms x-lambda: 0.6455416083335876 lambdas: [0.01665785349905491, 0.0011468675220385194, -0.059106603264808655, -0.05787911266088486, 0.02758287824690342, 0.010711472481489182, -0.0303559061139822, 0.03093278966844082, -0.06820768862962723] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:4875/5550 val_loss:2.954111 train_time:1230238ms step_avg:252.36ms x-lambda: 0.652391791343689 lambdas: [0.01576300896704197, -0.00032008366542868316, -0.05841882899403572, -0.05801438167691231, 0.02673025242984295, 0.00927135068923235, -0.02995198592543602, 0.02931537851691246, -0.06800833344459534] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5000/5550 val_loss:2.945837 train_time:1262927ms step_avg:252.59ms x-lambda: 0.6590513586997986 lambdas: [0.016131460666656494, 0.0001588747400091961, -0.05821475386619568, -0.05702842026948929, 0.02683096006512642, 0.009139024652540684, -0.029963793233036995, 0.028943324461579323, -0.06893987953662872] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5125/5550 val_loss:2.938430 train_time:1295763ms step_avg:252.83ms x-lambda: 0.6663772463798523 lambdas: [0.015473871491849422, 5.872702240594663e-05, -0.057305365800857544, -0.05717894062399864, 0.026232752948999405, 0.009573159739375114, -0.029601795598864555, 0.03012062795460224, -0.06919492781162262] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5250/5550 val_loss:2.931113 train_time:1328791ms step_avg:253.10ms x-lambda: 0.6729204654693604 lambdas: [0.015087929554283619, 0.0005174293182790279, -0.05665544793009758, -0.05711471661925316, 0.02654721401631832, 0.008887228555977345, -0.0284996647387743, 0.029601730406284332, -0.06906726211309433] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5375/5550 val_loss:2.924649 train_time:1361964ms step_avg:253.39ms x-lambda: 0.681881844997406 lambdas: [0.016103923320770264, 1.4910328900441527e-06, -0.05745916813611984, -0.05668460577726364, 0.02641291730105877, 0.009178858250379562, -0.029198603704571724, 0.02932831458747387, -0.06932777911424637] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5500/5550 val_loss:2.919813 train_time:1395388ms step_avg:253.71ms x-lambda: 0.6867717504501343 lambdas: [0.01573357544839382, -0.000295627600280568, -0.05748244747519493, -0.05585199221968651, 0.02572433277964592, 0.008486064150929451, -0.028651917353272438, 0.028549393638968468, -0.06908977031707764] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]
step:5550/5550 val_loss:2.918657 train_time:1408796ms step_avg:253.84ms x-lambda: 0.6878800988197327 lambdas: [0.015327746979892254, -0.00020401029905769974, -0.057377688586711884, -0.05593958869576454, 0.025687484070658684, 0.008769000880420208, -0.028163451701402664, 0.02845156379044056, -0.06934463232755661] skip-layers: [0, 1, 2, 3, 4, 5, 6, 7, 8]



## 8000-add-skip-multiple-9-method-random-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.13ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:125/5550 val_loss:4.261305 train_time:29259ms step_avg:234.07ms x-lambda: 1.0466328859329224 lambdas: [0.019336648285388947, 0.013891380280256271, 0.02610478363931179, 0.02896886132657528, 0.024860389530658722, 0.01941840723156929, 0.0155161302536726, 0.041732653975486755, 0.03006330318748951] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:250/5550 val_loss:3.848096 train_time:58701ms step_avg:234.80ms x-lambda: 1.089413046836853 lambdas: [-0.005438227206468582, -0.0006435078103095293, -0.0062720212154090405, -0.003179644700139761, -0.002064255066215992, -0.005117346532642841, -0.006706362124532461, 0.007780368439853191, -0.0057248505763709545] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:375/5550 val_loss:3.676643 train_time:88566ms step_avg:236.18ms x-lambda: 1.0891953706741333 lambdas: [-0.022877981886267662, -0.0117796016857028, -0.018882278352975845, -0.01634705625474453, -0.014987167902290821, -0.02119693160057068, -0.012229882180690765, -0.017204351723194122, -0.021777106449007988] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:500/5550 val_loss:3.560244 train_time:118797ms step_avg:237.59ms x-lambda: 1.0544871091842651 lambdas: [-0.029849793761968613, -0.01683506742119789, -0.026063261553645134, -0.023999424651265144, -0.02231423743069172, -0.028421549126505852, -0.01477603055536747, -0.02753383293747902, -0.03165538236498833] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:625/5550 val_loss:3.483387 train_time:149232ms step_avg:238.77ms x-lambda: 1.0105643272399902 lambdas: [-0.03071293979883194, -0.01638323813676834, -0.02898923121392727, -0.02646963857114315, -0.02581341192126274, -0.03181101009249687, -0.017534220591187477, -0.029108550399541855, -0.03618074953556061] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:750/5550 val_loss:3.429365 train_time:179967ms step_avg:239.96ms x-lambda: 0.9668291211128235 lambdas: [-0.0325341671705246, -0.017504042014479637, -0.02870974689722061, -0.027627935633063316, -0.026010992005467415, -0.030795900151133537, -0.019376488402485847, -0.02928156778216362, -0.036431748420000076] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:875/5550 val_loss:3.384329 train_time:210802ms step_avg:240.92ms x-lambda: 0.9198289513587952 lambdas: [-0.031007573008537292, -0.016960572451353073, -0.029074309393763542, -0.02751007489860058, -0.028053760528564453, -0.030170049518346786, -0.01907697319984436, -0.028890974819660187, -0.03813999891281128] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1000/5550 val_loss:3.349727 train_time:241949ms step_avg:241.95ms x-lambda: 0.8777243494987488 lambdas: [-0.03010953590273857, -0.01625608466565609, -0.027408843860030174, -0.026499534025788307, -0.02559572272002697, -0.029625561088323593, -0.018711697310209274, -0.026913434267044067, -0.03701067715883255] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1125/5550 val_loss:3.320335 train_time:273097ms step_avg:242.75ms x-lambda: 0.8412862420082092 lambdas: [-0.02991771139204502, -0.01483955793082714, -0.026665600016713142, -0.025109685957431793, -0.02653190679848194, -0.028365444391965866, -0.0184697937220335, -0.025060780346393585, -0.03492109104990959] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1250/5550 val_loss:3.297340 train_time:304349ms step_avg:243.48ms x-lambda: 0.8104503154754639 lambdas: [-0.02596266008913517, -0.012329804711043835, -0.02288876101374626, -0.021686289459466934, -0.022557590156793594, -0.025021342560648918, -0.014665864408016205, -0.021303607150912285, -0.03010871820151806] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1375/5550 val_loss:3.273408 train_time:335771ms step_avg:244.20ms x-lambda: 0.7784605026245117 lambdas: [-0.02576318569481373, -0.013767545111477375, -0.02385103702545166, -0.022345684468746185, -0.023844655603170395, -0.024751950055360794, -0.015590009279549122, -0.021482445299625397, -0.030825907364487648] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1500/5550 val_loss:3.253304 train_time:367178ms step_avg:244.79ms x-lambda: 0.7547998428344727 lambdas: [-0.02398383989930153, -0.013637898489832878, -0.021912312135100365, -0.021279985085129738, -0.022698739543557167, -0.023329248651862144, -0.014866645447909832, -0.019810756668448448, -0.028994688764214516] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1625/5550 val_loss:3.239239 train_time:398636ms step_avg:245.31ms x-lambda: 0.7296363711357117 lambdas: [-0.021817998960614204, -0.011342689394950867, -0.019964586943387985, -0.01883145049214363, -0.021283624693751335, -0.021508557721972466, -0.013911878690123558, -0.019252894446253777, -0.028144769370555878] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1750/5550 val_loss:3.223253 train_time:430079ms step_avg:245.76ms x-lambda: 0.7092832922935486 lambdas: [-0.02205624058842659, -0.010069669224321842, -0.019520966336131096, -0.018678579479455948, -0.019480012357234955, -0.0201914981007576, -0.012145401909947395, -0.017467834055423737, -0.026078619062900543] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:1875/5550 val_loss:3.207026 train_time:461583ms step_avg:246.18ms x-lambda: 0.6955058574676514 lambdas: [-0.019461914896965027, -0.009178349748253822, -0.01698056235909462, -0.01648535579442978, -0.01743503101170063, -0.018147319555282593, -0.010747452266514301, -0.015945710241794586, -0.024800142273306847] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2000/5550 val_loss:3.190411 train_time:493285ms step_avg:246.64ms x-lambda: 0.6780518889427185 lambdas: [-0.02020324021577835, -0.01027065422385931, -0.018256526440382004, -0.01620064117014408, -0.01789707876741886, -0.017631888389587402, -0.010945870541036129, -0.015558712184429169, -0.024112405255436897] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2125/5550 val_loss:3.174545 train_time:525027ms step_avg:247.07ms x-lambda: 0.6663548946380615 lambdas: [-0.019339969381690025, -0.008950791321694851, -0.017154822126030922, -0.016610128805041313, -0.018456896767020226, -0.01802440918982029, -0.012439129874110222, -0.015870042145252228, -0.024883627891540527] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2250/5550 val_loss:3.161096 train_time:556781ms step_avg:247.46ms x-lambda: 0.6571052074432373 lambdas: [-0.018291233107447624, -0.009518863633275032, -0.016832999885082245, -0.015729224309325218, -0.017478758469223976, -0.01781594008207321, -0.011107470840215683, -0.014513094909489155, -0.023184724152088165] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2375/5550 val_loss:3.148992 train_time:588524ms step_avg:247.80ms x-lambda: 0.6480755805969238 lambdas: [-0.01868746429681778, -0.010381398722529411, -0.015624888241291046, -0.016002153977751732, -0.017823657020926476, -0.018164558336138725, -0.01146775484085083, -0.015738459303975105, -0.02239513210952282] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2500/5550 val_loss:3.138256 train_time:620231ms step_avg:248.09ms x-lambda: 0.6401793956756592 lambdas: [-0.01800631359219551, -0.009391594678163528, -0.014805993065237999, -0.01538029219955206, -0.016857774928212166, -0.017055463045835495, -0.01031484268605709, -0.014619256369769573, -0.02082722634077072] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2625/5550 val_loss:3.127199 train_time:651927ms step_avg:248.35ms x-lambda: 0.6370120048522949 lambdas: [-0.016791991889476776, -0.008543962612748146, -0.014279481954872608, -0.013889682479202747, -0.016332756727933884, -0.01590089127421379, -0.010200471617281437, -0.013373760506510735, -0.021068111062049866] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2750/5550 val_loss:3.115039 train_time:683648ms step_avg:248.60ms x-lambda: 0.632038950920105 lambdas: [-0.016269758343696594, -0.008375280536711216, -0.014051385223865509, -0.013684835284948349, -0.015183241106569767, -0.015585251152515411, -0.009710007347166538, -0.013769113458693027, -0.019920922815799713] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:2875/5550 val_loss:3.105718 train_time:715384ms step_avg:248.83ms x-lambda: 0.6276841163635254 lambdas: [-0.015653107315301895, -0.008570914156734943, -0.014327059499919415, -0.013376041315495968, -0.014416900463402271, -0.014989963732659817, -0.009378577582538128, -0.012023964896798134, -0.01921444945037365] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3000/5550 val_loss:3.094493 train_time:747129ms step_avg:249.04ms x-lambda: 0.6259952187538147 lambdas: [-0.016510896384716034, -0.008191604167222977, -0.013821874745190144, -0.013487168587744236, -0.016196558251976967, -0.014921475201845169, -0.009315564297139645, -0.013134228065609932, -0.020342672243714333] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3125/5550 val_loss:3.083687 train_time:778888ms step_avg:249.24ms x-lambda: 0.6224754452705383 lambdas: [-0.01707213744521141, -0.008766871877014637, -0.013092491775751114, -0.013931718654930592, -0.016174191609025, -0.015336768701672554, -0.00930563174188137, -0.014344582334160805, -0.019693713635206223] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3250/5550 val_loss:3.072147 train_time:810641ms step_avg:249.43ms x-lambda: 0.6238057017326355 lambdas: [-0.016523053869605064, -0.008878073655068874, -0.013355554081499577, -0.014287217520177364, -0.014606906101107597, -0.01411884929984808, -0.009065287187695503, -0.013080173172056675, -0.019688783213496208] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3375/5550 val_loss:3.063806 train_time:842372ms step_avg:249.59ms x-lambda: 0.6236697435379028 lambdas: [-0.0169453714042902, -0.009511592797935009, -0.013341386802494526, -0.014032622799277306, -0.015025117434561253, -0.014105044305324554, -0.00885267835110426, -0.012888665311038494, -0.020364072173833847] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3500/5550 val_loss:3.054703 train_time:874121ms step_avg:249.75ms x-lambda: 0.6223172545433044 lambdas: [-0.01583733595907688, -0.009130345657467842, -0.012937135994434357, -0.01404603198170662, -0.014725579880177975, -0.014514205977320671, -0.009656842797994614, -0.013963105157017708, -0.019707554951310158] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3625/5550 val_loss:3.045769 train_time:905866ms step_avg:249.89ms x-lambda: 0.6250119805335999 lambdas: [-0.015057221055030823, -0.008496318943798542, -0.014098317362368107, -0.012551813386380672, -0.015281202271580696, -0.01394700538367033, -0.008461606688797474, -0.012568352743983269, -0.018511123955249786] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3750/5550 val_loss:3.035938 train_time:937599ms step_avg:250.03ms x-lambda: 0.6259498000144958 lambdas: [-0.014234574511647224, -0.008092885836958885, -0.012554467655718327, -0.012353276833891869, -0.014381663873791695, -0.013598419725894928, -0.008848456665873528, -0.011863051913678646, -0.01978587917983532] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:3875/5550 val_loss:3.027143 train_time:969397ms step_avg:250.17ms x-lambda: 0.631279706954956 lambdas: [-0.014822244644165039, -0.007989396341145039, -0.013630464673042297, -0.012456215918064117, -0.014317560009658337, -0.012678303755819798, -0.007604827173054218, -0.012200387194752693, -0.017958231270313263] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4000/5550 val_loss:3.017860 train_time:1001172ms step_avg:250.29ms x-lambda: 0.6341736912727356 lambdas: [-0.015362411737442017, -0.007604521233588457, -0.01266718003898859, -0.012268112041056156, -0.014418944716453552, -0.01408857386559248, -0.008480338379740715, -0.012309418059885502, -0.01846824400126934] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4125/5550 val_loss:3.008490 train_time:1032998ms step_avg:250.42ms x-lambda: 0.6392830610275269 lambdas: [-0.014498447999358177, -0.007532206363976002, -0.0116199292242527, -0.012299031019210815, -0.013468001037836075, -0.012145208194851875, -0.008369971066713333, -0.011308451183140278, -0.017713526263833046] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4250/5550 val_loss:3.000186 train_time:1065037ms step_avg:250.60ms x-lambda: 0.6426676511764526 lambdas: [-0.014881739392876625, -0.007557314354926348, -0.011732256039977074, -0.011476762592792511, -0.01269812323153019, -0.013592272065579891, -0.007106238976120949, -0.010881774127483368, -0.018230637535452843] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4375/5550 val_loss:2.991591 train_time:1097096ms step_avg:250.76ms x-lambda: 0.6462647914886475 lambdas: [-0.015261804684996605, -0.008247802034020424, -0.0137120820581913, -0.013055475428700447, -0.014181212522089481, -0.01349606178700924, -0.009221541695296764, -0.012407316826283932, -0.01890213042497635] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4500/5550 val_loss:2.983106 train_time:1129210ms step_avg:250.94ms x-lambda: 0.6511176228523254 lambdas: [-0.013837906531989574, -0.008641297928988934, -0.012131485156714916, -0.012332893908023834, -0.013238354586064816, -0.013174067251384258, -0.008170648477971554, -0.011816506274044514, -0.018234221264719963] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4625/5550 val_loss:2.973565 train_time:1161443ms step_avg:251.12ms x-lambda: 0.6584883332252502 lambdas: [-0.014915295876562595, -0.00790125411003828, -0.01329874899238348, -0.012983406893908978, -0.013589700683951378, -0.014189157634973526, -0.008062677457928658, -0.010668335482478142, -0.01764703169465065] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4750/5550 val_loss:2.964321 train_time:1193796ms step_avg:251.33ms x-lambda: 0.6644997596740723 lambdas: [-0.012702148407697678, -0.007726363372057676, -0.011263576336205006, -0.01122495997697115, -0.01230106595903635, -0.012989392504096031, -0.008108088746666908, -0.010327599942684174, -0.016995886340737343] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:4875/5550 val_loss:2.955315 train_time:1226323ms step_avg:251.55ms x-lambda: 0.6700668334960938 lambdas: [-0.012919636443257332, -0.007315376307815313, -0.012075233273208141, -0.011622949503362179, -0.013126240111887455, -0.013140473514795303, -0.008130905218422413, -0.011863422580063343, -0.017568008974194527] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5000/5550 val_loss:2.947171 train_time:1258958ms step_avg:251.79ms x-lambda: 0.6783835887908936 lambdas: [-0.013958869501948357, -0.0069978730753064156, -0.011658216826617718, -0.012147463858127594, -0.011565374210476875, -0.011892473325133324, -0.008588775061070919, -0.010793054476380348, -0.0178404338657856] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5125/5550 val_loss:2.939535 train_time:1291705ms step_avg:252.04ms x-lambda: 0.6857304573059082 lambdas: [-0.013068626634776592, -0.006841502618044615, -0.011899984441697598, -0.011222188360989094, -0.013035805895924568, -0.01163944136351347, -0.00784976314753294, -0.011336631141602993, -0.017460914328694344] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5250/5550 val_loss:2.932253 train_time:1324704ms step_avg:252.32ms x-lambda: 0.6920953989028931 lambdas: [-0.012500292621552944, -0.006806483492255211, -0.011991642415523529, -0.012026097625494003, -0.012475929223001003, -0.011789592914283276, -0.008526498451828957, -0.010347975417971611, -0.016899466514587402] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5375/5550 val_loss:2.925838 train_time:1357748ms step_avg:252.60ms x-lambda: 0.7003803849220276 lambdas: [-0.012733019888401031, -0.006799148395657539, -0.011507319286465645, -0.011301853694021702, -0.0127834752202034, -0.012654650956392288, -0.007791898678988218, -0.011252404190599918, -0.017215589061379433] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5500/5550 val_loss:2.921059 train_time:1391121ms step_avg:252.93ms x-lambda: 0.7058883905410767 lambdas: [-0.012912478297948837, -0.007165662944316864, -0.011538634076714516, -0.011609948240220547, -0.012962304055690765, -0.012327802367508411, -0.008297819644212723, -0.011129527352750301, -0.016920218244194984] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]
step:5550/5550 val_loss:2.919876 train_time:1404523ms step_avg:253.07ms x-lambda: 0.7070310115814209 lambdas: [-0.012931379489600658, -0.007521091029047966, -0.012107159942388535, -0.011998038738965988, -0.012828324921429157, -0.012358077801764011, -0.00805412046611309, -0.010986322537064552, -0.017240844666957855] skip-layers: [0, 4, 5, 1, 12, 9, 3, 11, 7]



## 8000-add-skip-multiple-9-method-wtb-0

step:0/5550 val_loss:10.825840 train_time:0ms step_avg:0.11ms x-lambda: 1.0 lambdas: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:125/5550 val_loss:4.253046 train_time:29276ms step_avg:234.21ms x-lambda: 1.030454158782959 lambdas: [-0.0028493304271250963, -0.03075859695672989, 0.03229386731982231, 0.022402381524443626, 0.03539027273654938, 0.05368952453136444, 0.033458411693573, 0.06873617321252823, 0.030198657885193825] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:250/5550 val_loss:3.846356 train_time:58700ms step_avg:234.80ms x-lambda: 1.0114237070083618 lambdas: [-0.051898300647735596, -0.10210561752319336, 0.01602395623922348, 0.01636294461786747, 0.0043166931718587875, 0.0598033145070076, 0.03735991194844246, 0.05659576132893562, 0.035778943449258804] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:375/5550 val_loss:3.673397 train_time:88566ms step_avg:236.18ms x-lambda: 0.991425096988678 lambdas: [-0.06057426333427429, -0.12875713407993317, 0.006935518700629473, 0.011682020500302315, -0.027878643944859505, 0.04714817926287651, 0.02867775969207287, 0.049287427216768265, 0.031683921813964844] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:500/5550 val_loss:3.557402 train_time:118765ms step_avg:237.53ms x-lambda: 0.9728990793228149 lambdas: [-0.061874598264694214, -0.1451185792684555, 0.004428008571267128, -0.0012561766197904944, -0.049869850277900696, 0.036620546132326126, 0.010175371542572975, 0.043428752571344376, 0.018109168857336044] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:625/5550 val_loss:3.480951 train_time:149160ms step_avg:238.66ms x-lambda: 0.9588374495506287 lambdas: [-0.05509260669350624, -0.1502409130334854, 0.008509080857038498, -0.010952685959637165, -0.05831924453377724, 0.036336176097393036, -0.005889588035643101, 0.04276484623551369, 0.00724077457562089] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:750/5550 val_loss:3.425789 train_time:179856ms step_avg:239.81ms x-lambda: 0.9460294246673584 lambdas: [-0.04982535541057587, -0.1523931920528412, 0.00982771348208189, -0.021060511469841003, -0.06412026286125183, 0.03312841057777405, -0.02329157665371895, 0.03982966020703316, -0.004674174357205629] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:875/5550 val_loss:3.382221 train_time:210669ms step_avg:240.76ms x-lambda: 0.9313837289810181 lambdas: [-0.04240909591317177, -0.14737407863140106, 0.010394655168056488, -0.029948152601718903, -0.06407143920660019, 0.03199262171983719, -0.038106437772512436, 0.03810204192996025, -0.01481328159570694] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1000/5550 val_loss:3.347547 train_time:241739ms step_avg:241.74ms x-lambda: 0.9187033772468567 lambdas: [-0.037156760692596436, -0.14164811372756958, 0.010448139160871506, -0.0385734997689724, -0.06343375891447067, 0.030110634863376617, -0.052586451172828674, 0.03616660460829735, -0.02407916449010372] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1125/5550 val_loss:3.318746 train_time:272883ms step_avg:242.56ms x-lambda: 0.9060949683189392 lambdas: [-0.03503405302762985, -0.13723818957805634, 0.008699463680386543, -0.047315023839473724, -0.06431867927312851, 0.02586672455072403, -0.06593606621026993, 0.03168129920959473, -0.033979181200265884] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1250/5550 val_loss:3.294486 train_time:304131ms step_avg:243.30ms x-lambda: 0.8994925022125244 lambdas: [-0.02969406545162201, -0.12938426434993744, 0.010525450110435486, -0.05094669759273529, -0.05997885391116142, 0.026693912222981453, -0.07465753704309464, 0.03202570602297783, -0.03889475762844086] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1375/5550 val_loss:3.271343 train_time:335580ms step_avg:244.06ms x-lambda: 0.8890885710716248 lambdas: [-0.02822382189333439, -0.12373749166727066, 0.008608962409198284, -0.057657599449157715, -0.06076175719499588, 0.023117119446396828, -0.08623041957616806, 0.02896731346845627, -0.04730783775448799] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1500/5550 val_loss:3.253137 train_time:367003ms step_avg:244.67ms x-lambda: 0.8817557096481323 lambdas: [-0.026319976896047592, -0.11798423528671265, 0.00825386494398117, -0.06235906854271889, -0.05868321284651756, 0.022109955549240112, -0.09534622728824615, 0.027097824960947037, -0.0536005012691021] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1625/5550 val_loss:3.237599 train_time:398498ms step_avg:245.23ms x-lambda: 0.8752347230911255 lambdas: [-0.023585917428135872, -0.11211136728525162, 0.010392478667199612, -0.06577468663454056, -0.0553169846534729, 0.020938711240887642, -0.10191456228494644, 0.0285663865506649, -0.057687122374773026] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1750/5550 val_loss:3.221648 train_time:429973ms step_avg:245.70ms x-lambda: 0.8675198554992676 lambdas: [-0.0221076812595129, -0.10588686168193817, 0.010517618618905544, -0.06977206468582153, -0.053262315690517426, 0.0207819864153862, -0.10881214588880539, 0.026751577854156494, -0.06284767389297485] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:1875/5550 val_loss:3.203257 train_time:461521ms step_avg:246.14ms x-lambda: 0.8623266220092773 lambdas: [-0.021319549530744553, -0.1030673235654831, 0.008833548054099083, -0.07360798865556717, -0.05357993021607399, 0.019108057022094727, -0.11546561121940613, 0.02497563324868679, -0.0691593810915947] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2000/5550 val_loss:3.188403 train_time:493242ms step_avg:246.62ms x-lambda: 0.8594308495521545 lambdas: [-0.019079556688666344, -0.09786970913410187, 0.008563617244362831, -0.07628487795591354, -0.04982196167111397, 0.018626000732183456, -0.11991908401250839, 0.024485062807798386, -0.07280177623033524] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2125/5550 val_loss:3.173171 train_time:525005ms step_avg:247.06ms x-lambda: 0.8566392660140991 lambdas: [-0.019090257585048676, -0.09489885717630386, 0.007962510921061039, -0.07894346863031387, -0.048874836415052414, 0.01721251755952835, -0.12489565461874008, 0.02330319583415985, -0.07716136425733566] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2250/5550 val_loss:3.159717 train_time:556774ms step_avg:247.46ms x-lambda: 0.8565746545791626 lambdas: [-0.01747271418571472, -0.09074307233095169, 0.009175445884466171, -0.08007842302322388, -0.047359492629766464, 0.017690202221274376, -0.12785111367702484, 0.023336801677942276, -0.08035821467638016] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2375/5550 val_loss:3.147687 train_time:588566ms step_avg:247.82ms x-lambda: 0.85395348072052 lambdas: [-0.01728074625134468, -0.08894198387861252, 0.006709341425448656, -0.08321218192577362, -0.04735076054930687, 0.015506269410252571, -0.13256151974201202, 0.02119489759206772, -0.08572056144475937] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2500/5550 val_loss:3.135412 train_time:620290ms step_avg:248.12ms x-lambda: 0.8543621301651001 lambdas: [-0.017083216458559036, -0.08634757995605469, 0.006944955326616764, -0.08461760729551315, -0.04570113867521286, 0.014304415322840214, -0.13445203006267548, 0.02119865082204342, -0.08831891417503357] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2625/5550 val_loss:3.124660 train_time:652029ms step_avg:248.39ms x-lambda: 0.8545960783958435 lambdas: [-0.015603365376591682, -0.08318459987640381, 0.007784316316246986, -0.0852491557598114, -0.0445706807076931, 0.014516929164528847, -0.13659654557704926, 0.02129369042813778, -0.09077408164739609] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2750/5550 val_loss:3.113823 train_time:683772ms step_avg:248.64ms x-lambda: 0.854551374912262 lambdas: [-0.015335561707615852, -0.08006242662668228, 0.006518228445202112, -0.08684521913528442, -0.04231244698166847, 0.015182209201157093, -0.14032287895679474, 0.020037630572915077, -0.09493684768676758] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:2875/5550 val_loss:3.105189 train_time:715535ms step_avg:248.88ms x-lambda: 0.8567501306533813 lambdas: [-0.014059092849493027, -0.0766359493136406, 0.00604973454028368, -0.08690735697746277, -0.041632454842329025, 0.014239512383937836, -0.14043794572353363, 0.02182956226170063, -0.09697259962558746] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3000/5550 val_loss:3.093635 train_time:747298ms step_avg:249.10ms x-lambda: 0.8573135137557983 lambdas: [-0.013594488613307476, -0.0756530612707138, 0.006338182836771011, -0.08867859840393066, -0.04138834774494171, 0.013272082433104515, -0.14307287335395813, 0.01865561306476593, -0.10112866014242172] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3125/5550 val_loss:3.083857 train_time:779093ms step_avg:249.31ms x-lambda: 0.8578831553459167 lambdas: [-0.01585119031369686, -0.07749036699533463, 0.004912407603114843, -0.09060607850551605, -0.041848938912153244, 0.01126387994736433, -0.14601464569568634, 0.018069542944431305, -0.10500513762235641] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3250/5550 val_loss:3.071084 train_time:810853ms step_avg:249.49ms x-lambda: 0.8616818189620972 lambdas: [-0.01343580987304449, -0.07400482147932053, 0.006045700516551733, -0.08924312144517899, -0.04024875536561012, 0.012061318382620811, -0.1454649269580841, 0.019762570038437843, -0.1058155819773674] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3375/5550 val_loss:3.062246 train_time:842606ms step_avg:249.66ms x-lambda: 0.8641257882118225 lambdas: [-0.013041570782661438, -0.0726967602968216, 0.004894985351711512, -0.09029407054185867, -0.039114780724048615, 0.011942214332520962, -0.14756888151168823, 0.019229687750339508, -0.10941062867641449] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3500/5550 val_loss:3.053473 train_time:874366ms step_avg:249.82ms x-lambda: 0.8671985268592834 lambdas: [-0.01310722902417183, -0.07128749787807465, 0.0038703647442162037, -0.09129997342824936, -0.0390152670443058, 0.011346421204507351, -0.14883683621883392, 0.01844724826514721, -0.11203096807003021] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3625/5550 val_loss:3.044796 train_time:906155ms step_avg:249.97ms x-lambda: 0.8717228174209595 lambdas: [-0.01257679145783186, -0.07062220573425293, 0.005108708515763283, -0.09015219658613205, -0.03799735754728317, 0.011037309654057026, -0.1489565074443817, 0.018308000639081, -0.11328457295894623] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3750/5550 val_loss:3.035394 train_time:937899ms step_avg:250.11ms x-lambda: 0.8745805025100708 lambdas: [-0.011981906369328499, -0.06871599704027176, 0.005406364798545837, -0.09166464954614639, -0.03673281520605087, 0.011920875869691372, -0.1505405455827713, 0.017763834446668625, -0.1161549836397171] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:3875/5550 val_loss:3.026698 train_time:969759ms step_avg:250.26ms x-lambda: 0.8814445734024048 lambdas: [-0.011707860045135021, -0.06775624305009842, 0.003754598554223776, -0.08998409658670425, -0.036142636090517044, 0.010548260062932968, -0.15059684216976166, 0.018752537667751312, -0.11728847026824951] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4000/5550 val_loss:3.017356 train_time:1001552ms step_avg:250.39ms x-lambda: 0.8851758241653442 lambdas: [-0.011756706051528454, -0.06752113997936249, 0.003926166333258152, -0.09163793921470642, -0.03732505068182945, 0.009460516273975372, -0.15181703865528107, 0.01779348962008953, -0.1211148351430893] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4125/5550 val_loss:3.007912 train_time:1033397ms step_avg:250.52ms x-lambda: 0.8904534578323364 lambdas: [-0.011188240721821785, -0.06496146321296692, 0.004569151904433966, -0.09146851301193237, -0.035949818789958954, 0.010376245714724064, -0.1516648381948471, 0.019320862367749214, -0.12263450026512146] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4250/5550 val_loss:2.999673 train_time:1065438ms step_avg:250.69ms x-lambda: 0.8957036733627319 lambdas: [-0.010496046394109726, -0.06488891690969467, 0.004201794508844614, -0.09078443050384521, -0.03526007756590843, 0.011920998804271221, -0.15265341103076935, 0.018156934529542923, -0.12438872456550598] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4375/5550 val_loss:2.990509 train_time:1097538ms step_avg:250.87ms x-lambda: 0.9001943469047546 lambdas: [-0.011120615527033806, -0.06575547158718109, 0.0021921314764767885, -0.0918765440583229, -0.0354800783097744, 0.009681877680122852, -0.15414103865623474, 0.017992770299315453, -0.12769734859466553] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4500/5550 val_loss:2.982402 train_time:1129676ms step_avg:251.04ms x-lambda: 0.9063114523887634 lambdas: [-0.011244647204875946, -0.06507855653762817, 0.0024809499736875296, -0.09191157668828964, -0.034833189100027084, 0.010146203450858593, -0.15460845828056335, 0.01753523387014866, -0.12961328029632568] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4625/5550 val_loss:2.972892 train_time:1161940ms step_avg:251.23ms x-lambda: 0.9134896397590637 lambdas: [-0.011041872203350067, -0.06324303895235062, 0.002169795334339142, -0.09027276188135147, -0.033860694617033005, 0.010389312170445919, -0.15460792183876038, 0.017667239531874657, -0.13004092872142792] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4750/5550 val_loss:2.963624 train_time:1194322ms step_avg:251.44ms x-lambda: 0.919941246509552 lambdas: [-0.010435177013278008, -0.06262149661779404, 0.00365225737914443, -0.09036947786808014, -0.034551165997982025, 0.009763986803591251, -0.155343696475029, 0.01867217943072319, -0.13170260190963745] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:4875/5550 val_loss:2.954736 train_time:1226874ms step_avg:251.67ms x-lambda: 0.9264193177223206 lambdas: [-0.010587044060230255, -0.06235814094543457, 0.001827365136705339, -0.09063446521759033, -0.03456272557377815, 0.009476461447775364, -0.15587888658046722, 0.018048768863081932, -0.13283909857273102] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5000/5550 val_loss:2.946661 train_time:1259536ms step_avg:251.91ms x-lambda: 0.9333608150482178 lambdas: [-0.010536447167396545, -0.0621437132358551, 0.0017845649272203445, -0.0907159373164177, -0.03353247046470642, 0.008492045104503632, -0.15619860589504242, 0.017732050269842148, -0.13434462249279022] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5125/5550 val_loss:2.939036 train_time:1292302ms step_avg:252.16ms x-lambda: 0.9388833045959473 lambdas: [-0.009652203880250454, -0.06156665086746216, 0.002312525874003768, -0.09085895121097565, -0.03344864398241043, 0.009182563982903957, -0.15579158067703247, 0.017965752631425858, -0.13558809459209442] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5250/5550 val_loss:2.931915 train_time:1325278ms step_avg:252.43ms x-lambda: 0.9441965222358704 lambdas: [-0.009867248125374317, -0.06031494587659836, 0.0019100219942629337, -0.09095381945371628, -0.032910242676734924, 0.009443307295441628, -0.15600687265396118, 0.017110180109739304, -0.136864572763443] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5375/5550 val_loss:2.925498 train_time:1358365ms step_avg:252.72ms x-lambda: 0.9514062404632568 lambdas: [-0.01035210769623518, -0.06123899295926094, 0.0011595494579523802, -0.09016504138708115, -0.03301868215203285, 0.008296647109091282, -0.1562274694442749, 0.017947908490896225, -0.13722263276576996] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5500/5550 val_loss:2.920722 train_time:1391725ms step_avg:253.04ms x-lambda: 0.9540225267410278 lambdas: [-0.010366044007241726, -0.06124219670891762, 0.001050849910825491, -0.09039109945297241, -0.03260289877653122, 0.00839141197502613, -0.156654953956604, 0.01727064698934555, -0.13781540095806122] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
step:5550/5550 val_loss:2.919546 train_time:1405160ms step_avg:253.18ms x-lambda: 0.95512455701828 lambdas: [-0.010090642608702183, -0.061397772282361984, 0.0006763217388652265, -0.09014677256345749, -0.032435085624456406, 0.00843768659979105, -0.15654844045639038, 0.01724417693912983, -0.13780254125595093] skip-layers: [1, 2, 7, 14, 6, 5, 12, 0, 13]
